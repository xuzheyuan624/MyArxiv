{"2023-01-31T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.13868v1","updated":"2023-01-31T18:59:22Z","published":"2023-01-31T18:59:22Z","title":"PADL: Language-Directed Physics-Based Character Control","summary":"  Developing systems that can synthesize natural and life-like motions for\nsimulated characters has long been a focus for computer animation. But in order\nfor these systems to be useful for downstream applications, they need not only\nproduce high-quality motions, but must also provide an accessible and versatile\ninterface through which users can direct a character's behaviors. Natural\nlanguage provides a simple-to-use and expressive medium for specifying a user's\nintent. Recent breakthroughs in natural language processing (NLP) have\ndemonstrated effective use of language-based interfaces for applications such\nas image generation and program synthesis. In this work, we present PADL, which\nleverages recent innovations in NLP in order to take steps towards developing\nlanguage-directed controllers for physics-based character animation. PADL\nallows users to issue natural language commands for specifying both high-level\ntasks and low-level skills that a character should perform. We present an\nadversarial imitation learning approach for training policies to map high-level\nlanguage commands to low-level controls that enable a character to perform the\ndesired task and skill specified by a user's commands. Furthermore, we propose\na multi-task aggregation method that leverages a language-based multiple-choice\nquestion-answering approach to determine high-level task objectives from\nlanguage commands. We show that our framework can be applied to effectively\ndirect a simulated humanoid character to perform a diverse array of complex\nmotor skills.\n","authors":["Jordan Juravsky","Yunrong Guo","Sanja Fidler","Xue Bin Peng"],"pdf_url":"https://arxiv.org/pdf/2301.13868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13867v1","updated":"2023-01-31T18:59:03Z","published":"2023-01-31T18:59:03Z","title":"Mathematical Capabilities of ChatGPT","summary":"  We investigate the mathematical capabilities of ChatGPT by testing it on\npublicly available datasets, as well as hand-crafted ones, and measuring its\nperformance against other models trained on a mathematical corpus, such as\nMinerva. We also test whether ChatGPT can be a useful assistant to professional\nmathematicians by emulating various use cases that come up in the daily\nprofessional activities of mathematicians (question answering, theorem\nsearching). In contrast to formal mathematics, where large databases of formal\nproofs are available (e.g., the Lean Mathematical Library), current datasets of\nnatural-language mathematics, used to benchmark language models, only cover\nelementary mathematics. We address this issue by introducing a new dataset:\nGHOSTS. It is the first natural-language dataset made and curated by working\nresearchers in mathematics that (1) aims to cover graduate-level mathematics\nand (2) provides a holistic overview of the mathematical capabilities of\nlanguage models. We benchmark ChatGPT on GHOSTS and evaluate performance\nagainst fine-grained criteria. We make this new dataset publicly available to\nassist a community-driven comparison of ChatGPT with (future) large language\nmodels in terms of advanced mathematical comprehension. We conclude that\ncontrary to many positive reports in the media (a potential case of selection\nbias), ChatGPT's mathematical abilities are significantly below those of an\naverage mathematics graduate student. Our results show that ChatGPT often\nunderstands the question but fails to provide correct solutions. Hence, if your\ngoal is to use it to pass a university exam, you would be better off copying\nfrom your average peer!\n","authors":["Simon Frieder","Luca Pinchetti","Ryan-Rhys Griffiths","Tommaso Salvatori","Thomas Lukasiewicz","Philipp Christian Petersen","Alexis Chevalier","Julius Berner"],"pdf_url":"https://arxiv.org/pdf/2301.13867v1.pdf","comment":"The GHOSTS dataset will be available at\n  https://github.com/friederrr/science-GHOSTS"},{"id":"http://arxiv.org/abs/2301.13848v1","updated":"2023-01-31T18:46:19Z","published":"2023-01-31T18:46:19Z","title":"Benchmarking Large Language Models for News Summarization","summary":"  Large language models (LLMs) have shown promise for automatic summarization\nbut the reasons behind their successes are poorly understood. By conducting a\nhuman evaluation on ten LLMs across different pretraining methods, prompts, and\nmodel scales, we make two important observations. First, we find instruction\ntuning, and not model size, is the key to the LLM's zero-shot summarization\ncapability. Second, existing studies have been limited by low-quality\nreferences, leading to underestimates of human performance and lower few-shot\nand finetuning performance. To better evaluate LLMs, we perform human\nevaluation over high-quality summaries we collect from freelance writers.\nDespite major stylistic differences such as the amount of paraphrasing, we find\nthat LMM summaries are judged to be on par with human written summaries.\n","authors":["Tianyi Zhang","Faisal Ladhak","Esin Durmus","Percy Liang","Kathleen McKeown","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2301.13848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13844v1","updated":"2023-01-31T18:40:46Z","published":"2023-01-31T18:40:46Z","title":"Do Multi-Document Summarization Models Synthesize?","summary":"  Multi-document summarization entails producing concise synopses of\ncollections of inputs. For some applications, the synopsis should accurately\n\\emph{synthesize} inputs with respect to a key property or aspect. For example,\na synopsis of film reviews all written about a particular movie should reflect\nthe average critic consensus. As a more consequential example, consider\nnarrative summaries that accompany biomedical \\emph{systematic reviews} of\nclinical trial results. These narratives should fairly summarize the\npotentially conflicting results from individual trials.\n  In this paper we ask: To what extent do modern multi-document summarization\nmodels implicitly perform this type of synthesis? To assess this we perform a\nsuite of experiments that probe the degree to which conditional generation\nmodels trained for summarization using standard methods yield outputs that\nappropriately synthesize inputs. We find that existing models do partially\nperform synthesis, but do so imperfectly. In particular, they are\nover-sensitive to changes in input ordering and under-sensitive to changes in\ninput compositions (e.g., the ratio of positive to negative movie reviews). We\npropose a simple, general method for improving model synthesis capabilities by\ngenerating an explicitly diverse set of candidate outputs, and then selecting\nfrom these the string best aligned with the expected aggregate measure for the\ninputs, or \\emph{abstaining} when the model produces no good candidate. This\napproach improves model synthesis performance. We hope highlighting the need\nfor synthesis (in some summarization settings), motivates further research into\nmulti-document summarization methods and learning objectives that explicitly\naccount for the need to synthesize.\n","authors":["Jay DeYoung","Stephanie C. Martinez","Iain J. Marshall","Byron C. Wallace"],"pdf_url":"https://arxiv.org/pdf/2301.13844v1.pdf","comment":"22 Pages, 13 Figures, 22 Tables. ACL Formatted paper; expanded\n  version of rejected ICLR submisssion\n  https://openreview.net/forum?id=1PTeB4MWCfU Paper de-anonymized ahead of ICLR\n  de-anonymization due to ACL policies/additional conference submission"},{"id":"http://arxiv.org/abs/2301.13823v1","updated":"2023-01-31T18:33:44Z","published":"2023-01-31T18:33:44Z","title":"Grounding Language Models to Images for Multimodal Generation","summary":"  We propose an efficient method to ground pretrained text-only language models\nto the visual domain, enabling them to process and generate arbitrarily\ninterleaved image-and-text data. Our method leverages the abilities of language\nmodels learnt from large scale text-only pretraining, such as in-context\nlearning and free-form text generation. We keep the language model frozen, and\nfinetune input and output linear layers to enable cross-modality interactions.\nThis allows our model to process arbitrarily interleaved image-and-text inputs,\nand generate free-form text interleaved with retrieved images. We achieve\nstrong zero-shot performance on grounded tasks such as contextual image\nretrieval and multimodal dialogue, and showcase compelling interactive\nabilities. Our approach works with any off-the-shelf language model and paves\nthe way towards an effective, general solution for leveraging pretrained\nlanguage models in visually grounded settings.\n","authors":["Jing Yu Koh","Ruslan Salakhutdinov","Daniel Fried"],"pdf_url":"https://arxiv.org/pdf/2301.13823v1.pdf","comment":"Project page: https://jykoh.com/fromage"},{"id":"http://arxiv.org/abs/2301.13826v1","updated":"2023-01-31T18:10:38Z","published":"2023-01-31T18:10:38Z","title":"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image\n  Diffusion Models","summary":"  Recent text-to-image generative models have demonstrated an unparalleled\nability to generate diverse and creative imagery guided by a target text\nprompt. While revolutionary, current state-of-the-art diffusion models may\nstill fail in generating images that fully convey the semantics in the given\ntext prompt. We analyze the publicly available Stable Diffusion model and\nassess the existence of catastrophic neglect, where the model fails to generate\none or more of the subjects from the input prompt. Moreover, we find that in\nsome cases the model also fails to correctly bind attributes (e.g., colors) to\ntheir corresponding subjects. To help mitigate these failure cases, we\nintroduce the concept of Generative Semantic Nursing (GSN), where we seek to\nintervene in the generative process on the fly during inference time to improve\nthe faithfulness of the generated images. Using an attention-based formulation\nof GSN, dubbed Attend-and-Excite, we guide the model to refine the\ncross-attention units to attend to all subject tokens in the text prompt and\nstrengthen - or excite - their activations, encouraging the model to generate\nall subjects described in the text prompt. We compare our approach to\nalternative approaches and demonstrate that it conveys the desired concepts\nmore faithfully across a range of text prompts.\n","authors":["Hila Chefer","Yuval Alaluf","Yael Vinker","Lior Wolf","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2301.13826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13816v1","updated":"2023-01-31T18:02:26Z","published":"2023-01-31T18:02:26Z","title":"Execution-based Code Generation using Deep Reinforcement Learning","summary":"  The utilization of programming language (PL) models, pretrained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting specific sequence-level\nfeatures of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that combines pretrained PL\nmodels with Proximal Policy Optimization (PPO) deep reinforcement learning and\nemploys execution feedback as the external source of knowledge into the model\noptimization. PPOCoder is transferable across different code generation tasks\nand PLs. Extensive experiments on three code generation tasks demonstrate the\neffectiveness of our proposed approach compared to SOTA methods, improving the\nsuccess rate of compilation and functional correctness over different PLs. Our\ncode can be found at https://github.com/reddy-lab-code-research/PPOCoder .\n","authors":["Parshin Shojaee","Aneesh Jain","Sindhu Tipirneni","Chandan K. Reddy"],"pdf_url":"https://arxiv.org/pdf/2301.13816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13808v1","updated":"2023-01-31T17:51:45Z","published":"2023-01-31T17:51:45Z","title":"Large Language Models are Versatile Decomposers: Decompose Evidence and\n  Questions for Table-based Reasoning","summary":"  Table-based reasoning has shown remarkable progress in combining deep models\nwith discrete reasoning, which requires reasoning over both free-form natural\nlanguage (NL) questions and structured tabular data. However, previous\ntable-based reasoning solutions usually suffer from significant performance\ndegradation on huge evidence (tables). In addition, most existing methods\nstruggle to reason over complex questions since the required information is\nscattered in different places. To alleviate the above challenges, we exploit\nlarge language models (LLMs) as decomposers for effective table-based\nreasoning, which (i) decompose huge evidence (a huge table) into sub-evidence\n(a small table) to mitigate the interference of useless information for table\nreasoning; and (ii) decompose complex questions into simpler sub-questions for\ntext reasoning. Specifically, we first use the LLMs to break down the evidence\n(tables) involved in the current question, retaining the relevant evidence and\nexcluding the remaining irrelevant evidence from the huge table. In addition,\nwe propose a \"parsing-execution-filling\" strategy to alleviate the\nhallucination dilemma of the chain of thought by decoupling logic and numerical\ncomputation in each step. Extensive experiments show that our method can\neffectively leverage decomposed evidence and questions and outperforms the\nstrong baselines on TabFact, WikiTableQuestion, and FetaQA datasets. Notably,\nour model outperforms human performance for the first time on the TabFact\ndataset.\n","authors":["Yunhu Ye","Binyuan Hui","Min Yang","Binhua Li","Fei Huang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2301.13808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13771v1","updated":"2023-01-31T17:15:33Z","published":"2023-01-31T17:15:33Z","title":"The Touché23-ValueEval Dataset for Identifying Human Values behind\n  Arguments","summary":"  We present the Touch\\'e23-ValueEval Dataset for Identifying Human Values\nbehind Arguments. To investigate approaches for the automated detection of\nhuman values behind arguments, we collected 9324 arguments from 6 diverse\nsources, covering religious texts, political discussions, free-text arguments,\nnewspaper editorials, and online democracy platforms. Each argument was\nannotated by 3 crowdworkers for 54 values. The Touch\\'e23-ValueEval dataset\nextends the Webis-ArgValues-22. In comparison to the previous dataset, the\neffectiveness of a 1-Baseline decreases, but that of an out-of-the-box BERT\nmodel increases. Therefore, though the classification difficulty increased as\nper the label distribution, the larger dataset allows for training better\nmodels.\n","authors":["Nailia Mirzakhmedova","Johannes Kiesel","Milad Alshomary","Maximilian Heinrich","Nicolas Handke","Xiaoni Cai","Barriere Valentin","Doratossadat Dastgheib","Omid Ghahroodi","Mohammad Ali Sadraei","Ehsaneddin Asgari","Lea Kawaletz","Henning Wachsmuth","Benno Stein"],"pdf_url":"https://arxiv.org/pdf/2301.13771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.05327v5","updated":"2023-01-31T16:51:28Z","published":"2021-09-11T17:44:13Z","title":"An Objective Metric for Explainable AI: How and Why to Estimate the\n  Degree of Explainability","summary":"  Explainable AI was born as a pathway to allow humans to explore and\nunderstand the inner working of complex systems. However, establishing what is\nan explanation and objectively evaluating explainability are not trivial tasks.\nThis paper presents a new model-agnostic metric to measure the Degree of\nExplainability of information in an objective way. We exploit a specific\ntheoretical model from Ordinary Language Philosophy called the Achinstein's\nTheory of Explanations, implemented with an algorithm relying on deep language\nmodels for knowledge graph extraction and information retrieval. To understand\nwhether this metric can measure explainability, we devised a few experiments\nand user studies involving more than 190 participants, evaluating two realistic\nsystems for healthcare and finance using famous AI technology, including\nArtificial Neural Networks and TreeSHAP. The results we obtained are\nstatistically significant (with P values lower than .01), suggesting that our\nproposed metric for measuring the Degree of Explainability is robust in several\nscenarios, and it aligns with concrete expectations.\n","authors":["Francesco Sovrano","Fabio Vitali"],"pdf_url":"https://arxiv.org/pdf/2109.05327v5.pdf","comment":"24 pages, 7 figures, 6 tables, Source code available at:\n  https://github.com/Francesco-Sovrano/DoXpy"},{"id":"http://arxiv.org/abs/2012.12311v2","updated":"2023-01-31T16:42:04Z","published":"2020-12-22T19:32:52Z","title":"Video Influencers: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent elements in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using a novel \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) followed by acoustics (audio). Our interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video elements. We\neliminate several spurious and confounded relationships, and identify a smaller\nsubset of theory-based relationships. We uncover novel findings that establish\ndistinct effects for measures of shallow and deep engagement which are based on\nthe dual-system framework of human thinking. Our approach is validated using\nsimulated data, and we discuss the learnings from our findings for influencers\nand brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v2.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2301.13753v1","updated":"2023-01-31T16:41:06Z","published":"2023-01-31T16:41:06Z","title":"Dynamic Scheduled Sampling with Imitation Loss for Neural Text\n  Generation","summary":"  State-of-the-art neural text generation models are typically trained to\nmaximize the likelihood of each token in the ground-truth sequence conditioned\non the previous target tokens. However, during inference, the model needs to\nmake a prediction conditioned on the tokens generated by itself. This\ntrain-test discrepancy is referred to as exposure bias. Scheduled sampling is a\ncurriculum learning strategy that gradually exposes the model to its own\npredictions during training to mitigate this bias. Most of the proposed\napproaches design a scheduler based on training steps, which generally requires\ncareful tuning depending on the training setup. In this work, we introduce\nDynamic Scheduled Sampling with Imitation Loss (DySI), which maintains the\nschedule based solely on the training time accuracy, while enhancing the\ncurriculum learning by introducing an imitation loss, which attempts to make\nthe behavior of the decoder indistinguishable from the behavior of a\nteacher-forced decoder. DySI is universally applicable across training setups\nwith minimal tuning. Extensive experiments and analysis show that DySI not only\nachieves notable improvements on standard machine translation benchmarks, but\nalso significantly improves the robustness of other text generation models.\n","authors":["Xiang Lin","Prathyusha Jwalapuram","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2301.13753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08745v2","updated":"2023-01-31T16:39:51Z","published":"2023-01-20T08:51:36Z","title":"Is ChatGPT A Good Translator? A Preliminary Study","summary":"  This report provides a preliminary evaluation of ChatGPT for machine\ntranslation, including translation prompt, multilingual translation, and\ntranslation robustness. We adopt the prompts advised by ChatGPT to trigger its\ntranslation ability and find that the candidate prompts generally work well and\nshow minor performance differences. By evaluating on a number of benchmark test\nsets, we find that ChatGPT performs competitively with commercial translation\nproducts (e.g., Google Translate) on high-resource European languages but lags\nbehind significantly on low-resource or distant languages. For distant\nlanguages, we explore an interesting strategy named $\\mathbf{pivot~prompting}$\nthat asks ChatGPT to translate the source sentence into a high-resource pivot\nlanguage before into the target language, which improves the translation\nperformance significantly. As for the translation robustness, ChatGPT does not\nperform as well as the commercial systems on biomedical abstracts or Reddit\ncomments but is potentially a good translator for spoken language. Scripts and\ndata: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator\n","authors":["Wenxiang Jiao","Wenxuan Wang","Jen-tse Huang","Xing Wang","Zhaopeng Tu"],"pdf_url":"https://arxiv.org/pdf/2301.08745v2.pdf","comment":"6 pages; added Pivot Prompting for distant languages; added\n  limitations"},{"id":"http://arxiv.org/abs/2301.13741v1","updated":"2023-01-31T16:18:52Z","published":"2023-01-31T16:18:52Z","title":"UPop: Unified and Progressive Pruning for Compressing Vision-Language\n  Transformers","summary":"  Real-world data contains a vast amount of multimodal information, among which\nvision and language are the two most representative modalities. Moreover,\nincreasingly heavier models, e.g., Transformers, have attracted the attention\nof researchers to model compression. However, how to compress multimodal\nmodels, especially vison-language Transformers, is still under-explored. This\npaper proposes the \\textbf{U}nified and \\textbf{P}r\\textbf{o}gressive\n\\textbf{P}runing (UPop) as a universal vison-language Transformer compression\nframework, which incorporates 1) unifiedly searching multimodal subnets in a\ncontinuous optimization space from the original model, which enables automatic\nassignment of pruning ratios among compressible modalities and structures; 2)\nprogressively searching and retraining the subnet, which maintains convergence\nbetween the search and retrain to attain higher compression ratios. Experiments\non multiple generative and discriminative vision-language tasks, including\nVisual Reasoning, Image Caption, Visual Question Answer, Image-Text Retrieval,\nText-Image Retrieval, and Image Classification, demonstrate the effectiveness\nand versatility of the proposed UPop framework.\n","authors":["Dachuan Shi","Chaofan Tao","Ying Jin","Zhendong Yang","Chun Yuan","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13741v1.pdf","comment":"16 pages, 5 figures, 13 tables"},{"id":"http://arxiv.org/abs/2210.11794v2","updated":"2023-01-31T15:57:19Z","published":"2022-10-21T08:13:34Z","title":"Diffuser: Efficient Transformers with Multi-hop Attention Diffusion for\n  Long Sequences","summary":"  Efficient Transformers have been developed for long sequence modeling, due to\ntheir subquadratic memory and time complexity. Sparse Transformer is a popular\napproach to improving the efficiency of Transformers by restricting\nself-attention to locations specified by the predefined sparse patterns.\nHowever, leveraging sparsity may sacrifice expressiveness compared to\nfull-attention, when important token correlations are multiple hops away. To\ncombine advantages of both the efficiency of sparse transformer and the\nexpressiveness of full-attention Transformer, we propose \\textit{Diffuser}, a\nnew state-of-the-art efficient Transformer. Diffuser incorporates all token\ninteractions within one attention layer while maintaining low computation and\nmemory costs. The key idea is to expand the receptive field of sparse attention\nusing Attention Diffusion, which computes multi-hop token correlations based on\nall paths between corresponding disconnected tokens, besides attention among\nneighboring tokens. Theoretically, we show the expressiveness of Diffuser as a\nuniversal sequence approximator for sequence-to-sequence modeling, and\ninvestigate its ability to approximate full-attention by analyzing the graph\nexpander property from the spectral perspective. Experimentally, we investigate\nthe effectiveness of Diffuser with extensive evaluations, including language\nmodeling, image modeling, and Long Range Arena (LRA). Evaluation results show\nthat Diffuser achieves improvements by an average of 0.94% on text\nclassification tasks and 2.30% on LRA, with 1.67$\\times$ memory savings\ncompared to state-of-the-art benchmarks, which demonstrates superior\nperformance of Diffuser in both expressiveness and efficiency aspects.\n","authors":["Aosong Feng","Irene Li","Yuang Jiang","Rex Ying"],"pdf_url":"https://arxiv.org/pdf/2210.11794v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13720v1","updated":"2023-01-31T15:56:40Z","published":"2023-01-31T15:56:40Z","title":"Zero-shot cross-lingual transfer language selection using linguistic\n  similarity","summary":"  We study the selection of transfer languages for different Natural Language\nProcessing tasks, specifically sentiment analysis, named entity recognition and\ndependency parsing. In order to select an optimal transfer language, we propose\nto utilize different linguistic similarity metrics to measure the distance\nbetween languages and make the choice of transfer language based on this\ninformation instead of relying on intuition. We demonstrate that linguistic\nsimilarity correlates with cross-lingual transfer performance for all of the\nproposed tasks. We also show that there is a statistically significant\ndifference in choosing the optimal language as the transfer source instead of\nEnglish. This allows us to select a more suitable transfer language which can\nbe used to better leverage knowledge from high-resource languages in order to\nimprove the performance of language applications lacking data. For the study,\nwe used datasets from eight different languages from three language families.\n","authors":["Juuso Eronen","Michal Ptaszynski","Fumito Masui"],"pdf_url":"https://arxiv.org/pdf/2301.13720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13714v1","updated":"2023-01-31T15:46:39Z","published":"2023-01-31T15:46:39Z","title":"Recursive Neural Networks with Bottlenecks Diagnose\n  (Non-)Compositionality","summary":"  A recent line of work in NLP focuses on the (dis)ability of models to\ngeneralise compositionally for artificial languages. However, when considering\nnatural language tasks, the data involved is not strictly, or locally,\ncompositional. Quantifying the compositionality of data is a challenging task,\nwhich has been investigated primarily for short utterances. We use recursive\nneural models (Tree-LSTMs) with bottlenecks that limit the transfer of\ninformation between nodes. We illustrate that comparing data's representations\nin models with and without the bottleneck can be used to produce a\ncompositionality metric. The procedure is applied to the evaluation of\narithmetic expressions using synthetic data, and sentiment classification using\nnatural language data. We demonstrate that compression through a bottleneck\nimpacts non-compositional examples disproportionately and then use the\nbottleneck compositionality metric (BCM) to distinguish compositional from\nnon-compositional samples, yielding a compositionality ranking over a dataset.\n","authors":["Verna Dankers","Ivan Titov"],"pdf_url":"https://arxiv.org/pdf/2301.13714v1.pdf","comment":"Published in EMNLP 2023 findings; 18 pages total (9 in the main\n  paper, 3 pages of limitations and references and 6 pages with appendices)"},{"id":"http://arxiv.org/abs/2301.13688v1","updated":"2023-01-31T15:03:44Z","published":"2023-01-31T15:03:44Z","title":"The Flan Collection: Designing Data and Methods for Effective\n  Instruction Tuning","summary":"  We study the design decisions of publicly available instruction tuning\nmethods, and break down the development of Flan 2022 (Chung et al., 2022).\nThrough careful ablation studies on the Flan Collection of tasks and methods,\nwe tease apart the effect of design decisions which enable Flan-T5 to\noutperform prior work by 3-17%+ across evaluation settings. We find task\nbalancing and enrichment techniques are overlooked but critical to effective\ninstruction tuning, and in particular, training with mixed prompt settings\n(zero-shot, few-shot, and chain-of-thought) actually yields stronger (2%+)\nperformance in all settings. In further experiments, we show Flan-T5 requires\nless finetuning to converge higher and faster than T5 on single downstream\ntasks, motivating instruction-tuned models as more computationally-efficient\nstarting checkpoints for new tasks. Finally, to accelerate research on\ninstruction tuning, we make the Flan 2022 collection of datasets, templates,\nand methods publicly available at\nhttps://github.com/google-research/FLAN/tree/main/flan/v2.\n","authors":["Shayne Longpre","Le Hou","Tu Vu","Albert Webson","Hyung Won Chung","Yi Tay","Denny Zhou","Quoc V. Le","Barret Zoph","Jason Wei","Adam Roberts"],"pdf_url":"https://arxiv.org/pdf/2301.13688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13683v1","updated":"2023-01-31T15:00:56Z","published":"2023-01-31T15:00:56Z","title":"Friend-training: Learning from Models of Different but Related Tasks","summary":"  Current self-training methods such as standard self-training, co-training,\ntri-training, and others often focus on improving model performance on a single\ntask, utilizing differences in input features, model architectures, and\ntraining processes. However, many tasks in natural language processing are\nabout different but related aspects of language, and models trained for one\ntask can be great teachers for other related tasks. In this work, we propose\nfriend-training, a cross-task self-training framework, where models trained to\ndo different tasks are used in an iterative training, pseudo-labeling, and\nretraining process to help each other for better selection of pseudo-labels.\nWith two dialogue understanding tasks, conversational semantic role labeling\nand dialogue rewriting, chosen for a case study, we show that the models\ntrained with the friend-training framework achieve the best performance\ncompared to strong baselines.\n","authors":["Mian Zhang","Lifeng Jin","Linfeng Song","Haitao Mi","Xiabing Zhou","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2301.13683v1.pdf","comment":"Accepted by EACL2023"},{"id":"http://arxiv.org/abs/2301.13668v1","updated":"2023-01-31T14:37:04Z","published":"2023-01-31T14:37:04Z","title":"Automated Sentiment and Hate Speech Analysis of Facebook Data by\n  Employing Multilingual Transformer Models","summary":"  In recent years, there has been a heightened consensus within academia and in\nthe public discourse that Social Media Platforms (SMPs), amplify the spread of\nhateful and negative sentiment content. Researchers have identified how hateful\ncontent, political propaganda, and targeted messaging contributed to real-world\nharms including insurrections against democratically elected governments,\ngenocide, and breakdown of social cohesion due to heightened negative discourse\ntowards certain communities in parts of the world. To counter these issues,\nSMPs have created semi-automated systems that can help identify toxic speech.\nIn this paper we analyse the statistical distribution of hateful and negative\nsentiment contents within a representative Facebook dataset (n= 604,703)\nscrapped through 648 public Facebook pages which identify themselves as\nproponents (and followers) of far-right Hindutva actors. These pages were\nidentified manually using keyword searches on Facebook and on CrowdTangleand\nclassified as far-right Hindutva pages based on page names, page descriptions,\nand discourses shared on these pages. We employ state-of-the-art, open-source\nXLM-T multilingual transformer-based language models to perform sentiment and\nhate speech analysis of the textual contents shared on these pages over a\nperiod of 5.5 years. The result shows the statistical distributions of the\npredicted sentiment and the hate speech labels; top actors, and top page\ncategories. We further discuss the benchmark performances and limitations of\nthese pre-trained language models.\n","authors":["Ritumbra Manuvie","Saikat Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2301.13668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13631v1","updated":"2023-01-31T13:44:34Z","published":"2023-01-31T13:44:34Z","title":"TopoBERT: Plug and Play Toponym Recognition Module Harnessing Fine-tuned\n  BERT","summary":"  Extracting precise geographical information from textual contents is crucial\nin a plethora of applications. For example, during hazardous events, a robust\nand unbiased toponym extraction framework can provide an avenue to tie the\nlocation concerned to the topic discussed by news media posts and pinpoint\nhumanitarian help requests or damage reports from social media. Early studies\nhave leveraged rule-based, gazetteer-based, deep learning, and hybrid\napproaches to address this problem. However, the performance of existing tools\nis deficient in supporting operations like emergency rescue, which relies on\nfine-grained, accurate geographic information. The emerging pretrained language\nmodels can better capture the underlying characteristics of text information,\nincluding place names, offering a promising pathway to optimize toponym\nrecognition to underpin practical applications. In this paper, TopoBERT, a\ntoponym recognition module based on a one dimensional Convolutional Neural\nNetwork (CNN1D) and Bidirectional Encoder Representation from Transformers\n(BERT), is proposed and fine-tuned. Three datasets (CoNLL2003-Train,\nWikipedia3000, WNUT2017) are leveraged to tune the hyperparameters, discover\nthe best training strategy, and train the model. Another two datasets\n(CoNLL2003-Test and Harvey2017) are used to evaluate the performance. Three\ndistinguished classifiers, linear, multi-layer perceptron, and CNN1D, are\nbenchmarked to determine the optimal model architecture. TopoBERT achieves\nstate-of-the-art performance (f1-score=0.865) compared to the other five\nbaseline models and can be applied to diverse toponym recognition tasks without\nadditional training.\n","authors":["Bing Zhou","Lei Zou","Yingjie Hu","Yi Qiang"],"pdf_url":"https://arxiv.org/pdf/2301.13631v1.pdf","comment":"9 Pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.06916v2","updated":"2023-01-31T13:33:03Z","published":"2023-01-13T08:24:21Z","title":"Automated speech- and text-based classification of neuropsychiatric\n  conditions in a multidiagnostic setting","summary":"  Speech patterns have been identified as potential diagnostic markers for\nneuropsychiatric conditions. However, most studies only compare a single\nclinical group to healthy controls, whereas clinical practice often requires\ndifferentiating between multiple potential diagnoses (multiclass settings). To\naddress this, we assembled a dataset of repeated recordings from 420\nparticipants (67 with major depressive disorder, 106 with schizophrenia and 46\nwith autism, as well as matched controls), and tested the performance of a\nrange of conventional machine learning models and advanced Transformer models\non both binary and multiclass classification, based on voice and text features.\n  While binary models performed comparably to previous research (F1 scores\nbetween 0.54-0.75 for autism spectrum disorder, ASD; 0.67-0.92 for major\ndepressive disorder, MDD; and 0.71-0.83 for schizophrenia); when\ndifferentiating between multiple diagnostic groups performance decreased\nmarkedly (F1 scores between 0.35-0.44 for ASD, 0.57-0.75 for MDD, 0.15-0.66 for\nschizophrenia, and 0.38-0.52 macro F1). Combining voice and text-based models\nyielded increased performance, suggesting that they capture complementary\ndiagnostic information.\n  Our results indicate that models trained on binary classification may learn\nto rely on markers of generic differences between clinical and non-clinical\npopulations, or markers of clinical features that overlap across conditions,\nrather than identifying markers specific to individual conditions. We provide\nrecommendations for future research in the field, suggesting increased focus on\ndeveloping larger transdiagnostic datasets that include more fine-grained\nclinical features, and that can support the development of models that better\ncapture the complexity of neuropsychiatric conditions and naturalistic\ndiagnostic assessment.\n","authors":["Lasse Hansen","Roberta Rocca","Arndis Simonsen","Alberto Parola","Vibeke Bliksted","Nicolai Ladegaard","Dan Bang","Kristian Tylén","Ethan Weed","Søren Dinesen Østergaard","Riccardo Fusaroli"],"pdf_url":"https://arxiv.org/pdf/2301.06916v2.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2209.12900v3","updated":"2023-01-31T10:49:08Z","published":"2022-09-26T15:21:06Z","title":"The Efficacy of Self-Supervised Speech Models for Audio Representations","summary":"  Self-supervised learning (SSL) speech models, which can serve as powerful\nupstream models to extract meaningful speech representations, have achieved\nunprecedented success in speech representation learning. However, their\neffectiveness on non-speech datasets is relatively less explored. In this work,\nwe propose an ensemble framework, with a combination of ensemble techniques, to\nfuse SSL speech models' embeddings. Extensive experiments on speech and\nnon-speech audio datasets are conducted to investigate the representation\nabilities of our ensemble method and its single constituent model. Ablation\nstudies are carried out to evaluate the performances of different ensemble\ntechniques, such as feature averaging and concatenation. All experiments are\nconducted during NeurIPS 2021 HEAR Challenge as a standard evaluation pipeline\nprovided by competition officials. Results demonstrate SSL speech models'\nstrong abilities on various non-speech tasks, while we also note that they fail\nto deal with fine-grained music tasks, such as pitch classification and note\nonset detection. In addition, feature ensemble is shown to have great potential\non producing more holistic representations, as our proposed framework generally\nsurpasses state-of-the-art SSL speech/audio models and has superior performance\non various datasets compared with other teams in HEAR Challenge. Our code is\navailable at https://github.com/tony10101105/HEAR-2021-NeurIPS-Challenge --\nNTU-GURA.\n","authors":["Tung-Yu Wu","Chen-An Li","Tzu-Han Lin","Tsu-Yuan Hsu","Hung-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2209.12900v3.pdf","comment":"to appear in Proceedings of Machine Learning Research (PMLR): NeurIPS\n  2021 Competition Track"},{"id":"http://arxiv.org/abs/2301.11719v2","updated":"2023-01-31T09:55:23Z","published":"2023-01-27T14:05:12Z","title":"Incorporating Knowledge into Document Summarization: an Application of\n  Prefix-Tuning on GPT-2","summary":"  Despite the great development of document summarization techniques nowadays,\nfactual inconsistencies between the generated summaries and the original text\nstill occur from time to time. This paper proposes a prefix-tuning-based\napproach that uses a set of trainable continuous prefix prompt together with\ndiscrete prompts to aid model generation, which makes a significant impact on\nboth CNN/Daily Mail and XSum summaries generated using GPT-2. The improvements\non fact preservation in the generated summaries indicates the effectiveness of\nadopting this prefix-tuning-based method in knowledge-enhanced document\nsummarization, and also shows a great potential on other natural language\nprocessing tasks.\n","authors":["Chen Chen","Wei Emma Zhang","Alireza Seyed Shakeri"],"pdf_url":"https://arxiv.org/pdf/2301.11719v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.08159v3","updated":"2023-01-31T09:39:22Z","published":"2021-12-15T14:31:32Z","title":"One size does not fit all: Investigating strategies for\n  differentially-private learning across NLP tasks","summary":"  Preserving privacy in contemporary NLP models allows us to work with\nsensitive data, but unfortunately comes at a price. We know that stricter\nprivacy guarantees in differentially-private stochastic gradient descent\n(DP-SGD) generally degrade model performance. However, previous research on the\nefficiency of DP-SGD in NLP is inconclusive or even counter-intuitive. In this\nshort paper, we provide an extensive analysis of different privacy preserving\nstrategies on seven downstream datasets in five different `typical' NLP tasks\nwith varying complexity using modern neural models based on BERT and\nXtremeDistil architectures. We show that unlike standard non-private approaches\nto solving NLP tasks, where bigger is usually better, privacy-preserving\nstrategies do not exhibit a winning pattern, and each task and privacy regime\nrequires a special treatment to achieve adequate performance.\n","authors":["Manuel Senge","Timour Igamberdiev","Ivan Habernal"],"pdf_url":"https://arxiv.org/pdf/2112.08159v3.pdf","comment":"EMNLP 2022 final camera-ready version"},{"id":"http://arxiv.org/abs/2212.09412v2","updated":"2023-01-31T09:21:38Z","published":"2022-12-19T12:44:25Z","title":"Difformer: Empowering Diffusion Models on the Embedding Space for Text\n  Generation","summary":"  Diffusion models have achieved state-of-the-art synthesis quality on both\nvisual and audio tasks, and recent works further adapt them to textual data by\ndiffusing on the embedding space. In this paper, we conduct systematic studies\nand analyze the challenges between the continuous data space and the embedding\nspace which have not been carefully explored. Firstly, the data distribution is\nlearnable for embeddings, which may lead to the collapse of the loss function.\nSecondly, as the norm of embeddings varies between popular and rare words,\nadding the same noise scale will lead to sub-optimal results. In addition, we\nfind the normal level of noise causes insufficient training of the model. To\naddress the above challenges, we propose Difformer, an embedding diffusion\nmodel based on Transformer, which consists of three essential modules including\nan additional anchor loss function, a layer normalization module for\nembeddings, and a noise factor to the Gaussian noise. Experiments on two\nseminal text generation tasks including machine translation and text\nsummarization show the superiority of Difformer over compared embedding\ndiffusion baselines.\n","authors":["Zhujin Gao","Junliang Guo","Xu Tan","Yongxin Zhu","Fang Zhang","Jiang Bian","Linli Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13479v1","updated":"2023-01-31T08:58:47Z","published":"2023-01-31T08:58:47Z","title":"Archive TimeLine Summarization (ATLS): Conceptual Framework for Timeline\n  Generation over Historical Document Collections","summary":"  Archive collections are nowadays mostly available through search engines\ninterfaces, which allow a user to retrieve documents by issuing queries. The\nstudy of these collections may be, however, impaired by some aspects of search\nengines, such as the overwhelming number of documents returned or the lack of\ncontextual knowledge provided. New methods that could work independently or in\ncombination with search engines are then required to access these collections.\nIn this position paper, we propose to extend TimeLine Summarization (TLS)\nmethods on archive collections to assist in their studies. We provide an\noverview of existing TLS methods and we describe a conceptual framework for an\nArchive TimeLine Summarization (ATLS) system, which aims to generate\ninformative, readable and interpretable timelines.\n","authors":["Nicolas Gutehrlé","Antoine Doucet","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2301.13479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16285v2","updated":"2023-01-31T08:51:19Z","published":"2022-11-29T15:14:47Z","title":"Evaluating Unsupervised Text Classification: Zero-shot and\n  Similarity-based Approaches","summary":"  Text classification of unseen classes is a challenging Natural Language\nProcessing task and is mainly attempted using two different types of\napproaches. Similarity-based approaches attempt to classify instances based on\nsimilarities between text document representations and class description\nrepresentations. Zero-shot text classification approaches aim to generalize\nknowledge gained from a training task by assigning appropriate labels of\nunknown classes to text documents. Although existing studies have already\ninvestigated individual approaches to these categories, the experiments in\nliterature do not provide a consistent comparison. This paper addresses this\ngap by conducting a systematic evaluation of different similarity-based and\nzero-shot approaches for text classification of unseen classes. Different\nstate-of-the-art approaches are benchmarked on four text classification\ndatasets, including a new dataset from the medical domain. Additionally, novel\nSimCSE and SBERT-based baselines are proposed, as other baselines used in\nexisting work yield weak classification results and are easily outperformed.\nFinally, the novel similarity-based Lbl2TransformerVec approach is presented,\nwhich outperforms previous state-of-the-art approaches in unsupervised text\nclassification. Our experiments show that similarity-based approaches\nsignificantly outperform zero-shot approaches in most cases. Additionally,\nusing SimCSE or SBERT embeddings instead of simpler text representations\nincreases similarity-based classification results even further.\n","authors":["Tim Schopf","Daniel Braun","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2211.16285v2.pdf","comment":"Accepted to 6th International Conference on Natural Language\n  Processing and Information Retrieval (NLPIR '22)"},{"id":"http://arxiv.org/abs/2210.13432v2","updated":"2023-01-31T08:08:18Z","published":"2022-10-24T17:46:57Z","title":"Towards Better Few-Shot and Finetuning Performance with Forgetful Causal\n  Language Models","summary":"  Large language models (LLM) trained using the next-token-prediction\nobjective, such as GPT3 and PaLM, have revolutionized natural language\nprocessing in recent years by showing impressive zero-shot and few-shot\ncapabilities across a wide range of tasks. In this work, we propose a simple\ntechnique that significantly boosts the performance of LLMs without adding\ncomputational cost. Our key observation is that, by performing the next token\nprediction task with randomly selected past tokens masked out, we can improve\nthe quality of the learned representations for downstream language\nunderstanding tasks. We hypothesize that randomly masking past tokens prevents\nover-attending to recent tokens and encourages attention to tokens in the\ndistant past. We find that our method, Forgetful Causal Masking (FCM),\nsignificantly improves both few-shot and finetuning performance of PaLM. We\nfurther consider a simple extension, T-FCM, which introduces bidirectional\ncontext to causal language model without altering the sequence order, and\nfurther improves finetuning performance.\n","authors":["Hao Liu","Xinyang Geng","Lisa Lee","Igor Mordatch","Sergey Levine","Sharan Narang","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2210.13432v2.pdf","comment":"Added T-FCM and better FCM results"},{"id":"http://arxiv.org/abs/2301.13455v1","updated":"2023-01-31T07:31:34Z","published":"2023-01-31T07:31:34Z","title":"ZhichunRoad at Amazon KDD Cup 2022: MultiTask Pre-Training for\n  E-Commerce Product Search","summary":"  In this paper, we propose a robust multilingual model to improve the quality\nof search results. Our model not only leverage the processed class-balanced\ndataset, but also benefit from multitask pre-training that leads to more\ngeneral representations. In pre-training stage, we adopt mlm task,\nclassification task and contrastive learning task to achieve considerably\nperformance. In fine-tuning stage, we use confident learning, exponential\nmoving average method (EMA), adversarial training (FGM) and regularized dropout\nstrategy (R-Drop) to improve the model's generalization and robustness.\nMoreover, we use a multi-granular semantic unit to discover the queries and\nproducts textual metadata for enhancing the representation of the model. Our\napproach obtained competitive results and ranked top-8 in three tasks. We\nrelease the source code and pre-trained models associated with this work.\n","authors":["Xuange Cui","Wei Xiong","Songlin Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13455v1.pdf","comment":"KDD Cup Workshop @ KDD 2022"},{"id":"http://arxiv.org/abs/2301.12331v2","updated":"2023-01-31T05:30:55Z","published":"2023-01-29T02:58:01Z","title":"Time out of Mind: Generating Rate of Speech conditioned on emotion and\n  speaker","summary":"  Voice synthesis has seen significant improvements in the past decade\nresulting in highly intelligible voices. Further investigations have resulted\nin models that can produce variable speech, including conditional emotional\nexpression. The problem lies, however, in a focus on phrase-level modifications\nand prosodic vocal features. Using the CREMA-D dataset we have trained a GAN\nconditioned on emotion to generate worth lengths for a given input text. These\nword lengths are relative to neutral speech and can be provided, through speech\nsynthesis markup language (SSML) to a text-to-speech (TTS) system to generate\nmore expressive speech. Additionally, a generative model is also trained using\nimplicit maximum likelihood estimation (IMLE) and a comparative analysis with\nGANs is included. We were able to achieve better performances on objective\nmeasures for neutral speech, and better time alignment for happy speech when\ncompared to an out-of-box model. However, further investigation of subjective\nevaluation is required.\n","authors":["Navjot Kaur","Paige Tuttosi"],"pdf_url":"https://arxiv.org/pdf/2301.12331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07499v2","updated":"2023-01-31T05:01:51Z","published":"2022-10-14T03:55:36Z","title":"Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks","summary":"  Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a\ntarget sequence. The Connectionist Temporal Classification (CTC) criterion is\nwidely used in multiple seq2seq tasks. Besides predicting the target sequence,\na side product of CTC is to predict the alignment, which is the most probable\ninput-long sequence that specifies a hard aligning relationship between the\ninput and target units. As there are multiple potential aligning sequences\n(called paths) that are equally considered in CTC formulation, the choice of\nwhich path will be most probable and become the predicted alignment is always\nuncertain. In addition, it is usually observed that the alignment predicted by\nvanilla CTC will drift compared with its reference and rarely provides\npractical functionalities. Thus, the motivation of this work is to make the CTC\nalignment prediction controllable and thus equip CTC with extra\nfunctionalities. The Bayes risk CTC (BRCTC) criterion is then proposed in this\nwork, in which a customizable Bayes risk function is adopted to enforce the\ndesired characteristics of the predicted alignment. With the risk function, the\nBRCTC is a general framework to adopt some customizable preference over the\npaths in order to concentrate the posterior into a particular subset of the\npaths. In applications, we explore one particular preference which yields\nmodels with the down-sampling ability and reduced inference costs. By using\nBRCTC with another preference for early emissions, we obtain an improved\nperformance-latency trade-off for online models. Experimentally, the proposed\nBRCTC reduces the inference cost of offline models by up to 47% without\nperformance degradation and cuts down the overall latency of online systems to\nan unseen level.\n","authors":["Jinchuan Tian","Brian Yan","Jianwei Yu","Chao Weng","Dong Yu","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2210.07499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.13100v4","updated":"2023-01-31T04:55:22Z","published":"2022-02-26T09:55:54Z","title":"SemSup: Semantic Supervision for Simple and Scalable Zero-shot\n  Generalization","summary":"  Zero-shot learning is the problem of predicting instances over classes not\nseen during training. One approach to zero-shot learning is providing auxiliary\nclass information to the model. Prior work along this vein have largely used\nexpensive per-instance annotation or singular class-level descriptions, but\nper-instance descriptions are hard to scale and single class descriptions may\nnot be rich enough. Furthermore, these works have used natural-language\ndescriptions exclusively, simple bi-encoders models, and modality or\ntask-specific methods. These approaches have several limitations: text\nsupervision may not always be available or optimal and bi-encoders may only\nlearn coarse relations between inputs and class descriptions. In this work, we\npresent SemSup, a novel approach that uses (1) a scalable multiple description\nsampling method which improves performance over single descriptions, (2)\nalternative description formats such as JSON that are easy to generate and\noutperform text on certain settings, and (3) hybrid lexical-semantic similarity\nto leverage fine-grained information in class descriptions. We demonstrate the\neffectiveness of SemSup across four datasets, two modalities, and three\ngeneralization settings. For example, across text and image datasets, SemSup\nincreases unseen class generalization accuracy by 15 points on average compared\nto the closest baseline.\n","authors":["Austin W. Hanjie","Ameet Deshpande","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2202.13100v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08110v3","updated":"2023-01-31T04:29:18Z","published":"2022-08-17T06:56:32Z","title":"PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for\n  Curriculum Data Augmentation","summary":"  Curriculum Data Augmentation (CDA) improves neural models by presenting\nsynthetic data with increasing difficulties from easy to hard. However,\ntraditional CDA simply treats the ratio of word perturbation as the difficulty\nmeasure and goes through the curriculums only once. This paper presents\n\\textbf{PCC}: \\textbf{P}araphrasing with Bottom-k Sampling and \\textbf{C}yclic\nLearning for \\textbf{C}urriculum Data Augmentation, a novel CDA framework via\nparaphrasing, which exploits the textual paraphrase similarity as the\ncurriculum difficulty measure. We propose a curriculum-aware paraphrase\ngeneration module composed of three units: a paraphrase candidate generator\nwith bottom-k sampling, a filtering mechanism and a difficulty measure. We also\npropose a cyclic learning strategy that passes through the curriculums multiple\ntimes. The bottom-k sampling is proposed to generate super-hard instances for\nthe later curriculums. Experimental results on few-shot text classification as\nwell as dialogue generation indicate that PCC surpasses competitive baselines.\nHuman evaluation and extensive case studies indicate that bottom-k sampling\neffectively generates super-hard instances, and PCC significantly improves the\nbaseline dialogue agent.\n","authors":["Hongyuan Lu","Wai Lam"],"pdf_url":"https://arxiv.org/pdf/2208.08110v3.pdf","comment":"Accepted to EACL 2023 (main)"},{"id":"http://arxiv.org/abs/2301.11004v3","updated":"2023-01-31T03:22:52Z","published":"2023-01-26T09:26:01Z","title":"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental\n  Health on Social Media","summary":"  Interactions among humans on social media often convey intentions behind\ntheir actions, yielding a psychological language resource for Mental Health\nAnalysis (MHA) of online users. The success of Computational Intelligence\nTechniques (CIT) for inferring mental illness from such social media resources\npoints to NLP as a lens for causal analysis and perception mining. However, we\nargue that more consequential and explainable research is required for optimal\nimpact on clinical psychology practice and personalized mental healthcare. To\nbridge this gap, we posit two significant dimensions: (1) Causal analysis to\nillustrate a cause and effect relationship in the user generated text; (2)\nPerception mining to infer psychological perspectives of social effects on\nonline users intentions. Within the scope of Natural Language Processing (NLP),\nwe further explore critical areas of inquiry associated with these two\ndimensions, specifically through recent advancements in discourse analysis.\nThis position paper guides the community to explore solutions in this space and\nadvance the state of practice in developing conversational agents for inferring\nmental health from social media. We advocate for a more explainable approach\ntoward modeling computational psychology problems through the lens of language\nas we observe an increased number of research contributions in dataset and\nproblem formulation for causal relation extraction and perception enhancements\nwhile inferring mental states.\n","authors":["Muskan Garg","Chandni Saxena","Usman Naseem","Bonnie J Dorr"],"pdf_url":"https://arxiv.org/pdf/2301.11004v3.pdf","comment":"Will revise the work"},{"id":"http://arxiv.org/abs/2301.13382v1","updated":"2023-01-31T03:14:57Z","published":"2023-01-31T03:14:57Z","title":"Numeracy from Literacy: Data Science as an Emergent Skill from Large\n  Language Models","summary":"  Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique\ntestbeds for exploring the translation challenges of turning literacy into\nnumeracy. Previous publicly-available transformer models from eighteen months\nprior and 1000 times smaller failed to provide basic arithmetic. The\nstatistical analysis of four complex datasets described here combines\narithmetic manipulations that cannot be memorized or encoded by simple rules.\nThe work examines whether next-token prediction succeeds from sentence\ncompletion into the realm of actual numerical understanding. For example, the\nwork highlights cases for descriptive statistics on in-memory datasets that the\nLLM initially loads from memory or generates randomly using python libraries.\nThe resulting exploratory data analysis showcases the model's capabilities to\ngroup by or pivot categorical sums, infer feature importance, derive\ncorrelations, and predict unseen test cases using linear regression. To extend\nthe model's testable range, the research deletes and appends random rows such\nthat recall alone cannot explain emergent numeracy.\n","authors":["David Noever","Forrest McKee"],"pdf_url":"https://arxiv.org/pdf/2301.13382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13379v1","updated":"2023-01-31T03:04:26Z","published":"2023-01-31T03:04:26Z","title":"Faithful Chain-of-Thought Reasoning","summary":"  While Chain-of-Thought (CoT) prompting boosts Language Models' (LM)\nperformance on a gamut of complex reasoning tasks, the generated reasoning\nchain does not necessarily reflect how the model arrives at the answer (aka.\nfaithfulness). We propose Faithful CoT, a faithful-by-construction framework\nthat decomposes a reasoning task into two stages: Translation (Natural Language\nquery $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning\nchain $\\rightarrow$ answer), using an LM and a deterministic solver\nrespectively. We demonstrate the efficacy of our approach on 10 reasoning\ndatasets from 4 diverse domains. It outperforms traditional CoT prompting on 9\nout of the 10 datasets, with an average accuracy gain of 4.4 on Math Word\nProblems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1\non Logical Inference, under greedy decoding. Together with self-consistency\ndecoding, we achieve new state-of-the-art few-shot performance on 7 out of the\n10 datasets, showing a strong synergy between faithfulness and accuracy.\n","authors":["Qing Lyu","Shreya Havaldar","Adam Stein","Li Zhang","Delip Rao","Eric Wong","Marianna Apidianaki","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2301.13379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13372v1","updated":"2023-01-31T02:31:42Z","published":"2023-01-31T02:31:42Z","title":"Improving Open-Domain Dialogue Evaluation with a Causal Inference Model","summary":"  Effective evaluation methods remain a significant challenge for research on\nopen-domain conversational dialogue systems. Explicit satisfaction ratings can\nbe elicited from users, but users often do not provide ratings when asked, and\nthose they give can be highly subjective. Post-hoc ratings by experts are an\nalternative, but these can be both expensive and complex to collect. Here, we\nexplore the creation of automated methods for predicting both expert and user\nratings of open-domain dialogues. We compare four different approaches. First,\nwe train a baseline model using an end-to-end transformer to predict ratings\ndirectly from the raw dialogue text. The other three methods are variants of a\ntwo-stage approach in which we first extract interpretable features at the turn\nlevel that capture, among other aspects, user dialogue behaviors indicating\ncontradiction, repetition, disinterest, compliments, or criticism. We project\nthese features to the dialogue level and train a dialogue-level MLP regression\nmodel, a dialogue-level LSTM, and a novel causal inference model called\ncounterfactual-LSTM (CF-LSTM) to predict ratings. The proposed CF-LSTM is a\nsequential model over turn-level features which predicts ratings using multiple\nregressors depending on hypotheses derived from the turn-level features. As a\ncausal inference model, CF-LSTM aims to learn the underlying causes of a\nspecific event, such as a low rating. We also bin the user ratings and perform\nclassification experiments with all four models. In evaluation experiments on\nconversational data from the Alexa Prize SocialBot, we show that the CF-LSTM\nachieves the best performance for predicting dialogue ratings and\nclassification.\n","authors":["Cat P. Le","Luke Dai","Michael Johnston","Yang Liu","Marilyn Walker","Reza Ghanadan"],"pdf_url":"https://arxiv.org/pdf/2301.13372v1.pdf","comment":"Accepted as a conference paper at IWSDS 2023"},{"id":"http://arxiv.org/abs/2112.06295v3","updated":"2023-01-31T02:03:39Z","published":"2021-12-12T18:38:27Z","title":"Towards More Efficient Insertion Transformer with Fractional Positional\n  Encoding","summary":"  Auto-regressive neural sequence models have been shown to be effective across\ntext generation tasks. However, their left-to-right decoding order prevents\ngeneration from being parallelized. Insertion Transformer (Stern et al., 2019)\nis an attractive alternative that allows outputting multiple tokens in a single\ngeneration step. Nevertheless, due to the incompatibility between absolute\npositional encoding and insertion-based generation schemes, it needs to refresh\nthe encoding of every token in the generated partial hypothesis at each step,\nwhich could be costly. We design a novel reusable positional encoding scheme\nfor Insertion Transformers called Fractional Positional Encoding (FPE), which\nallows reusing representations calculated in previous steps. Empirical studies\non various text generation tasks demonstrate the effectiveness of FPE, which\nleads to floating-point operation reduction and latency improvements on batched\ndecoding.\n","authors":["Zhisong Zhang","Yizhe Zhang","Bill Dolan"],"pdf_url":"https://arxiv.org/pdf/2112.06295v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13352v1","updated":"2023-01-31T01:03:07Z","published":"2023-01-31T01:03:07Z","title":"Sentence Identification with BOS and EOS Label Combinations","summary":"  The sentence is a fundamental unit in many NLP applications. Sentence\nsegmentation is widely used as the first preprocessing task, where an input\ntext is split into consecutive sentences considering the end of the sentence\n(EOS) as their boundaries. This task formulation relies on a strong assumption\nthat the input text consists only of sentences, or what we call the sentential\nunits (SUs). However, real-world texts often contain non-sentential units\n(NSUs) such as metadata, sentence fragments, nonlinguistic markers, etc. which\nare unreasonable or undesirable to be treated as a part of an SU. To tackle\nthis issue, we formulate a novel task of sentence identification, where the\ngoal is to identify SUs while excluding NSUs in a given text. To conduct\nsentence identification, we propose a simple yet effective method which\ncombines the beginning of the sentence (BOS) and EOS labels to determine the\nmost probable SUs and NSUs based on dynamic programming. To evaluate this task,\nwe design an automatic, language-independent procedure to convert the Universal\nDependencies corpora into sentence identification benchmarks. Finally, our\nexperiments on the sentence identification task demonstrate that our proposed\nmethod generally outperforms sentence segmentation baselines which only utilize\nEOS labels.\n","authors":["Takuma Udagawa","Hiroshi Kanayama","Issei Yoshida"],"pdf_url":"https://arxiv.org/pdf/2301.13352v1.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2301.13345v1","updated":"2023-01-31T00:31:11Z","published":"2023-01-31T00:31:11Z","title":"Differentiable Entailment for Parameter Efficient Few Shot Learning","summary":"  Few-shot learning allows pre-trained language models to adapt to downstream\ntasks while using a limited number of training examples. However, practical\napplications are limited when all model parameters must be optimized. In this\nwork we apply a new technique for parameter efficient few shot learning while\nadopting a strict definition of parameter efficiency. Our training method\ncombines 1) intermediate training by reformulating natural language tasks as\nentailment tasks \\cite{wang_entailment_2021} and 2) differentiable optimization\nof template and label tokens \\cite{zhang_differentiable_2021}. We quantify the\ntradeoff between parameter efficiency and performance in the few-shot regime\nand propose a simple model agnostic approach that can be extended to any task\nBy achieving competitive performance while only optimizing 3\\% of a model's\nparameters and allowing for batched inference, we allow for more efficient\npractical deployment of models.\n","authors":["Ethan Kim","Jerry Yang"],"pdf_url":"https://arxiv.org/pdf/2301.13345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01989v2","updated":"2023-01-31T22:54:32Z","published":"2022-10-05T02:37:59Z","title":"WISE: Wavelet Transformation for Boosting Transformers' Long Sequence\n  Learning Ability","summary":"  Transformer and its variants are fundamental neural architectures in deep\nlearning. Recent works show that learning attention in the Fourier space can\nimprove the long sequence learning capability of Transformers. We argue that\nwavelet transform shall be a better choice because it captures both position\nand frequency information with a linear time complexity. Therefore, in this\npaper, we systematically study the synergy between wavelet transform and\nTransformers. Specifically, we focus on a new paradigm WISE, which replaces the\nattention in Transformers by (1) applying forward wavelet transform to project\nthe input sequences to multi-resolution bases, (2) conducting non-linear\ntransformations in the wavelet coefficient space, and (3) reconstructing the\nrepresentation in input space via backward wavelet transform. Extensive\nexperiments on the Long Range Arena benchmark demonstrate that learning\nattention in the wavelet space using either fixed or adaptive wavelets can\nconsistently improve Transformer's performance and also significantly\noutperform Fourier-based methods.\n","authors":["Yufan Zhuang","Zihan Wang","Fangbo Tao","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2210.01989v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00129v1","updated":"2023-01-31T22:35:11Z","published":"2023-01-31T22:35:11Z","title":"Universal Topological Regularities of Syntactic Structures: Decoupling\n  Efficiency from Optimization","summary":"  Human syntactic structures are usually represented as graphs. Much research\nhas focused on the mapping between such graphs and linguistic sequences, but\nless attention has been paid to the shapes of the graphs themselves: their\ntopologies. This study investigates how the topologies of syntactic graphs\nreveal traces of the processes that led to their emergence. I report a new\nuniversal regularity in syntactic structures: Their topology is communicatively\nefficient above chance. The pattern holds, without exception, for all 124\nlanguages studied, across linguistic families and modalities (spoken, written,\nand signed). This pattern can arise from a process optimizing for communicative\nefficiency or, alternatively, by construction, as a by-effect of a sublinear\npreferential attachment process reflecting language production mechanisms known\nfrom psycholinguistics. This dual explanation shows how communicative\nefficiency, per se, does not require optimization. Among the two options,\nefficiency without optimization offers the better explanation for the new\npattern.\n","authors":["Fermín Moscoso del Prado Martín"],"pdf_url":"https://arxiv.org/pdf/2302.00129v1.pdf","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.00119v1","updated":"2023-01-31T21:59:35Z","published":"2023-01-31T21:59:35Z","title":"Machine Translation Impact in E-commerce Multilingual Search","summary":"  Previous work suggests that performance of cross-lingual information\nretrieval correlates highly with the quality of Machine Translation. However,\nthere may be a threshold beyond which improving query translation quality\nyields little or no benefit to further improve the retrieval performance. This\nthreshold may depend upon multiple factors including the source and target\nlanguages, the existing MT system quality and the search pipeline. In order to\nidentify the benefit of improving an MT system for a given search pipeline, we\ninvestigate the sensitivity of retrieval quality to the presence of different\nlevels of MT quality using experimental datasets collected from actual traffic.\nWe systematically improve the performance of our MT systems quality on language\npairs as measured by MT evaluation metrics including Bleu and Chrf to determine\ntheir impact on search precision metrics and extract signals that help to guide\nthe improvement strategies. Using this information we develop techniques to\ncompare query translations for multiple language pairs and identify the most\npromising language pairs to invest and improve.\n","authors":["Bryan Zhang","Amita Misra"],"pdf_url":"https://arxiv.org/pdf/2302.00119v1.pdf","comment":"Accepted by EMNLP 2022 (Industry Track)"},{"id":"http://arxiv.org/abs/2302.00102v1","updated":"2023-01-31T21:08:58Z","published":"2023-01-31T21:08:58Z","title":"Detecting Harmful Agendas in News Articles","summary":"  Manipulated news online is a growing problem which necessitates the use of\nautomated systems to curtail its spread. We argue that while misinformation and\ndisinformation detection have been studied, there has been a lack of investment\nin the important open challenge of detecting harmful agendas in news articles;\nidentifying harmful agendas is critical to flag news campaigns with the\ngreatest potential for real world harm. Moreover, due to real concerns around\ncensorship, harmful agenda detectors must be interpretable to be effective. In\nthis work, we propose this new task and release a dataset, NewsAgendas, of\nannotated news articles for agenda identification. We show how interpretable\nsystems can be effective on this task and demonstrate that they can perform\ncomparably to black-box models.\n","authors":["Melanie Subbiah","Amrita Bhattacharjee","Bobby Yilun Hua","Tharindu Kumarage","Huan Liu","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2302.00102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00093v1","updated":"2023-01-31T20:48:57Z","published":"2023-01-31T20:48:57Z","title":"Large Language Models Can Be Easily Distracted by Irrelevant Context","summary":"  Large language models have achieved impressive performance on various natural\nlanguage processing tasks. However, so far they have been evaluated primarily\non benchmarks where all information in the input context is relevant for\nsolving the task. In this work, we investigate the distractibility of large\nlanguage models, i.e., how the model problem-solving accuracy can be influenced\nby irrelevant context. In particular, we introduce Grade-School Math with\nIrrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant\ninformation in the problem description. We use this benchmark to measure the\ndistractibility of cutting-edge prompting techniques for large language models,\nand find that the model performance is dramatically decreased when irrelevant\ninformation is included. We also identify several approaches for mitigating\nthis deficiency, such as decoding with self-consistency and adding to the\nprompt an instruction that tells the language model to ignore the irrelevant\ninformation.\n","authors":["Freda Shi","Xinyun Chen","Kanishka Misra","Nathan Scales","David Dohan","Ed Chi","Nathanael Schärli","Denny Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00083v1","updated":"2023-01-31T20:26:16Z","published":"2023-01-31T20:26:16Z","title":"In-Context Retrieval-Augmented Language Models","summary":"  Retrieval-Augmented Language Modeling (RALM) methods, that condition a\nlanguage model (LM) on relevant documents from a grounding corpus during\ngeneration, have been shown to significantly improve language modeling while\nalso providing a natural source attribution mechanism. Existing RALM approaches\nfocus on modifying the LM architecture in order to facilitate the incorporation\nof external information, significantly complicating deployment. This paper\nproposes an under-explored alternative, which we dub In-Context RALM: leaving\nthe LM architecture unchanged and prepending grounding documents to the input.\nWe show that in-context RALM which uses off-the-shelf general purpose\nretrievers provides surprisingly large LM gains across model sizes and diverse\ncorpora. We also demonstrate that the document retrieval and ranking mechanism\ncan be specialized to the RALM setting to further boost performance. We\nconclude that in-context RALM has considerable potential to increase the\nprevalence of LM grounding, particularly in settings where a pretrained LM must\nbe used without modification or even via API access. To that end, we make our\ncode publicly available.\n","authors":["Ori Ram","Yoav Levine","Itay Dalmedigos","Dor Muhlgay","Amnon Shashua","Kevin Leyton-Brown","Yoav Shoham"],"pdf_url":"https://arxiv.org/pdf/2302.00083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05613v3","updated":"2023-01-31T19:37:52Z","published":"2022-12-11T21:56:44Z","title":"A Study of Slang Representation Methods","summary":"  Considering the large amount of content created online by the minute,\nslang-aware automatic tools are critically needed to promote social good, and\nassist policymakers and moderators in restricting the spread of offensive\nlanguage, abuse, and hate speech. Despite the success of large language models\nand the spontaneous emergence of slang dictionaries, it is unclear how far\ntheir combination goes in terms of slang understanding for downstream social\ngood tasks. In this paper, we provide a framework to study different\ncombinations of representation learning models and knowledge resources for a\nvariety of downstream tasks that rely on slang understanding. Our experiments\nshow the superiority of models that have been pre-trained on social media data,\nwhile the impact of dictionaries is positive only for static word embeddings.\nOur error analysis identifies core challenges for slang representation\nlearning, including out-of-vocabulary words, polysemy, variance, and annotation\ndisagreements, which can be traced to characteristics of slang as a quickly\nevolving and highly subjective language.\n","authors":["Aravinda Kolla","Filip Ilievski","Hông-Ân Sandlin","Alain Mermoud"],"pdf_url":"https://arxiv.org/pdf/2212.05613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00003v1","updated":"2023-01-31T00:29:39Z","published":"2023-01-31T00:29:39Z","title":"The Power of External Memory in Increasing Predictive Model Capacity","summary":"  One way of introducing sparsity into deep networks is by attaching an\nexternal table of parameters that is sparsely looked up at different layers of\nthe network. By storing the bulk of the parameters in the external table, one\ncan increase the capacity of the model without necessarily increasing the\ninference time. Two crucial questions in this setting are then: what is the\nlookup function for accessing the table and how are the contents of the table\nconsumed? Prominent methods for accessing the table include 1) using\nwords/wordpieces token-ids as table indices, 2) LSH hashing the token vector in\neach layer into a table of buckets, and 3) learnable softmax style routing to a\ntable entry. The ways to consume the contents include adding/concatenating to\ninput representation, and using the contents as expert networks that specialize\nto different inputs. In this work, we conduct rigorous experimental evaluations\nof existing ideas and their combinations. We also introduce a new method,\nalternating updates, that enables access to an increased token dimension\nwithout increasing the computation time, and demonstrate its effectiveness in\nlanguage modeling.\n","authors":["Cenk Baykal","Dylan J Cutler","Nishanth Dikkala","Nikhil Ghosh","Rina Panigrahy","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00003v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2301.13310"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.13865v1","updated":"2023-01-31T18:58:41Z","published":"2023-01-31T18:58:41Z","title":"From Semi-supervised to Omni-supervised Room Layout Estimation Using\n  Point Clouds","summary":"  Room layout estimation is a long-existing robotic vision task that benefits\nboth environment sensing and motion planning. However, layout estimation using\npoint clouds (PCs) still suffers from data scarcity due to annotation\ndifficulty. As such, we address the semi-supervised setting of this task based\nupon the idea of model exponential moving averaging. But adapting this scheme\nto the state-of-the-art (SOTA) solution for PC-based layout estimation is not\nstraightforward. To this end, we define a quad set matching strategy and\nseveral consistency losses based upon metrics tailored for layout quads.\nBesides, we propose a new online pseudo-label harvesting algorithm that\ndecomposes the distribution of a hybrid distance measure between quads and PC\ninto two components. This technique does not need manual threshold selection\nand intuitively encourages quads to align with reliable layout points.\nSurprisingly, this framework also works for the fully-supervised setting,\nachieving a new SOTA on the ScanNet benchmark. Last but not least, we also push\nthe semi-supervised setting to the realistic omni-supervised setting,\ndemonstrating significantly promoted performance on a newly annotated\nARKitScenes testing set. Our codes, data and models are released in this\nrepository.\n","authors":["Huan-ang Gao","Beiwen Tian","Pengfei Li","Xiaoxue Chen","Hao Zhao","Guyue Zhou","Yurong Chen","Hongbin Zha"],"pdf_url":"https://arxiv.org/pdf/2301.13865v1.pdf","comment":"Accepted to ICRA2023. Code: https://github.com/AIR-DISCOVER/Omni-PQ"},{"id":"http://arxiv.org/abs/2301.13862v1","updated":"2023-01-31T18:56:41Z","published":"2023-01-31T18:56:41Z","title":"Salient Conditional Diffusion for Defending Against Backdoor Attacks","summary":"  We propose a novel algorithm, Salient Conditional Diffusion (Sancdifi), a\nstate-of-the-art defense against backdoor attacks. Sancdifi uses a denoising\ndiffusion probabilistic model (DDPM) to degrade an image with noise and then\nrecover said image using the learned reverse diffusion. Critically, we compute\nsaliency map-based masks to condition our diffusion, allowing for stronger\ndiffusion on the most salient pixels by the DDPM. As a result, Sancdifi is\nhighly effective at diffusing out triggers in data poisoned by backdoor\nattacks. At the same time, it reliably recovers salient features when applied\nto clean data. This performance is achieved without requiring access to the\nmodel parameters of the Trojan network, meaning Sancdifi operates as a\nblack-box defense.\n","authors":["Brandon B. May","N. Joseph Tatro","Piyush Kumar","Nathan Shnidman"],"pdf_url":"https://arxiv.org/pdf/2301.13862v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.13823v1","updated":"2023-01-31T18:33:44Z","published":"2023-01-31T18:33:44Z","title":"Grounding Language Models to Images for Multimodal Generation","summary":"  We propose an efficient method to ground pretrained text-only language models\nto the visual domain, enabling them to process and generate arbitrarily\ninterleaved image-and-text data. Our method leverages the abilities of language\nmodels learnt from large scale text-only pretraining, such as in-context\nlearning and free-form text generation. We keep the language model frozen, and\nfinetune input and output linear layers to enable cross-modality interactions.\nThis allows our model to process arbitrarily interleaved image-and-text inputs,\nand generate free-form text interleaved with retrieved images. We achieve\nstrong zero-shot performance on grounded tasks such as contextual image\nretrieval and multimodal dialogue, and showcase compelling interactive\nabilities. Our approach works with any off-the-shelf language model and paves\nthe way towards an effective, general solution for leveraging pretrained\nlanguage models in visually grounded settings.\n","authors":["Jing Yu Koh","Ruslan Salakhutdinov","Daniel Fried"],"pdf_url":"https://arxiv.org/pdf/2301.13823v1.pdf","comment":"Project page: https://jykoh.com/fromage"},{"id":"http://arxiv.org/abs/2301.13838v1","updated":"2023-01-31T18:31:20Z","published":"2023-01-31T18:31:20Z","title":"Image Shortcut Squeezing: Countering Perturbative Availability Poisons\n  with Compression","summary":"  Perturbative availability poisoning (PAP) adds small changes to images to\nprevent their use for model training. Current research adopts the belief that\npractical and effective approaches to countering such poisons do not exist. In\nthis paper, we argue that it is time to abandon this belief. We present\nextensive experiments showing that 12 state-of-the-art PAP methods are\nvulnerable to Image Shortcut Squeezing (ISS), which is based on simple\ncompression. For example, on average, ISS restores the CIFAR-10 model accuracy\nto $81.73\\%$, surpassing the previous best preprocessing-based countermeasures\nby $37.97\\%$ absolute. ISS also (slightly) outperforms adversarial training and\nhas higher generalizability to unseen perturbation norms and also higher\nefficiency. Our investigation reveals that the property of PAP perturbations\ndepends on the type of surrogate model used for poison generation, and it\nexplains why a specific ISS compression yields the best performance for a\nspecific type of PAP perturbation. We further test stronger, adaptive\npoisoning, and show it falls short of being an ideal defense against ISS.\nOverall, our results demonstrate the importance of considering various (simple)\ncountermeasures to ensure the meaningfulness of analysis carried out during the\ndevelopment of availability poisons.\n","authors":["Zhuoran Liu","Zhengyu Zhao","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2301.13838v1.pdf","comment":"Our code is available at\n  https://github.com/liuzrcc/ImageShortcutSqueezing"},{"id":"http://arxiv.org/abs/2104.03509v3","updated":"2023-01-31T18:23:30Z","published":"2021-04-08T04:52:21Z","title":"Py-Feat: Python Facial Expression Analysis Toolbox","summary":"  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n","authors":["Jin Hyun Cheong","Eshin Jolly","Tiankang Xie","Sophie Byrne","Matthew Kenny","Luke J. Chang"],"pdf_url":"https://arxiv.org/pdf/2104.03509v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13826v1","updated":"2023-01-31T18:10:38Z","published":"2023-01-31T18:10:38Z","title":"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image\n  Diffusion Models","summary":"  Recent text-to-image generative models have demonstrated an unparalleled\nability to generate diverse and creative imagery guided by a target text\nprompt. While revolutionary, current state-of-the-art diffusion models may\nstill fail in generating images that fully convey the semantics in the given\ntext prompt. We analyze the publicly available Stable Diffusion model and\nassess the existence of catastrophic neglect, where the model fails to generate\none or more of the subjects from the input prompt. Moreover, we find that in\nsome cases the model also fails to correctly bind attributes (e.g., colors) to\ntheir corresponding subjects. To help mitigate these failure cases, we\nintroduce the concept of Generative Semantic Nursing (GSN), where we seek to\nintervene in the generative process on the fly during inference time to improve\nthe faithfulness of the generated images. Using an attention-based formulation\nof GSN, dubbed Attend-and-Excite, we guide the model to refine the\ncross-attention units to attend to all subject tokens in the text prompt and\nstrengthen - or excite - their activations, encouraging the model to generate\nall subjects described in the text prompt. We compare our approach to\nalternative approaches and demonstrate that it conveys the desired concepts\nmore faithfully across a range of text prompts.\n","authors":["Hila Chefer","Yuval Alaluf","Yael Vinker","Lior Wolf","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2301.13826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13817v1","updated":"2023-01-31T18:04:35Z","published":"2023-01-31T18:04:35Z","title":"Patch Gradient Descent: Training Neural Networks on Very Large Images","summary":"  Traditional CNN models are trained and tested on relatively low resolution\nimages (<300 px), and cannot be directly operated on large-scale images due to\ncompute and memory constraints. We propose Patch Gradient Descent (PatchGD), an\neffective learning strategy that allows to train the existing CNN architectures\non large-scale images in an end-to-end manner. PatchGD is based on the\nhypothesis that instead of performing gradient-based updates on an entire image\nat once, it should be possible to achieve a good solution by performing model\nupdates on only small parts of the image at a time, ensuring that the majority\nof it is covered over the course of iterations. PatchGD thus extensively enjoys\nbetter memory and compute efficiency when training models on large scale\nimages. PatchGD is thoroughly evaluated on two datasets - PANDA and UltraMNIST\nwith ResNet50 and MobileNetV2 models under different memory constraints. Our\nevaluation clearly shows that PatchGD is much more stable and efficient than\nthe standard gradient-descent method in handling large images, and especially\nwhen the compute memory is limited.\n","authors":["Deepak K. Gupta","Gowreesh Mago","Arnav Chavan","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2301.13817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13809v1","updated":"2023-01-31T17:53:16Z","published":"2023-01-31T17:53:16Z","title":"Ultrasound Based Prosthetic Arm Control","summary":"  The loss of an upper limb can have a substantial impact on a person's quality\nof life since it limits a person's ability to work, interact, and perform daily\nduties independently. Artificial limbs are used in prosthetics to help people\nwho have lost limbs enhance their function and quality of life. Despite\nsignificant breakthroughs in prosthetic technology, rejection rates for complex\nprosthetic devices remain high[1]-[5]. A quarter to a third of upper-limb\namputees abandon their prosthetics due to a lack of comprehension of the\ntechnology. The most extensively used method for monitoring muscle activity and\nregulating the prosthetic arm, surface electromyography (sEMG), has significant\ndrawbacks, including a low signal-to-noise ratio and poor amplitude\nresolution[6]-[8].Unlike myoelectric control systems, which use electrical\nmuscle activation to calculate end-effector velocity, our strategy employs\nultrasound to directly monitor mechanical muscle deformation and then uses the\nextracted signals to proportionally control end-effector location. This\ninvestigation made use of four separate hand motions performed by three\nphysically healthy volunteers. A virtual robotic hand simulation was created\nusing ROS. After witnessing performance comparable to that of a hand with very\nless training, we concluded that our control method is reliable and natural.\n","authors":["Ayush Singh","Harikrishnan Pisharody Gopalkrishnan","Mahesh Raveendranatha Panicker"],"pdf_url":"https://arxiv.org/pdf/2301.13809v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13803v1","updated":"2023-01-31T17:44:59Z","published":"2023-01-31T17:44:59Z","title":"Fairness-aware Vision Transformer via Debiased Self-Attention","summary":"  Vision Transformer (ViT) has recently gained significant interest in solving\ncomputer vision (CV) problems due to its capability of extracting informative\nfeatures and modeling long-range dependencies through the self-attention\nmechanism. To fully realize the advantages of ViT in real-world applications,\nrecent works have explored the trustworthiness of ViT, including its robustness\nand explainability. However, another desiderata, fairness has not yet been\nadequately addressed in the literature. We establish that the existing\nfairness-aware algorithms (primarily designed for CNNs) do not perform well on\nViT. This necessitates the need for developing our novel framework via Debiased\nSelf-Attention (DSA). DSA is a fairness-through-blindness approach that\nenforces ViT to eliminate spurious features correlated with the sensitive\nattributes for bias mitigation. Notably, adversarial examples are leveraged to\nlocate and mask the spurious features in the input image patches. In addition,\nDSA utilizes an attention weights alignment regularizer in the training\nobjective to encourage learning informative features for target prediction.\nImportantly, our DSA framework leads to improved fairness guarantees over prior\nworks on multiple prediction tasks without compromising target prediction\nperformance\n","authors":["Yao Qiang","Chengyin Li","Prashant Khanduri","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.13803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13786v1","updated":"2023-01-31T17:33:35Z","published":"2023-01-31T17:33:35Z","title":"Deep learning-based lung segmentation and automatic regional template in\n  chest X-ray images for pediatric tuberculosis","summary":"  Tuberculosis (TB) is still considered a leading cause of death and a\nsubstantial threat to global child health. Both TB infection and disease are\ncurable using antibiotics. However, most children who die of TB are never\ndiagnosed or treated. In clinical practice, experienced physicians assess TB by\nexamining chest X-rays (CXR). Pediatric CXR has specific challenges compared to\nadult CXR, which makes TB diagnosis in children more difficult. Computer-aided\ndiagnosis systems supported by Artificial Intelligence have shown performance\ncomparable to experienced radiologist TB readings, which could ease mass TB\nscreening and reduce clinical burden. We propose a multi-view deep\nlearning-based solution which, by following a proposed template, aims to\nautomatically regionalize and extract lung and mediastinal regions of interest\nfrom pediatric CXR images where key TB findings may be present. Experimental\nresults have shown accurate region extraction, which can be used for further\nanalysis to confirm TB finding presence and severity assessment. Code publicly\navailable at https://github.com/dani-capellan/pTB_LungRegionExtractor.\n","authors":["Daniel Capellán-Martín","Juan J. Gómez-Valverde","Ramon Sanchez-Jacob","David Bermejo-Peláez","Lara García-Delgado","Elisa López-Varela","Maria J. Ledesma-Carbayo"],"pdf_url":"https://arxiv.org/pdf/2301.13786v1.pdf","comment":"This work has been accepted at the SPIE Medical Imaging 2023, Image\n  Processing conference"},{"id":"http://arxiv.org/abs/2012.12311v2","updated":"2023-01-31T16:42:04Z","published":"2020-12-22T19:32:52Z","title":"Video Influencers: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent elements in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using a novel \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) followed by acoustics (audio). Our interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video elements. We\neliminate several spurious and confounded relationships, and identify a smaller\nsubset of theory-based relationships. We uncover novel findings that establish\ndistinct effects for measures of shallow and deep engagement which are based on\nthe dual-system framework of human thinking. Our approach is validated using\nsimulated data, and we discuss the learnings from our findings for influencers\nand brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v2.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2301.13743v1","updated":"2023-01-31T16:24:34Z","published":"2023-01-31T16:24:34Z","title":"Zero-shot-Learning Cross-Modality Data Translation Through Mutual\n  Information Guided Stochastic Diffusion","summary":"  Cross-modality data translation has attracted great interest in image\ncomputing. Deep generative models (\\textit{e.g.}, GANs) show performance\nimprovement in tackling those problems. Nevertheless, as a fundamental\nchallenge in image translation, the problem of Zero-shot-Learning\nCross-Modality Data Translation with fidelity remains unanswered. This paper\nproposes a new unsupervised zero-shot-learning method named Mutual Information\nguided Diffusion cross-modality data translation Model (MIDiffusion), which\nlearns to translate the unseen source data to the target domain. The\nMIDiffusion leverages a score-matching-based generative model, which learns the\nprior knowledge in the target domain. We propose a differentiable\nlocal-wise-MI-Layer ($LMI$) for conditioning the iterative denoising sampling.\nThe $LMI$ captures the identical cross-modality features in the statistical\ndomain for the diffusion guidance; thus, our method does not require retraining\nwhen the source domain is changed, as it does not rely on any direct mapping\nbetween the source and target domains. This advantage is critical for applying\ncross-modality data translation methods in practice, as a reasonable amount of\nsource domain dataset is not always available for supervised training. We\nempirically show the advanced performance of MIDiffusion in comparison with an\ninfluential group of generative models, including adversarial-based and other\nscore-matching-based models.\n","authors":["Zihao Wang","Yingyu Yang","Maxime Sermesant","Hervé Delingette","Ona Wu"],"pdf_url":"https://arxiv.org/pdf/2301.13743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13741v1","updated":"2023-01-31T16:18:52Z","published":"2023-01-31T16:18:52Z","title":"UPop: Unified and Progressive Pruning for Compressing Vision-Language\n  Transformers","summary":"  Real-world data contains a vast amount of multimodal information, among which\nvision and language are the two most representative modalities. Moreover,\nincreasingly heavier models, e.g., Transformers, have attracted the attention\nof researchers to model compression. However, how to compress multimodal\nmodels, especially vison-language Transformers, is still under-explored. This\npaper proposes the \\textbf{U}nified and \\textbf{P}r\\textbf{o}gressive\n\\textbf{P}runing (UPop) as a universal vison-language Transformer compression\nframework, which incorporates 1) unifiedly searching multimodal subnets in a\ncontinuous optimization space from the original model, which enables automatic\nassignment of pruning ratios among compressible modalities and structures; 2)\nprogressively searching and retraining the subnet, which maintains convergence\nbetween the search and retrain to attain higher compression ratios. Experiments\non multiple generative and discriminative vision-language tasks, including\nVisual Reasoning, Image Caption, Visual Question Answer, Image-Text Retrieval,\nText-Image Retrieval, and Image Classification, demonstrate the effectiveness\nand versatility of the proposed UPop framework.\n","authors":["Dachuan Shi","Chaofan Tao","Ying Jin","Zhendong Yang","Chun Yuan","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13741v1.pdf","comment":"16 pages, 5 figures, 13 tables"},{"id":"http://arxiv.org/abs/2301.13731v1","updated":"2023-01-31T16:11:47Z","published":"2023-01-31T16:11:47Z","title":"A relaxed proximal gradient descent algorithm for convergent\n  plug-and-play with proximal denoiser","summary":"  This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnP\nmethods are efficient iterative algorithms for solving image inverse problems\nformulated as the minimization of the sum of a data-fidelity term and a\nregularization term. PnP methods perform regularization by plugging a\npre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent\n(PGD). To ensure convergence of PnP schemes, many works study specific\nparametrizations of deep denoisers. However, existing results require either\nunverifiable or suboptimal hypotheses on the denoiser, or assume restrictive\nconditions on the parameters of the inverse problem. Observing that these\nlimitations can be due to the proximal algorithm in use, we study a relaxed\nversion of the PGD algorithm for minimizing the sum of a convex function and a\nweakly convex one. When plugged with a relaxed proximal denoiser, we show that\nthe proposed PnP-$\\alpha$PGD algorithm converges for a wider range of\nregularization parameters, thus allowing more accurate image restoration.\n","authors":["Samuel Hurault","Antonin Chambolle","Arthur Leclaire","Nicolas Papadakis"],"pdf_url":"https://arxiv.org/pdf/2301.13731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07346v2","updated":"2023-01-31T16:00:44Z","published":"2022-12-14T17:17:10Z","title":"Learning useful representations for shifting tasks and distributions","summary":"  Does the dominant approach to learn representations (as a side effect of\noptimizing an expected cost for a single training distribution) remain a good\napproach when we are dealing with multiple distributions? Our thesis is that\nsuch scenarios are better served by representations that are richer than those\nobtained with a single optimization episode. We support this thesis with simple\ntheoretical arguments and with experiments utilizing an apparently na\\\"{\\i}ve\nensembling technique: concatenating the representations obtained from multiple\ntraining episodes using the same data, model, algorithm, and hyper-parameters,\nbut different random seeds. These independently trained networks perform\nsimilarly. Yet, in a number of scenarios involving new distributions, the\nconcatenated representation performs substantially better than an equivalently\nsized network trained with a single training run. This proves that the\nrepresentations constructed by multiple training episodes are in fact\ndifferent. Although their concatenation carries little additional information\nabout the training task under the training distribution, it becomes\nsubstantially more informative when tasks or distributions change. Meanwhile, a\nsingle training episode is unlikely to yield such a redundant representation\nbecause the optimization process has no reason to accumulate features that do\nnot incrementally improve the training performance.\n","authors":["Jianyu Zhang","Léon Bottou"],"pdf_url":"https://arxiv.org/pdf/2212.07346v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2301.13721v1","updated":"2023-01-31T15:58:32Z","published":"2023-01-31T15:58:32Z","title":"DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models","summary":"  In this paper, targeting to understand the underlying explainable factors\nbehind observations and modeling the conditional generation process on these\nfactors, we propose a new task, disentanglement of diffusion probabilistic\nmodels (DPMs), to take advantage of the remarkable modeling ability of DPMs. To\ntackle this task, we further devise an unsupervised approach named DisDiff. For\nthe first time, we achieve disentangled representation learning in the\nframework of diffusion probabilistic models. Given a pre-trained DPM, DisDiff\ncan automatically discover the inherent factors behind the image data and\ndisentangle the gradient fields of DPM into sub-gradient fields, each\nconditioned on the representation of each discovered factor. We propose a novel\nDisentangling Loss for DisDiff to facilitate the disentanglement of the\nrepresentation and sub-gradients. The extensive experiments on synthetic and\nreal-world datasets demonstrate the effectiveness of DisDiff.\n","authors":["Tao Yang","Yuwang Wang","Yan Lv","Nanning Zh"],"pdf_url":"https://arxiv.org/pdf/2301.13721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.05707v2","updated":"2023-01-31T15:48:41Z","published":"2021-09-13T05:01:34Z","title":"Rethinking Lightweight Convolutional Neural Networks for Efficient and\n  High-quality Pavement Crack Detection","summary":"  Pixel-level road crack detection has always been a challenging task in\nintelligent transportation systems. Due to the external environments, such as\nweather, light, and other factors, pavement cracks often present low contrast,\npoor continuity, and different sizes in length and width. However, most of the\nexisting studies pay less attention to crack data under different situations.\nMeanwhile, recent algorithms based on deep convolutional neural networks\n(DCNNs) have promoted the development of cutting-edge models for crack\ndetection. Nevertheless, they usually focus on complex models for good\nperformance, but ignore detection efficiency in practical applications. In this\narticle, to address the first issue, we collected two new databases (i.e.\nRain365 and Sun520) captured in rainy and sunny days respectively, which enrich\nthe data of the open source community. For the second issue, we reconsider how\nto improve detection efficiency with excellent performance, and then propose\nour lightweight encoder-decoder architecture termed CarNet. Specifically, we\nintroduce a novel olive-shaped structure for the encoder network, a\nlight-weight multi-scale block and a new up-sampling method in the decoder\nnetwork. Numerous experiments show that our model can better balance detection\nperformance and efficiency compared with previous models. Especially, on the\nSun520 dataset, our CarNet significantly advances the state-of-the-art\nperformance with ODS F-score from 0.488 to 0.514. Meanwhile, it does so with an\nimproved detection speed (104 frame per second) which is orders of magnitude\nfaster than some recent DCNNs-based algorithms specially designed for crack\ndetection.\n","authors":["Kai Li","Jie Yang","Siwei Ma","Bo Wang","Shanshe Wang","Yingjie Tian","Zhiquan Qi"],"pdf_url":"https://arxiv.org/pdf/2109.05707v2.pdf","comment":"19 pages, 14 figures, 12 tables"},{"id":"http://arxiv.org/abs/2112.04417v3","updated":"2023-01-31T15:01:20Z","published":"2021-12-06T18:36:09Z","title":"What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation\n  Framework for Explainability Methods","summary":"  A multitude of explainability methods and associated fidelity performance\nmetrics have been proposed to help better understand how modern AI systems make\ndecisions. However, much of the current work has remained theoretical --\nwithout much consideration for the human end-user. In particular, it is not yet\nknown (1) how useful current explainability methods are in practice for more\nreal-world scenarios and (2) how well associated performance metrics accurately\npredict how much knowledge individual explanations contribute to a human\nend-user trying to understand the inner-workings of the system. To fill this\ngap, we conducted psychophysics experiments at scale to evaluate the ability of\nhuman participants to leverage representative attribution methods for\nunderstanding the behavior of different image classifiers representing three\nreal-world scenarios: identifying bias in an AI system, characterizing the\nvisual strategy it uses for tasks that are too difficult for an untrained\nnon-expert human observer as well as understanding its failure cases. Our\nresults demonstrate that the degree to which individual attribution methods\nhelp human participants better understand an AI system varied widely across\nthese scenarios. This suggests a critical need for the field to move past\nquantitative improvements of current attribution methods towards the\ndevelopment of complementary approaches that provide qualitatively different\nsources of information to human end-users.\n","authors":["Julien Colin","Thomas Fel","Remi Cadene","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2112.04417v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13674v1","updated":"2023-01-31T14:46:16Z","published":"2023-01-31T14:46:16Z","title":"Improved distinct bone segmentation in upper-body CT through\n  multi-resolution networks","summary":"  Purpose: Automated distinct bone segmentation from CT scans is widely used in\nplanning and navigation workflows. U-Net variants are known to provide\nexcellent results in supervised semantic segmentation. However, in distinct\nbone segmentation from upper body CTs a large field of view and a\ncomputationally taxing 3D architecture are required. This leads to\nlow-resolution results lacking detail or localisation errors due to missing\nspatial context when using high-resolution inputs.\n  Methods: We propose to solve this problem by using end-to-end trainable\nsegmentation networks that combine several 3D U-Nets working at different\nresolutions. Our approach, which extends and generalizes HookNet and MRN,\ncaptures spatial information at a lower resolution and skips the encoded\ninformation to the target network, which operates on smaller high-resolution\ninputs. We evaluated our proposed architecture against single resolution\nnetworks and performed an ablation study on information concatenation and the\nnumber of context networks.\n  Results: Our proposed best network achieves a median DSC of 0.86 taken over\nall 125 segmented bone classes and reduces the confusion among similar-looking\nbones in different locations. These results outperform our previously published\n3D U-Net baseline results on the task and distinct-bone segmentation results\nreported by other groups.\n  Conclusion: The presented multi-resolution 3D U-Nets address current\nshortcomings in bone segmentation from upper-body CT scans by allowing for\ncapturing a larger field of view while avoiding the cubic growth of the input\npixels and intermediate computations that quickly outgrow the computational\ncapacities in 3D. The approach thus improves the accuracy and efficiency of\ndistinct bone segmentation from upper-body CT.\n","authors":["Eva Schnider","Julia Wolleb","Antal Huck","Mireille Toranelli","Georg Rauter","Magdalena Müller-Gerbl","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2301.13674v1.pdf","comment":"Under submission"},{"id":"http://arxiv.org/abs/2301.13670v1","updated":"2023-01-31T14:40:05Z","published":"2023-01-31T14:40:05Z","title":"What Makes Good Examples for Visual In-Context Learning?","summary":"  Large-scale models trained on broad data have recently become the mainstream\narchitecture in computer vision due to their strong generalization performance.\nIn this paper, the main focus is on an emergent ability in large vision models,\nknown as in-context learning, which allows inference on unseen tasks by\nconditioning on in-context examples (a.k.a.~prompt) without updating the model\nparameters. This concept has been well-known in natural language processing but\nhas only been studied very recently for large vision models. We for the first\ntime provide a comprehensive investigation on the impact of in-context examples\nin computer vision, and find that the performance is highly sensitive to the\nchoice of in-context examples. To overcome the problem, we propose a prompt\nretrieval framework to automate the selection of in-context examples.\nSpecifically, we present (1) an unsupervised prompt retrieval method based on\nnearest example search using an off-the-shelf model, and (2) a supervised\nprompt retrieval method, which trains a neural network to choose examples that\ndirectly maximize in-context learning performance. The results demonstrate that\nour methods can bring non-trivial improvements to visual in-context learning in\ncomparison to the commonly-used random selection.\n","authors":["Yuanhan Zhang","Kaiyang Zhou","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2301.13670v1.pdf","comment":"code and\n  models:https://github.com/ZhangYuanhan-AI/visual_prompt_retrieval"},{"id":"http://arxiv.org/abs/2011.08559v6","updated":"2023-01-31T14:31:46Z","published":"2020-11-17T10:47:50Z","title":"Normalized Weighting Schemes for Image Interpolation Algorithms","summary":"  Image interpolation algorithms pervade many modern image processing and\nanalysis applications. However, when their weighting schemes inefficiently\ngenerate very unrealistic estimates, they may negatively affect the performance\nof the end user applications. Therefore, in this work, the author introduced\nfour weighting schemes based on some geometric shapes for digital image\ninterpolation operations. And, the quantity used to express the extent of each\nshape weight was the normalized area, especially when the sums of areas\nexceeded a unit square size. The introduced four weighting schemes are based on\nthe minimum side based diameter (MD) of a regular tetragon, hypotenuse based\nradius (HR), the virtual pixel length based height for the area of the triangle\n(AT), and the virtual pixel length for hypotenuse based radius for the area of\nthe circle (AC). At the smaller scaling ratio, the image interpolation\nalgorithm based on the HR scheme scored the highest at 66.6 % among non\ntraditional image interpolation algorithms presented. But, at the higher\nscaling ratio, the AC scheme based image interpolation algorithm scored the\nhighest at 66.6 % among non traditional algorithms presented and, here, its\nimage interpolation quality was generally superior or comparable to the quality\nof images interpolated by both non traditional and traditional algorithms.\n","authors":["Olivier Rukundo"],"pdf_url":"https://arxiv.org/pdf/2011.08559v6.pdf","comment":"17 pages, 15 figures, 2 Tables"},{"id":"http://arxiv.org/abs/2301.13659v1","updated":"2023-01-31T14:25:03Z","published":"2023-01-31T14:25:03Z","title":"Spyker: High-performance Library for Spiking Deep Neural Networks","summary":"  Spiking neural networks (SNNs) have been recently brought to light due to\ntheir promising capabilities. SNNs simulate the brain with higher biological\nplausibility compared to previous generations of neural networks. Learning with\nfewer samples and consuming less power are among the key features of these\nnetworks. However, the theoretical advantages of SNNs have not been seen in\npractice due to the slowness of simulation tools and the impracticality of the\nproposed network structures. In this work, we implement a high-performance\nlibrary named Spyker using C++/CUDA from scratch that outperforms its\npredecessor. Several SNNs are implemented in this work with different learning\nrules (spike-timing-dependent plasticity and reinforcement learning) using\nSpyker that achieve significantly better runtimes, to prove the practicality of\nthe library in the simulation of large-scale networks. To our knowledge, no\nsuch tools have been developed to simulate large-scale spiking neural networks\nwith high performance using a modular structure. Furthermore, a comparison of\nthe represented stimuli extracted from Spyker to recorded electrophysiology\ndata is performed to demonstrate the applicability of SNNs in describing the\nunderlying neural mechanisms of the brain functions. The aim of this library is\nto take a significant step toward uncovering the true potential of the brain\ncomputations using SNNs.\n","authors":["Shahriar Rezghi Shirsavar","Mohammad-Reza A. Dehaqani"],"pdf_url":"https://arxiv.org/pdf/2301.13659v1.pdf","comment":"11 pages, 6 figures, 6 listings"},{"id":"http://arxiv.org/abs/2301.13656v1","updated":"2023-01-31T14:18:19Z","published":"2023-01-31T14:18:19Z","title":"A Survey and Benchmark of Automatic Surface Reconstruction from Point\n  Clouds","summary":"  We survey and benchmark traditional and novel learning-based algorithms that\naddress the problem of surface reconstruction from point clouds. Surface\nreconstruction from point clouds is particularly challenging when applied to\nreal-world acquisitions, due to noise, outliers, non-uniform sampling and\nmissing data. Traditionally, different handcrafted priors of the input points\nor the output surface have been proposed to make the problem more tractable.\nHowever, hyperparameter tuning for adjusting priors to different acquisition\ndefects can be a tedious task. To this end, the deep learning community has\nrecently addressed the surface reconstruction problem. In contrast to\ntraditional approaches, deep surface reconstruction methods can learn priors\ndirectly from a training set of point clouds and corresponding true surfaces.\nIn our survey, we detail how different handcrafted and learned priors affect\nthe robustness of methods to defect-laden input and their capability to\ngenerate geometric and topologically accurate reconstructions. In our\nbenchmark, we evaluate the reconstructions of several traditional and\nlearning-based methods on the same grounds. We show that learning-based methods\ncan generalize to unseen shape categories, but their training and test sets\nmust share the same point cloud characteristics. We also provide the code and\ndata to compete in our benchmark and to further stimulate the development of\nlearning-based surface reconstruction\nhttps://github.com/raphaelsulzer/dsr-benchmark.\n","authors":["Raphael Sulzer","Loic Landrieu","Renaud Marlet","Bruno Vallet"],"pdf_url":"https://arxiv.org/pdf/2301.13656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02671v3","updated":"2023-01-31T14:14:49Z","published":"2022-06-06T15:20:07Z","title":"Canonical Cortical Graph Neural Networks and its Application for Speech\n  Enhancement in Audio-Visual Hearing Aids","summary":"  Despite the recent success of machine learning algorithms, most models face\ndrawbacks when considering more complex tasks requiring interaction between\ndifferent sources, such as multimodal input data and logical time sequences. On\nthe other hand, the biological brain is highly sharpened in this sense,\nempowered to automatically manage and integrate such streams of information. In\nthis context, this work draws inspiration from recent discoveries in brain\ncortical circuits to propose a more biologically plausible self-supervised\nmachine learning approach. This combines multimodal information using\nintra-layer modulations together with Canonical Correlation Analysis, and a\nmemory mechanism to keep track of temporal data, the overall approach termed\nCanonical Cortical Graph Neural networks. This is shown to outperform recent\nstate-of-the-art models in terms of clean audio reconstruction and energy\nefficiency for a benchmark audio-visual speech dataset. The enhanced\nperformance is demonstrated through a reduced and smother neuron firing rate\ndistribution. suggesting that the proposed model is amenable for speech\nenhancement in future audio-visual hearing aid devices.\n","authors":["Leandro A. Passos","João Paulo Papa","Amir Hussain","Ahsan Adeel"],"pdf_url":"https://arxiv.org/pdf/2206.02671v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06230v2","updated":"2023-01-31T13:50:47Z","published":"2023-01-16T01:41:35Z","title":"Swarm-SLAM : Sparse Decentralized Collaborative Simultaneous\n  Localization and Mapping Framework for Multi-Robot Systems","summary":"  Collaborative Simultaneous Localization And Mapping (C-SLAM) is a vital\ncomponent for successful multi-robot operations in environments without an\nexternal positioning system, such as indoors, underground or underwater. In\nthis paper, we introduce Swarm-SLAM, an open-source C-SLAM system that is\ndesigned to be scalable, flexible, decentralized, and sparse, which are all key\nproperties in swarm robotics. Our system supports inertial, lidar, stereo, and\nRGB-D sensing, and it includes a novel inter-robot loop closure prioritization\ntechnique that reduces communication and accelerates convergence. We evaluated\nour ROS-2 implementation on five different datasets, and in a real-world\nexperiment with three robots communicating through an ad-hoc network. Our code\nis publicly available: https://github.com/MISTLab/Swarm-SLAM\n","authors":["Pierre-Yves Lajoie","Giovanni Beltrame"],"pdf_url":"https://arxiv.org/pdf/2301.06230v2.pdf","comment":"Code: https://github.com/MISTLab/Swarm-SLAM"},{"id":"http://arxiv.org/abs/2301.13622v1","updated":"2023-01-31T13:29:19Z","published":"2023-01-31T13:29:19Z","title":"Learning Data Representations with Joint Diffusion Models","summary":"  We introduce a joint diffusion model that simultaneously learns meaningful\ninternal representations fit for both generative and predictive tasks. Joint\nmachine learning models that allow synthesizing and classifying data often\noffer uneven performance between those tasks or are unstable to train. In this\nwork, we depart from a set of empirical observations that indicate the\nusefulness of internal representations built by contemporary deep\ndiffusion-based generative models in both generative and predictive settings.\nWe then introduce an extension of the vanilla diffusion model with a classifier\nthat allows for stable joint training with shared parametrization between those\nobjectives. The resulting joint diffusion model offers superior performance\nacross various tasks, including generative modeling, semi-supervised\nclassification, and domain adaptation.\n","authors":["Kamil Deja","Tomasz Trzcinski","Jakub M. Tomczak"],"pdf_url":"https://arxiv.org/pdf/2301.13622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04748v2","updated":"2023-01-31T12:58:19Z","published":"2023-01-11T22:57:31Z","title":"LSDM: Long-Short Diffeomorphic Motion for Weakly-Supervised Ultrasound\n  Landmark Tracking","summary":"  Accurate tracking of an anatomical landmark over time has been of high\ninterests for disease assessment such as minimally invasive surgery and tumor\nradiation therapy. Ultrasound imaging is a promising modality benefiting from\nlow-cost and real-time acquisition. However, generating a precise landmark\ntracklet is very challenging, as attempts can be easily distorted by different\ninterference such as landmark deformation, visual ambiguity and partial\nobservation. In this paper, we propose a long-short diffeomorphic motion\nnetwork, which is a multi-task framework with a learnable deformation prior to\nsearch for the plausible deformation of landmark. Specifically, we design a\nnovel diffeomorphism representation in both long and short temporal domains for\ndelineating motion margins and reducing long-term cumulative tracking errors.\nTo further mitigate local anatomical ambiguity, we propose an expectation\nmaximisation motion alignment module to iteratively optimize both long and\nshort deformation, aligning to the same directional and spatial representation.\nThe proposed multi-task system can be trained in a weakly-supervised manner,\nwhich only requires few landmark annotations for tracking and zero annotation\nfor long-short deformation learning. We conduct extensive experiments on two\nultrasound landmark tracking datasets. Experimental results show that our\nproposed method can achieve better or competitive landmark tracking performance\ncompared with other state-of-the-art tracking methods, with a strong\ngeneralization capability across different scanner types and different\nultrasound modalities.\n","authors":["Zhihua Liu","Bin Yang","Yan Shen","Xuejun Ni","Huiyu Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.04748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13592v1","updated":"2023-01-31T12:45:19Z","published":"2023-01-31T12:45:19Z","title":"Priors are Powerful: Improving a Transformer for Multi-camera 3D\n  Detection with 2D Priors","summary":"  Transfomer-based approaches advance the recent development of multi-camera 3D\ndetection both in academia and industry. In a vanilla transformer architecture,\nqueries are randomly initialised and optimised for the whole dataset, without\nconsidering the differences among input frames. In this work, we propose to\nleverage the predictions from an image backbone, which is often highly\noptimised for 2D tasks, as priors to the transformer part of a 3D detection\nnetwork. The method works by (1). augmenting image feature maps with 2D priors,\n(2). sampling query locations via ray-casting along 2D box centroids, as well\nas (3). initialising query features with object-level image features.\nExperimental results shows that 2D priors not only help the model converge\nfaster, but also largely improve the baseline approach by up to 12% in terms of\naverage precision.\n","authors":["Di Feng","Francesco Ferroni"],"pdf_url":"https://arxiv.org/pdf/2301.13592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13591v1","updated":"2023-01-31T12:43:54Z","published":"2023-01-31T12:43:54Z","title":"Zero3D: Semantic-Driven Multi-Category 3D Shape Generation","summary":"  Semantic-driven 3D shape generation aims to generate 3D objects conditioned\non text. Previous works face problems with single-category generation,\nlow-frequency 3D details, and requiring a large number of paired datasets for\ntraining. To tackle these challenges, we propose a multi-category conditional\ndiffusion model. Specifically, 1) to alleviate the problem of lack of\nlarge-scale paired data, we bridge the text, 2D image and 3D shape based on the\npre-trained CLIP model, and 2) to obtain the multi-category 3D shape feature,\nwe apply the conditional flow model to generate 3D shape vector conditioned on\nCLIP embedding. 3) to generate multi-category 3D shape, we employ the\nhidden-layer diffusion model conditioned on the multi-category shape vector,\nwhich greatly reduces the training time and memory consumption.\n","authors":["Bo Han","Yitong Liu","Yixuan Shen"],"pdf_url":"https://arxiv.org/pdf/2301.13591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12914v2","updated":"2023-01-31T12:33:01Z","published":"2023-01-30T14:15:47Z","title":"PromptMix: Text-to-image diffusion models enhance the performance of\n  lightweight networks","summary":"  Many deep learning tasks require annotations that are too time consuming for\nhuman operators, resulting in small dataset sizes. This is especially true for\ndense regression problems such as crowd counting which requires the location of\nevery person in the image to be annotated. Techniques such as data augmentation\nand synthetic data generation based on simulations can help in such cases. In\nthis paper, we introduce PromptMix, a method for artificially boosting the size\nof existing datasets, that can be used to improve the performance of\nlightweight networks. First, synthetic images are generated in an end-to-end\ndata-driven manner, where text prompts are extracted from existing datasets via\nan image captioning deep network, and subsequently introduced to text-to-image\ndiffusion models. The generated images are then annotated using one or more\nhigh-performing deep networks, and mixed with the real dataset for training the\nlightweight network. By extensive experiments on five datasets and two tasks,\nwe show that PromptMix can significantly increase the performance of\nlightweight networks by up to 26%.\n","authors":["Arian Bakhtiarnia","Qi Zhang","Alexandros Iosifidis"],"pdf_url":"https://arxiv.org/pdf/2301.12914v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13576v1","updated":"2023-01-31T12:03:59Z","published":"2023-01-31T12:03:59Z","title":"Sport Task: Fine Grained Action Detection and Classification of Table\n  Tennis Strokes from Videos for MediaEval 2022","summary":"  Sports video analysis is a widespread research topic. Its applications are\nvery diverse, like events detection during a match, video summary, or\nfine-grained movement analysis of athletes. As part of the MediaEval 2022\nbenchmarking initiative, this task aims at detecting and classifying subtle\nmovements from sport videos. We focus on recordings of table tennis matches.\nConducted since 2019, this task provides a classification challenge from\nuntrimmed videos recorded under natural conditions with known temporal\nboundaries for each stroke. Since 2021, the task also provides a stroke\ndetection challenge from unannotated, untrimmed videos. This year, the\ntraining, validation, and test sets are enhanced to ensure that all strokes are\nrepresented in each dataset. The dataset is now similar to the one used in [1,\n2]. This research is intended to build tools for coaches and athletes who want\nto further evaluate their sport performances.\n","authors":["Pierre-Etienne Martin","Jordan Calandre","Boris Mansencal","Jenny Benois-Pineau","Renaud Péteri","Laurent Mascarilla","Julien Morlier"],"pdf_url":"https://arxiv.org/pdf/2301.13576v1.pdf","comment":"MediaEval 2022 Workshop, Jan 2023, Bergen, Norway. arXiv admin note:\n  substantial text overlap with arXiv:2112.11384"},{"id":"http://arxiv.org/abs/2301.13569v1","updated":"2023-01-31T11:44:45Z","published":"2023-01-31T11:44:45Z","title":"NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning","summary":"  Semi-supervised learning (SSL) has been widely explored in recent years, and\nit is an effective way of leveraging unlabeled data to reduce the reliance on\nlabeled data. In this work, we adjust neural processes (NPs) to the\nsemi-supervised image classification task, resulting in a new method named\nNP-Match. NP-Match is suited to this task for two reasons. Firstly, NP-Match\nimplicitly compares data points when making predictions, and as a result, the\nprediction of each unlabeled data point is affected by the labeled data points\nthat are similar to it, which improves the quality of pseudo-labels. Secondly,\nNP-Match is able to estimate uncertainty that can be used as a tool for\nselecting unlabeled samples with reliable pseudo-labels. Compared with\nuncertainty-based SSL methods implemented with Monte-Carlo (MC) dropout,\nNP-Match estimates uncertainty with much less computational overhead, which can\nsave time at both the training and the testing phases. We conducted extensive\nexperiments on five public datasets under three semi-supervised image\nclassification settings, namely, the standard semi-supervised image\nclassification, the imbalanced semi-supervised image classification, and the\nmulti-label semi-supervised image classification, and NP-Match outperforms\nstate-of-the-art (SOTA) approaches or achieves competitive results on them,\nwhich shows the effectiveness of NP-Match and its potential for SSL. The codes\nare at https://github.com/Jianf-Wang/NP-Match\n","authors":["Jianfeng Wang","Xiaolin Hu","Thomas Lukasiewicz"],"pdf_url":"https://arxiv.org/pdf/2301.13569v1.pdf","comment":"An journal version of our previous ICML 2022 paper arXiv:2207.01066 .\n  Codes are available at: https://github.com/Jianf-Wang/NP-Match"},{"id":"http://arxiv.org/abs/2301.13558v1","updated":"2023-01-31T11:16:21Z","published":"2023-01-31T11:16:21Z","title":"Lidar Upsampling with Sliced Wasserstein Distance","summary":"  Lidar became an important component of the perception systems in autonomous\ndriving. But challenges of training data acquisition and annotation made\nemphasized the role of the sensor to sensor domain adaptation. In this work, we\naddress the problem of lidar upsampling. Learning on lidar point clouds is\nrather a challenging task due to their irregular and sparse structure. Here we\npropose a method for lidar point cloud upsampling which can reconstruct\nfine-grained lidar scan patterns. The key idea is to utilize edge-aware dense\nconvolutions for both feature extraction and feature expansion. Additionally\napplying a more accurate Sliced Wasserstein Distance facilitates learning of\nthe fine lidar sweep structures. This in turn enables our method to employ a\none-stage upsampling paradigm without the need for coarse and fine\nreconstruction. We conduct several experiments to evaluate our method and\ndemonstrate that it provides better upsampling.\n","authors":["Artem Savkin","Yida Wang","Sebastian Wirkert","Nassir Navab","Federico Tombar"],"pdf_url":"https://arxiv.org/pdf/2301.13558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13554v1","updated":"2023-01-31T11:09:15Z","published":"2023-01-31T11:09:15Z","title":"NoiseTransfer: Image Noise Generation with Contrastive Embeddings","summary":"  Deep image denoising networks have achieved impressive success with the help\nof a considerably large number of synthetic train datasets. However, real-world\ndenoising is a still challenging problem due to the dissimilarity between\ndistributions of real and synthetic noisy datasets. Although several real-world\nnoisy datasets have been presented, the number of train datasets (i.e., pairs\nof clean and real noisy images) is limited, and acquiring more real noise\ndatasets is laborious and expensive. To mitigate this problem, numerous\nattempts to simulate real noise models using generative models have been\nstudied. Nevertheless, previous works had to train multiple networks to handle\nmultiple different noise distributions. By contrast, we propose a new\ngenerative model that can synthesize noisy images with multiple different noise\ndistributions. Specifically, we adopt recent contrastive learning to learn\ndistinguishable latent features of the noise. Moreover, our model can generate\nnew noisy images by transferring the noise characteristics solely from a single\nreference noisy image. We demonstrate the accuracy and the effectiveness of our\nnoise model for both known and unknown noise removal.\n","authors":["Seunghwan Lee","Tae Hyun Kim"],"pdf_url":"https://arxiv.org/pdf/2301.13554v1.pdf","comment":"ACCV 2022 oral"},{"id":"http://arxiv.org/abs/2301.09190v3","updated":"2023-01-31T11:05:59Z","published":"2023-01-22T19:51:22Z","title":"Apples and Oranges? Assessing Image Quality over Content Recognition","summary":"  Image recognition and quality assessment are two important viewing tasks,\nwhile potentially following different visual mechanisms. This paper\ninvestigates if the two tasks can be performed in a multitask learning manner.\nA sequential spatial-channel attention module is proposed to simulate the\nvisual attention and contrast sensitivity mechanisms that are crucial for\ncontent recognition and quality assessment. Spatial attention is shared between\ncontent recognition and quality assessment, while channel attention is solely\nfor quality assessment. Such attention module is integrated into Transformer to\nbuild a uniform model for the two viewing tasks. The experimental results have\ndemonstrated that the proposed uniform model can achieve promising performance\nfor both quality assessment and content recognition tasks.\n","authors":["Junyong You","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.09190v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13549v1","updated":"2023-01-31T10:59:09Z","published":"2023-01-31T10:59:09Z","title":"Review of methods for automatic cerebral microbleeds detection","summary":"  Cerebral microbleeds detection is an important and challenging task. With the\ngaining popularity of the MRI, the ability to detect cerebral microbleeds also\nraises. Unfortunately, for radiologists, it is a time-consuming and laborious\nprocedure. For this reason, various solutions to automate this process have\nbeen proposed for several years, but none of them is currently used in medical\npractice. In this context, the need to systematize the existing knowledge and\nbest practices has been recognized as a factor facilitating the imminent\nsynthesis of a real CMBs detection system practically applicable in medicine.\nTo the best of our knowledge, all available publications regarding automatic\ncerebral microbleeds detection have been gathered, described, and assessed in\nthis paper in order to distinguish the current research state and provide a\nstarting point for future studies.\n","authors":["Maria Ferlin","Zuzanna Klawikowska","Michał Grochowski","Małgorzata Grzywińska","Edyta Szurowska"],"pdf_url":"https://arxiv.org/pdf/2301.13549v1.pdf","comment":"32 pages, 6 figures, 3 tables, 174 references"},{"id":"http://arxiv.org/abs/2206.08890v2","updated":"2023-01-31T10:40:52Z","published":"2022-06-17T16:53:12Z","title":"Disentangling Model Multiplicity in Deep Learning","summary":"  Model multiplicity is a well-known but poorly understood phenomenon that\nundermines the generalisation guarantees of machine learning models. It appears\nwhen two models with similar training-time performance differ in their\npredictions and real-world performance characteristics. This observed\n'predictive' multiplicity (PM) also implies elusive differences in the\ninternals of the models, their 'representational' multiplicity (RM). We\nintroduce a conceptual and experimental setup for analysing RM by measuring\nactivation similarity via singular vector canonical correlation analysis\n(SVCCA). We show that certain differences in training methods systematically\nresult in larger RM than others and evaluate RM and PM over a finite sample as\npredictors for generalizability. We further correlate RM with PM measured by\nthe variance in i.i.d. and out-of-distribution test predictions in four\nstandard image data sets. Finally, instead of attempting to eliminate RM, we\ncall for its systematic measurement and maximal exposure.\n","authors":["Ari Heljakka","Martin Trapp","Juho Kannala","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2206.08890v2.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.13538v1","updated":"2023-01-31T10:32:13Z","published":"2023-01-31T10:32:13Z","title":"AMD: Adaptive Masked Distillation for Object","summary":"  As a general model compression paradigm, feature-based knowledge distillation\nallows the student model to learn expressive features from the teacher\ncounterpart. In this paper, we mainly focus on designing an effective\nfeature-distillation framework and propose a spatial-channel adaptive masked\ndistillation (AMD) network for object detection. More specifically, in order to\naccurately reconstruct important feature regions, we first perform\nattention-guided feature masking on the feature map of the student network,\nsuch that we can identify the important features via spatially adaptive feature\nmasking instead of random masking in the previous methods. In addition, we\nemploy a simple and efficient module to allow the student network channel to be\nadaptive, improving its model capability in object perception and detection. In\ncontrast to the previous methods, more crucial object-aware features can be\nreconstructed and learned from the proposed network, which is conducive to\naccurate object detection. The empirical experiments demonstrate the\nsuperiority of our method: with the help of our proposed distillation method,\nthe student networks report 41.3\\%, 42.4\\%, and 42.7\\% mAP scores when\nRetinaNet, Cascade Mask-RCNN and RepPoints are respectively used as the teacher\nframework for object detection, which outperforms the previous state-of-the-art\ndistillation methods including FGD and MGD.\n","authors":["Guang Yang","Yin Tang","Jun Li","Jianhua Xu","Xili Wan"],"pdf_url":"https://arxiv.org/pdf/2301.13538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13530v1","updated":"2023-01-31T10:24:50Z","published":"2023-01-31T10:24:50Z","title":"Domain-Generalizable Multiple-Domain Clustering","summary":"  Accurately clustering high-dimensional measurements is vital for adequately\nanalyzing scientific data. Deep learning machinery has remarkably improved\nclustering capabilities in recent years due to its ability to extract\nmeaningful representations. In this work, we are given unlabeled samples from\nmultiple source domains, and we aim to learn a shared classifier that assigns\nthe examples to various clusters. Evaluation is done by using the classifier\nfor predicting cluster assignments in a previously unseen domain. This setting\ngeneralizes the problem of unsupervised domain generalization to the case in\nwhich no supervised learning samples are given (completely unsupervised).\nTowards this goal, we present an end-to-end model and evaluate its capabilities\non several multi-domain image datasets. Specifically, we demonstrate that our\nmodel is more accurate than schemes that require fine-tuning using samples from\nthe target domain or some level of supervision.\n","authors":["Amit Rozner","Barak Battash","Lior Wolf","Ofir Lindenbaum"],"pdf_url":"https://arxiv.org/pdf/2301.13530v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.13514v1","updated":"2023-01-31T10:05:35Z","published":"2023-01-31T10:05:35Z","title":"Fourier Sensitivity and Regularization of Computer Vision Models","summary":"  Recent work has empirically shown that deep neural networks latch on to the\nFourier statistics of training data and show increased sensitivity to\nFourier-basis directions in the input. Understanding and modifying this\nFourier-sensitivity of computer vision models may help improve their\nrobustness. Hence, in this paper we study the frequency sensitivity\ncharacteristics of deep neural networks using a principled approach. We first\npropose a basis trick, proving that unitary transformations of the\ninput-gradient of a function can be used to compute its gradient in the basis\ninduced by the transformation. Using this result, we propose a general measure\nof any differentiable model's Fourier-sensitivity using the unitary\nFourier-transform of its input-gradient. When applied to deep neural networks,\nwe find that computer vision models are consistently sensitive to particular\nfrequencies dependent on the dataset, training method and architecture. Based\non this measure, we further propose a Fourier-regularization framework to\nmodify the Fourier-sensitivities and frequency bias of models. Using our\nproposed regularizer-family, we demonstrate that deep neural networks obtain\nimproved classification accuracy on robustness evaluations.\n","authors":["Kiran Krishnamachari","See-Kiong Ng","Chuan-Sheng Foo"],"pdf_url":"https://arxiv.org/pdf/2301.13514v1.pdf","comment":"Published in TMLR, https://openreview.net/forum?id=VmTYgjYloM"},{"id":"http://arxiv.org/abs/2205.07246v3","updated":"2023-01-31T10:04:52Z","published":"2022-05-15T10:07:52Z","title":"FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning","summary":"  Semi-supervised Learning (SSL) has witnessed great success owing to the\nimpressive performances brought by various methods based on pseudo labeling and\nconsistency regularization. However, we argue that existing methods might fail\nto utilize the unlabeled data more effectively since they either use a\npre-defined / fixed threshold or an ad-hoc threshold adjusting scheme,\nresulting in inferior performance and slow convergence. We first analyze a\nmotivating example to obtain intuitions on the relationship between the\ndesirable threshold and model's learning status. Based on the analysis, we\nhence propose FreeMatch to adjust the confidence threshold in a self-adaptive\nmanner according to the model's learning status. We further introduce a\nself-adaptive class fairness regularization penalty to encourage the model for\ndiverse predictions during the early training stage. Extensive experiments\nindicate the superiority of FreeMatch especially when the labeled data are\nextremely rare. FreeMatch achieves 5.78%, 13.59%, and 1.28% error rate\nreduction over the latest state-of-the-art method FlexMatch on CIFAR-10 with 1\nlabel per class, STL-10 with 4 labels per class, and ImageNet with 100 labels\nper class, respectively. Moreover, FreeMatch can also boost the performance of\nimbalanced SSL. The codes can be found at\nhttps://github.com/microsoft/Semi-supervised-learning.\n","authors":["Yidong Wang","Hao Chen","Qiang Heng","Wenxin Hou","Yue Fan","Zhen Wu","Jindong Wang","Marios Savvides","Takahiro Shinozaki","Bhiksha Raj","Bernt Schiele","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2205.07246v3.pdf","comment":"Accepted by ICLR 2023. Code:\n  https://github.com/microsoft/Semi-supervised-learning"},{"id":"http://arxiv.org/abs/2301.13510v1","updated":"2023-01-31T09:54:20Z","published":"2023-01-31T09:54:20Z","title":"Monocular Scene Reconstruction with 3D SDF Transformers","summary":"  Monocular scene reconstruction from posed images is challenging due to the\ncomplexity of a large environment. Recent volumetric methods learn to directly\npredict the TSDF volume and have demonstrated promising results in this task.\nHowever, most methods focus on how to extract and fuse the 2D features to a 3D\nfeature volume, but none of them improve the way how the 3D volume is\naggregated. In this work, we propose an SDF transformer network, which replaces\nthe role of 3D CNN for better 3D feature aggregation. To reduce the explosive\ncomputation complexity of the 3D multi-head attention, we propose a sparse\nwindow attention module, where the attention is only calculated between the\nnon-empty voxels within a local window. Then a top-down-bottom-up 3D attention\nnetwork is built for 3D feature aggregation, where a dilate-attention structure\nis proposed to prevent geometry degeneration, and two global modules are\nemployed to equip with global receptive fields. The experiments on multiple\ndatasets show that this 3D transformer network generates a more accurate and\ncomplete reconstruction, which outperforms previous methods by a large margin.\nRemarkably, the mesh accuracy is improved by 41.8%, and the mesh completeness\nis improved by 25.3% on the ScanNet dataset. Project page:\nhttps://weihaosky.github.io/sdfformer.\n","authors":["Weihao Yuan","Xiaodong Gu","Heng Li","Zilong Dong","Siyu Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.13510v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2301.13504v1","updated":"2023-01-31T09:44:52Z","published":"2023-01-31T09:44:52Z","title":"Transfer Learning and Class Decomposition for Detecting the Cognitive\n  Decline of Alzheimer Disease","summary":"  Early diagnosis of Alzheimer's disease (AD) is essential in preventing the\ndisease's progression. Therefore, detecting AD from neuroimaging data such as\nstructural magnetic resonance imaging (sMRI) has been a topic of intense\ninvestigation in recent years. Deep learning has gained considerable attention\nin Alzheimer's detection. However, training a convolutional neural network from\nscratch is challenging since it demands more computational time and a\nsignificant amount of annotated data. By transferring knowledge learned from\nother image recognition tasks to medical image classification, transfer\nlearning can provide a promising and effective solution. Irregularities in the\ndataset distribution present another difficulty. Class decomposition can tackle\nthis issue by simplifying learning a dataset's class boundaries. Motivated by\nthese approaches, this paper proposes a transfer learning method using class\ndecomposition to detect Alzheimer's disease from sMRI images. We use two\nImageNet-trained architectures: VGG19 and ResNet50, and an entropy-based\ntechnique to determine the most informative images. The proposed model achieved\nstate-of-the-art performance in the Alzheimer's disease (AD) vs mild cognitive\nimpairment (MCI) vs cognitively normal (CN) classification task with a 3\\%\nincrease in accuracy from what is reported in the literature.\n","authors":["Maha M. Alwuthaynani","Zahraa S. Abdallah","Raul Santos-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2301.13504v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2205.14938v4","updated":"2023-01-31T09:36:26Z","published":"2022-05-30T09:03:28Z","title":"Spectral Maps for Learning on Subgraphs","summary":"  In graph learning, maps between graphs and their subgraphs frequently arise.\nFor instance, when coarsening or rewiring operations are present along the\npipeline, one needs to keep track of the corresponding nodes between the\noriginal and modified graphs. Classically, these maps are represented as binary\nnode-to-node correspondence matrices and used as-is to transfer node-wise\nfeatures between the graphs. In this paper, we argue that simply changing this\nmap representation can bring notable benefits to graph learning tasks. Drawing\ninspiration from recent progress in geometry processing, we introduce a\nspectral representation for maps that is easy to integrate into existing graph\nlearning models. This spectral representation is a compact and straightforward\nplug-in replacement and is robust to topological changes of the graphs.\nRemarkably, the representation exhibits structural properties that make it\ninterpretable, drawing an analogy with recent results on smooth manifolds. We\ndemonstrate the benefits of incorporating spectral maps in graph learning\npipelines, addressing scenarios where a node-to-node map is not well defined,\nor in the absence of exact isomorphism. Our approach bears practical benefits\nin knowledge distillation and hierarchical learning, where we show comparable\nor improved performance at a fraction of the computational cost.\n","authors":["Marco Pegoraro","Riccardo Marin","Arianna Rampini","Simone Melzi","Luca Cosmo","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2205.14938v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13487v1","updated":"2023-01-31T09:12:16Z","published":"2023-01-31T09:12:16Z","title":"Adversarial Training of Self-supervised Monocular Depth Estimation\n  against Physical-World Attacks","summary":"  Monocular Depth Estimation (MDE) is a critical component in applications such\nas autonomous driving. There are various attacks against MDE networks. These\nattacks, especially the physical ones, pose a great threat to the security of\nsuch systems. Traditional adversarial training method requires ground-truth\nlabels hence cannot be directly applied to self-supervised MDE that does not\nhave ground-truth depth. Some self-supervised model hardening techniques (e.g.,\ncontrastive learning) ignore the domain knowledge of MDE and can hardly achieve\noptimal performance. In this work, we propose a novel adversarial training\nmethod for self-supervised MDE models based on view synthesis without using\nground-truth depth. We improve adversarial robustness against physical-world\nattacks using L0-norm-bounded perturbation in training. We compare our method\nwith supervised learning based and contrastive learning based methods that are\ntailored for MDE. Results on two representative MDE networks show that we\nachieve better robustness against various adversarial attacks with nearly no\nbenign performance degradation.\n","authors":["Zhiyuan Cheng","James Liang","Guanhong Tao","Dongfang Liu","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13487v1.pdf","comment":"Accepted to ICLR2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2301.13473v1","updated":"2023-01-31T08:41:18Z","published":"2023-01-31T08:41:18Z","title":"CRC-RL: A Novel Visual Feature Representation Architecture for\n  Unsupervised Reinforcement Learning","summary":"  This paper addresses the problem of visual feature representation learning\nwith an aim to improve the performance of end-to-end reinforcement learning\n(RL) models. Specifically, a novel architecture is proposed that uses a\nheterogeneous loss function, called CRC loss, to learn improved visual features\nwhich can then be used for policy learning in RL. The CRC-loss function is a\ncombination of three individual loss functions, namely, contrastive,\nreconstruction and consistency loss. The feature representation is learned in\nparallel to the policy learning while sharing the weight updates through a\nSiamese Twin encoder model. This encoder model is augmented with a decoder\nnetwork and a feature projection network to facilitate computation of the above\nloss components. Through empirical analysis involving latent feature\nvisualization, an attempt is made to provide an insight into the role played by\nthis loss function in learning new action-dependent features and how they are\nlinked to the complexity of the problems being solved. The proposed\narchitecture, called CRC-RL, is shown to outperform the existing\nstate-of-the-art methods on the challenging Deep mind control suite\nenvironments by a significant margin thereby creating a new benchmark in this\nfield.\n","authors":["Darshita Jain","Anima Majumder","Samrat Dutta","Swagat Kumar"],"pdf_url":"https://arxiv.org/pdf/2301.13473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08185v2","updated":"2023-01-31T08:17:16Z","published":"2022-07-17T14:07:49Z","title":"Mind the Gap: Polishing Pseudo labels for Accurate Semi-supervised\n  Object Detection","summary":"  Exploiting pseudo labels (e.g., categories and bounding boxes) of unannotated\nobjects produced by a teacher detector have underpinned much of recent progress\nin semi-supervised object detection (SSOD). However, due to the limited\ngeneralization capacity of the teacher detector caused by the scarce\nannotations, the produced pseudo labels often deviate from ground truth,\nespecially those with relatively low classification confidences, thus limiting\nthe generalization performance of SSOD. To mitigate this problem, we propose a\ndual pseudo-label polishing framework for SSOD. Instead of directly exploiting\nthe pseudo labels produced by the teacher detector, we take the first attempt\nat reducing their deviation from ground truth using dual polishing learning,\nwhere two differently structured polishing networks are elaborately developed\nand trained using synthesized paired pseudo labels and the corresponding ground\ntruth for categories and bounding boxes on the given annotated objects,\nrespectively. By doing this, both polishing networks can infer more accurate\npseudo labels for unannotated objects through sufficiently exploiting their\ncontext knowledge based on the initially produced pseudo labels, and thus\nimprove the generalization performance of SSOD. Moreover, such a scheme can be\nseamlessly plugged into the existing SSOD framework for joint end-to-end\nlearning. In addition, we propose to disentangle the polished pseudo categories\nand bounding boxes of unannotated objects for separate category classification\nand bounding box regression in SSOD, which enables introducing more unannotated\nobjects during model training and thus further improve the performance.\nExperiments on both PASCAL VOC and MS COCO benchmarks demonstrate the\nsuperiority of the proposed method over existing state-of-the-art baselines.\n","authors":["Lei Zhang","Yuxuan Sun","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2207.08185v2.pdf","comment":"Accepted by Thirty-Seventh AAAI Conference on Artificial Intelligence\n  (AAAI 2023)"},{"id":"http://arxiv.org/abs/2210.13431v3","updated":"2023-01-31T08:00:36Z","published":"2022-10-24T17:46:47Z","title":"InstructRL: Simple yet Effective Instruction-Following Agents with\n  Multimodal Transformer","summary":"  Humans are excellent at understanding language and vision to accomplish a\nwide range of tasks. In contrast, creating general instruction-following\nembodied agents remains a difficult challenge. Prior work that uses pure\nlanguage-only models lack visual grounding, making it difficult to connect\nlanguage instructions with visual observations. On the other hand, methods that\nuse pre-trained multimodal models typically come with divided language and\nvisual representations, requiring designing specialized network architecture to\nfuse them together. We propose a simple yet effective model for robots to solve\ninstruction-following tasks in vision-based environments. Our \\ours method\nconsists of a multimodal transformer that encodes visual observations and\nlanguage instructions, and a transformer-based policy that predicts actions\nbased on encoded representations. The multimodal transformer is pre-trained on\nmillions of image-text pairs and natural language text, thereby producing\ngeneric cross-modal representations of observations and instructions. The\ntransformer-based policy keeps track of the full history of observations and\nactions, and predicts actions autoregressively. Despite its simplicity, we show\nthat this unified transformer model outperforms all state-of-the-art\npre-trained or trained-from-scratch methods in both single-task and multi-task\nsettings. Our model also shows better model scalability and generalization\nability than prior work.\n","authors":["Hao Liu","Lisa Lee","Kimin Lee","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2210.13431v3.pdf","comment":"improved results and presentation"},{"id":"http://arxiv.org/abs/2301.13459v1","updated":"2023-01-31T07:49:25Z","published":"2023-01-31T07:49:25Z","title":"Learning Generalized Hybrid Proximity Representation for Image\n  Recognition","summary":"  Recently, deep metric learning techniques received attention, as the learned\ndistance representations are useful to capture the similarity relationship\namong samples and further improve the performance of various of supervised or\nunsupervised learning tasks. We propose a novel supervised metric learning\nmethod that can learn the distance metrics in both geometric and probabilistic\nspace for image recognition. In contrast to the previous metric learning\nmethods which usually focus on learning the distance metrics in Euclidean\nspace, our proposed method is able to learn better distance representation in a\nhybrid approach. To achieve this, we proposed a Generalized Hybrid Metric Loss\n(GHM-Loss) to learn the general hybrid proximity features from the image data\nby controlling the trade-off between geometric proximity and probabilistic\nproximity. To evaluate the effectiveness of our method, we first provide\ntheoretical derivations and proofs of the proposed loss function, then we\nperform extensive experiments on two public datasets to show the advantage of\nour method compared to other state-of-the-art metric learning methods.\n","authors":["Zhiyuan Li","Anca Ralescu"],"pdf_url":"https://arxiv.org/pdf/2301.13459v1.pdf","comment":"The paper has been accepted by the IEEE ICTAI 2022"},{"id":"http://arxiv.org/abs/2301.13445v1","updated":"2023-01-31T06:49:42Z","published":"2023-01-31T06:49:42Z","title":"A Survey of Explainable AI in Deep Visual Modeling: Methods and Metrics","summary":"  Deep visual models have widespread applications in high-stake domains. Hence,\ntheir black-box nature is currently attracting a large interest of the research\ncommunity. We present the first survey in Explainable AI that focuses on the\nmethods and metrics for interpreting deep visual models. Covering the landmark\ncontributions along the state-of-the-art, we not only provide a taxonomic\norganization of the existing techniques, but also excavate a range of\nevaluation metrics and collate them as measures of different properties of\nmodel explanations. Along the insightful discussion on the current trends, we\nalso discuss the challenges and future avenues for this research direction.\n","authors":["Naveed Akhtar"],"pdf_url":"https://arxiv.org/pdf/2301.13445v1.pdf","comment":"Short accessible survey (9pgs)"},{"id":"http://arxiv.org/abs/2301.13444v1","updated":"2023-01-31T06:47:19Z","published":"2023-01-31T06:47:19Z","title":"Rethinking Soft Label in Label Distribution Learning Perspective","summary":"  The primary goal of training in early convolutional neural networks (CNN) is\nthe higher generalization performance of the model. However, as the expected\ncalibration error (ECE), which quantifies the explanatory power of model\ninference, was recently introduced, research on training models that can be\nexplained is in progress. We hypothesized that a gap in supervision criteria\nduring training and inference leads to overconfidence, and investigated that\nperforming label distribution learning (LDL) would enhance the model\ncalibration in CNN training. To verify this assumption, we used a simple LDL\nsetting with recent data augmentation techniques. Based on a series of\nexperiments, the following results are obtained: 1) State-of-the-art KD methods\nsignificantly impede model calibration. 2) Training using LDL with recent data\naugmentation can have excellent effects on model calibration and even in\ngeneralization performance. 3) Online LDL brings additional improvements in\nmodel calibration and accuracy with long training, especially in large-size\nmodels. Using the proposed approach, we simultaneously achieved a lower ECE and\nhigher generalization performance for the image classification datasets\nCIFAR10, 100, STL10, and ImageNet. We performed several visualizations and\nanalyses and witnessed several interesting behaviors in CNN training with the\nLDL.\n","authors":["Seungbum Hong","Jihun Yoon","Bogyu Park","Min-Kook Choi"],"pdf_url":"https://arxiv.org/pdf/2301.13444v1.pdf","comment":"11 pages main manuscript + references and 11 pages supplementary\n  materials"},{"id":"http://arxiv.org/abs/2301.13430v1","updated":"2023-01-31T05:56:06Z","published":"2023-01-31T05:56:06Z","title":"GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face\n  Synthesis","summary":"  Generating photo-realistic video portrait with arbitrary speech audio is a\ncrucial problem in film-making and virtual reality. Recently, several works\nexplore the usage of neural radiance field in this task to improve 3D realness\nand image fidelity. However, the generalizability of previous NeRF-based\nmethods to out-of-domain audio is limited by the small scale of training data.\nIn this work, we propose GeneFace, a generalized and high-fidelity NeRF-based\ntalking face generation method, which can generate natural results\ncorresponding to various out-of-domain audio. Specifically, we learn a\nvariaitional motion generator on a large lip-reading corpus, and introduce a\ndomain adaptative post-net to calibrate the result. Moreover, we learn a\nNeRF-based renderer conditioned on the predicted facial motion. A head-aware\ntorso-NeRF is proposed to eliminate the head-torso separation problem.\nExtensive experiments show that our method achieves more generalized and\nhigh-fidelity talking face generation compared to previous methods.\n","authors":["Zhenhui Ye","Ziyue Jiang","Yi Ren","Jinglin Liu","JinZheng He","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.13430v1.pdf","comment":"Accepted by ICLR2023. Project page: https://geneface.github.io/"},{"id":"http://arxiv.org/abs/2301.13428v1","updated":"2023-01-31T05:51:05Z","published":"2023-01-31T05:51:05Z","title":"Contrast and Clustering: Learning Neighborhood Pair Representation for\n  Source-free Domain Adaptation","summary":"  Domain adaptation has attracted a great deal of attention in the machine\nlearning community, but it requires access to source data, which often raises\nconcerns about data privacy. We are thus motivated to address these issues and\npropose a simple yet efficient method. This work treats domain adaptation as an\nunsupervised clustering problem and trains the target model without access to\nthe source data. Specifically, we propose a loss function called contrast and\nclustering (CaC), where a positive pair term pulls neighbors belonging to the\nsame class together in the feature space to form clusters, while a negative\npair term pushes samples of different classes apart. In addition, extended\nneighbors are taken into account by querying the nearest neighbor indexes in\nthe memory bank to mine for more valuable negative pairs. Extensive experiments\non three common benchmarks, VisDA, Office-Home and Office-31, demonstrate that\nour method achieves state-of-the-art performance. The code will be made\npublicly available at https://github.com/yukilulu/CaC.\n","authors":["Yuqi Chen","Xiangbin Zhu","Yonggang Li","Yingjian Li","Yuanwang Wei","Haojie Fang"],"pdf_url":"https://arxiv.org/pdf/2301.13428v1.pdf","comment":"conference paper"},{"id":"http://arxiv.org/abs/2209.13274v2","updated":"2023-01-31T05:39:28Z","published":"2022-09-27T09:37:57Z","title":"Orbeez-SLAM: A Real-time Monocular Visual SLAM with ORB Features and\n  NeRF-realized Mapping","summary":"  A spatial AI that can perform complex tasks through visual signals and\ncooperate with humans is highly anticipated. To achieve this, we need a visual\nSLAM that easily adapts to new scenes without pre-training and generates dense\nmaps for downstream tasks in real-time. None of the previous learning-based and\nnon-learning-based visual SLAMs satisfy all needs due to the intrinsic\nlimitations of their components. In this work, we develop a visual SLAM named\nOrbeez-SLAM, which successfully collaborates with implicit neural\nrepresentation and visual odometry to achieve our goals. Moreover, Orbeez-SLAM\ncan work with the monocular camera since it only needs RGB inputs, making it\nwidely applicable to the real world. Results show that our SLAM is up to 800x\nfaster than the strong baseline with superior rendering outcomes. Code link:\nhttps://github.com/MarvinChung/Orbeez-SLAM.\n","authors":["Chi-Ming Chung","Yang-Che Tseng","Ya-Ching Hsu","Xiang-Qian Shi","Yun-Hung Hua","Jia-Fong Yeh","Wen-Chin Chen","Yi-Ting Chen","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2209.13274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13422v1","updated":"2023-01-31T05:32:34Z","published":"2023-01-31T05:32:34Z","title":"Anomaly Segmentation for High-Resolution Remote Sensing Images Based on\n  Pixel Descriptors","summary":"  Anomaly segmentation in high spatial resolution (HSR) remote sensing imagery\nis aimed at segmenting anomaly patterns of the earth deviating from normal\npatterns, which plays an important role in various Earth vision applications.\nHowever, it is a challenging task due to the complex distribution and the\nirregular shapes of objects, and the lack of abnormal samples. To tackle these\nproblems, an anomaly segmentation model based on pixel descriptors (ASD) is\nproposed for anomaly segmentation in HSR imagery. Specifically, deep one-class\nclassification is introduced for anomaly segmentation in the feature space with\ndiscriminative pixel descriptors. The ASD model incorporates the data argument\nfor generating virtual ab-normal samples, which can force the pixel descriptors\nto be compact for normal data and meanwhile to be diverse to avoid the model\ncollapse problems when only positive samples participated in the training. In\naddition, the ASD introduced a multi-level and multi-scale feature extraction\nstrategy for learning the low-level and semantic information to make the pixel\ndescriptors feature-rich. The proposed ASD model was validated using four HSR\ndatasets and compared with the recent state-of-the-art models, showing its\npotential value in Earth vision applications.\n","authors":["Jingtao Li","Xinyu Wang","Hengwei Zhao","Shaoyu Wang","Yanfei Zhong"],"pdf_url":"https://arxiv.org/pdf/2301.13422v1.pdf","comment":"to be published in AAAI2023"},{"id":"http://arxiv.org/abs/2301.13419v1","updated":"2023-01-31T05:18:34Z","published":"2023-01-31T05:18:34Z","title":"Recurrent Structure Attention Guidance for Depth Super-Resolution","summary":"  Image guidance is an effective strategy for depth super-resolution.\nGenerally, most existing methods employ hand-crafted operators to decompose the\nhigh-frequency (HF) and low-frequency (LF) ingredients from low-resolution\ndepth maps and guide the HF ingredients by directly concatenating them with\nimage features. However, the hand-designed operators usually cause inferior HF\nmaps (e.g., distorted or structurally missing) due to the diverse appearance of\ncomplex depth maps. Moreover, the direct concatenation often results in weak\nguidance because not all image features have a positive effect on the HF maps.\nIn this paper, we develop a recurrent structure attention guided (RSAG)\nframework, consisting of two important parts. First, we introduce a deep\ncontrastive network with multi-scale filters for adaptive frequency-domain\nseparation, which adopts contrastive networks from large filters to small ones\nto calculate the pixel contrasts for adaptive high-quality HF predictions.\nSecond, instead of the coarse concatenation guidance, we propose a recurrent\nstructure attention block, which iteratively utilizes the latest depth\nestimation and the image features to jointly select clear patterns and\nboundaries, aiming at providing refined guidance for accurate depth recovery.\nIn addition, we fuse the features of HF maps to enhance the edge structures in\nthe decomposed LF maps. Extensive experiments show that our approach obtains\nsuperior performance compared with state-of-the-art depth super-resolution\nmethods.\n","authors":["Jiayi Yuan","Haobo Jiang","Xiang Li","Jianjun Qian","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2301.13419v1.pdf","comment":"Accepted by AAAI-2023"},{"id":"http://arxiv.org/abs/2301.13418v1","updated":"2023-01-31T05:14:49Z","published":"2023-01-31T05:14:49Z","title":"BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete\n  Annotations","summary":"  Methods to detect malignant lesions from screening mammograms are usually\ntrained with fully annotated datasets, where images are labelled with the\nlocalisation and classification of cancerous lesions. However, real-world\nscreening mammogram datasets commonly have a subset that is fully annotated and\nanother subset that is weakly annotated with just the global classification\n(i.e., without lesion localisation). Given the large size of such datasets,\nresearchers usually face a dilemma with the weakly annotated subset: to not use\nit or to fully annotate it. The first option will reduce detection accuracy\nbecause it does not use the whole dataset, and the second option is too\nexpensive given that the annotation needs to be done by expert radiologists. In\nthis paper, we propose a middle-ground solution for the dilemma, which is to\nformulate the training as a weakly- and semi-supervised learning problem that\nwe refer to as malignant breast lesion detection with incomplete annotations.\nTo address this problem, our new method comprises two stages, namely: 1)\npre-training a multi-view mammogram classifier with weak supervision from the\nwhole dataset, and 2) extending the trained classifier to become a multi-view\ndetector that is trained with semi-supervised student-teacher learning, where\nthe training set contains fully and weakly-annotated mammograms. We provide\nextensive detection results on two real-world screening mammogram datasets\ncontaining incomplete annotations, and show that our proposed approach achieves\nstate-of-the-art results in the detection of malignant breast lesions with\nincomplete annotations.\n","authors":["Yuanhong Chen","Yuyuan Liu","Chong Wang","Michael Elliott","Chun Fung Kwok","Carlos Pe na-Solorzano","Yu Tian","Fengbei Liu","Helen Frazer","Davis J. McCarthy","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2301.13418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13416v1","updated":"2023-01-31T05:13:55Z","published":"2023-01-31T05:13:55Z","title":"Structure Flow-Guided Network for Real Depth Super-Resolution","summary":"  Real depth super-resolution (DSR), unlike synthetic settings, is a\nchallenging task due to the structural distortion and the edge noise caused by\nthe natural degradation in real-world low-resolution (LR) depth maps. These\ndefeats result in significant structure inconsistency between the depth map and\nthe RGB guidance, which potentially confuses the RGB-structure guidance and\nthereby degrades the DSR quality. In this paper, we propose a novel structure\nflow-guided DSR framework, where a cross-modality flow map is learned to guide\nthe RGB-structure information transferring for precise depth upsampling.\nSpecifically, our framework consists of a cross-modality flow-guided upsampling\nnetwork (CFUNet) and a flow-enhanced pyramid edge attention network (PEANet).\nCFUNet contains a trilateral self-attention module combining both the geometric\nand semantic correlations for reliable cross-modality flow learning. Then, the\nlearned flow maps are combined with the grid-sampling mechanism for coarse\nhigh-resolution (HR) depth prediction. PEANet targets at integrating the\nlearned flow map as the edge attention into a pyramid network to hierarchically\nlearn the edge-focused guidance feature for depth edge refinement. Extensive\nexperiments on real and synthetic DSR datasets verify that our approach\nachieves excellent performance compared to state-of-the-art methods.\n","authors":["Jiayi Yuan","Haobo Jiang","Xiang Li","Jianjun Qian","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2301.13416v1.pdf","comment":"Accepted by AAAI-2023"},{"id":"http://arxiv.org/abs/2209.14074v2","updated":"2023-01-31T05:06:47Z","published":"2022-09-28T13:15:03Z","title":"Recipro-CAM: Gradient-free reciprocal class activation map","summary":"  Convolutional neural network (CNN) becomes one of the most popular and\nprominent deep learning architectures for computer vision, but its black box\nfeature hides the internal prediction process. For this reason, AI\npractitioners have shed light on explainable AI to provide the interpretability\nof the model behavior. In particular, class activation map (CAM) and Grad-CAM\nbased methods have shown promise results, but they have architectural\nlimitation or gradient computing burden. To resolve these, Score-CAM has been\nsuggested as a gradient-free method, however, it requires more execution time\ncompared to CAM or Grad-CAM based methods. Therefore, we propose a lightweight\narchitecture and gradient free Reciprocal CAM (Recipro-CAM) by spatially\nmasking the extracted feature maps to exploit the correlation between\nactivation maps and network outputs. With the proposed method, we achieved the\ngains of 1.78 - 3.72% in the ResNet family compared to Score-CAM in Average\nDrop- Coherence-Complexity (ADCC) metric, excluding the VGG-16 (1.39% drop). In\naddition, Recipro-CAM exhibits a saliency map generation rate similar to\nGrad-CAM and approximately 148 times faster than Score-CAM. The source code of\nRecipro-CAM is available at our data analysis framework.\n","authors":["Seok-Yong Byun","Wonju Lee"],"pdf_url":"https://arxiv.org/pdf/2209.14074v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13411v1","updated":"2023-01-31T04:58:21Z","published":"2023-01-31T04:58:21Z","title":"Few-Shot Object Detection via Variational Feature Aggregation","summary":"  As few-shot object detectors are often trained with abundant base samples and\nfine-tuned on few-shot novel examples,the learned models are usually biased to\nbase classes and sensitive to the variance of novel examples. To address this\nissue, we propose a meta-learning framework with two novel feature aggregation\nschemes. More precisely, we first present a Class-Agnostic Aggregation (CAA)\nmethod, where the query and support features can be aggregated regardless of\ntheir categories. The interactions between different classes encourage\nclass-agnostic representations and reduce confusion between base and novel\nclasses. Based on the CAA, we then propose a Variational Feature Aggregation\n(VFA) method, which encodes support examples into class-level support features\nfor robust feature aggregation. We use a variational autoencoder to estimate\nclass distributions and sample variational features from distributions that are\nmore robust to the variance of support examples. Besides, we decouple\nclassification and regression tasks so that VFA is performed on the\nclassification branch without affecting object localization. Extensive\nexperiments on PASCAL VOC and COCO demonstrate that our method significantly\noutperforms a strong baseline (up to 16\\%) and previous state-of-the-art\nmethods (4\\% in average). Code will be available at:\n\\url{https://github.com/csuhan/VFA}\n","authors":["Jiaming Han","Yuqiang Ren","Jian Ding","Ke Yan","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2301.13411v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2202.13100v4","updated":"2023-01-31T04:55:22Z","published":"2022-02-26T09:55:54Z","title":"SemSup: Semantic Supervision for Simple and Scalable Zero-shot\n  Generalization","summary":"  Zero-shot learning is the problem of predicting instances over classes not\nseen during training. One approach to zero-shot learning is providing auxiliary\nclass information to the model. Prior work along this vein have largely used\nexpensive per-instance annotation or singular class-level descriptions, but\nper-instance descriptions are hard to scale and single class descriptions may\nnot be rich enough. Furthermore, these works have used natural-language\ndescriptions exclusively, simple bi-encoders models, and modality or\ntask-specific methods. These approaches have several limitations: text\nsupervision may not always be available or optimal and bi-encoders may only\nlearn coarse relations between inputs and class descriptions. In this work, we\npresent SemSup, a novel approach that uses (1) a scalable multiple description\nsampling method which improves performance over single descriptions, (2)\nalternative description formats such as JSON that are easy to generate and\noutperform text on certain settings, and (3) hybrid lexical-semantic similarity\nto leverage fine-grained information in class descriptions. We demonstrate the\neffectiveness of SemSup across four datasets, two modalities, and three\ngeneralization settings. For example, across text and image datasets, SemSup\nincreases unseen class generalization accuracy by 15 points on average compared\nto the closest baseline.\n","authors":["Austin W. Hanjie","Ameet Deshpande","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2202.13100v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13403v1","updated":"2023-01-31T04:42:47Z","published":"2023-01-31T04:42:47Z","title":"A Modular Multi-stage Lightweight Graph Transformer Network for Human\n  Pose and Shape Estimation from 2D Human Pose","summary":"  In this research, we address the challenge faced by existing deep\nlearning-based human mesh reconstruction methods in balancing accuracy and\ncomputational efficiency. These methods typically prioritize accuracy,\nresulting in large network sizes and excessive computational complexity, which\nmay hinder their practical application in real-world scenarios, such as virtual\nreality systems. To address this issue, we introduce a modular multi-stage\nlightweight graph-based transformer network for human pose and shape estimation\nfrom 2D human pose, a pose-based human mesh reconstruction approach that\nprioritizes computational efficiency without sacrificing reconstruction\naccuracy. Our method consists of a 2D-to-3D lifter module that utilizes graph\ntransformers to analyze structured and implicit joint correlations in 2D human\nposes, and a mesh regression module that combines the extracted pose features\nwith a mesh template to produce the final human mesh parameters.\n","authors":["Ayman Ali","Ekkasit Pinyoanuntapong","Pu Wang","Mohsen Dorodchi"],"pdf_url":"https://arxiv.org/pdf/2301.13403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13402v1","updated":"2023-01-31T04:38:42Z","published":"2023-01-31T04:38:42Z","title":"ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing","summary":"  The StyleGAN family succeed in high-fidelity image generation and allow for\nflexible and plausible editing of generated images by manipulating the\nsemantic-rich latent style space.However, projecting a real image into its\nlatent space encounters an inherent trade-off between inversion quality and\neditability. Existing encoder-based or optimization-based StyleGAN inversion\nmethods attempt to mitigate the trade-off but see limited performance. To\nfundamentally resolve this problem, we propose a novel two-phase framework by\ndesignating two separate networks to tackle editing and reconstruction\nrespectively, instead of balancing the two. Specifically, in Phase I, a\nW-space-oriented StyleGAN inversion network is trained and used to perform\nimage inversion and editing, which assures the editability but sacrifices\nreconstruction quality. In Phase II, a carefully designed rectifying network is\nutilized to rectify the inversion errors and perform ideal reconstruction.\nExperimental results show that our approach yields near-perfect reconstructions\nwithout sacrificing the editability, thus allowing accurate manipulation of\nreal images. Further, we evaluate the performance of our rectifying network,\nand see great generalizability towards unseen manipulation types and\nout-of-domain images.\n","authors":["Bingchuan Li","Tianxiang Ma","Peng Zhang","Miao Hua","Wei Liu","Qian He","Zili Yi"],"pdf_url":"https://arxiv.org/pdf/2301.13402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12093v2","updated":"2023-01-31T04:02:40Z","published":"2023-01-28T05:18:13Z","title":"Local Contrast and Global Contextual Information Make Infrared Small\n  Object Salient Again","summary":"  Infrared small object detection (ISOS) aims to segment small objects only\ncovered with several pixels from clutter background in infrared images. It's of\ngreat challenge due to: 1) small objects lack of sufficient intensity, shape\nand texture information; 2) small objects are easily lost in the process where\ndetection models, say deep neural networks, obtain high-level semantic features\nand image-level receptive fields through successive downsampling. This paper\nproposes a reliable detection model for ISOS, dubbed UCFNet, which can handle\nwell the two issues. It builds upon central difference convolution (CDC) and\nfast Fourier convolution (FFC). On one hand, CDC can effectively guide the\nnetwork to learn the contrast information between small objects and the\nbackground, as the contrast information is very essential in human visual\nsystem dealing with the ISOS task. On the other hand, FFC can gain image-level\nreceptive fields and extract global information while preventing small objects\nfrom being overwhelmed.Experiments on several public datasets demonstrate that\nour method significantly outperforms the state-of-the-art ISOS models, and can\nprovide useful guidelines for designing better ISOS deep models. Codes will be\navailable soon.\n","authors":["Chenyi Wang","Huan Wang","Peiwen Pan"],"pdf_url":"https://arxiv.org/pdf/2301.12093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13082v2","updated":"2023-01-31T03:50:44Z","published":"2023-01-30T17:22:10Z","title":"PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying\n  Fused Chinese Painting and Calligraphy","summary":"  AI-Generated Content (AIGC) has recently gained a surge in popularity,\npowered by its high efficiency and consistency in production, and its\ncapability of being customized and diversified. The cross-modality nature of\nthe representation learning mechanism in most AIGC technology allows for more\nfreedom and flexibility in exploring new types of art that would be impossible\nin the past. Inspired by the pictogram subset of Chinese characters, we\nproposed PaCaNet, a CycleGAN-based pipeline for producing novel artworks that\nfuse two different art types, traditional Chinese painting and calligraphy. In\nan effort to produce stable and diversified output, we adopted three main\ntechnical innovations: 1. Using one-shot learning to increase the creativity of\npre-trained models and diversify the content of the fused images. 2.\nControlling the preference over generated Chinese calligraphy by freezing\nrandomly sampled parameters in pre-trained models. 3. Using a regularization\nmethod to encourage the models to produce images similar to Chinese paintings.\nFurthermore, we conducted a systematic study to explore the performance of\nPaCaNet in diversifying fused Chinese painting and calligraphy, which showed\nsatisfying results. In conclusion, we provide a new direction of creating arts\nby fusing the visual information in paintings and the stroke features in\nChinese calligraphy. Our approach creates a unique aesthetic experience rooted\nin the origination of Chinese hieroglyph characters. It is also a unique\nopportunity to delve deeper into traditional artwork and, in doing so, to\ncreate a meaningful impact on preserving and revitalizing traditional heritage.\n","authors":["Zuhao Yang","Huajun Bai","Zhang Luo","Yang Xu","Wei Pang","Yue Wang","Yisheng Yuan","Yingfang Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.13082v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13385v1","updated":"2023-01-31T03:31:43Z","published":"2023-01-31T03:31:43Z","title":"Fisheye traffic data set of point center markers","summary":"  This study presents an open data-market platform and a dataset containing\n160,000 markers and 18,000 images. We hope that this dataset will bring more\nnew data value and applications In this paper, we introduce the format and\nusage of the dataset, and we show a demonstration of deep learning vehicle\ndetection trained by this dataset.\n","authors":["Chung-I Huang","Wei-Yu Chen","Wei Jan Ko","Jih-Sheng Chang","Chen-Kai Sun","Hui Hung Yu","Fang-Pang Lin"],"pdf_url":"https://arxiv.org/pdf/2301.13385v1.pdf","comment":"https://youtu.be/sjUQ-Ayxxtk"},{"id":"http://arxiv.org/abs/2210.01891v2","updated":"2023-01-31T03:21:13Z","published":"2022-10-04T20:28:38Z","title":"Adaptively Weighted Data Augmentation Consistency Regularization for\n  Robust Optimization under Concept Shift","summary":"  Concept shift is a prevailing problem in natural tasks like medical image\nsegmentation where samples usually come from different subpopulations with\nvariant correlations between features and labels. One common type of concept\nshift in medical image segmentation is the \"information imbalance\" between\nlabel-sparse samples with few (if any) segmentation labels and label-dense\nsamples with plentiful labeled pixels. Existing distributionally robust\nalgorithms have focused on adaptively truncating/down-weighting the \"less\ninformative\" (i.e., label-sparse in our context) samples. To exploit data\nfeatures of label-sparse samples more efficiently, we propose an adaptively\nweighted online optimization algorithm -- AdaWAC -- to incorporate data\naugmentation consistency regularization in sample reweighting. Our method\nintroduces a set of trainable weights to balance the supervised loss and\nunsupervised consistency regularization of each sample separately. At the\nsaddle point of the underlying objective, the weights assign label-dense\nsamples to the supervised loss and label-sparse samples to the unsupervised\nconsistency regularization. We provide a convergence guarantee by recasting the\noptimization as online mirror descent on a saddle point problem. Our empirical\nresults demonstrate that AdaWAC not only enhances the segmentation performance\nand sample efficiency but also improves the robustness to concept shift on\nvarious medical image segmentation tasks with different UNet-style backbones.\n","authors":["Yijun Dong","Yuege Xie","Rachel Ward"],"pdf_url":"https://arxiv.org/pdf/2210.01891v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13384v1","updated":"2023-01-31T03:21:08Z","published":"2023-01-31T03:21:08Z","title":"GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition","summary":"  mmWave radar-based gait recognition is a novel user identification method\nthat captures human gait biometrics from mmWave radar return signals. This\ntechnology offers privacy protection and is resilient to weather and lighting\nconditions. However, its generalization performance is yet unknown and limits\nits practical deployment. To address this problem, in this paper, a\nnon-synthetic dataset is collected and analyzed to reveal the presence of\nspatial and temporal domain shifts in mmWave gait biometric data, which\nsignificantly impacts identification accuracy. To address this issue, a novel\nself-aligned domain adaptation method called GaitSADA is proposed. GaitSADA\nimproves system generalization performance by using a two-stage semi-supervised\nmodel training approach. The first stage uses semi-supervised contrastive\nlearning and the second stage uses semi-supervised consistency training with\ncentroid alignment. Extensive experiments show that GaitSADA outperforms\nrepresentative domain adaptation methods by an average of 15.41% in low data\nregimes.\n","authors":["Ekkasit Pinyoanuntapong","Ayman Ali","Kalvik Jakkala","Pu Wang","Minwoo Lee","Qucheng Peng","Chen Chen","Zhi Sun"],"pdf_url":"https://arxiv.org/pdf/2301.13384v1.pdf","comment":"Submitted to ACM Transactions on Sensor Networks (TOSN)"},{"id":"http://arxiv.org/abs/2301.13381v1","updated":"2023-01-31T03:06:47Z","published":"2023-01-31T03:06:47Z","title":"When Source-Free Domain Adaptation Meets Learning with Noisy Labels","summary":"  Recent state-of-the-art source-free domain adaptation (SFDA) methods have\nfocused on learning meaningful cluster structures in the feature space, which\nhave succeeded in adapting the knowledge from source domain to unlabeled target\ndomain without accessing the private source data. However, existing methods\nrely on the pseudo-labels generated by source models that can be noisy due to\ndomain shift. In this paper, we study SFDA from the perspective of learning\nwith label noise (LLN). Unlike the label noise in the conventional LLN\nscenario, we prove that the label noise in SFDA follows a different\ndistribution assumption. We also prove that such a difference makes existing\nLLN methods that rely on their distribution assumptions unable to address the\nlabel noise in SFDA. Empirical evidence suggests that only marginal\nimprovements are achieved when applying the existing LLN methods to solve the\nSFDA problem. On the other hand, although there exists a fundamental difference\nbetween the label noise in the two scenarios, we demonstrate theoretically that\nthe early-time training phenomenon (ETP), which has been previously observed in\nconventional label noise settings, can also be observed in the SFDA problem.\nExtensive experiments demonstrate significant improvements to existing SFDA\nalgorithms by leveraging ETP to address the label noise in SFDA.\n","authors":["Li Yi","Gezheng Xu","Pengcheng Xu","Jiaqi Li","Ruizhi Pu","Charles Ling","A. Ian McLeod","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13381v1.pdf","comment":"33 pages, 16 figures, accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2301.12688v2","updated":"2023-01-31T03:02:25Z","published":"2023-01-30T06:37:35Z","title":"Dynamic Storyboard Generation in an Engine-based Virtual Environment for\n  Video Production","summary":"  Amateurs working on mini-films and short-form videos usually spend lots of\ntime and effort on the multi-round complicated process of setting and adjusting\nscenes, plots, and cameras to deliver satisfying video shots. We present\nVirtual Dynamic Storyboard (VDS) to allow users storyboarding shots in virtual\nenvironments, where the filming staff can easily test the settings of shots\nbefore the actual filming. VDS runs on a \"propose-simulate-discriminate\" mode:\nGiven a formatted story script and a camera script as input, it generates\nseveral character animation and camera movement proposals following predefined\nstory and cinematic rules to allow an off-the-shelf simulation engine to render\nvideos. To pick up the top-quality dynamic storyboard from the candidates, we\nequip it with a shot ranking discriminator based on shot quality criteria\nlearned from professional manual-created data. VDS is comprehensively validated\nvia extensive experiments and user studies, demonstrating its efficiency,\neffectiveness, and great potential in assisting amateur video production.\n","authors":["Anyi Rao","Xuekun Jiang","Yuwei Guo","Linning Xu","Lei Yang","Libiao Jin","Dahua Lin","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2301.12688v2.pdf","comment":"Project page: https://virtualfilmstudio.github.io/"},{"id":"http://arxiv.org/abs/2301.13376v1","updated":"2023-01-31T02:46:57Z","published":"2023-01-31T02:46:57Z","title":"Quantized Neural Networks for Low-Precision Accumulation with Guaranteed\n  Overflow Avoidance","summary":"  We introduce a quantization-aware training algorithm that guarantees avoiding\nnumerical overflow when reducing the precision of accumulators during\ninference. We leverage weight normalization as a means of constraining\nparameters during training using accumulator bit width bounds that we derive.\nWe evaluate our algorithm across multiple quantized models that we train for\ndifferent tasks, showing that our approach can reduce the precision of\naccumulators while maintaining model accuracy with respect to a floating-point\nbaseline. We then show that this reduction translates to increased design\nefficiency for custom FPGA-based accelerators. Finally, we show that our\nalgorithm not only constrains weights to fit into an accumulator of\nuser-defined bit width, but also increases the sparsity and compressibility of\nthe resulting weights. Across all of our benchmark models trained with 8-bit\nweights and activations, we observe that constraining the hidden layers of\nquantized neural networks to fit into 16-bit accumulators yields an average\n98.2% sparsity with an estimated compression rate of 46.5x all while\nmaintaining 99.2% of the floating-point performance.\n","authors":["Ian Colbert","Alessandro Pappalardo","Jakoba Petri-Koenig"],"pdf_url":"https://arxiv.org/pdf/2301.13376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13371v1","updated":"2023-01-31T02:31:18Z","published":"2023-01-31T02:31:18Z","title":"Demystifying Disagreement-on-the-Line in High Dimensions","summary":"  Evaluating the performance of machine learning models under distribution\nshift is challenging, especially when we only have unlabeled data from the\nshifted (target) domain, along with labeled data from the original (source)\ndomain. Recent work suggests that the notion of disagreement, the degree to\nwhich two models trained with different randomness differ on the same input, is\na key to tackle this problem. Experimentally, disagreement and prediction error\nhave been shown to be strongly connected, which has been used to estimate model\nperformance. Experiments have lead to the discovery of the\ndisagreement-on-the-line phenomenon, whereby the classification error under the\ntarget domain is often a linear function of the classification error under the\nsource domain; and whenever this property holds, disagreement under the source\nand target domain follow the same linear relation. In this work, we develop a\ntheoretical foundation for analyzing disagreement in high-dimensional random\nfeatures regression; and study under what conditions the\ndisagreement-on-the-line phenomenon occurs in our setting. Experiments on\nCIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and\nsupport the universality of the theoretical findings.\n","authors":["Donghwan Lee","Behrad Moniri","Xinmeng Huang","Edgar Dobriban","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2301.13371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05299v3","updated":"2023-01-31T02:30:06Z","published":"2022-09-12T15:05:41Z","title":"Deep Convolutional Pooling Transformer for Deepfake Detection","summary":"  Recently, Deepfake has drawn considerable public attention due to security\nand privacy concerns in social media digital forensics. As the wildly spreading\nDeepfake videos on the Internet become more realistic, traditional detection\ntechniques have failed in distinguishing between real and fake. Most existing\ndeep learning methods mainly focus on local features and relations within the\nface image using convolutional neural networks as a backbone. However, local\nfeatures and relations are insufficient for model training to learn enough\ngeneral information for Deepfake detection. Therefore, the existing Deepfake\ndetection methods have reached a bottleneck to further improve the detection\nperformance. To address this issue, we propose a deep convolutional Transformer\nto incorporate the decisive image features both locally and globally.\nSpecifically, we apply convolutional pooling and re-attention to enrich the\nextracted features and enhance efficacy. Moreover, we employ the barely\ndiscussed image keyframes in model training for performance improvement and\nvisualize the feature quantity gap between the key and normal image frames\ncaused by video compression. We finally illustrate the transferability with\nextensive experiments on several Deepfake benchmark datasets. The proposed\nsolution consistently outperforms several state-of-the-art baselines on both\nwithin- and cross-dataset experiments.\n","authors":["Tianyi Wang","Harry Cheng","Kam Pui Chow","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2209.05299v3.pdf","comment":"13 pages for peer review"},{"id":"http://arxiv.org/abs/2301.13366v1","updated":"2023-01-31T02:12:33Z","published":"2023-01-31T02:12:33Z","title":"CaraNet: Context Axial Reverse Attention Network for Segmentation of\n  Small Medical Objects","summary":"  Segmenting medical images accurately and reliably is important for disease\ndiagnosis and treatment. It is a challenging task because of the wide variety\nof objects' sizes, shapes, and scanning modalities. Recently, many\nconvolutional neural networks (CNN) have been designed for segmentation tasks\nand achieved great success. Few studies, however, have fully considered the\nsizes of objects, and thus most demonstrate poor performance for small objects\nsegmentation. This can have a significant impact on the early detection of\ndiseases. This paper proposes a Context Axial Reverse Attention Network\n(CaraNet) to improve the segmentation performance on small objects compared\nwith several recent state-of-the-art models. CaraNet applies axial reserve\nattention (ARA) and channel-wise feature pyramid (CFP) module to dig feature\ninformation of small medical object. And we evaluate our model by six different\nmeasurement metrics. We test our CaraNet on brain tumor (BraTS 2018) and polyp\n(Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300, and ETIS-LaribPolypDB)\nsegmentation datasets. Our CaraNet achieves the top-rank mean Dice segmentation\naccuracy, and results show a distinct advantage of CaraNet in the segmentation\nof small medical objects.\n","authors":["Ange Lou","Shuyue Guan","Murray Loew"],"pdf_url":"https://arxiv.org/pdf/2301.13366v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2108.07368"},{"id":"http://arxiv.org/abs/2207.11727v2","updated":"2023-01-31T02:09:16Z","published":"2022-07-24T12:14:48Z","title":"Can we achieve robustness from data alone?","summary":"  We introduce a meta-learning algorithm for adversarially robust\nclassification. The proposed method tries to be as model agnostic as possible\nand optimizes a dataset prior to its deployment in a machine learning system,\naiming to effectively erase its non-robust features. Once the dataset has been\ncreated, in principle no specialized algorithm (besides standard gradient\ndescent) is needed to train a robust model. We formulate the data optimization\nprocedure as a bi-level optimization problem on kernel regression, with a class\nof kernels that describe infinitely wide neural nets (Neural Tangent Kernels).\nWe present extensive experiments on standard computer vision benchmarks using a\nvariety of different models, demonstrating the effectiveness of our method,\nwhile also pointing out its current shortcomings. In parallel, we revisit prior\nwork that also focused on the problem of data optimization for robust\nclassification \\citep{Ily+19}, and show that being robust to adversarial\nattacks after standard (gradient descent) training on a suitable dataset is\nmore challenging than previously thought.\n","authors":["Nikolaos Tsilivis","Jingtong Su","Julia Kempe"],"pdf_url":"https://arxiv.org/pdf/2207.11727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12935v2","updated":"2023-01-31T01:46:08Z","published":"2023-01-30T14:32:47Z","title":"ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion\n  Probabilistic Models","summary":"  Though denoising diffusion probabilistic models (DDPMs) have achieved\nremarkable generation results, the low sampling efficiency of DDPMs still\nlimits further applications. Since DDPMs can be formulated as diffusion\nordinary differential equations (ODEs), various fast sampling methods can be\nderived from solving diffusion ODEs. However, we notice that previous sampling\nmethods with fixed analytical form are not robust with the error in the noise\nestimated from pretrained diffusion models. In this work, we construct an\nerror-robust Adams solver (ERA-Solver), which utilizes the implicit Adams\nnumerical method that consists of a predictor and a corrector. Different from\nthe traditional predictor based on explicit Adams methods, we leverage a\nLagrange interpolation function as the predictor, which is further enhanced\nwith an error-robust strategy to adaptively select the Lagrange bases with\nlower error in the estimated noise. Experiments on Cifar10, LSUN-Church, and\nLSUN-Bedroom datasets demonstrate that our proposed ERA-Solver achieves 5.14,\n9.42, and 9.69 Fenchel Inception Distance (FID) for image generation, with only\n10 network evaluations.\n","authors":["Shengmeng Li","Luping Liu","Zenghao Chai","Runnan Li","Xu Tan"],"pdf_url":"https://arxiv.org/pdf/2301.12935v2.pdf","comment":"Typo Error"},{"id":"http://arxiv.org/abs/2301.13361v1","updated":"2023-01-31T01:31:43Z","published":"2023-01-31T01:31:43Z","title":"Iterative Loop Learning Combining Self-Training and Active Learning for\n  Domain Adaptive Semantic Segmentation","summary":"  Recently, self-training and active learning have been proposed to alleviate\nthis problem. Self-training can improve model accuracy with massive unlabeled\ndata, but some pseudo labels containing noise would be generated with limited\nor imbalanced training data. And there will be suboptimal models if human\nguidance is absent. Active learning can select more effective data to\nintervene, while the model accuracy can not be improved because the massive\nunlabeled data are not used. And the probability of querying sub-optimal\nsamples will increase when the domain difference is too large, increasing\nannotation cost. This paper proposes an iterative loop learning method\ncombining Self-Training and Active Learning (STAL) for domain adaptive semantic\nsegmentation. The method first uses self-training to learn massive unlabeled\ndata to improve model accuracy and provide more accurate selection models for\nactive learning. Secondly, combined with the sample selection strategy of\nactive learning, manual intervention is used to correct the self-training\nlearning. Iterative loop to achieve the best performance with minimal label\ncost. Extensive experiments show that our method establishes state-of-the-art\nperformance on tasks of GTAV to Cityscapes, SYNTHIA to Cityscapes, improving by\n4.9% mIoU and 5.2% mIoU, compared to the previous best method, respectively.\nCode will be available.\n","authors":["Licong Guan","Xue Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.13361v1.pdf","comment":"11 pages,5 figures"},{"id":"http://arxiv.org/abs/2301.13360v1","updated":"2023-01-31T01:26:17Z","published":"2023-01-31T01:26:17Z","title":"Skeleton-based Human Action Recognition via Convolutional Neural\n  Networks (CNN)","summary":"  Recently, there has been a remarkable increase in the interest towards\nskeleton-based action recognition within the research community, owing to its\nvarious advantageous features, including computational efficiency,\nrepresentative features, and illumination invariance. Despite this, researchers\ncontinue to explore and investigate the most optimal way to represent human\nactions through skeleton representation and the extracted features. As a\nresult, the growth and availability of human action recognition datasets have\nrisen substantially. In addition, deep learning-based algorithms have gained\nwidespread popularity due to the remarkable advancements in various computer\nvision tasks. Most state-of-the-art contributions in skeleton-based action\nrecognition incorporate a Graph Neural Network (GCN) architecture for\nrepresenting the human body and extracting features. Our research demonstrates\nthat Convolutional Neural Networks (CNNs) can attain comparable results to GCN,\nprovided that the proper training techniques, augmentations, and optimizers are\napplied. Our approach has been rigorously validated, and we have achieved a\nscore of 95% on the NTU-60 dataset\n","authors":["Ayman Ali","Ekkasit Pinyoanuntapong","Pu Wang","Mohsen Dorodchi"],"pdf_url":"https://arxiv.org/pdf/2301.13360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13359v1","updated":"2023-01-31T01:24:45Z","published":"2023-01-31T01:24:45Z","title":"IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing","summary":"  Image anomaly detection (IAD) is an emerging and vital computer vision task\nin industrial manufacturing (IM). Recently many advanced algorithms have been\npublished, but their performance deviates greatly. We realize that the lack of\nactual IM settings most probably hinders the development and usage of these\nmethods in real-world applications. As far as we know, IAD methods are not\nevaluated systematically. As a result, this makes it difficult for researchers\nto analyze them because they are designed for different or special cases. To\nsolve this problem, we first propose a uniform IM setting to assess how well\nthese algorithms perform, which includes several aspects, i.e., various levels\nof supervision (unsupervised vs. semi-supervised), few-shot learning, continual\nlearning, noisy labels, memory usage, and inference speed. Moreover, we\nskillfully build a comprehensive image anomaly detection benchmark (IM-IAD)\nthat includes 16 algorithms on 7 mainstream datasets with uniform settings. Our\nextensive experiments (17,017 in total) provide in-depth insights for IAD\nalgorithm redesign or selection under the IM setting. Next, the proposed\nbenchmark IM-IAD gives challenges as well as directions for the future. To\nfoster reproducibility and accessibility, the source code of IM-IAD is uploaded\non the website, https://github.com/M-3LAB/IM-IAD.\n","authors":["Guoyang Xie","Jinbao Wang","Jiaqi Liu","Jiayi Lyu","Yong Liu","Chengjie Wang","Feng Zheng","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2301.13359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13358v1","updated":"2023-01-31T01:24:34Z","published":"2023-01-31T01:24:34Z","title":"Hierarchical Disentangled Representation for Invertible Image Denoising\n  and Beyond","summary":"  Image denoising is a typical ill-posed problem due to complex degradation.\nLeading methods based on normalizing flows have tried to solve this problem\nwith an invertible transformation instead of a deterministic mapping. However,\nthe implicit bijective mapping is not explored well. Inspired by a latent\nobservation that noise tends to appear in the high-frequency part of the image,\nwe propose a fully invertible denoising method that injects the idea of\ndisentangled learning into a general invertible neural network to split noise\nfrom the high-frequency part. More specifically, we decompose the noisy image\ninto clean low-frequency and hybrid high-frequency parts with an invertible\ntransformation and then disentangle case-specific noise and high-frequency\ncomponents in the latent space. In this way, denoising is made tractable by\ninversely merging noiseless low and high-frequency parts. Furthermore, we\nconstruct a flexible hierarchical disentangling framework, which aims to\ndecompose most of the low-frequency image information while disentangling noise\nfrom the high-frequency part in a coarse-to-fine manner. Extensive experiments\non real image denoising, JPEG compressed artifact removal, and medical low-dose\nCT image restoration have demonstrated that the proposed method achieves\ncompeting performance on both quantitative metrics and visual quality, with\nsignificantly less computational cost.\n","authors":["Wenchao Du","Hu Chen","Yi Zhang","H. Yang"],"pdf_url":"https://arxiv.org/pdf/2301.13358v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2301.11482v2","updated":"2023-01-31T01:21:25Z","published":"2023-01-27T01:11:42Z","title":"Diffusion Denoising for Low-Dose-CT Model","summary":"  Low-dose Computed Tomography (LDCT) reconstruction is an important task in\nmedical image analysis. Recent years have seen many deep learning based\nmethods, proved to be effective in this area. However, these methods mostly\nfollow a supervised architecture, which needs paired CT image of full dose and\nquarter dose, and the solution is highly dependent on specific measurements. In\nthis work, we introduce Denoising Diffusion LDCT Model, dubbed as DDLM,\ngenerating noise-free CT image using conditioned sampling. DDLM uses pretrained\nmodel, and need no training nor tuning process, thus our proposal is in\nunsupervised manner. Experiments on LDCT images have shown comparable\nperformance of DDLM using less inference time, surpassing other\nstate-of-the-art methods, proving both accurate and efficient. Implementation\ncode will be set to public soon.\n","authors":["Runyi Li"],"pdf_url":"https://arxiv.org/pdf/2301.11482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01917v2","updated":"2023-01-31T01:17:32Z","published":"2023-01-05T05:32:22Z","title":"Small Moving Object Detection Algorithm in Surveillance Video Based on\n  Motion Information","summary":"  A Small Moving Object Detection algorithm Based on Motion Information\n(SMOD-BMI) is proposed to detect small moving objects with a low\nSignal-to-Noise Ratio (SNR) in surveillance video. Firstly, a ConvLSTM-PAN\nmodel structure is designed to capture suspicious small moving objects, in\nwhich the Convolutional Long and Short Time Memory (ConvLSTM) network\naggregated the Spatio-temporal features of the adjacent multi-frame small\nmoving object and the Path Aggregation Network (PAN) located the suspicious\nsmall moving objects. Then, an object tracking algorithm is used to track\nsuspicious small objects and calculate their Motion Range (MR). At the same\ntime, the size of the MR of the suspicious small moving object is adjusted\nadaptively according to its speed of movement (specifically, if the object\nmoves slowly, its MR will be expanded according to the speed of the object to\nensure the necessary environmental information of the object). Adaptive\nSpatio-temporal Cubes (ASt-Cubes) of the small moving objects are generated to\nensure that the SNR of the moving objects is improved, and the necessary\nenvironmental information is retained adaptively. Finally, a LightWeight\nU-Shape Net (LW-USN) based on ASt-Cubes is designed to detect small moving\nobjects, which rejects false detections and returns the position of small\nmoving objects. This paper uses the bird in the surveillance video as the\nexperimental data set to verify the algorithm's performance. The experimental\nresults show that the proposed small moving object detection method based on\nmotion information in surveillance video can effectively reduce the missed and\nfalse detection rate of small moving objects.\n","authors":["Ziwei Sun","Zexi Hua","Hengcao Li","Haiyan Zhong"],"pdf_url":"https://arxiv.org/pdf/2301.01917v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13356v1","updated":"2023-01-31T01:17:03Z","published":"2023-01-31T01:17:03Z","title":"Inference Time Evidences of Adversarial Attacks for Forensic on\n  Transformers","summary":"  Vision Transformers (ViTs) are becoming a very popular paradigm for vision\ntasks as they achieve state-of-the-art performance on image classification.\nHowever, although early works implied that this network structure had increased\nrobustness against adversarial attacks, some works argue ViTs are still\nvulnerable. This paper presents our first attempt toward detecting adversarial\nattacks during inference time using the network's input and outputs as well as\nlatent features. We design four quantifications (or derivatives) of input,\noutput, and latent vectors of ViT-based models that provide a signature of the\ninference, which could be beneficial for the attack detection, and empirically\nstudy their behavior over clean samples and adversarial samples. The results\ndemonstrate that the quantifications from input (images) and output (posterior\nprobabilities) are promising for distinguishing clean and adversarial samples,\nwhile latent vectors offer less discriminative power, though they give some\ninsights on how adversarial perturbations work.\n","authors":["Hugo Lemarchant","Liangzi Li","Yiming Qian","Yuta Nakashima","Hajime Nagahara"],"pdf_url":"https://arxiv.org/pdf/2301.13356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13343v1","updated":"2023-01-31T00:28:18Z","published":"2023-01-31T00:28:18Z","title":"Few-Shot Image-to-Semantics Translation for Policy Transfer in\n  Reinforcement Learning","summary":"  We investigate policy transfer using image-to-semantics translation to\nmitigate learning difficulties in vision-based robotics control agents. This\nproblem assumes two environments: a simulator environment with semantics, that\nis, low-dimensional and essential information, as the state space, and a\nreal-world environment with images as the state space. By learning mapping from\nimages to semantics, we can transfer a policy, pre-trained in the simulator, to\nthe real world, thereby eliminating real-world on-policy agent interactions to\nlearn, which are costly and risky. In addition, using image-to-semantics\nmapping is advantageous in terms of the computational efficiency to train the\npolicy and the interpretability of the obtained policy over other types of\nsim-to-real transfer strategies. To tackle the main difficulty in learning\nimage-to-semantics mapping, namely the human annotation cost for producing a\ntraining dataset, we propose two techniques: pair augmentation with the\ntransition function in the simulator environment and active learning. We\nobserved a reduction in the annotation cost without a decline in the\nperformance of the transfer, and the proposed approach outperformed the\nexisting approach without annotation.\n","authors":["Rei Sato","Kazuto Fukuchi","Jun Sakuma","Youhei Akimoto"],"pdf_url":"https://arxiv.org/pdf/2301.13343v1.pdf","comment":"The 2022 International Joint Conference on Neural Networks\n  (IJCNN2022)"},{"id":"http://arxiv.org/abs/2301.13338v1","updated":"2023-01-31T00:06:56Z","published":"2023-01-31T00:06:56Z","title":"Continuous Spatiotemporal Transformers","summary":"  Modeling spatiotemporal dynamical systems is a fundamental challenge in\nmachine learning. Transformer models have been very successful in NLP and\ncomputer vision where they provide interpretable representations of data.\nHowever, a limitation of transformers in modeling continuous dynamical systems\nis that they are fundamentally discrete time and space models and thus have no\nguarantees regarding continuous sampling. To address this challenge, we present\nthe Continuous Spatiotemporal Transformer (CST), a new transformer architecture\nthat is designed for the modeling of continuous systems. This new framework\nguarantees a continuous and smooth output via optimization in Sobolev space. We\nbenchmark CST against traditional transformers as well as other spatiotemporal\ndynamics modeling methods and achieve superior performance in a number of tasks\non synthetic and real systems, including learning brain dynamics from calcium\nimaging data.\n","authors":["Antonio H. de O. Fonseca","Emanuele Zappala","Josue Ortega Caro","David van Dijk"],"pdf_url":"https://arxiv.org/pdf/2301.13338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13449v2","updated":"2023-01-31T22:45:41Z","published":"2022-11-24T07:30:27Z","title":"Fast Sampling of Diffusion Models via Operator Learning","summary":"  Diffusion models have found widespread adoption in various areas. However,\ntheir sampling process is slow because it requires hundreds to thousands of\nnetwork evaluations to emulate a continuous process defined by differential\nequations. In this work, we use neural operators, an efficient method to solve\nthe probability flow differential equations, to accelerate the sampling process\nof diffusion models. Compared to other fast sampling methods that have a\nsequential nature, we are the first to propose parallel decoding method that\ngenerates images with only one model forward pass. We propose \\textit{diffusion\nmodel sampling with neural operator} (DSNO) that maps the initial condition,\ni.e., Gaussian distribution, to the continuous-time solution trajectory of the\nreverse diffusion process. To model the temporal correlations along the\ntrajectory, we introduce temporal convolution layers that are parameterized in\nthe Fourier space into the given diffusion model backbone. We show our method\nachieves state-of-the-art FID of 4.12 for CIFAR-10 and 8.35 for ImageNet-64 in\nthe one-model-evaluation setting.\n","authors":["Hongkai Zheng","Weili Nie","Arash Vahdat","Kamyar Azizzadenesheli","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2211.13449v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00123v1","updated":"2023-01-31T22:04:53Z","published":"2023-01-31T22:04:53Z","title":"Design and Implementation of A Soccer Ball Detection System with\n  Multiple Cameras","summary":"  The detection of small and medium-sized objects in three dimensions has\nalways been a frontier exploration problem. This technology has a very wide\napplication in sports analysis, games, virtual reality, human animation and\nother fields. The traditional three-dimensional small target detection\ntechnology has the disadvantages of high cost, low precision and inconvenience,\nso it is difficult to apply in practice. With the development of machine\nlearning and deep learning, the technology of computer vision algorithms is\nbecoming more mature. Creating an immersive media experience is considered to\nbe a very important research work in sports.\n  The main work is to explore and solve the problem of football detection under\nthe multiple cameras, aiming at the research and implementation of the live\nbroadcast system of football matches. Using multi cameras detects a target ball\nand determines its position in three dimension with the occlusion, motion, low\nillumination of the target object.\n  This paper designed and implemented football detection system under multiple\ncameras for the detection and capture of targets in real-time matches. The main\nwork mainly consists of three parts, football detector, single camera\ndetection, and multi-cameras detection. The system used bundle adjustment to\nobtain the three-dimensional position of the target, and the GPU to accelerates\ndata pre-processing and achieve accurate real-time capture of the target. By\ntesting the system, it shows that the system can accurately detect and capture\nthe moving targets in 3D.\n  In addition, the solution in this paper is reusable for large-scale\ncompetitions, like basketball and soccer. The system framework can be well\ntransplanted into other similar engineering project systems. It has been put\ninto the market.\n","authors":["Lei Li","Tianfang Zhang","Zhongfeng Kang","Wenhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00123v1.pdf","comment":"89 pages"},{"id":"http://arxiv.org/abs/2302.00117v1","updated":"2023-01-31T21:54:15Z","published":"2023-01-31T21:54:15Z","title":"Real Estate Property Valuation using Self-Supervised Vision Transformers","summary":"  The use of Artificial Intelligence (AI) in the real estate market has been\ngrowing in recent years. In this paper, we propose a new method for property\nvaluation that utilizes self-supervised vision transformers, a recent\nbreakthrough in computer vision and deep learning. Our proposed algorithm uses\na combination of machine learning, computer vision and hedonic pricing models\ntrained on real estate data to estimate the value of a given property. We\ncollected and pre-processed a data set of real estate properties in the city of\nBoulder, Colorado and used it to train, validate and test our algorithm. Our\ndata set consisted of qualitative images (including house interiors, exteriors,\nand street views) as well as quantitative features such as the number of\nbedrooms, bathrooms, square footage, lot square footage, property age, crime\nrates, and proximity to amenities. We evaluated the performance of our model\nusing metrics such as Root Mean Squared Error (RMSE). Our findings indicate\nthat these techniques are able to accurately predict the value of properties,\nwith a low RMSE. The proposed algorithm outperforms traditional appraisal\nmethods that do not leverage property images and has the potential to be used\nin real-world applications.\n","authors":["Mahdieh Yazdani","Maziar Raissi"],"pdf_url":"https://arxiv.org/pdf/2302.00117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.08741v2","updated":"2023-01-31T20:49:39Z","published":"2022-01-21T15:16:39Z","title":"Improving Across-Dataset Brain Tissue Segmentation Using Transformer","summary":"  Brain tissue segmentation has demonstrated great utility in quantifying MRI\ndata through Voxel-Based Morphometry and highlighting subtle structural changes\nassociated with various conditions within the brain. However, manual\nsegmentation is highly labor-intensive, and automated approaches have struggled\ndue to properties inherent to MRI acquisition, leaving a great need for an\neffective segmentation tool. Despite the recent success of deep convolutional\nneural networks (CNNs) for brain tissue segmentation, many such solutions do\nnot generalize well to new datasets, which is critical for a reliable solution.\nTransformers have demonstrated success in natural image segmentation and have\nrecently been applied to 3D medical image segmentation tasks due to their\nability to capture long-distance relationships in the input where the local\nreceptive fields of CNNs struggle. This study introduces a novel\nCNN-Transformer hybrid architecture designed for brain tissue segmentation. We\nvalidate our model's performance across four multi-site T1w MRI datasets,\ncovering different vendors, field strengths, scan parameters, time points, and\nneuropsychiatric conditions. In all situations, our model achieved the greatest\ngenerality and reliability. Out method is inherently robust and can serve as a\nvaluable tool for brain-related T1w MRI studies. The code for the TABS network\nis available at: https://github.com/raovish6/TABS.\n","authors":["Vishwanatha M. Rao","Zihan Wan","Soroush Arabshahi","David J. Ma","Pin-Yu Lee","Ye Tian","Xuzhe Zhang","Andrew F. Laine","Jia Guo"],"pdf_url":"https://arxiv.org/pdf/2201.08741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00070v1","updated":"2023-01-31T20:09:33Z","published":"2023-01-31T20:09:33Z","title":"Debiasing Vision-Language Models via Biased Prompts","summary":"  Machine learning models have been shown to inherit biases from their training\ndatasets, which can be particularly problematic for vision-language foundation\nmodels trained on uncurated datasets scraped from the internet. The biases can\nbe amplified and propagated to downstream applications like zero-shot\nclassifiers and text-to-image generative models. In this study, we propose a\ngeneral approach for debiasing vision-language foundation models by projecting\nout biased directions in the text embedding. In particular, we show that\ndebiasing only the text embedding with a calibrated projection matrix suffices\nto yield robust classifiers and fair generative models. The closed-form\nsolution enables easy integration into large-scale pipelines, and empirical\nresults demonstrate that our approach effectively reduces social bias and\nspurious correlation in both discriminative and generative vision-language\nmodels without the need for additional data or training.\n","authors":["Ching-Yao Chuang","Varun Jampani","Yuanzhen Li","Antonio Torralba","Stefanie Jegelka"],"pdf_url":"https://arxiv.org/pdf/2302.00070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01987v2","updated":"2023-01-31T19:52:37Z","published":"2022-10-05T02:28:25Z","title":"ImpressLearn: Continual Learning via Combined Task Impressions","summary":"  This work proposes a new method to sequentially train deep neural networks on\nmultiple tasks without suffering catastrophic forgetting, while endowing it\nwith the capability to quickly adapt to unseen tasks. Starting from existing\nwork on network masking (Wortsman et al., 2020), we show that simply learning a\nlinear combination of a small number of task-specific supermasks (impressions)\non a randomly initialized backbone network is sufficient to both retain\naccuracy on previously learned tasks, as well as achieve high accuracy on\nunseen tasks. In contrast to previous methods, we do not require to generate\ndedicated masks or contexts for each new task, instead leveraging transfer\nlearning to keep per-task parameter overhead small. Our work illustrates the\npower of linearly combining individual impressions, each of which fares poorly\nin isolation, to achieve performance comparable to a dedicated mask. Moreover,\neven repeated impressions from the same task (homogeneous masks), when\ncombined, can approach the performance of heterogeneous combinations if\nsufficiently many impressions are used. Our approach scales more efficiently\nthan existing methods, often requiring orders of magnitude fewer parameters and\ncan function without modification even when task identity is missing. In\naddition, in the setting where task labels are not given at inference, our\nalgorithm gives an often favorable alternative to the one-shot procedure used\nby Wortsman et al., 2020. We evaluate our method on a number of well-known\nimage classification datasets and network architectures.\n","authors":["Dhrupad Bhardwaj","Julia Kempe","Artem Vysogorets","Angela M. Teng","Evaristus C. Ezekwem"],"pdf_url":"https://arxiv.org/pdf/2210.01987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00059v1","updated":"2023-01-31T19:48:37Z","published":"2023-01-31T19:48:37Z","title":"NASiam: Efficient Representation Learning using Neural Architecture\n  Search for Siamese Networks","summary":"  Siamese networks are one of the most trending methods to achieve\nself-supervised visual representation learning (SSL). Since hand labeling is\ncostly, SSL can play a crucial part by allowing deep learning to train on large\nunlabeled datasets. Meanwhile, Neural Architecture Search (NAS) is becoming\nincreasingly important as a technique to discover novel deep learning\narchitectures. However, early NAS methods based on reinforcement learning or\nevolutionary algorithms suffered from ludicrous computational and memory costs.\nIn contrast, differentiable NAS, a gradient-based approach, has the advantage\nof being much more efficient and has thus retained most of the attention in the\npast few years. In this article, we present NASiam, a novel approach that uses\nfor the first time differentiable NAS to improve the multilayer perceptron\nprojector and predictor (encoder/predictor pair) architectures inside\nsiamese-networks-based contrastive learning frameworks (e.g., SimCLR, SimSiam,\nand MoCo) while preserving the simplicity of previous baselines. We crafted a\nsearch space designed explicitly for multilayer perceptrons, inside which we\nexplored several alternatives to the standard ReLU activation function. We show\nthat these new architectures allow ResNet backbone convolutional models to\nlearn strong representations efficiently. NASiam reaches competitive\nperformance in both small-scale (i.e., CIFAR-10/CIFAR-100) and large-scale\n(i.e., ImageNet) image classification datasets while costing only a few GPU\nhours. We discuss the composition of the NAS-discovered architectures and emit\nhypotheses on why they manage to prevent collapsing behavior. Our code is\navailable at https://github.com/aheuillet/NASiam.\n","authors":["Alexandre Heuillet","Hedi Tabia","Hichem Arioui"],"pdf_url":"https://arxiv.org/pdf/2302.00059v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2108.06663v3","updated":"2023-01-31T19:47:50Z","published":"2021-08-15T05:48:07Z","title":"HCR-Net: A deep learning based script independent handwritten character\n  recognition network","summary":"  Despite being studied extensively for a few decades, handwritten character\nrecognition (HCR) is still considered a challenging learning problem in pattern\nrecognition, and there is very limited research on script independent models.\nThis is mainly because of similarity in structure of characters, different\nhandwriting styles, noisy datasets, diversity of scripts, focus of the\nconventional research on handcrafted feature extraction techniques, and\nunavailability of public datasets and code-repositories to reproduce the\nresults. On the other hand, deep learning has witnessed huge success in\ndifferent areas of pattern recognition, including HCR, and provides an\nend-to-end learning. However, deep learning techniques are computationally\nexpensive, need large amount of data for training and have been developed for\nspecific scripts only. To address the above limitations, we have proposed a\nnovel generic deep learning architecture for script independent handwritten\ncharacter recognition, called HCR-Net. HCR-Net is based on a novel transfer\nlearning approach for HCR, which partly utilizes feature extraction layers of a\npre-trained network. Due to transfer learning and image-augmentation, HCR-Net\nprovides faster and computationally efficient training, better performance and\nbetter generalizations, and can work with small datasets. HCR-Net is\nextensively evaluated on 40 publicly available datasets of Bangla, Punjabi,\nHindi, English, Swedish, Urdu, Farsi, Tibetan, Kannada, Malayalam, Telugu,\nMarathi, Nepali and Arabic languages, and established 26 new benchmark results\nwhile performed close to the best results in the rest cases. HCR-Net showed\nperformance improvements up to 11% against the existing results and achieved a\nfast convergence rate showing up to 99% of final performance in the very first\nepoch. HCR-Net significantly outperformed the state-of-the-art transfer\nlearning techniques...\n","authors":["Vinod Kumar Chauhan","Sukhdeep Singh","Anuj Sharma"],"pdf_url":"https://arxiv.org/pdf/2108.06663v3.pdf","comment":"23 pages (double-column), 6 figures, 16 tables (under review) --\n  revised version"},{"id":"http://arxiv.org/abs/2302.00487v1","updated":"2023-01-31T11:34:56Z","published":"2023-01-31T11:34:56Z","title":"A Comprehensive Survey of Continual Learning: Theory, Method and\n  Application","summary":"  To cope with real-world dynamics, an intelligent agent needs to incrementally\nacquire, update, accumulate, and exploit knowledge throughout its lifetime.\nThis ability, known as continual learning, provides a foundation for AI systems\nto develop themselves adaptively. In a general sense, continual learning is\nexplicitly limited by catastrophic forgetting, where learning a new task\nusually results in a dramatic performance drop of the old tasks. Beyond this,\nincreasingly numerous advances have emerged in recent years that largely extend\nthe understanding and application of continual learning. The growing and\nwidespread interest in this direction demonstrates its realistic significance\nas well as complexity. In this work, we present a comprehensive survey of\ncontinual learning, seeking to bridge the basic settings, theoretical\nfoundations, representative methods, and practical applications. Based on\nexisting theoretical and empirical results, we summarize the general objectives\nof continual learning as ensuring a proper stability-plasticity trade-off and\nan adequate intra/inter-task generalizability in the context of resource\nefficiency. Then we provide a state-of-the-art and elaborated taxonomy,\nextensively analyzing how representative strategies address continual learning,\nand how they are adapted to particular challenges in various applications.\nThrough an in-depth discussion of continual learning in terms of the current\ntrends, cross-directional prospects and interdisciplinary connections with\nneuroscience, we believe that such a holistic perspective can greatly\nfacilitate subsequent exploration in this field and beyond.\n","authors":["Liyuan Wang","Xingxing Zhang","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.00487v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.13524v1","updated":"2023-01-31T10:17:53Z","published":"2023-01-31T10:17:53Z","title":"Quantum contextual bandits and recommender systems for quantum data","summary":"  We study a recommender system for quantum data using the linear contextual\nbandit framework. In each round, a learner receives an observable (the context)\nand has to recommend from a finite set of unknown quantum states (the actions)\nwhich one to measure. The learner has the goal of maximizing the reward in each\nround, that is the outcome of the measurement on the unknown state. Using this\nmodel we formulate the low energy quantum state recommendation problem where\nthe context is a Hamiltonian and the goal is to recommend the state with the\nlowest energy. For this task, we study two families of contexts: the Ising\nmodel and a generalized cluster model. We observe that if we interpret the\nactions as different phases of the models then the recommendation is done by\nclassifying the correct phase of the given Hamiltonian and the strategy can be\ninterpreted as an online quantum phase classifier.\n","authors":["Shrigyan Brahmachari","Josep Lumbreras","Marco Tomamichel"],"pdf_url":"https://arxiv.org/pdf/2301.13524v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.13507v1","updated":"2023-01-31T09:48:53Z","published":"2023-01-31T09:48:53Z","title":"An Analysis of Classification Approaches for Hit Song Prediction using\n  Engineered Metadata Features with Lyrics and Audio Features","summary":"  Hit song prediction, one of the emerging fields in music information\nretrieval (MIR), remains a considerable challenge. Being able to understand\nwhat makes a given song a hit is clearly beneficial to the whole music\nindustry. Previous approaches to hit song prediction have focused on using\naudio features of a record. This study aims to improve the prediction result of\nthe top 10 hits among Billboard Hot 100 songs using more alternative metadata,\nincluding song audio features provided by Spotify, song lyrics, and novel\nmetadata-based features (title topic, popularity continuity and genre class).\nFive machine learning approaches are applied, including: k-nearest neighbours,\nNaive Bayes, Random Forest, Logistic Regression and Multilayer Perceptron. Our\nresults show that Random Forest (RF) and Logistic Regression (LR) with all\nfeatures (including novel features, song audio features and lyrics features)\noutperforms other models, achieving 89.1% and 87.2% accuracy, and 0.91 and 0.93\nAUC, respectively. Our findings also demonstrate the utility of our novel music\nmetadata features, which contributed most to the models' discriminative\nperformance.\n","authors":["Mengyisong Zhao","Morgan Harvey","David Cameron","Frank Hopfgartner","Valerie J. Gillet"],"pdf_url":"https://arxiv.org/pdf/2301.13507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07854v2","updated":"2023-01-31T06:09:08Z","published":"2023-01-19T02:51:47Z","title":"FE-TCM: Filter-Enhanced Transformer Click Model for Web Search","summary":"  Constructing click models and extracting implicit relevance feedback\ninformation from the interaction between users and search engines are very\nimportant to improve the ranking of search results. Using neural network to\nmodel users' click behaviors has become one of the effective methods to\nconstruct click models. In this paper, We use Transformer as the backbone\nnetwork of feature extraction, add filter layer innovatively, and propose a new\nFilter-Enhanced Transformer Click Model (FE-TCM) for web search. Firstly, in\norder to reduce the influence of noise on user behavior data, we use the\nlearnable filters to filter log noise. Secondly, following the examination\nhypothesis, we model the attraction estimator and examination predictor\nrespectively to output the attractiveness scores and examination probabilities.\nA novel transformer model is used to learn the deeper representation among\ndifferent features. Finally, we apply the combination functions to integrate\nattractiveness scores and examination probabilities into the click prediction.\nFrom our experiments on two real-world session datasets, it is proved that\nFE-TCM outperforms the existing click models for the click prediction.\n","authors":["Yingfei Wang","Jianping Liu","Jian Wang","Xiaofeng Wang","Meng Wang","Xintao Chu"],"pdf_url":"https://arxiv.org/pdf/2301.07854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12700v2","updated":"2023-01-31T04:56:10Z","published":"2023-01-30T07:12:38Z","title":"CSDR-BERT: a pre-trained scientific dataset match model for Chinese\n  Scientific Dataset Retrieval","summary":"  As the number of open and shared scientific datasets on the Internet\nincreases under the open science movement, efficiently retrieving these\ndatasets is a crucial task in information retrieval (IR) research. In recent\nyears, the development of large models, particularly the pre-training and\nfine-tuning paradigm, which involves pre-training on large models and\nfine-tuning on downstream tasks, has provided new solutions for IR match tasks.\nIn this study, we use the original BERT token in the embedding layer, improve\nthe Sentence-BERT model structure in the model layer by introducing the SimCSE\nand K-Nearest Neighbors method, and use the cosent loss function in the\noptimization phase to optimize the target output. Our experimental results show\nthat our model outperforms other competing models on both public and self-built\ndatasets through comparative experiments and ablation implementations. This\nstudy explores and validates the feasibility and efficiency of pre-training\ntechniques for semantic retrieval of Chinese scientific datasets.\n","authors":["Xintao Chu","Jianping Liu","Jian Wang","Xiaofeng Wang","Yingfei Wang","Meng Wang","Xunxun Gu"],"pdf_url":"https://arxiv.org/pdf/2301.12700v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13388v1","updated":"2023-01-31T03:37:59Z","published":"2023-01-31T03:37:59Z","title":"Large Music Recommendation Studies for Small Teams","summary":"  Running live music recommendation studies without direct industry\npartnerships can be a prohibitively daunting task, especially for small teams.\nIn order to help future researchers interested in such evaluations, we present\na number of struggles we faced in the process of generating our own such\nevaluation system alongside potential solutions. These problems span the topics\nof users, data, computation, and application architecture.\n","authors":["Kyle Robinson","Dan Brown"],"pdf_url":"https://arxiv.org/pdf/2301.13388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13364v1","updated":"2023-01-31T02:08:34Z","published":"2023-01-31T02:08:34Z","title":"A Counterfactual Collaborative Session-based Recommender System","summary":"  Most session-based recommender systems (SBRSs) focus on extracting\ninformation from the observed items in the current session of a user to predict\na next item, ignoring the causes outside the session (called outer-session\ncauses, OSCs) that influence the user's selection of items. However, these\ncauses widely exist in the real world, and few studies have investigated their\nrole in SBRSs. In this work, we analyze the causalities and correlations of the\nOSCs in SBRSs from the perspective of causal inference. We find that the OSCs\nare essentially the confounders in SBRSs, which leads to spurious correlations\nin the data used to train SBRS models. To address this problem, we propose a\nnovel SBRS framework named COCO-SBRS (COunterfactual COllaborative\nSession-Based Recommender Systems) to learn the causality between OSCs and\nuser-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised\napproach to pre-train a recommendation model by designing pseudo-labels of\ncauses for each user's selection of the item in data to guide the training\nprocess. Next, COCO-SBRS adopts counterfactual inference to recommend items\nbased on the outputs of the pre-trained recommendation model considering the\ncausalities to alleviate the data sparsity problem. As a result, COCO-SBRS can\nlearn the causalities in data, preventing the model from learning spurious\ncorrelations. The experimental results of our extensive experiments conducted\non three real-world datasets demonstrate the superiority of our proposed\nframework over ten representative SBRSs.\n","authors":["Wenzhuo Song","Shoujin Wang","Yan Wang","Kunpeng Liu","Xueyan Liu","Minghao Yin"],"pdf_url":"https://arxiv.org/pdf/2301.13364v1.pdf","comment":"accepted by the ACM WebConf 2023"},{"id":"http://arxiv.org/abs/2301.12097v2","updated":"2023-01-31T01:58:48Z","published":"2023-01-28T05:40:28Z","title":"Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal\n  Recommendation","summary":"  User interaction data in recommender systems is a form of dyadic relation\nthat reflects the preferences of users with items. Learning the representations\nof these two discrete sets of objects, users and items, is critical for\nrecommendation. Recent multimodal recommendation models leveraging multimodal\nfeatures (e.g., images and text descriptions) have been demonstrated to be\neffective in improving recommendation accuracy. However, state-of-the-art\nmodels enhance the dyadic relations between users and items by considering\neither user-user or item-item relations, leaving the high-order relations of\nthe other side (i.e., users or items) unexplored. Furthermore, we\nexperimentally reveal that the current multimodality fusion methods in the\nstate-of-the-art models may degrade their recommendation performance. That is,\nwithout tainting the model architectures, these models can achieve even better\nrecommendation accuracy with uni-modal information. On top of the finding, we\npropose a model that enhances the dyadic relations by learning Dual\nRepresentAtions of both users and items via constructing homogeneous Graphs for\nmultimOdal recommeNdation. We name our model as DRAGON. Specifically, DRAGON\nconstructs the user-user graph based on the commonly interacted items and the\nitem-item graph from item multimodal features. It then utilizes graph learning\non both the user-item heterogeneous graph and the homogeneous graphs (user-user\nand item-item) to obtain the dual representations of users and items. To\ncapture information from each modality, DRAGON employs a simple yet effective\nfusion method, attentive concatenation, to derive the representations of users\nand items. Extensive experiments on three public datasets and seven baselines\nshow that DRAGON can outperform the strongest baseline by 22.03% on average.\nVarious ablation studies are conducted on DRAGON to validate its effectiveness.\n","authors":["Hongyu Zhou","Xin Zhou","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2301.12097v2.pdf","comment":"modify the format"},{"id":"http://arxiv.org/abs/2212.12888v2","updated":"2023-01-31T00:57:04Z","published":"2022-12-25T10:36:25Z","title":"On Cache-Aided Multi-User Private Information Retrieval with Small\n  Caches","summary":"  In this paper, we propose a scheme for the problem of cache-aided multi-user\nprivate information retrieval with small caches, in which $K$ users are\nconnected to $S$ non-colluding databases via shared links. Each database\ncontains a set of $N$ files, and each user has a dedicated cache of size\nequivalent to the size of $M$ files. All the users want to retrieve a file\nwithout revealing their demands to the databases. During off-peak hours, all\nthe users will fill their caches, and when required, users will demand their\ndesired files by cooperatively generating query sets for each database. After\nreceiving the transmissions from databases, all the users should get their\ndesired files using transmitted data and their cache contents. This problem has\nbeen studied in [X. Zhang, K. Wan, H. Sun, M. Ji and G. Caire, \\tqt{Fundamental\nlimits of cache-aided multiuser private information retrieval}, IEEE Trans.\nCommun., 2021], in which authors proposed a product design scheme. In this\npaper, we propose a scheme that gives a better rate for a particular value of\n$M$ than the product design scheme. We consider a slightly different approach\nfor the placement phase. Instead of a database filling the caches of all users\ndirectly, a database will broadcast cache content for all users on a shared\nlink, and then the users will decide unitedly which part of the broadcasted\ncontent will be stored in the cache of each user. This variation facilitates\nmaintaining the privacy constraint at a reduced rate.\n","authors":["Charul Rajput","B. Sundar Rajan"],"pdf_url":"https://arxiv.org/pdf/2212.12888v2.pdf","comment":"35 pages, 7 tables and 3 figures. Two figures have been added"},{"id":"http://arxiv.org/abs/2302.00119v1","updated":"2023-01-31T21:59:35Z","published":"2023-01-31T21:59:35Z","title":"Machine Translation Impact in E-commerce Multilingual Search","summary":"  Previous work suggests that performance of cross-lingual information\nretrieval correlates highly with the quality of Machine Translation. However,\nthere may be a threshold beyond which improving query translation quality\nyields little or no benefit to further improve the retrieval performance. This\nthreshold may depend upon multiple factors including the source and target\nlanguages, the existing MT system quality and the search pipeline. In order to\nidentify the benefit of improving an MT system for a given search pipeline, we\ninvestigate the sensitivity of retrieval quality to the presence of different\nlevels of MT quality using experimental datasets collected from actual traffic.\nWe systematically improve the performance of our MT systems quality on language\npairs as measured by MT evaluation metrics including Bleu and Chrf to determine\ntheir impact on search precision metrics and extract signals that help to guide\nthe improvement strategies. Using this information we develop techniques to\ncompare query translations for multiple language pairs and identify the most\npromising language pairs to invest and improve.\n","authors":["Bryan Zhang","Amita Misra"],"pdf_url":"https://arxiv.org/pdf/2302.00119v1.pdf","comment":"Accepted by EMNLP 2022 (Industry Track)"},{"id":"http://arxiv.org/abs/2302.00083v1","updated":"2023-01-31T20:26:16Z","published":"2023-01-31T20:26:16Z","title":"In-Context Retrieval-Augmented Language Models","summary":"  Retrieval-Augmented Language Modeling (RALM) methods, that condition a\nlanguage model (LM) on relevant documents from a grounding corpus during\ngeneration, have been shown to significantly improve language modeling while\nalso providing a natural source attribution mechanism. Existing RALM approaches\nfocus on modifying the LM architecture in order to facilitate the incorporation\nof external information, significantly complicating deployment. This paper\nproposes an under-explored alternative, which we dub In-Context RALM: leaving\nthe LM architecture unchanged and prepending grounding documents to the input.\nWe show that in-context RALM which uses off-the-shelf general purpose\nretrievers provides surprisingly large LM gains across model sizes and diverse\ncorpora. We also demonstrate that the document retrieval and ranking mechanism\ncan be specialized to the RALM setting to further boost performance. We\nconclude that in-context RALM has considerable potential to increase the\nprevalence of LM grounding, particularly in settings where a pretrained LM must\nbe used without modification or even via API access. To that end, we make our\ncode publicly available.\n","authors":["Ori Ram","Yoav Levine","Itay Dalmedigos","Dor Muhlgay","Amnon Shashua","Kevin Leyton-Brown","Yoav Shoham"],"pdf_url":"https://arxiv.org/pdf/2302.00083v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.13868v1","updated":"2023-01-31T18:59:22Z","published":"2023-01-31T18:59:22Z","title":"PADL: Language-Directed Physics-Based Character Control","summary":"  Developing systems that can synthesize natural and life-like motions for\nsimulated characters has long been a focus for computer animation. But in order\nfor these systems to be useful for downstream applications, they need not only\nproduce high-quality motions, but must also provide an accessible and versatile\ninterface through which users can direct a character's behaviors. Natural\nlanguage provides a simple-to-use and expressive medium for specifying a user's\nintent. Recent breakthroughs in natural language processing (NLP) have\ndemonstrated effective use of language-based interfaces for applications such\nas image generation and program synthesis. In this work, we present PADL, which\nleverages recent innovations in NLP in order to take steps towards developing\nlanguage-directed controllers for physics-based character animation. PADL\nallows users to issue natural language commands for specifying both high-level\ntasks and low-level skills that a character should perform. We present an\nadversarial imitation learning approach for training policies to map high-level\nlanguage commands to low-level controls that enable a character to perform the\ndesired task and skill specified by a user's commands. Furthermore, we propose\na multi-task aggregation method that leverages a language-based multiple-choice\nquestion-answering approach to determine high-level task objectives from\nlanguage commands. We show that our framework can be applied to effectively\ndirect a simulated humanoid character to perform a diverse array of complex\nmotor skills.\n","authors":["Jordan Juravsky","Yunrong Guo","Sanja Fidler","Xue Bin Peng"],"pdf_url":"https://arxiv.org/pdf/2301.13868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13867v1","updated":"2023-01-31T18:59:03Z","published":"2023-01-31T18:59:03Z","title":"Mathematical Capabilities of ChatGPT","summary":"  We investigate the mathematical capabilities of ChatGPT by testing it on\npublicly available datasets, as well as hand-crafted ones, and measuring its\nperformance against other models trained on a mathematical corpus, such as\nMinerva. We also test whether ChatGPT can be a useful assistant to professional\nmathematicians by emulating various use cases that come up in the daily\nprofessional activities of mathematicians (question answering, theorem\nsearching). In contrast to formal mathematics, where large databases of formal\nproofs are available (e.g., the Lean Mathematical Library), current datasets of\nnatural-language mathematics, used to benchmark language models, only cover\nelementary mathematics. We address this issue by introducing a new dataset:\nGHOSTS. It is the first natural-language dataset made and curated by working\nresearchers in mathematics that (1) aims to cover graduate-level mathematics\nand (2) provides a holistic overview of the mathematical capabilities of\nlanguage models. We benchmark ChatGPT on GHOSTS and evaluate performance\nagainst fine-grained criteria. We make this new dataset publicly available to\nassist a community-driven comparison of ChatGPT with (future) large language\nmodels in terms of advanced mathematical comprehension. We conclude that\ncontrary to many positive reports in the media (a potential case of selection\nbias), ChatGPT's mathematical abilities are significantly below those of an\naverage mathematics graduate student. Our results show that ChatGPT often\nunderstands the question but fails to provide correct solutions. Hence, if your\ngoal is to use it to pass a university exam, you would be better off copying\nfrom your average peer!\n","authors":["Simon Frieder","Luca Pinchetti","Ryan-Rhys Griffiths","Tommaso Salvatori","Thomas Lukasiewicz","Philipp Christian Petersen","Alexis Chevalier","Julius Berner"],"pdf_url":"https://arxiv.org/pdf/2301.13867v1.pdf","comment":"The GHOSTS dataset will be available at\n  https://github.com/friederrr/science-GHOSTS"},{"id":"http://arxiv.org/abs/2301.13862v1","updated":"2023-01-31T18:56:41Z","published":"2023-01-31T18:56:41Z","title":"Salient Conditional Diffusion for Defending Against Backdoor Attacks","summary":"  We propose a novel algorithm, Salient Conditional Diffusion (Sancdifi), a\nstate-of-the-art defense against backdoor attacks. Sancdifi uses a denoising\ndiffusion probabilistic model (DDPM) to degrade an image with noise and then\nrecover said image using the learned reverse diffusion. Critically, we compute\nsaliency map-based masks to condition our diffusion, allowing for stronger\ndiffusion on the most salient pixels by the DDPM. As a result, Sancdifi is\nhighly effective at diffusing out triggers in data poisoned by backdoor\nattacks. At the same time, it reliably recovers salient features when applied\nto clean data. This performance is achieved without requiring access to the\nmodel parameters of the Trojan network, meaning Sancdifi operates as a\nblack-box defense.\n","authors":["Brandon B. May","N. Joseph Tatro","Piyush Kumar","Nathan Shnidman"],"pdf_url":"https://arxiv.org/pdf/2301.13862v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.13556v2","updated":"2023-01-31T18:55:19Z","published":"2022-12-27T17:16:48Z","title":"Limitations of Information-Theoretic Generalization Bounds for Gradient\n  Descent Methods in Stochastic Convex Optimization","summary":"  To date, no \"information-theoretic\" frameworks for reasoning about\ngeneralization error have been shown to establish minimax rates for gradient\ndescent in the setting of stochastic convex optimization. In this work, we\nconsider the prospect of establishing such rates via several existing\ninformation-theoretic frameworks: input-output mutual information bounds,\nconditional mutual information bounds and variants, PAC-Bayes bounds, and\nrecent conditional variants thereof. We prove that none of these bounds are\nable to establish minimax rates. We then consider a common tactic employed in\nstudying gradient methods, whereby the final iterate is corrupted by Gaussian\nnoise, producing a noisy \"surrogate\" algorithm. We prove that minimax rates\ncannot be established via the analysis of such surrogates. Our results suggest\nthat new ideas are required to analyze gradient descent using\ninformation-theoretic techniques.\n","authors":["Mahdi Haghifam","Borja Rodríguez-Gálvez","Ragnar Thobaben","Mikael Skoglund","Daniel M. Roy","Gintare Karolina Dziugaite"],"pdf_url":"https://arxiv.org/pdf/2212.13556v2.pdf","comment":"49 pages, 2 figures. To appear, Proc. International Conference on\n  Algorithmic Learning Theory (ALT), 2023"},{"id":"http://arxiv.org/abs/2301.13857v1","updated":"2023-01-31T18:54:36Z","published":"2023-01-31T18:54:36Z","title":"Learning in POMDPs is Sample-Efficient with Hindsight Observability","summary":"  POMDPs capture a broad class of decision making problems, but hardness\nresults suggest that learning is intractable even in simple settings due to the\ninherent partial observability. However, in many realistic problems, more\ninformation is either revealed or can be computed during some point of the\nlearning process. Motivated by diverse applications ranging from robotics to\ndata center scheduling, we formulate a \\setting (\\setshort) as a POMDP where\nthe latent states are revealed to the learner in hindsight and only during\ntraining. We introduce new algorithms for the tabular and function\napproximation settings that are provably sample-efficient with hindsight\nobservability, even in POMDPs that would otherwise be statistically\nintractable. We give a lower bound showing that the tabular algorithm is\noptimal in its dependence on latent state and observation cardinalities.\n","authors":["Jonathan N. Lee","Alekh Agarwal","Christoph Dann","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13856v1","updated":"2023-01-31T18:53:39Z","published":"2023-01-31T18:53:39Z","title":"Simplex Random Features","summary":"  We present Simplex Random Features (SimRFs), a new random feature (RF)\nmechanism for unbiased approximation of the softmax and Gaussian kernels by\ngeometrical correlation of random projection vectors. We prove that SimRFs\nprovide the smallest possible mean square error (MSE) on unbiased estimates of\nthese kernels among the class of weight-independent geometrically-coupled\npositive random feature (PRF) mechanisms, substantially outperforming the\npreviously most accurate Orthogonal Random Features at no observable extra\ncost. We present a more computationally expensive SimRFs+ variant, which we\nprove is asymptotically optimal in the broader family of weight-dependent\ngeometrical coupling schemes (which permit correlations between random vector\ndirections and norms). In extensive empirical studies, we show consistent gains\nprovided by SimRFs in settings including pointwise kernel estimation,\nnonparametric classification and scalable Transformers.\n","authors":["Isaac Reid","Krzysztof Choromanski","Valerii Likhosherstov","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2301.13856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13850v1","updated":"2023-01-31T18:47:42Z","published":"2023-01-31T18:47:42Z","title":"Gaussian Noise is Nearly Instance Optimal for Private Unbiased Mean\n  Estimation","summary":"  We investigate unbiased high-dimensional mean estimators in differential\nprivacy. We consider differentially private mechanisms whose expected output\nequals the mean of the input dataset, for every dataset drawn from a fixed\nconvex domain $K$ in $\\mathbb{R}^d$. In the setting of concentrated\ndifferential privacy, we show that, for every input such an unbiased mean\nestimator introduces approximately at least as much error as a mechanism that\nadds Gaussian noise with a carefully chosen covariance. This is true when the\nerror is measured with respect to $\\ell_p$ error for any $p \\ge 2$. We extend\nthis result to local differential privacy, and to approximate differential\nprivacy, but for the latter the error lower bound holds either for a dataset or\nfor a neighboring dataset. We also extend our results to mechanisms that take\ni.i.d.~samples from a distribution over $K$ and are unbiased with respect to\nthe mean of the distribution.\n","authors":["Aleksandar Nikolov","Haohua Tang"],"pdf_url":"https://arxiv.org/pdf/2301.13850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13848v1","updated":"2023-01-31T18:46:19Z","published":"2023-01-31T18:46:19Z","title":"Benchmarking Large Language Models for News Summarization","summary":"  Large language models (LLMs) have shown promise for automatic summarization\nbut the reasons behind their successes are poorly understood. By conducting a\nhuman evaluation on ten LLMs across different pretraining methods, prompts, and\nmodel scales, we make two important observations. First, we find instruction\ntuning, and not model size, is the key to the LLM's zero-shot summarization\ncapability. Second, existing studies have been limited by low-quality\nreferences, leading to underestimates of human performance and lower few-shot\nand finetuning performance. To better evaluate LLMs, we perform human\nevaluation over high-quality summaries we collect from freelance writers.\nDespite major stylistic differences such as the amount of paraphrasing, we find\nthat LMM summaries are judged to be on par with human written summaries.\n","authors":["Tianyi Zhang","Faisal Ladhak","Esin Durmus","Percy Liang","Kathleen McKeown","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2301.13848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13845v1","updated":"2023-01-31T18:41:28Z","published":"2023-01-31T18:41:28Z","title":"Interpreting Robustness Proofs of Deep Neural Networks","summary":"  In recent years numerous methods have been developed to formally verify the\nrobustness of deep neural networks (DNNs). Though the proposed techniques are\neffective in providing mathematical guarantees about the DNNs behavior, it is\nnot clear whether the proofs generated by these methods are\nhuman-interpretable. In this paper, we bridge this gap by developing new\nconcepts, algorithms, and representations to generate human understandable\ninterpretations of the proofs. Leveraging the proposed method, we show that the\nrobustness proofs of standard DNNs rely on spurious input features, while the\nproofs of DNNs trained to be provably robust filter out even the semantically\nmeaningful features. The proofs for the DNNs combining adversarial and provably\nrobust training are the most effective at selectively filtering out spurious\nfeatures as well as relying on human-understandable input features.\n","authors":["Debangshu Banerjee","Avaljot Singh","Gagandeep Singh"],"pdf_url":"https://arxiv.org/pdf/2301.13845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02742v4","updated":"2023-01-31T18:38:44Z","published":"2022-12-06T04:15:24Z","title":"A Learning Based Hypothesis Test for Harmful Covariate Shift","summary":"  The ability to quickly and accurately identify covariate shift at test time\nis a critical and often overlooked component of safe machine learning systems\ndeployed in high-risk domains. While methods exist for detecting when\npredictions should not be made on out-of-distribution test examples,\nidentifying distributional level differences between training and test time can\nhelp determine when a model should be removed from the deployment setting and\nretrained. In this work, we define harmful covariate shift (HCS) as a change in\ndistribution that may weaken the generalization of a predictive model. To\ndetect HCS, we use the discordance between an ensemble of classifiers trained\nto agree on training data and disagree on test data. We derive a loss function\nfor training this ensemble and show that the disagreement rate and entropy\nrepresent powerful discriminative statistics for HCS. Empirically, we\ndemonstrate the ability of our method to detect harmful covariate shift with\nstatistical certainty on a variety of high-dimensional datasets. Across\nnumerous domains and modalities, we show state-of-the-art performance compared\nto existing methods, particularly when the number of observed test samples is\nsmall.\n","authors":["Tom Ginsberg","Zhongyuan Liang","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2212.02742v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13823v1","updated":"2023-01-31T18:33:44Z","published":"2023-01-31T18:33:44Z","title":"Grounding Language Models to Images for Multimodal Generation","summary":"  We propose an efficient method to ground pretrained text-only language models\nto the visual domain, enabling them to process and generate arbitrarily\ninterleaved image-and-text data. Our method leverages the abilities of language\nmodels learnt from large scale text-only pretraining, such as in-context\nlearning and free-form text generation. We keep the language model frozen, and\nfinetune input and output linear layers to enable cross-modality interactions.\nThis allows our model to process arbitrarily interleaved image-and-text inputs,\nand generate free-form text interleaved with retrieved images. We achieve\nstrong zero-shot performance on grounded tasks such as contextual image\nretrieval and multimodal dialogue, and showcase compelling interactive\nabilities. Our approach works with any off-the-shelf language model and paves\nthe way towards an effective, general solution for leveraging pretrained\nlanguage models in visually grounded settings.\n","authors":["Jing Yu Koh","Ruslan Salakhutdinov","Daniel Fried"],"pdf_url":"https://arxiv.org/pdf/2301.13823v1.pdf","comment":"Project page: https://jykoh.com/fromage"},{"id":"http://arxiv.org/abs/2301.13838v1","updated":"2023-01-31T18:31:20Z","published":"2023-01-31T18:31:20Z","title":"Image Shortcut Squeezing: Countering Perturbative Availability Poisons\n  with Compression","summary":"  Perturbative availability poisoning (PAP) adds small changes to images to\nprevent their use for model training. Current research adopts the belief that\npractical and effective approaches to countering such poisons do not exist. In\nthis paper, we argue that it is time to abandon this belief. We present\nextensive experiments showing that 12 state-of-the-art PAP methods are\nvulnerable to Image Shortcut Squeezing (ISS), which is based on simple\ncompression. For example, on average, ISS restores the CIFAR-10 model accuracy\nto $81.73\\%$, surpassing the previous best preprocessing-based countermeasures\nby $37.97\\%$ absolute. ISS also (slightly) outperforms adversarial training and\nhas higher generalizability to unseen perturbation norms and also higher\nefficiency. Our investigation reveals that the property of PAP perturbations\ndepends on the type of surrogate model used for poison generation, and it\nexplains why a specific ISS compression yields the best performance for a\nspecific type of PAP perturbation. We further test stronger, adaptive\npoisoning, and show it falls short of being an ideal defense against ISS.\nOverall, our results demonstrate the importance of considering various (simple)\ncountermeasures to ensure the meaningfulness of analysis carried out during the\ndevelopment of availability poisons.\n","authors":["Zhuoran Liu","Zhengyu Zhao","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2301.13838v1.pdf","comment":"Our code is available at\n  https://github.com/liuzrcc/ImageShortcutSqueezing"},{"id":"http://arxiv.org/abs/2208.14960v2","updated":"2023-01-31T18:27:41Z","published":"2022-08-31T16:40:40Z","title":"Stationary Kernels and Gaussian Processes on Lie Groups and their\n  Homogeneous Spaces I: the compact case","summary":"  Gaussian processes are arguably the most important model class in spatial\nstatistics. They encode prior information about the modeled function and can be\nused for exact or approximate Bayesian inference. In many applications,\nparticularly in physical sciences and engineering, but also in areas such as\ngeostatistics and neuroscience, invariance to symmetries is one of the most\nfundamental forms of prior information one can consider. The invariance of a\nGaussian process' covariance to such symmetries gives rise to the most natural\ngeneralization of the concept of stationarity to such spaces. In this work, we\ndevelop constructive and practical techniques for building stationary Gaussian\nprocesses on a very large class of non-Euclidean spaces arising in the context\nof symmetries. Our techniques make it possible to (i) calculate covariance\nkernels and (ii) sample from prior and posterior Gaussian processes defined on\nsuch spaces, both in a practical manner. This work is split into two parts,\neach involving different technical considerations: part I studies compact\nspaces, while part II studies non-compact spaces possessing certain structure.\nOur contributions make the non-Euclidean Gaussian process models we study\ncompatible with well-understood computational techniques available in standard\nGaussian process software packages, thereby making them accessible to\npractitioners.\n","authors":["Iskander Azangulov","Andrei Smolensky","Alexander Terenin","Viacheslav Borovitskiy"],"pdf_url":"https://arxiv.org/pdf/2208.14960v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13833v1","updated":"2023-01-31T18:25:36Z","published":"2023-01-31T18:25:36Z","title":"A Mathematical Model for Curriculum Learning","summary":"  Curriculum learning (CL) - training using samples that are generated and\npresented in a meaningful order - was introduced in the machine learning\ncontext around a decade ago. While CL has been extensively used and analysed\nempirically, there has been very little mathematical justification for its\nadvantages. We introduce a CL model for learning the class of k-parities on d\nbits of a binary string with a neural network trained by stochastic gradient\ndescent (SGD). We show that a wise choice of training examples, involving two\nor more product distributions, allows to reduce significantly the computational\ncost of learning this class of functions, compared to learning under the\nuniform distribution. We conduct experiments to support our analysis.\nFurthermore, we show that for another class of functions - namely the `Hamming\nmixtures' - CL strategies involving a bounded number of product distributions\nare not beneficial, while we conjecture that CL with unbounded many curriculum\nsteps can learn this class efficiently.\n","authors":["Elisabetta Cornacchia","Elchanan Mossel"],"pdf_url":"https://arxiv.org/pdf/2301.13833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.02600v3","updated":"2023-01-31T18:24:34Z","published":"2021-06-04T16:59:24Z","title":"Causal Graph Discovery from Self and Mutually Exciting Time Series","summary":"  We present a generalized linear structural causal model, coupled with a novel\ndata-adaptive linear regularization, to recover causal directed acyclic graphs\n(DAGs) from time series. By leveraging a recently developed stochastic monotone\nVariational Inequality (VI) formulation, we cast the causal discovery problem\nas a general convex optimization. Furthermore, we develop a non-asymptotic\nrecovery guarantee and quantifiable uncertainty by solving a linear program to\nestablish confidence intervals for a wide range of non-linear monotone link\nfunctions. We validate our theoretical results and show the competitive\nperformance of our method via extensive numerical experiments. Most\nimportantly, we demonstrate the effectiveness of our approach in recovering\nhighly interpretable causal DAGs over Sepsis Associated Derangements (SADs)\nwhile achieving comparable prediction performance to powerful ``black-box''\nmodels such as XGBoost. Thus, the future adoption of our proposed method to\nconduct continuous surveillance of high-risk patients by clinicians is much\nmore likely.\n","authors":["Song Wei","Yao Xie","Christopher S. Josef","Rishikesan Kamaleswaran"],"pdf_url":"https://arxiv.org/pdf/2106.02600v3.pdf","comment":"See v2 for a previous workshop paper on Interpretable ML in\n  Healthcare (IMLH) at ICML 2021, titled \"Causal Graph Recovery for\n  Sepsis-Associated Derangements via Interpretable Hawkes Networks\". Also, see\n  arXiv:2301.11336 for a short conference version with more experiments of our\n  proposed method to learn \"strict\" DAGs"},{"id":"http://arxiv.org/abs/2104.03509v3","updated":"2023-01-31T18:23:30Z","published":"2021-04-08T04:52:21Z","title":"Py-Feat: Python Facial Expression Analysis Toolbox","summary":"  Studying facial expressions is a notoriously difficult endeavor. Recent\nadvances in the field of affective computing have yielded impressive progress\nin automatically detecting facial expressions from pictures and videos.\nHowever, much of this work has yet to be widely disseminated in social science\ndomains such as psychology. Current state of the art models require\nconsiderable domain expertise that is not traditionally incorporated into\nsocial science training programs. Furthermore, there is a notable absence of\nuser-friendly and open-source software that provides a comprehensive set of\ntools and functions that support facial expression research. In this paper, we\nintroduce Py-Feat, an open-source Python toolbox that provides support for\ndetecting, preprocessing, analyzing, and visualizing facial expression data.\nPy-Feat makes it easy for domain experts to disseminate and benchmark computer\nvision models and also for end users to quickly process, analyze, and visualize\nface expression data. We hope this platform will facilitate increased use of\nfacial expression data in human behavior research.\n","authors":["Jin Hyun Cheong","Eshin Jolly","Tiankang Xie","Sophie Byrne","Matthew Kenny","Luke J. Chang"],"pdf_url":"https://arxiv.org/pdf/2104.03509v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12057v2","updated":"2023-01-31T18:17:26Z","published":"2022-10-21T15:49:20Z","title":"Efficient Global Planning in Large MDPs via Stochastic Primal-Dual\n  Optimization","summary":"  We propose a new stochastic primal-dual optimization algorithm for planning\nin a large discounted Markov decision process with a generative model and\nlinear function approximation. Assuming that the feature map approximately\nsatisfies standard realizability and Bellman-closedness conditions and also\nthat the feature vectors of all state-action pairs are representable as convex\ncombinations of a small core set of state-action pairs, we show that our method\noutputs a near-optimal policy after a polynomial number of queries to the\ngenerative model. Our method is computationally efficient and comes with the\nmajor advantage that it outputs a single softmax policy that is compactly\nrepresented by a low-dimensional parameter vector, and does not need to execute\ncomputationally expensive local planning subroutines in runtime.\n","authors":["Gergely Neu","Nneka Okolo"],"pdf_url":"https://arxiv.org/pdf/2210.12057v2.pdf","comment":"23 pages including reference and appendix"},{"id":"http://arxiv.org/abs/2201.09592v2","updated":"2023-01-31T18:12:46Z","published":"2022-01-24T11:05:30Z","title":"Unsupervised Music Source Separation Using Differentiable Parametric\n  Source Models","summary":"  Supervised deep learning approaches to underdetermined audio source\nseparation achieve state-of-the-art performance but require a dataset of\nmixtures along with their corresponding isolated source signals. Such datasets\ncan be extremely costly to obtain for musical mixtures. This raises a need for\nunsupervised methods. We propose a novel unsupervised model-based deep learning\napproach to musical source separation. Each source is modelled with a\ndifferentiable parametric source-filter model. A neural network is trained to\nreconstruct the observed mixture as a sum of the sources by estimating the\nsource models' parameters given their fundamental frequencies. At test time,\nsoft masks are obtained from the synthesized source signals. The experimental\nevaluation on a vocal ensemble separation task shows that the proposed method\noutperforms learning-free methods based on nonnegative matrix factorization and\na supervised deep learning baseline. Integrating domain knowledge in the form\nof source models into a data-driven method leads to high data efficiency: the\nproposed approach achieves good separation quality even when trained on less\nthan three minutes of audio. This work makes powerful deep learning based\nseparation usable in scenarios where training data with ground truth is\nexpensive or nonexistent.\n","authors":["Kilian Schulze-Forster","Gaël Richard","Liam Kelley","Clement S. J. Doire","Roland Badeau"],"pdf_url":"https://arxiv.org/pdf/2201.09592v2.pdf","comment":"Revised version of the submission"},{"id":"http://arxiv.org/abs/2301.13826v1","updated":"2023-01-31T18:10:38Z","published":"2023-01-31T18:10:38Z","title":"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image\n  Diffusion Models","summary":"  Recent text-to-image generative models have demonstrated an unparalleled\nability to generate diverse and creative imagery guided by a target text\nprompt. While revolutionary, current state-of-the-art diffusion models may\nstill fail in generating images that fully convey the semantics in the given\ntext prompt. We analyze the publicly available Stable Diffusion model and\nassess the existence of catastrophic neglect, where the model fails to generate\none or more of the subjects from the input prompt. Moreover, we find that in\nsome cases the model also fails to correctly bind attributes (e.g., colors) to\ntheir corresponding subjects. To help mitigate these failure cases, we\nintroduce the concept of Generative Semantic Nursing (GSN), where we seek to\nintervene in the generative process on the fly during inference time to improve\nthe faithfulness of the generated images. Using an attention-based formulation\nof GSN, dubbed Attend-and-Excite, we guide the model to refine the\ncross-attention units to attend to all subject tokens in the text prompt and\nstrengthen - or excite - their activations, encouraging the model to generate\nall subjects described in the text prompt. We compare our approach to\nalternative approaches and demonstrate that it conveys the desired concepts\nmore faithfully across a range of text prompts.\n","authors":["Hila Chefer","Yuval Alaluf","Yael Vinker","Lior Wolf","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2301.13826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.17193v2","updated":"2023-01-31T18:10:31Z","published":"2022-03-31T17:17:08Z","title":"Learning from many trajectories","summary":"  We initiate a study of supervised learning from many independent sequences\n(\"trajectories\") of non-independent covariates, reflecting tasks in sequence\nmodeling, control, and reinforcement learning. Conceptually, our\nmulti-trajectory setup sits between two traditional settings in statistical\nlearning theory: learning from independent examples and learning from a single\nauto-correlated sequence. Our conditions for efficient learning generalize the\nformer setting--trajectories must be non-degenerate in ways that extend\nstandard requirements for independent examples. Notably, we do not require that\ntrajectories be ergodic, long, nor strictly stable.\n  For linear least-squares regression, given $n$-dimensional examples produced\nby $m$ trajectories, each of length $T$, we observe a notable change in\nstatistical efficiency as the number of trajectories increases from a few\n(namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we\nestablish that the worst-case error rate of this problem is $\\Theta(n / m T)$\nwhenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp)\nlower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by\na simple, marginally unstable linear dynamical system. A key upshot is that, in\ndomains where trajectories regularly reset, the error rate eventually behaves\nas if all of the examples were independent, drawn from their marginals. As a\ncorollary of our analysis, we also improve guarantees for the linear system\nidentification problem.\n","authors":["Stephen Tu","Roy Frostig","Mahdi Soltanolkotabi"],"pdf_url":"https://arxiv.org/pdf/2203.17193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13821v1","updated":"2023-01-31T18:07:26Z","published":"2023-01-31T18:07:26Z","title":"Complete Neural Networks for Euclidean Graphs","summary":"  We propose a 2-WL-like geometric graph isomorphism test and prove it is\ncomplete when applied to Euclidean Graphs in $\\mathbb{R}^3$. We then use recent\nresults on multiset embeddings to devise an efficient geometric GNN model with\nequivalent separation power. We verify empirically that our GNN model is able\nto separate particularly challenging synthetic examples, and demonstrate its\nusefulness for a chemical property prediction problem.\n","authors":["Snir Hordan","Tal Amir","Steven J. Gortler","Nadav Dym"],"pdf_url":"https://arxiv.org/pdf/2301.13821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13816v1","updated":"2023-01-31T18:02:26Z","published":"2023-01-31T18:02:26Z","title":"Execution-based Code Generation using Deep Reinforcement Learning","summary":"  The utilization of programming language (PL) models, pretrained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting specific sequence-level\nfeatures of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that combines pretrained PL\nmodels with Proximal Policy Optimization (PPO) deep reinforcement learning and\nemploys execution feedback as the external source of knowledge into the model\noptimization. PPOCoder is transferable across different code generation tasks\nand PLs. Extensive experiments on three code generation tasks demonstrate the\neffectiveness of our proposed approach compared to SOTA methods, improving the\nsuccess rate of compilation and functional correctness over different PLs. Our\ncode can be found at https://github.com/reddy-lab-code-research/PPOCoder .\n","authors":["Parshin Shojaee","Aneesh Jain","Sindhu Tipirneni","Chandan K. Reddy"],"pdf_url":"https://arxiv.org/pdf/2301.13816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06987v3","updated":"2023-01-31T18:01:40Z","published":"2022-08-15T03:08:58Z","title":"A Unified Causal View of Domain Invariant Representation Learning","summary":"  Machine learning methods can be unreliable when deployed in domains that\ndiffer from the domains on which they were trained. There are a wide range of\nproposals for mitigating this problem by learning representations that are\n``invariant'' in some sense.However, these methods generally contradict each\nother, and none of them consistently improve performance on real-world domain\nshift benchmarks. There are two main questions that must be addressed to\nunderstand when, if ever, we should use each method. First, how does each ad\nhoc notion of ``invariance'' relate to the structure of real-world problems?\nAnd, second, when does learning invariant representations actually yield robust\nmodels? To address these issues, we introduce a broad formal notion of what it\nmeans for a real-world domain shift to admit invariant structure. Then, we\ncharacterize the causal structures that are compatible with this notion of\ninvariance.With this in hand, we find conditions under which method-specific\ninvariance notions correspond to real-world invariant structure, and we clarify\nthe relationship between invariant structure and robustness to domain shifts.\nFor both questions, we find that the true underlying causal structure of the\ndata plays a critical role.\n","authors":["Zihao Wang","Victor Veitch"],"pdf_url":"https://arxiv.org/pdf/2208.06987v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10483v2","updated":"2023-01-31T17:58:55Z","published":"2022-08-22T17:55:43Z","title":"Prioritizing Samples in Reinforcement Learning with Reducible Loss","summary":"  Most reinforcement learning algorithms take advantage of an experience replay\nbuffer to repeatedly train on samples the agent has observed in the past. Not\nall samples carry the same amount of significance and simply assigning equal\nimportance to each of the samples is a na\\\"ive strategy. In this paper, we\npropose a method to prioritize samples based on how much we can learn from a\nsample. We define the learn-ability of a sample as the steady decrease of the\ntraining loss associated with this sample over time. We develop an algorithm to\nprioritize samples with high learn-ability, while assigning lower priority to\nthose that are hard-to-learn, typically caused by noise or stochasticity. We\nempirically show that our method is more robust than random sampling and also\nbetter than just prioritizing with respect to the training loss, i.e. the\ntemporal difference loss, which is used in prioritized experience replay.\n","authors":["Shivakanth Sujit","Somjit Nath","Pedro H. M. Braga","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2208.10483v2.pdf","comment":"DeepRL Workshop, NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.13807v1","updated":"2023-01-31T17:50:52Z","published":"2023-01-31T17:50:52Z","title":"Identifying the Hazard Boundary of ML-enabled Autonomous Systems Using\n  Cooperative Co-Evolutionary Search","summary":"  In Machine Learning (ML)-enabled autonomous systems (MLASs), it is essential\nto identify the hazard boundary of ML Components (MLCs) in the MLAS under\nanalysis. Given that such boundary captures the conditions in terms of MLC\nbehavior and system context that can lead to hazards, it can then be used to,\nfor example, build a safety monitor that can take any predefined fallback\nmechanisms at runtime when reaching the hazard boundary. However, determining\nsuch hazard boundary for an ML component is challenging. This is due to the\nspace combining system contexts (i.e., scenarios) and MLC behaviors (i.e.,\ninputs and outputs) being far too large for exhaustive exploration and even to\nhandle using conventional metaheuristics, such as genetic algorithms.\nAdditionally, the high computational cost of simulations required to determine\nany MLAS safety violations makes the problem even more challenging.\nFurthermore, it is unrealistic to consider a region in the problem space\ndeterministically safe or unsafe due to the uncontrollable parameters in\nsimulations and the non-linear behaviors of ML models (e.g., deep neural\nnetworks) in the MLAS under analysis. To address the challenges, we propose\nMLCSHE (ML Component Safety Hazard Envelope), a novel method based on a\nCooperative Co-Evolutionary Algorithm (CCEA), which aims to tackle a\nhigh-dimensional problem by decomposing it into two lower-dimensional search\nsubproblems. Moreover, we take a probabilistic view of safe and unsafe regions\nand define a novel fitness function to measure the distance from the\nprobabilistic hazard boundary and thus drive the search effectively. We\nevaluate the effectiveness and efficiency of MLCSHE on a complex Autonomous\nVehicle (AV) case study. Our evaluation results show that MLCSHE is\nsignificantly more effective and efficient compared to a standard genetic\nalgorithm and random search.\n","authors":["Sepehr Sharifi","Donghwan Shin","Lionel C. Briand","Nathan Aschbacher"],"pdf_url":"https://arxiv.org/pdf/2301.13807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13803v1","updated":"2023-01-31T17:44:59Z","published":"2023-01-31T17:44:59Z","title":"Fairness-aware Vision Transformer via Debiased Self-Attention","summary":"  Vision Transformer (ViT) has recently gained significant interest in solving\ncomputer vision (CV) problems due to its capability of extracting informative\nfeatures and modeling long-range dependencies through the self-attention\nmechanism. To fully realize the advantages of ViT in real-world applications,\nrecent works have explored the trustworthiness of ViT, including its robustness\nand explainability. However, another desiderata, fairness has not yet been\nadequately addressed in the literature. We establish that the existing\nfairness-aware algorithms (primarily designed for CNNs) do not perform well on\nViT. This necessitates the need for developing our novel framework via Debiased\nSelf-Attention (DSA). DSA is a fairness-through-blindness approach that\nenforces ViT to eliminate spurious features correlated with the sensitive\nattributes for bias mitigation. Notably, adversarial examples are leveraged to\nlocate and mask the spurious features in the input image patches. In addition,\nDSA utilizes an attention weights alignment regularizer in the training\nobjective to encourage learning informative features for target prediction.\nImportantly, our DSA framework leads to improved fairness guarantees over prior\nworks on multiple prediction tasks without compromising target prediction\nperformance\n","authors":["Yao Qiang","Chengyin Li","Prashant Khanduri","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.13803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13799v1","updated":"2023-01-31T17:41:07Z","published":"2023-01-31T17:41:07Z","title":"Partitioning Distributed Compute Jobs with Reinforcement Learning and\n  Graph Neural Networks","summary":"  From natural language processing to genome sequencing, large-scale machine\nlearning models are bringing advances to a broad range of fields. Many of these\nmodels are too large to be trained on a single machine, and instead must be\ndistributed across multiple devices. This has motivated the research of new\ncompute and network systems capable of handling such tasks. In particular,\nrecent work has focused on developing management schemes which decide how to\nallocate distributed resources such that some overall objective, such as\nminimising the job completion time (JCT), is optimised. However, such studies\nomit explicit consideration of how much a job should be distributed, usually\nassuming that maximum distribution is desirable. In this work, we show that\nmaximum parallelisation is sub-optimal in relation to user-critical metrics\nsuch as throughput and blocking rate. To address this, we propose PAC-ML\n(partitioning for asynchronous computing with machine learning). PAC-ML\nleverages a graph neural network and reinforcement learning to learn how much\nto partition computation graphs such that the number of jobs which meet\narbitrary user-defined JCT requirements is maximised. In experiments with five\nreal deep learning computation graphs on a recently proposed optical\narchitecture across four user-defined JCT requirement distributions, we\ndemonstrate PAC-ML achieving up to 56.2% lower blocking rates in dynamic job\narrival settings than the canonical maximum parallelisation strategy used by\nmost prior works.\n","authors":["Christopher W. F. Parsonson","Zacharaya Shabka","Alessandro Ottino","Georgios Zervas"],"pdf_url":"https://arxiv.org/pdf/2301.13799v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2301.13791v1","updated":"2023-01-31T17:35:43Z","published":"2023-01-31T17:35:43Z","title":"Improved Algorithms for Multi-period Multi-class Packing Problems\n  with~Bandit~Feedback","summary":"  We consider the linear contextual multi-class multi-period packing\nproblem~(LMMP) where the goal is to pack items such that the total vector of\nconsumption is below a given budget vector and the total value is as large as\npossible. We consider the setting where the reward and the consumption vector\nassociated with each action is a class-dependent linear function of the\ncontext, and the decision-maker receives bandit feedback. LMMP includes linear\ncontextual bandits with knapsacks and online revenue management as special\ncases. We establish a new more efficient estimator which guarantees a faster\nconvergence rate, and consequently, a lower regret in such problems. We propose\na bandit policy that is a closed-form function of said estimated parameters.\nWhen the contexts are non-degenerate, the regret of the proposed policy is\nsublinear in the context dimension, the number of classes, and the time\nhorizon~$T$ when the budget grows at least as $\\sqrt{T}$. We also resolve an\nopen problem posed in Agrawal & Devanur (2016), and extend the result to a\nmulti-class setting. Our numerical experiments clearly demonstrate that the\nperformance of our policy is superior to other benchmarks in the literature.\n","authors":["Wonyoung Kim","Garud Iyengar","Assaf Zeevi"],"pdf_url":"https://arxiv.org/pdf/2301.13791v1.pdf","comment":"42 pages including Appendix"},{"id":"http://arxiv.org/abs/2301.13786v1","updated":"2023-01-31T17:33:35Z","published":"2023-01-31T17:33:35Z","title":"Deep learning-based lung segmentation and automatic regional template in\n  chest X-ray images for pediatric tuberculosis","summary":"  Tuberculosis (TB) is still considered a leading cause of death and a\nsubstantial threat to global child health. Both TB infection and disease are\ncurable using antibiotics. However, most children who die of TB are never\ndiagnosed or treated. In clinical practice, experienced physicians assess TB by\nexamining chest X-rays (CXR). Pediatric CXR has specific challenges compared to\nadult CXR, which makes TB diagnosis in children more difficult. Computer-aided\ndiagnosis systems supported by Artificial Intelligence have shown performance\ncomparable to experienced radiologist TB readings, which could ease mass TB\nscreening and reduce clinical burden. We propose a multi-view deep\nlearning-based solution which, by following a proposed template, aims to\nautomatically regionalize and extract lung and mediastinal regions of interest\nfrom pediatric CXR images where key TB findings may be present. Experimental\nresults have shown accurate region extraction, which can be used for further\nanalysis to confirm TB finding presence and severity assessment. Code publicly\navailable at https://github.com/dani-capellan/pTB_LungRegionExtractor.\n","authors":["Daniel Capellán-Martín","Juan J. Gómez-Valverde","Ramon Sanchez-Jacob","David Bermejo-Peláez","Lara García-Delgado","Elisa López-Varela","Maria J. Ledesma-Carbayo"],"pdf_url":"https://arxiv.org/pdf/2301.13786v1.pdf","comment":"This work has been accepted at the SPIE Medical Imaging 2023, Image\n  Processing conference"},{"id":"http://arxiv.org/abs/2301.13778v1","updated":"2023-01-31T17:27:05Z","published":"2023-01-31T17:27:05Z","title":"Differentially Private Distributed Bayesian Linear Regression with MCMC","summary":"  We propose a novel Bayesian inference framework for distributed\ndifferentially private linear regression. We consider a distributed setting\nwhere multiple parties hold parts of the data and share certain summary\nstatistics of their portions in privacy-preserving noise. We develop a novel\ngenerative statistical model for privately shared statistics, which exploits a\nuseful distributional relation between the summary statistics of linear\nregression. Bayesian estimation of the regression coefficients is conducted\nmainly using Markov chain Monte Carlo algorithms, while we also provide a fast\nversion to perform Bayesian estimation in one iteration. The proposed methods\nhave computational advantages over their competitors. We provide numerical\nresults on both real and simulated data, which demonstrate that the proposed\nalgorithms provide well-rounded estimation and prediction.\n","authors":["Barış Alparslan","Sinan Yıldırım","Ş. İlker Birbil"],"pdf_url":"https://arxiv.org/pdf/2301.13778v1.pdf","comment":"20 pages, 3 figures, code available at:\n  https://github.com/sinanyildirim/Bayesian_DP_dist_LR"},{"id":"http://arxiv.org/abs/2301.13767v1","updated":"2023-01-31T17:05:24Z","published":"2023-01-31T17:05:24Z","title":"Multicalibration as Boosting for Regression","summary":"  We study the connection between multicalibration and boosting for squared\nerror regression. First we prove a useful characterization of multicalibration\nin terms of a ``swap regret'' like condition on squared error. Using this\ncharacterization, we give an exceedingly simple algorithm that can be analyzed\nboth as a boosting algorithm for regression and as a multicalibration algorithm\nfor a class H that makes use only of a standard squared error regression oracle\nfor H. We give a weak learning assumption on H that ensures convergence to\nBayes optimality without the need to make any realizability assumptions --\ngiving us an agnostic boosting algorithm for regression. We then show that our\nweak learning assumption on H is both necessary and sufficient for\nmulticalibration with respect to H to imply Bayes optimality. We also show that\nif H satisfies our weak learning condition relative to another class C then\nmulticalibration with respect to H implies multicalibration with respect to C.\nFinally we investigate the empirical performance of our algorithm\nexperimentally using an open source implementation that we make available. Our\ncode repository can be found at\nhttps://github.com/Declancharrison/Level-Set-Boosting.\n","authors":["Ira Globus-Harris","Declan Harrison","Michael Kearns","Aaron Roth","Jessica Sorrell"],"pdf_url":"https://arxiv.org/pdf/2301.13767v1.pdf","comment":"Code available here:\n  https://github.com/Declancharrison/Level-Set-Boosting"},{"id":"http://arxiv.org/abs/2301.13764v1","updated":"2023-01-31T16:55:42Z","published":"2023-01-31T16:55:42Z","title":"Semi-Supervised Classification with Graph Convolutional Kernel Machines","summary":"  We present a deep Graph Convolutional Kernel Machine (GCKM) for\nsemi-supervised node classification in graphs. First, we introduce an\nunsupervised kernel machine propagating the node features in a one-hop\nneighbourhood. Then, we specify a semi-supervised classification kernel machine\nthrough the lens of the Fenchel-Young inequality. The deep graph convolutional\nkernel machine is obtained by stacking multiple shallow kernel machines. After\nshowing that unsupervised and semi-supervised layer corresponds to an\neigenvalue problem and a linear system on the aggregated node features,\nrespectively, we derive an efficient end-to-end training algorithm in the dual\nvariables. Numerical experiments demonstrate that our approach is competitive\nwith state-of-the-art graph neural networks for homophilious and heterophilious\nbenchmark datasets. Notably, GCKM achieves superior performance when very few\nlabels are available.\n","authors":["Sonny Achten","Francesco Tonin","Panagiotis Patrinos","Johan A. K. Suykens"],"pdf_url":"https://arxiv.org/pdf/2301.13764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13758v1","updated":"2023-01-31T16:47:09Z","published":"2023-01-31T16:47:09Z","title":"Learning, Fast and Slow: A Goal-Directed Memory-Based Approach for\n  Dynamic Environments","summary":"  Model-based next state prediction and state value prediction are slow to\nconverge. To address these challenges, we do the following: i) Instead of a\nneural network, we do model-based planning using a parallel memory retrieval\nsystem (which we term the slow mechanism); ii) Instead of learning state\nvalues, we guide the agent's actions using goal-directed exploration, by using\na neural network to choose the next action given the current state and the goal\nstate (which we term the fast mechanism). The goal-directed exploration is\ntrained online using hippocampal replay of visited states and future imagined\nstates every single time step, leading to fast and efficient training.\nEmpirical studies show that our proposed method has a 92% solve rate across 100\nepisodes in a dynamically changing grid world, significantly outperforming\nstate-of-the-art actor critic mechanisms such as PPO (54%), TRPO (50%) and A2C\n(24%). Ablation studies demonstrate that both mechanisms are crucial. We posit\nthat the future of Reinforcement Learning (RL) will be to model goals and\nsub-goals for various tasks, and plan it out in a goal-directed memory-based\napproach.\n","authors":["Tan Chong Min John","Mehul Motani"],"pdf_url":"https://arxiv.org/pdf/2301.13758v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2301.13757v1","updated":"2023-01-31T16:45:49Z","published":"2023-01-31T16:45:49Z","title":"Toward Efficient Gradient-Based Value Estimation","summary":"  Gradient-based methods for value estimation in reinforcement learning have\nfavorable stability properties, but they are typically much slower than\nTemporal Difference (TD) learning methods. We study the root causes of this\nslowness and show that Mean Square Bellman Error (MSBE) is an ill-conditioned\nloss function in the sense that its Hessian has large condition-number. To\nresolve the adverse effect of poor conditioning of MSBE on gradient based\nmethods, we propose a low complexity batch-free proximal method that\napproximately follows the Gauss-Newton direction and is asymptotically robust\nto parameterization. Our main algorithm, called RANS, is efficient in the sense\nthat it is significantly faster than the residual gradient methods while having\nalmost the same computational complexity, and is competitive with TD on the\nclassic problems that we tested.\n","authors":["Arsalan Sharifnassab","Richard Sutton"],"pdf_url":"https://arxiv.org/pdf/2301.13757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13755v1","updated":"2023-01-31T16:43:53Z","published":"2023-01-31T16:43:53Z","title":"Retrosynthetic Planning with Dual Value Networks","summary":"  Retrosynthesis, which aims to find a route to synthesize a target molecule\nfrom commercially available starting materials, is a critical task in drug\ndiscovery and materials design. Recently, the combination of ML-based\nsingle-step reaction predictors with multi-step planners has led to promising\nresults. However, the single-step predictors are mostly trained offline to\noptimize the single-step accuracy, without considering complete routes. Here,\nwe leverage reinforcement learning (RL) to improve the single-step predictor,\nby using a tree-shaped MDP to optimize complete routes while retaining\nsingle-step accuracy. Desirable routes should be both synthesizable and of low\ncost. We propose an online training algorithm, called Planning with Dual Value\nNetworks (PDVN), in which two value networks predict the synthesizability and\ncost of molecules, respectively. To maintain the single-step accuracy, we\ndesign a two-branch network structure for the single-step predictor. On the\nwidely-used USPTO dataset, our PDVN algorithm improves the search success rate\nof existing multi-step planners (e.g., increasing the success rate from 85.79%\nto 98.95% for Retro*, and reducing the number of model calls by half while\nsolving 99.47% molecules for RetroGraph). Furthermore, PDVN finds shorter\nsynthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for\nRetro*, and from 5.63 to 4.78 for RetroGraph).\n","authors":["Guoqing Liu","Di Xue","Shufang Xie","Yingce Xia","Austin Tripp","Krzysztof Maziarz","Marwin Segler","Tao Qin","Zongzhang Zhang","Tie-Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2301.13755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v2","updated":"2023-01-31T16:42:04Z","published":"2020-12-22T19:32:52Z","title":"Video Influencers: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent elements in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using a novel \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) followed by acoustics (audio). Our interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video elements. We\neliminate several spurious and confounded relationships, and identify a smaller\nsubset of theory-based relationships. We uncover novel findings that establish\ndistinct effects for measures of shallow and deep engagement which are based on\nthe dual-system framework of human thinking. Our approach is validated using\nsimulated data, and we discuss the learnings from our findings for influencers\nand brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v2.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2201.06463v4","updated":"2023-01-31T16:40:06Z","published":"2022-01-17T15:16:26Z","title":"Bayesian Calibration of Imperfect Computer Models using Physics-Informed\n  Priors","summary":"  We introduce a computational efficient data-driven framework suitable for\nquantifying the uncertainty in physical parameters and model formulation of\ncomputer models, represented by differential equations. We construct\nphysics-informed priors, which are multi-output GP priors that encode the\nmodel's structure in the covariance function. This is extended into a fully\nBayesian framework that quantifies the uncertainty of physical parameters and\nmodel predictions. Since physical models often are imperfect descriptions of\nthe real process, we allow the model to deviate from the observed data by\nconsidering a discrepancy function. For inference, Hamiltonian Monte Carlo is\nused. Further, approximations for big data are developed that reduce the\ncomputational complexity from $\\mathcal{O}(N^3)$ to $\\mathcal{O}(N\\cdot m^2),$\nwhere $m \\ll N.$ Our approach is demonstrated in simulation and real data case\nstudies where the physics are described by time-dependent ODEs describe\n(cardiovascular models) and space-time dependent PDEs (heat equation). In the\nstudies, it is shown that our modelling framework can recover the true\nparameters of the physical models in cases where 1) the reality is more complex\nthan our modelling choice and 2) the data acquisition process is biased while\nalso producing accurate predictions. Furthermore, it is demonstrated that our\napproach is computationally faster than traditional Bayesian calibration\nmethods.\n","authors":["Michail Spitieris","Ingelin Steinsland"],"pdf_url":"https://arxiv.org/pdf/2201.06463v4.pdf","comment":"48 pages, 21 figures"},{"id":"http://arxiv.org/abs/2206.02795v2","updated":"2023-01-31T16:37:00Z","published":"2022-06-06T11:58:11Z","title":"Forecasting COVID- 19 cases using Statistical Models and Ontology-based\n  Semantic Modelling: A real time data analytics approach","summary":"  SARS-COV-19 is the most prominent issue which many countries face today. The\nfrequent changes in infections, recovered and deaths represents the dynamic\nnature of this pandemic. It is very crucial to predict the spreading rate of\nthis virus for accurate decision making against fighting with the situation of\ngetting infected through the virus, tracking and controlling the virus\ntransmission in the community. We develop a prediction model using statistical\ntime series models such as SARIMA and FBProphet to monitor the daily active,\nrecovered and death cases of COVID-19 accurately. Then with the help of various\ndetails across each individual patient (like height, weight, gender etc.), we\ndesigned a set of rules using Semantic Web Rule Language and some mathematical\nmodels for dealing with COVID19 infected cases on an individual basis. After\ncombining all the models, a COVID-19 Ontology is developed and performs various\nqueries using SPARQL query on designed Ontology which accumulate the risk\nfactors, provide appropriate diagnosis, precautions and preventive suggestions\nfor COVID Patients. After comparing the performance of SARIMA and FBProphet, it\nis observed that the SARIMA model performs better in forecasting of COVID\ncases. On individual basis COVID case prediction, approx. 497 individual\nsamples have been tested and classified into five different levels of COVID\nclasses such as Having COVID, No COVID, High Risk COVID case, Medium to High\nRisk case, and Control needed case.\n","authors":["Sadhana Tiwari","Ritesh Chandra","Sonali Agarwal"],"pdf_url":"https://arxiv.org/pdf/2206.02795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13749v1","updated":"2023-01-31T16:33:46Z","published":"2023-01-31T16:33:46Z","title":"Multi-fidelity covariance estimation in the log-Euclidean geometry","summary":"  We introduce a multi-fidelity estimator of covariance matrices that employs\nthe log-Euclidean geometry of the symmetric positive-definite manifold. The\nestimator fuses samples from a hierarchy of data sources of differing\nfidelities and costs for variance reduction while guaranteeing definiteness, in\ncontrast with previous approaches. The new estimator makes covariance\nestimation tractable in applications where simulation or data collection is\nexpensive; to that end, we develop an optimal sample allocation scheme that\nminimizes the mean-squared error of the estimator given a fixed budget.\nGuaranteed definiteness is crucial to metric learning, data assimilation, and\nother downstream tasks. Evaluations of our approach using data from physical\napplications (heat conduction, fluid dynamics) demonstrate more accurate metric\nlearning and speedups of more than one order of magnitude compared to\nbenchmarks.\n","authors":["Aimee Maurais","Terrence Alsup","Benjamin Peherstorfer","Youssef Marzouk"],"pdf_url":"https://arxiv.org/pdf/2301.13749v1.pdf","comment":"27 pages, 10 figures, code supplement"},{"id":"http://arxiv.org/abs/2301.13748v1","updated":"2023-01-31T16:33:22Z","published":"2023-01-31T16:33:22Z","title":"Archetypal Analysis++: Rethinking the Initialization Strategy","summary":"  Archetypal analysis is a matrix factorization method with convexity\nconstraints. Due to local minima, a good initialization is essential.\nFrequently used initialization methods yield either sub-optimal starting points\nor are prone to get stuck in poor local minima. In this paper, we propose\narchetypal analysis++ (AA++), a probabilistic initialization strategy for\narchetypal analysis that sequentially samples points based on their influence\non the objective, similar to $k$-means++. In fact, we argue that $k$-means++\nalready approximates the proposed initialization method. Furthermore, we\nsuggest to adapt an efficient Monte Carlo approximation of $k$-means++ to AA++.\nIn an extensive empirical evaluation of 13 real-world data sets of varying\nsizes and dimensionalities and considering two pre-processing strategies, we\nshow that AA++ almost consistently outperforms all baselines, including the\nmost frequently used ones.\n","authors":["Sebastian Mair","Jens Sjölund"],"pdf_url":"https://arxiv.org/pdf/2301.13748v1.pdf","comment":"20 pages, 13 figures, preprint"},{"id":"http://arxiv.org/abs/2301.13743v1","updated":"2023-01-31T16:24:34Z","published":"2023-01-31T16:24:34Z","title":"Zero-shot-Learning Cross-Modality Data Translation Through Mutual\n  Information Guided Stochastic Diffusion","summary":"  Cross-modality data translation has attracted great interest in image\ncomputing. Deep generative models (\\textit{e.g.}, GANs) show performance\nimprovement in tackling those problems. Nevertheless, as a fundamental\nchallenge in image translation, the problem of Zero-shot-Learning\nCross-Modality Data Translation with fidelity remains unanswered. This paper\nproposes a new unsupervised zero-shot-learning method named Mutual Information\nguided Diffusion cross-modality data translation Model (MIDiffusion), which\nlearns to translate the unseen source data to the target domain. The\nMIDiffusion leverages a score-matching-based generative model, which learns the\nprior knowledge in the target domain. We propose a differentiable\nlocal-wise-MI-Layer ($LMI$) for conditioning the iterative denoising sampling.\nThe $LMI$ captures the identical cross-modality features in the statistical\ndomain for the diffusion guidance; thus, our method does not require retraining\nwhen the source domain is changed, as it does not rely on any direct mapping\nbetween the source and target domains. This advantage is critical for applying\ncross-modality data translation methods in practice, as a reasonable amount of\nsource domain dataset is not always available for supervised training. We\nempirically show the advanced performance of MIDiffusion in comparison with an\ninfluential group of generative models, including adversarial-based and other\nscore-matching-based models.\n","authors":["Zihao Wang","Yingyu Yang","Maxime Sermesant","Hervé Delingette","Ona Wu"],"pdf_url":"https://arxiv.org/pdf/2301.13743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13741v1","updated":"2023-01-31T16:18:52Z","published":"2023-01-31T16:18:52Z","title":"UPop: Unified and Progressive Pruning for Compressing Vision-Language\n  Transformers","summary":"  Real-world data contains a vast amount of multimodal information, among which\nvision and language are the two most representative modalities. Moreover,\nincreasingly heavier models, e.g., Transformers, have attracted the attention\nof researchers to model compression. However, how to compress multimodal\nmodels, especially vison-language Transformers, is still under-explored. This\npaper proposes the \\textbf{U}nified and \\textbf{P}r\\textbf{o}gressive\n\\textbf{P}runing (UPop) as a universal vison-language Transformer compression\nframework, which incorporates 1) unifiedly searching multimodal subnets in a\ncontinuous optimization space from the original model, which enables automatic\nassignment of pruning ratios among compressible modalities and structures; 2)\nprogressively searching and retraining the subnet, which maintains convergence\nbetween the search and retrain to attain higher compression ratios. Experiments\non multiple generative and discriminative vision-language tasks, including\nVisual Reasoning, Image Caption, Visual Question Answer, Image-Text Retrieval,\nText-Image Retrieval, and Image Classification, demonstrate the effectiveness\nand versatility of the proposed UPop framework.\n","authors":["Dachuan Shi","Chaofan Tao","Ying Jin","Zhendong Yang","Chun Yuan","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2301.13741v1.pdf","comment":"16 pages, 5 figures, 13 tables"},{"id":"http://arxiv.org/abs/2301.13737v1","updated":"2023-01-31T16:17:18Z","published":"2023-01-31T16:17:18Z","title":"Self-Consistent Velocity Matching of Probability Flows","summary":"  We present a discretization-free scalable framework for solving a large class\nof mass-conserving partial differential equations (PDEs), including the\ntime-dependent Fokker-Planck equation and the Wasserstein gradient flow. The\nmain observation is that the time-varying velocity field of the PDE solution\nneeds to be self-consistent: it must satisfy a fixed-point equation involving\nthe flow characterized by the same velocity field. By parameterizing the flow\nas a time-dependent neural network, we propose an end-to-end iterative\noptimization framework called self-consistent velocity matching to solve this\nclass of PDEs. Compared to existing approaches, our method does not suffer from\ntemporal or spatial discretization, covers a wide range of PDEs, and scales to\nhigh dimensions. Experimentally, our method recovers analytical solutions\naccurately when they are available and achieves comparable or better\nperformance in high dimensions with less training time compared to recent\nlarge-scale JKO-based methods that are designed for solving a more restrictive\nfamily of PDEs.\n","authors":["Lingxiao Li","Samuel Hurault","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2301.13737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.05022v3","updated":"2023-01-31T16:12:50Z","published":"2022-07-11T17:15:57Z","title":"STI: Turbocharge NLP Inference at the Edge via Elastic Pipelining","summary":"  Natural Language Processing (NLP) inference is seeing increasing adoption by\nmobile applications, where on-device inference is desirable for crucially\npreserving user data privacy and avoiding network roundtrips. Yet, the\nunprecedented size of an NLP model stresses both latency and memory, creating a\ntension between the two key resources of a mobile device. To meet a target\nlatency, holding the whole model in memory launches execution as soon as\npossible but increases one app's memory footprints by several times, limiting\nits benefits to only a few inferences before being recycled by mobile memory\nmanagement. On the other hand, loading the model from storage on demand incurs\nIO as long as a few seconds, far exceeding the delay range satisfying to a\nuser; pipelining layerwise model loading and execution does not hide IO either,\ndue to the high skewness between IO and computation delays.\n  To this end, we propose Speedy Transformer Inference (STI). Built on the key\nidea of maximizing IO/compute resource utilization on the most important parts\nof a model, STI reconciles the latency v.s. memory tension via two novel\ntechniques. First, model sharding. STI manages model parameters as\nindependently tunable shards, and profiles their importance to accuracy.\nSecond, elastic pipeline planning with a preload buffer. STI instantiates an\nIO/compute pipeline and uses a small buffer for preload shards to bootstrap\nexecution without stalling at early stages; it judiciously selects, tunes, and\nassembles shards per their importance for resource-elastic execution,\nmaximizing inference accuracy.\n  Atop two commodity SoCs, we build STI and evaluate it against a wide range of\nNLP tasks, under a practical range of target latencies, and on both CPU and\nGPU. We demonstrate that STI delivers high accuracies with 1-2 orders of\nmagnitude lower memory, outperforming competitive baselines.\n","authors":["Liwei Guo","Wonkyo Choe","Felix Xiaozhu Lin"],"pdf_url":"https://arxiv.org/pdf/2207.05022v3.pdf","comment":"ASPLOS'23"},{"id":"http://arxiv.org/abs/2301.13734v1","updated":"2023-01-31T16:12:31Z","published":"2023-01-31T16:12:31Z","title":"Improving Monte Carlo Evaluation with Offline Data","summary":"  Monte Carlo (MC) methods are the most widely used methods to estimate the\nperformance of a policy. Given an interested policy, MC methods give estimates\nby repeatedly running this policy to collect samples and taking the average of\nthe outcomes. Samples collected during this process are called online samples.\nTo get an accurate estimate, MC methods consume massive online samples. When\nonline samples are expensive, e.g., online recommendations and inventory\nmanagement, we want to reduce the number of online samples while achieving the\nsame estimate accuracy. To this end, we use off-policy MC methods that evaluate\nthe interested policy by running a different policy called behavior policy. We\ndesign a tailored behavior policy such that the variance of the off-policy MC\nestimator is provably smaller than the ordinary MC estimator. Importantly, this\ntailored behavior policy can be efficiently learned from existing offline data,\ni,e., previously logged data, which are much cheaper than online samples. With\nreduced variance, our off-policy MC method requires fewer online samples to\nevaluate the performance of a policy compared with the ordinary MC method.\nMoreover, our off-policy MC estimator is always unbiased.\n","authors":["Shuze Liu","Shangtong Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13733v1","updated":"2023-01-31T16:12:26Z","published":"2023-01-31T16:12:26Z","title":"A Bayesian Generative Adversarial Network (GAN) to Generate Synthetic\n  Time-Series Data, Application in Combined Sewer Flow Prediction","summary":"  Despite various breakthroughs in machine learning and data analysis\ntechniques for improving smart operation and management of urban water\ninfrastructures, some key limitations obstruct this progress. Among these\nshortcomings, the absence of freely available data due to data privacy or high\ncosts of data gathering and the nonexistence of adequate rare or extreme events\nin the available data plays a crucial role. Here, Generative Adversarial\nNetworks (GANs) can help overcome these challenges. In machine learning,\ngenerative models are a class of methods capable of learning data distribution\nto generate artificial data. In this study, we developed a GAN model to\ngenerate synthetic time series to balance our limited recorded time series data\nand improve the accuracy of a data-driven model for combined sewer flow\nprediction. We considered the sewer system of a small town in Germany as the\ntest case. Precipitation and inflow to the storage tanks are used for the\nData-Driven model development. The aim is to predict the flow using\nprecipitation data and examine the impact of data augmentation using synthetic\ndata in model performance. Results show that GAN can successfully generate\nsynthetic time series from real data distribution, which helps more accurate\npeak flow prediction. However, the model without data augmentation works better\nfor dry weather prediction. Therefore, an ensemble model is suggested to\ncombine the advantages of both models.\n","authors":["Amin E. Bakhshipour","Alireza Koochali","Ulrich Dittmer","Ali Haghighi","Sheraz Ahmad","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2301.13733v1.pdf","comment":"Accepted in WDSA/CCWI 2022 Conference"},{"id":"http://arxiv.org/abs/2301.13732v1","updated":"2023-01-31T16:11:54Z","published":"2023-01-31T16:11:54Z","title":"Preserving local densities in low-dimensional embeddings","summary":"  Low-dimensional embeddings and visualizations are an indispensable tool for\nanalysis of high-dimensional data. State-of-the-art methods, such as tSNE and\nUMAP, excel in unveiling local structures hidden in high-dimensional data and\nare therefore routinely applied in standard analysis pipelines in biology. We\nshow, however, that these methods fail to reconstruct local properties, such as\nrelative differences in densities (Fig. 1) and that apparent differences in\ncluster size can arise from computational artifact caused by differing sample\nsizes (Fig. 2). Providing a theoretical analysis of this issue, we then suggest\ndtSNE, which approximately conserves local densities. In an extensive study on\nsynthetic benchmark and real world data comparing against five state-of-the-art\nmethods, we empirically show that dtSNE provides similar global reconstruction,\nbut yields much more accurate depictions of local distances and relative\ndensities.\n","authors":["Jonas Fischer","Rebekka Burkholz","Jilles Vreeken"],"pdf_url":"https://arxiv.org/pdf/2301.13732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13731v1","updated":"2023-01-31T16:11:47Z","published":"2023-01-31T16:11:47Z","title":"A relaxed proximal gradient descent algorithm for convergent\n  plug-and-play with proximal denoiser","summary":"  This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnP\nmethods are efficient iterative algorithms for solving image inverse problems\nformulated as the minimization of the sum of a data-fidelity term and a\nregularization term. PnP methods perform regularization by plugging a\npre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent\n(PGD). To ensure convergence of PnP schemes, many works study specific\nparametrizations of deep denoisers. However, existing results require either\nunverifiable or suboptimal hypotheses on the denoiser, or assume restrictive\nconditions on the parameters of the inverse problem. Observing that these\nlimitations can be due to the proximal algorithm in use, we study a relaxed\nversion of the PGD algorithm for minimizing the sum of a convex function and a\nweakly convex one. When plugged with a relaxed proximal denoiser, we show that\nthe proposed PnP-$\\alpha$PGD algorithm converges for a wider range of\nregularization parameters, thus allowing more accurate image restoration.\n","authors":["Samuel Hurault","Antonin Chambolle","Arthur Leclaire","Nicolas Papadakis"],"pdf_url":"https://arxiv.org/pdf/2301.13731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13728v1","updated":"2023-01-31T16:06:54Z","published":"2023-01-31T16:06:54Z","title":"Convolutional autoencoder for the spatiotemporal latent representation\n  of turbulence","summary":"  Turbulence is characterised by chaotic dynamics and a high-dimensional state\nspace, which make the phenomenon challenging to predict. However, turbulent\nflows are often characterised by coherent spatiotemporal structures, such as\nvortices or large-scale modes, which can help obtain a latent description of\nturbulent flows. However, current approaches are often limited by either the\nneed to use some form of thresholding on quantities defining the isosurfaces to\nwhich the flow structures are associated or the linearity of traditional modal\nflow decomposition approaches, such as those based on proper orthogonal\ndecomposition. This problem is exacerbated in flows that exhibit extreme\nevents, which are rare and sudden changes in a turbulent state. The goal of\nthis paper is to obtain an efficient and accurate reduced-order latent\nrepresentation of a turbulent flow that exhibits extreme events. Specifically,\nwe employ a three-dimensional multiscale convolutional autoencoder (CAE) to\nobtain such latent representation. We apply it to a three-dimensional turbulent\nflow. We show that the Multiscale CAE is efficient, requiring less than 10%\ndegrees of freedom than proper orthogonal decomposition for compressing the\ndata and is able to accurately reconstruct flow states related to extreme\nevents. The proposed deep learning architecture opens opportunities for\nnonlinear reduced-order modeling of turbulent flows from data.\n","authors":["Nguyen Anh Khoa Doan","Alberto Racca","Luca Magri"],"pdf_url":"https://arxiv.org/pdf/2301.13728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13724v1","updated":"2023-01-31T16:01:12Z","published":"2023-01-31T16:01:12Z","title":"The passive symmetries of machine learning","summary":"  Any representation of data involves arbitrary investigator choices. Because\nthose choices are external to the data-generating process, each choice leads to\nan exact symmetry, corresponding to the group of transformations that takes one\npossible representation to another. These are the passive symmetries; they\ninclude coordinate freedom, gauge symmetry and units covariance, all of which\nhave led to important results in physics. Our goal is to understand the\nimplications of passive symmetries for machine learning: Which passive\nsymmetries play a role (e.g., permutation symmetry in graph neural networks)?\nWhat are dos and don'ts in machine learning practice? We assay conditions under\nwhich passive symmetries can be implemented as group equivariances. We also\ndiscuss links to causal modeling, and argue that the implementation of passive\nsymmetries is particularly valuable when the goal of the learning problem is to\ngeneralize out of sample. While this paper is purely conceptual, we believe\nthat it can have a significant impact on helping machine learning make the\ntransition that took place for modern physics in the first half of the\nTwentieth century.\n","authors":["Soledad Villar","David W. Hogg","Weichi Yao","George A. Kevrekidis","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2301.13724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07346v2","updated":"2023-01-31T16:00:44Z","published":"2022-12-14T17:17:10Z","title":"Learning useful representations for shifting tasks and distributions","summary":"  Does the dominant approach to learn representations (as a side effect of\noptimizing an expected cost for a single training distribution) remain a good\napproach when we are dealing with multiple distributions? Our thesis is that\nsuch scenarios are better served by representations that are richer than those\nobtained with a single optimization episode. We support this thesis with simple\ntheoretical arguments and with experiments utilizing an apparently na\\\"{\\i}ve\nensembling technique: concatenating the representations obtained from multiple\ntraining episodes using the same data, model, algorithm, and hyper-parameters,\nbut different random seeds. These independently trained networks perform\nsimilarly. Yet, in a number of scenarios involving new distributions, the\nconcatenated representation performs substantially better than an equivalently\nsized network trained with a single training run. This proves that the\nrepresentations constructed by multiple training episodes are in fact\ndifferent. Although their concatenation carries little additional information\nabout the training task under the training distribution, it becomes\nsubstantially more informative when tasks or distributions change. Meanwhile, a\nsingle training episode is unlikely to yield such a redundant representation\nbecause the optimization process has no reason to accumulate features that do\nnot incrementally improve the training performance.\n","authors":["Jianyu Zhang","Léon Bottou"],"pdf_url":"https://arxiv.org/pdf/2212.07346v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2210.11794v2","updated":"2023-01-31T15:57:19Z","published":"2022-10-21T08:13:34Z","title":"Diffuser: Efficient Transformers with Multi-hop Attention Diffusion for\n  Long Sequences","summary":"  Efficient Transformers have been developed for long sequence modeling, due to\ntheir subquadratic memory and time complexity. Sparse Transformer is a popular\napproach to improving the efficiency of Transformers by restricting\nself-attention to locations specified by the predefined sparse patterns.\nHowever, leveraging sparsity may sacrifice expressiveness compared to\nfull-attention, when important token correlations are multiple hops away. To\ncombine advantages of both the efficiency of sparse transformer and the\nexpressiveness of full-attention Transformer, we propose \\textit{Diffuser}, a\nnew state-of-the-art efficient Transformer. Diffuser incorporates all token\ninteractions within one attention layer while maintaining low computation and\nmemory costs. The key idea is to expand the receptive field of sparse attention\nusing Attention Diffusion, which computes multi-hop token correlations based on\nall paths between corresponding disconnected tokens, besides attention among\nneighboring tokens. Theoretically, we show the expressiveness of Diffuser as a\nuniversal sequence approximator for sequence-to-sequence modeling, and\ninvestigate its ability to approximate full-attention by analyzing the graph\nexpander property from the spectral perspective. Experimentally, we investigate\nthe effectiveness of Diffuser with extensive evaluations, including language\nmodeling, image modeling, and Long Range Arena (LRA). Evaluation results show\nthat Diffuser achieves improvements by an average of 0.94% on text\nclassification tasks and 2.30% on LRA, with 1.67$\\times$ memory savings\ncompared to state-of-the-art benchmarks, which demonstrates superior\nperformance of Diffuser in both expressiveness and efficiency aspects.\n","authors":["Aosong Feng","Irene Li","Yuang Jiang","Rex Ying"],"pdf_url":"https://arxiv.org/pdf/2210.11794v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14594v2","updated":"2023-01-31T15:52:23Z","published":"2022-11-26T15:35:36Z","title":"Direct-Effect Risk Minimization for Domain Generalization","summary":"  We study the problem of out-of-distribution (o.o.d.) generalization where\nspurious correlations of attributes vary across training and test domains. This\nis known as the problem of correlation shift and has posed concerns on the\nreliability of machine learning. In this work, we introduce the concepts of\ndirect and indirect effects from causal inference to the domain generalization\nproblem. We argue that models that learn direct effects minimize the worst-case\nrisk across correlation-shifted domains. To eliminate the indirect effects, our\nalgorithm consists of two stages: in the first stage, we learn an\nindirect-effect representation by minimizing the prediction error of domain\nlabels using the representation and the class label; in the second stage, we\nremove the indirect effects learned in the first stage by matching each data\nwith another data of similar indirect-effect representation but of different\nclass label. We also propose a new model selection method by matching the\nvalidation set in the same way, which is shown to improve the generalization\nperformance of existing models on correlation-shifted datasets. Experiments on\n5 correlation-shifted datasets and the DomainBed benchmark verify the\neffectiveness of our approach.\n","authors":["Yuhui Li","Zejia Wu","Chao Zhang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.14594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04345v3","updated":"2023-01-31T15:49:48Z","published":"2022-10-09T20:42:37Z","title":"LieGG: Studying Learned Lie Group Generators","summary":"  Symmetries built into a neural network have appeared to be very beneficial\nfor a wide range of tasks as it saves the data to learn them. We depart from\nthe position that when symmetries are not built into a model a priori, it is\nadvantageous for robust networks to learn symmetries directly from the data to\nfit a task function. In this paper, we present a method to extract symmetries\nlearned by a neural network and to evaluate the degree to which a network is\ninvariant to them. With our method, we are able to explicitly retrieve learned\ninvariances in a form of the generators of corresponding Lie-groups without\nprior knowledge of symmetries in the data. We use the proposed method to study\nhow symmetrical properties depend on a neural network's parameterization and\nconfiguration. We found that the ability of a network to learn symmetries\ngeneralizes over a range of architectures. However, the quality of learned\nsymmetries depends on the depth and the number of parameters.\n","authors":["Artem Moskalev","Anna Sepliarskaia","Ivan Sosnovik","Arnold Smeulders"],"pdf_url":"https://arxiv.org/pdf/2210.04345v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13710v1","updated":"2023-01-31T15:40:50Z","published":"2023-01-31T15:40:50Z","title":"On the Initialisation of Wide Low-Rank Feedforward Neural Networks","summary":"  The edge-of-chaos dynamics of wide randomly initialized low-rank feedforward\nnetworks are analyzed. Formulae for the optimal weight and bias variances are\nextended from the full-rank to low-rank setting and are shown to follow from\nmultiplicative scaling. The principle second order effect, the variance of the\ninput-output Jacobian, is derived and shown to increase as the rank to width\nratio decreases. These results inform practitioners how to randomly initialize\nfeedforward networks with a reduced number of learnable parameters while in the\nsame ambient dimension, allowing reductions in the computational cost and\nmemory constraints of the associated network.\n","authors":["Thiziri Nait Saada","Jared Tanner"],"pdf_url":"https://arxiv.org/pdf/2301.13710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06300v2","updated":"2023-01-31T15:27:26Z","published":"2022-09-13T21:08:13Z","title":"PINCH: An Adversarial Extraction Attack Framework for Deep Learning\n  Models","summary":"  Adversarial extraction attacks constitute an insidious threat against Deep\nLearning (DL) models in-which an adversary aims to steal the architecture,\nparameters, and hyper-parameters of a targeted DL model. Existing extraction\nattack literature have observed varying levels of attack success for different\nDL models and datasets, yet the underlying cause(s) behind their susceptibility\noften remain unclear, and would help facilitate creating secure DL systems. In\nthis paper we present PINCH: an efficient and automated extraction attack\nframework capable of designing, deploying, and analyzing extraction attack\nscenarios across heterogeneous hardware platforms. Using PINCH, we perform\nextensive experimental evaluation of extraction attacks against 21 model\narchitectures to explore new extraction attack scenarios and further attack\nstaging. Our findings show (1) key extraction characteristics whereby\nparticular model configurations exhibit strong resilience against specific\nattacks, (2) even partial extraction success enables further staging for other\nadversarial attacks, and (3) equivalent stolen models uncover differences in\nexpressive power, yet exhibit similar captured knowledge.\n","authors":["William Hackett","Stefan Trawicki","Zhengxin Yu","Neeraj Suri","Peter Garraghan"],"pdf_url":"https://arxiv.org/pdf/2209.06300v2.pdf","comment":"19 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2211.14236v2","updated":"2023-01-31T15:26:35Z","published":"2022-11-25T16:56:42Z","title":"Strategyproof Decision-Making in Panel Data Settings and Beyond","summary":"  We propose a framework for decision-making in the presence of strategic\nagents with panel data, a standard setting in econometrics and statistics where\none gets noisy, repeated measurements of multiple units. We consider a setup\nwhere there is a pre-intervention period, when the principal observes the\noutcomes of each unit, after which the principal uses these observations to\nassign a treatment to each unit. Our model can be thought of as a\ngeneralization of the synthetic controls and synthetic interventions\nframeworks, where units (or agents) may strategically manipulate\npre-intervention outcomes to receive a more desirable intervention. We identify\nnecessary and sufficient conditions under which a strategyproof mechanism that\nassigns interventions in the post-intervention period exists. Under a latent\nfactor model assumption, we show that whenever a strategyproof mechanism\nexists, there is one with a simple closed form. In the setting where there is a\nsingle treatment and control (i.e., no other interventions), we establish that\nthere is always a strategyproof mechanism, and provide an algorithm for\nlearning such a mechanism. For the setting of multiple interventions, we\nprovide an algorithm for learning a strategyproof mechanism, if there exists a\nsufficiently large gap in rewards between the different interventions. Finally,\nwe empirically evaluate our model using real-world panel data collected from\nproduct sales over 18 months. We find that our methods compare favorably to\nbaselines which do not take strategic interactions into consideration -- even\nin the presence of model misspecification. Along the way, we prove\nimpossibility results for multi-class strategic classification, which may be of\nindependent interest.\n","authors":["Keegan Harris","Anish Agarwal","Chara Podimata","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2211.14236v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13703v1","updated":"2023-01-31T15:22:24Z","published":"2023-01-31T15:22:24Z","title":"Dissecting the Effects of SGD Noise in Distinct Regimes of Deep Learning","summary":"  Understanding when the noise in stochastic gradient descent (SGD) affects\ngeneralization of deep neural networks remains a challenge, complicated by the\nfact that networks can operate in distinct training regimes. Here we study how\nthe magnitude of this noise $T$ affects performance as the size of the training\nset $P$ and the scale of initialization $\\alpha$ are varied. For gradient\ndescent, $\\alpha$ is a key parameter that controls if the network is `lazy'\n($\\alpha\\gg 1$) or instead learns features ($\\alpha\\ll 1$). For classification\nof MNIST and CIFAR10 images, our central results are: (i) obtaining phase\ndiagrams for performance in the $(\\alpha,T)$ plane. They show that SGD noise\ncan be detrimental or instead useful depending on the training regime.\nMoreover, although increasing $T$ or decreasing $\\alpha$ both allow the net to\nescape the lazy regime, these changes can have opposite effects on performance.\n(ii) Most importantly, we find that key dynamical quantities (including the\ntotal variations of weights during training) depend on both $T$ and $P$ as\npower laws, and the characteristic temperature $T_c$, where the noise of SGD\nstarts affecting performance, is a power law of $P$. These observations\nindicate that a key effect of SGD noise occurs late in training, by affecting\nthe stopping process whereby all data are fitted. We argue that due to SGD\nnoise, nets must develop a stronger `signal', i.e. larger informative weights,\nto fit the data, leading to a longer training time. The same effect occurs at\nlarger training set $P$. We confirm this view in the perceptron model, where\nsignal and noise can be precisely measured. Interestingly, exponents\ncharacterizing the effect of SGD depend on the density of data near the\ndecision boundary, as we explain.\n","authors":["Antonio Sclocchi","Mario Geiger","Matthieu Wyart"],"pdf_url":"https://arxiv.org/pdf/2301.13703v1.pdf","comment":"18 pages, 14 figures"},{"id":"http://arxiv.org/abs/2212.07383v2","updated":"2023-01-31T15:20:24Z","published":"2022-12-14T18:08:42Z","title":"Sequential Kernelized Independence Testing","summary":"  Independence testing is a fundamental and classical statistical problem that\nhas been extensively studied in the batch setting when one fixes the sample\nsize before collecting data. However, practitioners often prefer procedures\nthat adapt to the complexity of a problem at hand instead of setting sample\nsize in advance. Ideally, such procedures should (a) allow stopping earlier on\neasy tasks (and later on harder tasks), hence making better use of available\nresources, and (b) continuously monitor the data and efficiently incorporate\nstatistical evidence after collecting new data, while controlling the false\nalarm rate. It is well known that classical batch tests are not tailored for\nstreaming data settings: valid inference after data peeking requires correcting\nfor multiple testing but such corrections generally result in low power.\nFollowing the principle of testing by betting, we design sequential kernelized\nindependence tests (SKITs) that overcome such shortcomings. We exemplify our\nbroad framework using bets inspired by kernelized dependence measures, e.g, the\nHilbert-Schmidt independence criterion. Our test is valid under non-i.i.d.\ntime-varying settings, for which there exist no batch tests. We demonstrate the\npower of our approaches on both simulated and real data.\n","authors":["Aleksandr Podkopaev","Patrick Blöbaum","Shiva Prasad Kasiviswanathan","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2212.07383v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.01003v4","updated":"2023-01-31T15:16:55Z","published":"2022-08-01T17:19:32Z","title":"What can be learnt with wide convolutional neural networks?","summary":"  Understanding how convolutional neural networks (CNNs) can efficiently learn\nhigh-dimensional functions remains a fundamental challenge. A popular belief is\nthat these models harness the local and hierarchical structure of natural data\nsuch as images. Yet, we lack a quantitative understanding of how such structure\naffects performance, e.g. the rate of decay of the generalisation error with\nthe number of training samples. In this paper, we study deep CNNs in the kernel\nregime. First, we show that the spectrum of the corresponding kernel inherits\nthe hierarchical structure of the network, and we characterise its asymptotics.\nThen, we use this result together with generalisation bounds to prove that deep\nCNNs adapt to the spatial scale of the target function. In particular, we find\nthat if the target function depends on low-dimensional subsets of adjacent\ninput variables, then the rate of decay of the error is controlled by the\neffective dimensionality of these subsets. Conversely, if the target function\ndepends on the full set of input variables, then the error rate is inversely\nproportional to the input dimension. We conclude by computing the rate when a\ndeep CNN is trained on the output of another deep CNN with randomly-initialised\nparameters. Interestingly, we find that, despite their hierarchical structure,\nthe functions generated by deep CNNs are too rich to be efficiently learnable\nin high dimension.\n","authors":["Francesco Cagnetta","Alessandro Favero","Matthieu Wyart"],"pdf_url":"https://arxiv.org/pdf/2208.01003v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13694v1","updated":"2023-01-31T15:11:48Z","published":"2023-01-31T15:11:48Z","title":"Are Defenses for Graph Neural Networks Robust?","summary":"  A cursory reading of the literature suggests that we have made a lot of\nprogress in designing effective adversarial defenses for Graph Neural Networks\n(GNNs). Yet, the standard methodology has a serious flaw - virtually all of the\ndefenses are evaluated against non-adaptive attacks leading to overly\noptimistic robustness estimates. We perform a thorough robustness analysis of 7\nof the most popular defenses spanning the entire spectrum of strategies, i.e.,\naimed at improving the graph, the architecture, or the training. The results\nare sobering - most defenses show no or only marginal improvement compared to\nan undefended baseline. We advocate using custom adaptive attacks as a gold\nstandard and we outline the lessons we learned from successfully designing such\nattacks. Moreover, our diverse collection of perturbed graphs forms a\n(black-box) unit test offering a first glance at a model's robustness.\n","authors":["Felix Mujkanovic","Simon Geisler","Stephan Günnemann","Aleksandar Bojchevski"],"pdf_url":"https://arxiv.org/pdf/2301.13694v1.pdf","comment":"34 pages, 36th Conference on Neural Information Processing Systems\n  (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2301.11308v2","updated":"2023-01-31T15:08:11Z","published":"2023-01-26T18:45:04Z","title":"Neural Continuous-Discrete State Space Models for Irregularly-Sampled\n  Time Series","summary":"  Learning accurate predictive models of real-world dynamic phenomena (e.g.,\nclimate, biological) remains a challenging task. One key issue is that the data\ngenerated by both natural and artificial processes often comprise time series\nthat are irregularly sampled and/or contain missing observations. In this work,\nwe propose the Neural Continuous-Discrete State Space Model (NCDSSM) for\ncontinuous-time modeling of time series through discrete-time observations.\nNCDSSM employs auxiliary variables to disentangle recognition from dynamics,\nthus requiring amortized inference only for the auxiliary variables. Leveraging\ntechniques from continuous-discrete filtering theory, we demonstrate how to\nperform accurate Bayesian inference for the dynamic states. We propose three\nflexible parameterizations of the latent dynamics and an efficient training\nobjective that marginalizes the dynamic states during inference. Empirical\nresults on multiple benchmark datasets across various domains show improved\nimputation and forecasting performance of NCDSSM over existing models.\n","authors":["Abdul Fatir Ansari","Alvin Heng","Andre Lim","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2301.11308v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13691v1","updated":"2023-01-31T15:07:31Z","published":"2023-01-31T15:07:31Z","title":"Time Series Forecasting via Semi-Asymmetric Convolutional Architecture\n  with Global Atrous Sliding Window","summary":"  The proposed method in this paper is designed to address the problem of time\nseries forecasting. Although some exquisitely designed models achieve excellent\nprediction performances, how to extract more useful information and make\naccurate predictions is still an open issue. Most of modern models only focus\non a short range of information, which are fatal for problems such as time\nseries forecasting which needs to capture long-term information\ncharacteristics. As a result, the main concern of this work is to further mine\nrelationship between local and global information contained in time series to\nproduce more precise predictions. In this paper, to satisfactorily realize the\npurpose, we make three main contributions that are experimentally verified to\nhave performance advantages. Firstly, original time series is transformed into\ndifference sequence which serves as input to the proposed model. And secondly,\nwe introduce the global atrous sliding window into the forecasting model which\nreferences the concept of fuzzy time series to associate relevant global\ninformation with temporal data within a time period and utilizes\ncentral-bidirectional atrous algorithm to capture underlying-related features\nto ensure validity and consistency of captured data. Thirdly, a variation of\nwidely-used asymmetric convolution which is called semi-asymmetric convolution\nis devised to more flexibly extract relationships in adjacent elements and\ncorresponding associated global features with adjustable ranges of convolution\non vertical and horizontal directions. The proposed model in this paper\nachieves state-of-the-art on most of time series datasets provided compared\nwith competitive modern models.\n","authors":["Yuanpeng He"],"pdf_url":"https://arxiv.org/pdf/2301.13691v1.pdf","comment":"13pages,8 figures"},{"id":"http://arxiv.org/abs/2301.13688v1","updated":"2023-01-31T15:03:44Z","published":"2023-01-31T15:03:44Z","title":"The Flan Collection: Designing Data and Methods for Effective\n  Instruction Tuning","summary":"  We study the design decisions of publicly available instruction tuning\nmethods, and break down the development of Flan 2022 (Chung et al., 2022).\nThrough careful ablation studies on the Flan Collection of tasks and methods,\nwe tease apart the effect of design decisions which enable Flan-T5 to\noutperform prior work by 3-17%+ across evaluation settings. We find task\nbalancing and enrichment techniques are overlooked but critical to effective\ninstruction tuning, and in particular, training with mixed prompt settings\n(zero-shot, few-shot, and chain-of-thought) actually yields stronger (2%+)\nperformance in all settings. In further experiments, we show Flan-T5 requires\nless finetuning to converge higher and faster than T5 on single downstream\ntasks, motivating instruction-tuned models as more computationally-efficient\nstarting checkpoints for new tasks. Finally, to accelerate research on\ninstruction tuning, we make the Flan 2022 collection of datasets, templates,\nand methods publicly available at\nhttps://github.com/google-research/FLAN/tree/main/flan/v2.\n","authors":["Shayne Longpre","Le Hou","Tu Vu","Albert Webson","Hyung Won Chung","Yi Tay","Denny Zhou","Quoc V. Le","Barret Zoph","Jason Wei","Adam Roberts"],"pdf_url":"https://arxiv.org/pdf/2301.13688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.04417v3","updated":"2023-01-31T15:01:20Z","published":"2021-12-06T18:36:09Z","title":"What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation\n  Framework for Explainability Methods","summary":"  A multitude of explainability methods and associated fidelity performance\nmetrics have been proposed to help better understand how modern AI systems make\ndecisions. However, much of the current work has remained theoretical --\nwithout much consideration for the human end-user. In particular, it is not yet\nknown (1) how useful current explainability methods are in practice for more\nreal-world scenarios and (2) how well associated performance metrics accurately\npredict how much knowledge individual explanations contribute to a human\nend-user trying to understand the inner-workings of the system. To fill this\ngap, we conducted psychophysics experiments at scale to evaluate the ability of\nhuman participants to leverage representative attribution methods for\nunderstanding the behavior of different image classifiers representing three\nreal-world scenarios: identifying bias in an AI system, characterizing the\nvisual strategy it uses for tasks that are too difficult for an untrained\nnon-expert human observer as well as understanding its failure cases. Our\nresults demonstrate that the degree to which individual attribution methods\nhelp human participants better understand an AI system varied widely across\nthese scenarios. This suggests a critical need for the field to move past\nquantitative improvements of current attribution methods towards the\ndevelopment of complementary approaches that provide qualitatively different\nsources of information to human end-users.\n","authors":["Julien Colin","Thomas Fel","Remi Cadene","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2112.04417v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06203v3","updated":"2023-01-31T14:57:09Z","published":"2022-09-13T17:56:13Z","title":"Normalizing Flows for Interventional Density Estimation","summary":"  Existing machine learning methods for causal inference usually estimate\nquantities expressed via the mean of potential outcomes (e.g., average\ntreatment effect). However, such quantities do not capture the full information\nabout the distribution of potential outcomes. In this work, we estimate the\ndensity of potential outcomes after interventions from observational data. For\nthis, we propose a novel, fully-parametric deep learning method called\nInterventional Normalizing Flows. Specifically, we combine two normalizing\nflows, namely (i) a teacher flow for estimating nuisance parameters and (ii) a\nstudent flow for a parametric estimation of the density of potential outcomes.\nWe further develop a tractable optimization objective based on a one-step bias\ncorrection for an efficient and doubly robust estimation of the student flow\nparameters. As a result our Interventional Normalizing Flows offer a properly\nnormalized density estimator. Across various experiments, we demonstrate that\nour Interventional Normalizing Flows are expressive and highly effective, and\nscale well with both sample size and high-dimensional confounding. To the best\nof our knowledge, our Interventional Normalizing Flows are the first\nfully-parametric, deep learning method for density estimation of potential\noutcomes.\n","authors":["Valentyn Melnychuk","Dennis Frauen","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2209.06203v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06582v3","updated":"2023-01-31T14:54:48Z","published":"2023-01-16T19:40:50Z","title":"Antenna Array Calibration Via Gaussian Process Models","summary":"  Antenna array calibration is necessary to maintain the high fidelity of beam\npatterns across a wide range of advanced antenna systems and to ensure channel\nreciprocity in time division duplexing schemes. Despite the continuous\ndevelopment in this area, most existing solutions are optimised for specific\nradio architectures, require standardised over-the-air data transmission, or\nserve as extensions of conventional methods. The diversity of communication\nprotocols and hardware creates a problematic case, since this diversity\nrequires to design or update the calibration procedures for each new advanced\nantenna system. In this study, we formulate antenna calibration in an\nalternative way, namely as a task of functional approximation, and address it\nvia Bayesian machine learning. Our contributions are three-fold. Firstly, we\ndefine a parameter space, based on near-field measurements, that captures the\nunderlying hardware impairments corresponding to each radiating element, their\npositional offsets, as well as the mutual coupling effects between antenna\nelements. Secondly, Gaussian process regression is used to form models from a\nsparse set of the aforementioned near-field data. Once deployed, the learned\nnon-parametric models effectively serve to continuously transform the\nbeamforming weights of the system, resulting in corrected beam patterns.\nLastly, we demonstrate the viability of the described methodology for both\ndigital and analog beamforming antenna arrays of different scales and discuss\nits further extension to support real-time operation with dynamic hardware\nimpairments.\n","authors":["Sergey S. Tambovskiy","Gábor Fodor","Hugo M. Tullberg"],"pdf_url":"https://arxiv.org/pdf/2301.06582v3.pdf","comment":"International ITG 26th Workshop on Smart Antennas and 13th Conference\n  on Systems, Communications, and Coding"},{"id":"http://arxiv.org/abs/2209.05559v6","updated":"2023-01-31T14:54:22Z","published":"2022-09-12T19:18:48Z","title":"Deep Reinforcement Learning for Cryptocurrency Trading: Practical\n  Approach to Address Backtest Overfitting","summary":"  Designing profitable and reliable trading strategies is challenging in the\nhighly volatile cryptocurrency market. Existing works applied deep\nreinforcement learning methods and optimistically reported increased profits in\nbacktesting, which may suffer from the false positive issue due to overfitting.\nIn this paper, we propose a practical approach to address backtest overfitting\nfor cryptocurrency trading using deep reinforcement learning. First, we\nformulate the detection of backtest overfitting as a hypothesis test. Then, we\ntrain the DRL agents, estimate the probability of overfitting, and reject the\noverfitted agents, increasing the chance of good trading performance. Finally,\non 10 cryptocurrencies over a testing period from 05/01/2022 to 06/27/2022\n(during which the crypto market crashed two times), we show that the less\noverfitted deep reinforcement learning agents have a higher return than that of\nmore overfitted agents, an equal weight strategy, and the S&P DBM Index (market\nbenchmark), offering confidence in possible deployment to a real market.\n","authors":["Berend Jelmer Dirk Gort","Xiao-Yang Liu","Xinghang Sun","Jiechao Gao","Shuaiyu Chen","Christina Dan Wang"],"pdf_url":"https://arxiv.org/pdf/2209.05559v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13674v1","updated":"2023-01-31T14:46:16Z","published":"2023-01-31T14:46:16Z","title":"Improved distinct bone segmentation in upper-body CT through\n  multi-resolution networks","summary":"  Purpose: Automated distinct bone segmentation from CT scans is widely used in\nplanning and navigation workflows. U-Net variants are known to provide\nexcellent results in supervised semantic segmentation. However, in distinct\nbone segmentation from upper body CTs a large field of view and a\ncomputationally taxing 3D architecture are required. This leads to\nlow-resolution results lacking detail or localisation errors due to missing\nspatial context when using high-resolution inputs.\n  Methods: We propose to solve this problem by using end-to-end trainable\nsegmentation networks that combine several 3D U-Nets working at different\nresolutions. Our approach, which extends and generalizes HookNet and MRN,\ncaptures spatial information at a lower resolution and skips the encoded\ninformation to the target network, which operates on smaller high-resolution\ninputs. We evaluated our proposed architecture against single resolution\nnetworks and performed an ablation study on information concatenation and the\nnumber of context networks.\n  Results: Our proposed best network achieves a median DSC of 0.86 taken over\nall 125 segmented bone classes and reduces the confusion among similar-looking\nbones in different locations. These results outperform our previously published\n3D U-Net baseline results on the task and distinct-bone segmentation results\nreported by other groups.\n  Conclusion: The presented multi-resolution 3D U-Nets address current\nshortcomings in bone segmentation from upper-body CT scans by allowing for\ncapturing a larger field of view while avoiding the cubic growth of the input\npixels and intermediate computations that quickly outgrow the computational\ncapacities in 3D. The approach thus improves the accuracy and efficiency of\ndistinct bone segmentation from upper-body CT.\n","authors":["Eva Schnider","Julia Wolleb","Antal Huck","Mireille Toranelli","Georg Rauter","Magdalena Müller-Gerbl","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2301.13674v1.pdf","comment":"Under submission"},{"id":"http://arxiv.org/abs/2301.13671v1","updated":"2023-01-31T14:40:49Z","published":"2023-01-31T14:40:49Z","title":"Enhancing Hyper-To-Real Space Projections Through Euclidean Norm\n  Meta-Heuristic Optimization","summary":"  The continuous computational power growth in the last decades has made\nsolving several optimization problems significant to humankind a tractable\ntask; however, tackling some of them remains a challenge due to the\noverwhelming amount of candidate solutions to be evaluated, even by using\nsophisticated algorithms. In such a context, a set of nature-inspired\nstochastic methods, called meta-heuristic optimization, can provide robust\napproximate solutions to different kinds of problems with a small computational\nburden, such as derivative-free real function optimization. Nevertheless, these\nmethods may converge to inadequate solutions if the function landscape is too\nharsh, e.g., enclosing too many local optima. Previous works addressed this\nissue by employing a hypercomplex representation of the search space, like\nquaternions, where the landscape becomes smoother and supposedly easier to\noptimize. Under this approach, meta-heuristic computations happen in the\nhypercomplex space, whereas variables are mapped back to the real domain before\nfunction evaluation. Despite this latter operation being performed by the\nEuclidean norm, we have found that after the optimization procedure has\nfinished, it is usually possible to obtain even better solutions by employing\nthe Minkowski $p$-norm instead and fine-tuning $p$ through an auxiliary\nsub-problem with neglecting additional cost and no hyperparameters. Such\nbehavior was observed in eight well-established benchmarking functions, thus\nfostering a new research direction for hypercomplex meta-heuristic\noptimization.\n","authors":["Luiz C. F. Ribeiro","Mateus Roder","Gustavo H. de Rosa","Leandro A. Passos","João P. Papa"],"pdf_url":"https://arxiv.org/pdf/2301.13671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01852v2","updated":"2023-01-31T14:40:22Z","published":"2022-11-03T14:42:19Z","title":"Revisiting Hyperparameter Tuning with Differential Privacy","summary":"  Hyperparameter tuning is a common practice in the application of machine\nlearning but is a typically ignored aspect in the literature on\nprivacy-preserving machine learning due to its negative effect on the overall\nprivacy parameter. In this paper, we aim to tackle this fundamental yet\nchallenging problem by providing an effective hyperparameter tuning framework\nwith differential privacy. The proposed method allows us to adopt a broader\nhyperparameter search space and even to perform a grid search over the whole\nspace, since its privacy loss parameter is independent of the number of\nhyperparameter candidates. Interestingly, it instead correlates with the\nutility gained from hyperparameter searching, revealing an explicit and\nmandatory trade-off between privacy and utility. Theoretically, we show that\nits additional privacy loss bound incurred by hyperparameter tuning is\nupper-bounded by the squared root of the gained utility. However, we note that\nthe additional privacy loss bound would empirically scale like a squared root\nof the logarithm of the utility term, benefiting from the design of doubling\nstep.\n","authors":["Youlong Ding","Xueyang Wu"],"pdf_url":"https://arxiv.org/pdf/2211.01852v2.pdf","comment":"ML Safety Workshop of NeurIPS'22 Accepted Paper"},{"id":"http://arxiv.org/abs/2301.08203v2","updated":"2023-01-31T14:39:30Z","published":"2023-01-19T17:54:50Z","title":"An SDE for Modeling SAM: Theory and Insights","summary":"  We study the SAM (Sharpness-Aware Minimization) optimizer which has recently\nattracted a lot of interest due to its increased performance over more\nclassical variants of stochastic gradient descent. Our main contribution is the\nderivation of continuous-time models (in the form of SDEs) for SAM and two of\nits variants, both for the full-batch and mini-batch settings. We demonstrate\nthat these SDEs are rigorous approximations of the real discrete-time\nalgorithms (in a weak sense, scaling linearly with the step size). Using these\nmodels, we then offer an explanation of why SAM prefers flat minima over sharp\nones~--~by showing that it minimizes an implicitly regularized loss with a\nHessian-dependent noise structure. Finally, we prove that perhaps unexpectedly\nSAM is attracted to saddle points under some realistic conditions. Our\ntheoretical results are supported by detailed experiments.\n","authors":["Enea Monzio Compagnoni","Luca Biggio","Antonio Orvieto","Frank Norbert Proske","Hans Kersting","Aurelien Lucchi"],"pdf_url":"https://arxiv.org/pdf/2301.08203v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13669v1","updated":"2023-01-31T14:38:33Z","published":"2023-01-31T14:38:33Z","title":"Reinforcement learning and decision making via single-photon quantum\n  walks","summary":"  Variational quantum algorithms represent a promising approach to quantum\nmachine learning where classical neural networks are replaced by parametrized\nquantum circuits. Here, we present a variational approach to quantize\nprojective simulation (PS), a reinforcement learning model aimed at\ninterpretable artificial intelligence. Decision making in PS is modeled as a\nrandom walk on a graph describing the agent's memory. To implement the\nquantized model, we consider quantum walks of single photons in a lattice of\ntunable Mach-Zehnder interferometers. We propose variational algorithms\ntailored to reinforcement learning tasks, and we show, using an example from\ntransfer learning, that the quantized PS learning model can outperform its\nclassical counterpart. Finally, we discuss the role of quantum interference for\ntraining and decision making, paving the way for realizations of interpretable\nquantum learning agents.\n","authors":["Fulvio Flamini","Marius Krumm","Lukas J. Fiderer","Thomas Müller","Hans J. Briegel"],"pdf_url":"https://arxiv.org/pdf/2301.13669v1.pdf","comment":"10+6 pages, 6+5 figures, 2 tables. F. Flamini and M. Krumm\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2301.13668v1","updated":"2023-01-31T14:37:04Z","published":"2023-01-31T14:37:04Z","title":"Automated Sentiment and Hate Speech Analysis of Facebook Data by\n  Employing Multilingual Transformer Models","summary":"  In recent years, there has been a heightened consensus within academia and in\nthe public discourse that Social Media Platforms (SMPs), amplify the spread of\nhateful and negative sentiment content. Researchers have identified how hateful\ncontent, political propaganda, and targeted messaging contributed to real-world\nharms including insurrections against democratically elected governments,\ngenocide, and breakdown of social cohesion due to heightened negative discourse\ntowards certain communities in parts of the world. To counter these issues,\nSMPs have created semi-automated systems that can help identify toxic speech.\nIn this paper we analyse the statistical distribution of hateful and negative\nsentiment contents within a representative Facebook dataset (n= 604,703)\nscrapped through 648 public Facebook pages which identify themselves as\nproponents (and followers) of far-right Hindutva actors. These pages were\nidentified manually using keyword searches on Facebook and on CrowdTangleand\nclassified as far-right Hindutva pages based on page names, page descriptions,\nand discourses shared on these pages. We employ state-of-the-art, open-source\nXLM-T multilingual transformer-based language models to perform sentiment and\nhate speech analysis of the textual contents shared on these pages over a\nperiod of 5.5 years. The result shows the statistical distributions of the\npredicted sentiment and the hate speech labels; top actors, and top page\ncategories. We further discuss the benchmark performances and limitations of\nthese pre-trained language models.\n","authors":["Ritumbra Manuvie","Saikat Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2301.13668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13667v1","updated":"2023-01-31T14:35:26Z","published":"2023-01-31T14:35:26Z","title":"Collision-aware In-hand 6D Object Pose Estimation using Multiple\n  Vision-based Tactile Sensors","summary":"  In this paper, we address the problem of estimating the in-hand 6D pose of an\nobject in contact with multiple vision-based tactile sensors. We reason on the\npossible spatial configurations of the sensors along the object surface.\nSpecifically, we filter contact hypotheses using geometric reasoning and a\nConvolutional Neural Network (CNN), trained on simulated object-agnostic\nimages, to promote those that better comply with the actual tactile images from\nthe sensors. We use the selected sensors configurations to optimize over the\nspace of 6D poses using a Gradient Descent-based approach. We finally rank the\nobtained poses by penalizing those that are in collision with the sensors. We\ncarry out experiments in simulation using the DIGIT vision-based sensor with\nseveral objects, from the standard YCB model set. The results demonstrate that\nour approach estimates object poses that are compatible with actual\nobject-sensor contacts in $87.5\\%$ of cases while reaching an average\npositional error in the order of $2$ centimeters. Our analysis also includes\nqualitative results of experiments with a real DIGIT sensor.\n","authors":["Gabriele M. Caddeo","Nicola A. Piga","Fabrizio Bottarel","Lorenzo Natale"],"pdf_url":"https://arxiv.org/pdf/2301.13667v1.pdf","comment":"Accepted for publication at 2023 IEEE International Conference on\n  Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2009.10622v5","updated":"2023-01-31T14:29:41Z","published":"2020-09-22T15:23:35Z","title":"An $l_1$-oracle inequality for the Lasso in high-dimensional mixtures of\n  experts models","summary":"  Mixtures of experts (MoE) models are a popular framework for modeling\nheterogeneity in data, for both regression and classification problems in\nstatistics and machine learning, due to their flexibility and the abundance of\navailable statistical estimation and model choice tools. Such flexibility comes\nfrom allowing the mixture weights (or gating functions) in the MoE model to\ndepend on the explanatory variables, along with the experts (or component\ndensities). This permits the modeling of data arising from more complex data\ngenerating processes when compared to the classical finite mixtures and finite\nmixtures of regression models, whose mixing parameters are independent of the\ncovariates. The use of MoE models in a high-dimensional setting, when the\nnumber of explanatory variables can be much larger than the sample size, is\nchallenging from a computational point of view, and in particular from a\ntheoretical point of view, where the literature is still lacking results for\ndealing with the curse of dimensionality, for both the statistical estimation\nand feature selection problems. We consider the finite MoE model with soft-max\ngating functions and Gaussian experts for high-dimensional regression on\nheterogeneous data, and its $l_1$-regularized estimation via the Lasso. We\nfocus on the Lasso estimation properties rather than its feature selection\nproperties. We provide a lower bound on the regularization parameter of the\nLasso function that ensures an $l_1$-oracle inequality satisfied by the Lasso\nestimator according to the Kullback--Leibler loss.\n","authors":["TrungTin Nguyen","Hien D Nguyen","Faicel Chamroukhi","Geoffrey J McLachlan"],"pdf_url":"https://arxiv.org/pdf/2009.10622v5.pdf","comment":"Added more explanations"},{"id":"http://arxiv.org/abs/2301.12929v2","updated":"2023-01-31T14:26:52Z","published":"2023-01-30T14:30:50Z","title":"Can Persistent Homology provide an efficient alternative for Evaluation\n  of Knowledge Graph Completion Methods?","summary":"  In this paper we present a novel method, $\\textit{Knowledge Persistence}$\n($\\mathcal{KP}$), for faster evaluation of Knowledge Graph (KG) completion\napproaches. Current ranking-based evaluation is quadratic in the size of the\nKG, leading to long evaluation times and consequently a high carbon footprint.\n$\\mathcal{KP}$ addresses this by representing the topology of the KG completion\nmethods through the lens of topological data analysis, concretely using\npersistent homology. The characteristics of persistent homology allow\n$\\mathcal{KP}$ to evaluate the quality of the KG completion looking only at a\nfraction of the data. Experimental results on standard datasets show that the\nproposed metric is highly correlated with ranking metrics (Hits@N, MR, MRR).\nPerformance evaluation shows that $\\mathcal{KP}$ is computationally efficient:\nIn some cases, the evaluation time (validation+test) of a KG completion method\nhas been reduced from 18 hours (using Hits@10) to 27 seconds (using\n$\\mathcal{KP}$), and on average (across methods & data) reduces the evaluation\ntime (validation+test) by $\\approx$ $\\textbf{99.96}\\%$.\n","authors":["Anson Bastos","Kuldeep Singh","Abhishek Nadgeri","Johannes Hoffart","Toyotaro Suzumura","Manish Singh"],"pdf_url":"https://arxiv.org/pdf/2301.12929v2.pdf","comment":"To appear in proceedings of The Web Conference 2023 (WWW'23)"},{"id":"http://arxiv.org/abs/2102.03888v6","updated":"2023-01-31T14:11:57Z","published":"2021-02-07T19:12:09Z","title":"OPT-GAN: A Broad-Spectrum Global Optimizer for Black-box Problems by\n  Learning Distribution","summary":"  Black-box optimization (BBO) algorithms are concerned with finding the best\nsolutions for problems with missing analytical details. Most classical methods\nfor such problems are based on strong and fixed a priori assumptions, such as\nGaussianity. However, the complex real-world problems, especially when the\nglobal optimum is desired, could be very far from the a priori assumptions\nbecause of their diversities, causing unexpected obstacles. In this study, we\npropose a generative adversarial net-based broad-spectrum global optimizer\n(OPT-GAN) which estimates the distribution of optimum gradually, with\nstrategies to balance exploration-exploitation trade-off. It has potential to\nbetter adapt to the regularity and structure of diversified landscapes than\nother methods with fixed prior, e.g., Gaussian assumption or separability.\nExperiments on diverse BBO benchmarks and high dimensional real world\napplications exhibit that OPT-GAN outperforms other traditional and neural\nnet-based BBO algorithms.\n","authors":["Minfang Lu","Shuai Ning","Shuangrong Liu","Fengyang Sun","Bo Zhang","Bo Yang","Lin Wang"],"pdf_url":"https://arxiv.org/pdf/2102.03888v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13565v3","updated":"2023-01-31T13:58:59Z","published":"2022-09-27T17:36:26Z","title":"Neural parameter calibration for large-scale multi-agent models","summary":"  Computational models have become a powerful tool in the quantitative sciences\nto understand the behaviour of complex systems that evolve in time. However,\nthey often contain a potentially large number of free parameters whose values\ncannot be obtained from theory but need to be inferred from data. This is\nespecially the case for models in the social sciences, economics, or\ncomputational epidemiology. Yet many current parameter estimation methods are\nmathematically involved and computationally slow to run. In this paper we\npresent a computationally simple and fast method to retrieve accurate\nprobability densities for model parameters using neural differential equations.\nWe present a pipeline comprising multi-agent models acting as forward solvers\nfor systems of ordinary or stochastic differential equations, and a neural\nnetwork to then extract parameters from the data generated by the model. The\ntwo combined create a powerful tool that can quickly estimate densities on\nmodel parameters, even for very large systems. We demonstrate the method on\nsynthetic time series data of the SIR model of the spread of infection, and\nperform an in-depth analysis of the Harris-Wilson model of economic activity on\na network, representing a non-convex problem. For the latter, we apply our\nmethod both to synthetic data and to data of economic activity across Greater\nLondon. We find that our method calibrates the model orders of magnitude more\naccurately than a previous study of the same dataset using classical\ntechniques, while running between 195 and 390 times faster.\n","authors":["Thomas Gaskin","Grigorios A. Pavliotis","Mark Girolami"],"pdf_url":"https://arxiv.org/pdf/2209.13565v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13644v1","updated":"2023-01-31T13:56:55Z","published":"2023-01-31T13:56:55Z","title":"Exploring QSAR Models for Activity-Cliff Prediction","summary":"  Pairs of similar compounds that only differ by a small structural\nmodification but exhibit a large difference in their binding affinity for a\ngiven target are known as activity cliffs (ACs). It has been hypothesised that\nquantitative structure-activity relationship (QSAR) models struggle to predict\nACs and that ACs thus form a major source of prediction error. However, a study\nto explore the AC-prediction power of modern QSAR methods and its relationship\nto general QSAR-prediction performance is lacking. We systematically construct\nnine distinct QSAR models by combining three molecular representation methods\n(extended-connectivity fingerprints, physicochemical-descriptor vectors and\ngraph isomorphism networks) with three regression techniques (random forests,\nk-nearest neighbours and multilayer perceptrons); we then use each resulting\nmodel to classify pairs of similar compounds as ACs or non-ACs and to predict\nthe activities of individual molecules in three case studies: dopamine receptor\nD2, factor Xa, and SARS-CoV-2 main protease. We observe low AC-sensitivity\namongst the tested models when the activities of both compounds are unknown,\nbut a substantial increase in AC-sensitivity when the actual activity of one of\nthe compounds is given. Graph isomorphism features are found to be competitive\nwith or superior to classical molecular representations for AC-classification\nand can thus be employed as baseline AC-prediction models or simple\ncompound-optimisation tools. For general QSAR-prediction, however,\nextended-connectivity fingerprints still consistently deliver the best\nperformance. Our results provide strong support for the hypothesis that indeed\nQSAR methods frequently fail to predict ACs. We propose twin-network training\nfor deep learning models as a potential future pathway to increase\nAC-sensitivity and thus overall QSAR performance.\n","authors":["Markus Dablander","Thierry Hanser","Renaud Lambiotte","Garrett M. Morris"],"pdf_url":"https://arxiv.org/pdf/2301.13644v1.pdf","comment":"Submitted to Journal of Cheminformatics"},{"id":"http://arxiv.org/abs/2301.13642v1","updated":"2023-01-31T13:54:23Z","published":"2023-01-31T13:54:23Z","title":"An Efficient Solution to s-Rectangular Robust Markov Decision Processes","summary":"  We present an efficient robust value iteration for \\texttt{s}-rectangular\nrobust Markov Decision Processes (MDPs) with a time complexity comparable to\nstandard (non-robust) MDPs which is significantly faster than any existing\nmethod. We do so by deriving the optimal robust Bellman operator in concrete\nforms using our $L_p$ water filling lemma. We unveil the exact form of the\noptimal policies, which turn out to be novel threshold policies with the\nprobability of playing an action proportional to its advantage.\n","authors":["Navdeep Kumar","Kfir Levy","Kaixin Wang","Shie Mannor"],"pdf_url":"https://arxiv.org/pdf/2301.13642v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.14327"},{"id":"http://arxiv.org/abs/2301.13637v1","updated":"2023-01-31T13:51:37Z","published":"2023-01-31T13:51:37Z","title":"Tricking AI chips into Simulating the Human Brain: A Detailed\n  Performance Analysis","summary":"  Challenging the Nvidia monopoly, dedicated AI-accelerator chips have begun\nemerging for tackling the computational challenge that the inference and,\nespecially, the training of modern deep neural networks (DNNs) poses to modern\ncomputers. The field has been ridden with studies assessing the performance of\nthese contestants across various DNN model types. However, AI-experts are aware\nof the limitations of current DNNs and have been working towards the fourth AI\nwave which will, arguably, rely on more biologically inspired models,\npredominantly on spiking neural networks (SNNs). At the same time, GPUs have\nbeen heavily used for simulating such models in the field of computational\nneuroscience, yet AI-chips have not been tested on such workloads. The current\npaper aims at filling this important gap by evaluating multiple, cutting-edge\nAI-chips (Graphcore IPU, GroqChip, Nvidia GPU with Tensor Cores and Google TPU)\non simulating a highly biologically detailed model of a brain region, the\ninferior olive (IO). This IO application stress-tests the different\nAI-platforms for highlighting architectural tradeoffs by varying its compute\ndensity, memory requirements and floating-point numerical accuracy. Our\nperformance analysis reveals that the simulation problem maps extremely well\nonto the GPU and TPU architectures, which for networks of 125,000 cells leads\nto a 28x respectively 1,208x speedup over CPU runtimes. At this speed, the TPU\nsets a new record for largest real-time IO simulation. The GroqChip outperforms\nboth platforms for small networks but, due to implementing some floating-point\noperations at reduced accuracy, is found not yet usable for brain simulation.\n","authors":["Lennart P. L. Landsmeer","Max C. W. Engelen","Rene Miedema","Christos Strydis"],"pdf_url":"https://arxiv.org/pdf/2301.13637v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.13636v1","updated":"2023-01-31T13:50:16Z","published":"2023-01-31T13:50:16Z","title":"Transport with Support: Data-Conditional Diffusion Bridges","summary":"  The dynamic Schr\\\"odinger bridge problem provides an appealing setting for\nsolving optimal transport problems by learning non-linear diffusion processes\nusing efficient iterative solvers. Recent works have demonstrated\nstate-of-the-art results (eg. in modelling single-cell embryo RNA sequences or\nsampling from complex posteriors) but are limited to learning bridges with only\ninitial and terminal constraints. Our work extends this paradigm by proposing\nthe Iterative Smoothing Bridge (ISB). We integrate Bayesian filtering and\noptimal control into learning the diffusion process, enabling constrained\nstochastic processes governed by sparse observations at intermediate stages and\nterminal constraints. We assess the effectiveness of our method on synthetic\nand real-world data and show that the ISB generalises well to high-dimensional\ndata, is computationally efficient, and provides accurate estimates of the\nmarginals at intermediate and terminal times.\n","authors":["Ella Tamir","Martin Trapp","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2301.13636v1.pdf","comment":"23 pages, 11 figures"},{"id":"http://arxiv.org/abs/2301.13635v1","updated":"2023-01-31T13:49:52Z","published":"2023-01-31T13:49:52Z","title":"Active Learning-based Domain Adaptive Localized Polynomial Chaos\n  Expansion","summary":"  The paper presents a novel methodology to build surrogate models of\ncomplicated functions by an active learning-based sequential decomposition of\nthe input random space and construction of localized polynomial chaos\nexpansions, referred to as domain adaptive localized polynomial chaos expansion\n(DAL-PCE). The approach utilizes sequential decomposition of the input random\nspace into smaller sub-domains approximated by low-order polynomial expansions.\nThis allows approximation of functions with strong nonlinearties,\ndiscontinuities, and/or singularities. Decomposition of the input random space\nand local approximations alleviates the Gibbs phenomenon for these types of\nproblems and confines error to a very small vicinity near the non-linearity.\nThe global behavior of the surrogate model is therefore significantly better\nthan existing methods as shown in numerical examples. The whole process is\ndriven by an active learning routine that uses the recently proposed $\\Theta$\ncriterion to assess local variance contributions. The proposed approach\nbalances both \\emph{exploitation} of the surrogate model and \\emph{exploration}\nof the input random space and thus leads to efficient and accurate\napproximation of the original mathematical model. The numerical results show\nthe superiority of the DAL-PCE in comparison to (i) a single global polynomial\nchaos expansion and (ii) the recently proposed stochastic spectral embedding\n(SSE) method developed as an accurate surrogate model and which is based on a\nsimilar domain decomposition process. This method represents general framework\nupon which further extensions and refinements can be based, and which can be\ncombined with any technique for non-intrusive polynomial chaos expansion\nconstruction.\n","authors":["Lukáš Novák","Michael D. Shields","Václav Sadílek","Miroslav Vořechovský"],"pdf_url":"https://arxiv.org/pdf/2301.13635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13629v1","updated":"2023-01-31T13:42:36Z","published":"2023-01-31T13:42:36Z","title":"DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising\n  Diffusion Models","summary":"  Spatio-temporal graph neural networks (STGNN) have emerged as the dominant\nmodel for spatio-temporal graph (STG) forecasting. Despite their success, they\nfail to model intrinsic uncertainties within STG data, which cripples their\npracticality in downstream tasks for decision-making. To this end, this paper\nfocuses on probabilistic STG forecasting, which is challenging due to the\ndifficulty in modeling uncertainties and complex ST dependencies. In this\nstudy, we present the first attempt to generalize the popular denoising\ndiffusion probabilistic models to STGs, leading to a novel non-autoregressive\nframework called DiffSTG, along with the first denoising network UGnet for STG\nin the framework. Our approach combines the spatio-temporal learning\ncapabilities of STGNNs with the uncertainty measurements of diffusion models.\nExtensive experiments validate that DiffSTG reduces the Continuous Ranked\nProbability Score (CRPS) by 4%-14%, and Root Mean Squared Error (RMSE) by 2%-7%\nover existing methods on three real-world datasets.\n","authors":["Haomin Wen","Youfang Lin","Yutong Xia","Huaiyu Wan","Roger Zimmermann","Yuxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2301.13629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06916v2","updated":"2023-01-31T13:33:03Z","published":"2023-01-13T08:24:21Z","title":"Automated speech- and text-based classification of neuropsychiatric\n  conditions in a multidiagnostic setting","summary":"  Speech patterns have been identified as potential diagnostic markers for\nneuropsychiatric conditions. However, most studies only compare a single\nclinical group to healthy controls, whereas clinical practice often requires\ndifferentiating between multiple potential diagnoses (multiclass settings). To\naddress this, we assembled a dataset of repeated recordings from 420\nparticipants (67 with major depressive disorder, 106 with schizophrenia and 46\nwith autism, as well as matched controls), and tested the performance of a\nrange of conventional machine learning models and advanced Transformer models\non both binary and multiclass classification, based on voice and text features.\n  While binary models performed comparably to previous research (F1 scores\nbetween 0.54-0.75 for autism spectrum disorder, ASD; 0.67-0.92 for major\ndepressive disorder, MDD; and 0.71-0.83 for schizophrenia); when\ndifferentiating between multiple diagnostic groups performance decreased\nmarkedly (F1 scores between 0.35-0.44 for ASD, 0.57-0.75 for MDD, 0.15-0.66 for\nschizophrenia, and 0.38-0.52 macro F1). Combining voice and text-based models\nyielded increased performance, suggesting that they capture complementary\ndiagnostic information.\n  Our results indicate that models trained on binary classification may learn\nto rely on markers of generic differences between clinical and non-clinical\npopulations, or markers of clinical features that overlap across conditions,\nrather than identifying markers specific to individual conditions. We provide\nrecommendations for future research in the field, suggesting increased focus on\ndeveloping larger transdiagnostic datasets that include more fine-grained\nclinical features, and that can support the development of models that better\ncapture the complexity of neuropsychiatric conditions and naturalistic\ndiagnostic assessment.\n","authors":["Lasse Hansen","Roberta Rocca","Arndis Simonsen","Alberto Parola","Vibeke Bliksted","Nicolai Ladegaard","Dan Bang","Kristian Tylén","Ethan Weed","Søren Dinesen Østergaard","Riccardo Fusaroli"],"pdf_url":"https://arxiv.org/pdf/2301.06916v2.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.13622v1","updated":"2023-01-31T13:29:19Z","published":"2023-01-31T13:29:19Z","title":"Learning Data Representations with Joint Diffusion Models","summary":"  We introduce a joint diffusion model that simultaneously learns meaningful\ninternal representations fit for both generative and predictive tasks. Joint\nmachine learning models that allow synthesizing and classifying data often\noffer uneven performance between those tasks or are unstable to train. In this\nwork, we depart from a set of empirical observations that indicate the\nusefulness of internal representations built by contemporary deep\ndiffusion-based generative models in both generative and predictive settings.\nWe then introduce an extension of the vanilla diffusion model with a classifier\nthat allows for stable joint training with shared parametrization between those\nobjectives. The resulting joint diffusion model offers superior performance\nacross various tasks, including generative modeling, semi-supervised\nclassification, and domain adaptation.\n","authors":["Kamil Deja","Tomasz Trzcinski","Jakub M. Tomczak"],"pdf_url":"https://arxiv.org/pdf/2301.13622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13618v1","updated":"2023-01-31T13:23:34Z","published":"2023-01-31T13:23:34Z","title":"Scheduling Inference Workloads on Distributed Edge Clusters with\n  Reinforcement Learning","summary":"  Many real-time applications (e.g., Augmented/Virtual Reality, cognitive\nassistance) rely on Deep Neural Networks (DNNs) to process inference tasks.\nEdge computing is considered a key infrastructure to deploy such applications,\nas moving computation close to the data sources enables us to meet stringent\nlatency and throughput requirements. However, the constrained nature of edge\nnetworks poses several additional challenges to the management of inference\nworkloads: edge clusters can not provide unlimited processing power to DNN\nmodels, and often a trade-off between network and processing time should be\nconsidered when it comes to end-to-end delay requirements. In this paper, we\nfocus on the problem of scheduling inference queries on DNN models in edge\nnetworks at short timescales (i.e., few milliseconds). By means of simulations,\nwe analyze several policies in the realistic network settings and workloads of\na large ISP, highlighting the need for a dynamic scheduling policy that can\nadapt to network conditions and workloads. We therefore design ASET, a\nReinforcement Learning based scheduling algorithm able to adapt its decisions\naccording to the system conditions. Our results show that ASET effectively\nprovides the best performance compared to static policies when scheduling over\na distributed pool of edge resources.\n","authors":["Gabriele Castellano","Juan-José Nieto","Jordi Luque","Ferrán Diego","Carlos Segura","Diego Perino","Flavio Esposito","Fulvio Risso","Aravindh Raman"],"pdf_url":"https://arxiv.org/pdf/2301.13618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13616v1","updated":"2023-01-31T13:18:33Z","published":"2023-01-31T13:18:33Z","title":"Anti-Exploration by Random Network Distillation","summary":"  Despite the success of Random Network Distillation (RND) in various domains,\nit was shown as not discriminative enough to be used as an uncertainty\nestimator for penalizing out-of-distribution actions in offline reinforcement\nlearning. In this paper, we revisit these results and show that, with a naive\nchoice of conditioning for the RND prior, it becomes infeasible for the actor\nto effectively minimize the anti-exploration bonus and discriminativity is not\nan issue. We show that this limitation can be avoided with conditioning based\non Feature-wise Linear Modulation (FiLM), resulting in a simple and efficient\nensemble-free algorithm based on Soft Actor-Critic. We evaluate it on the D4RL\nbenchmark, showing that it is capable of achieving performance comparable to\nensemble-based methods and outperforming ensemble-free approaches by a wide\nmargin.\n","authors":["Alexander Nikulin","Vladislav Kurenkov","Denis Tarasov","Sergey Kolesnikov"],"pdf_url":"https://arxiv.org/pdf/2301.13616v1.pdf","comment":"Source code: https://github.com/tinkoff-ai/sac-rnd"},{"id":"http://arxiv.org/abs/2210.08942v2","updated":"2023-01-31T12:41:41Z","published":"2022-10-17T11:09:35Z","title":"Meta-Learning via Classifier(-free) Diffusion Guidance","summary":"  We introduce meta-learning algorithms that perform zero-shot weight-space\nadaptation of neural network models to unseen tasks. Our methods repurpose the\npopular generative image synthesis techniques of natural language guidance and\ndiffusion models to generate neural network weights adapted for tasks. We first\ntrain an unconditional generative hypernetwork model to produce neural network\nweights; then we train a second \"guidance\" model that, given a natural language\ntask description, traverses the hypernetwork latent space to find\nhigh-performance task-adapted weights in a zero-shot manner. We explore two\nalternative approaches for latent space guidance: \"HyperCLIP\"-based classifier\nguidance and a conditional Hypernetwork Latent Diffusion Model (\"HyperLDM\"),\nwhich we show to benefit from the classifier-free guidance technique common in\nimage generation. Finally, we demonstrate that our approaches outperform\nexisting multi-task and meta-learning methods in a series of zero-shot learning\nexperiments on our Meta-VQA dataset.\n","authors":["Elvis Nava","Seijin Kobayashi","Yifei Yin","Robert K. Katzschmann","Benjamin F. Grewe"],"pdf_url":"https://arxiv.org/pdf/2210.08942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13589v1","updated":"2023-01-31T12:40:50Z","published":"2023-01-31T12:40:50Z","title":"Policy Gradient for s-Rectangular Robust Markov Decision Processes","summary":"  We present a novel robust policy gradient method (RPG) for s-rectangular\nrobust Markov Decision Processes (MDPs). We are the first to derive the\nadversarial kernel in a closed form and demonstrate that it is a one-rank\nperturbation of the nominal kernel. This allows us to derive an RPG that is\nsimilar to the one used in non-robust MDPs, except with a robust Q-value\nfunction and an additional correction term. Both robust Q-values and correction\nterms are efficiently computable, thus the time complexity of our method\nmatches that of non-robust MDPs, which is significantly faster compared to\nexisting black box methods.\n","authors":["Navdeep Kumar","Esther Derman","Matthieu Geist","Kfir Levy","Shie Mannor"],"pdf_url":"https://arxiv.org/pdf/2301.13589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03928v4","updated":"2023-01-31T12:37:12Z","published":"2022-07-08T14:28:13Z","title":"Accelerating Material Design with the Generative Toolkit for Scientific\n  Discovery","summary":"  With the growing availability of data within various scientific domains,\ngenerative models hold enormous potential to accelerate scientific discovery.\nThey harness powerful representations learned from datasets to speed up the\nformulation of novel hypotheses with the potential to impact material discovery\nbroadly. We present the Generative Toolkit for Scientific Discovery (GT4SD).\nThis extensible open-source library enables scientists, developers, and\nresearchers to train and use state-of-the-art generative models to accelerate\nscientific discovery focused on material design.\n","authors":["Matteo Manica","Jannis Born","Joris Cadow","Dimitrios Christofidellis","Ashish Dave","Dean Clarke","Yves Gaetan Nana Teukam","Giorgio Giannone","Samuel C. Hoffman","Matthew Buchan","Vijil Chenthamarakshan","Timothy Donovan","Hsiang Han Hsu","Federico Zipoli","Oliver Schilter","Akihiro Kishimoto","Lisa Hamada","Inkit Padhi","Karl Wehden","Lauren McHugh","Alexy Khrabrov","Payel Das","Seiji Takeda","John R. Smith"],"pdf_url":"https://arxiv.org/pdf/2207.03928v4.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2301.13584v1","updated":"2023-01-31T12:31:13Z","published":"2023-01-31T12:31:13Z","title":"Support Exploration Algorithm for Sparse Support Recovery","summary":"  We introduce a new algorithm promoting sparsity called {\\it Support\nExploration Algorithm (SEA)} and analyze it in the context of support\nrecovery/model selection problems.The algorithm can be interpreted as an\ninstance of the {\\it straight-through estimator (STE)} applied to the\nresolution of a sparse linear inverse problem. SEA uses a non-sparse\nexploratory vector and makes it evolve in the input space to select the sparse\nsupport. We put to evidence an oracle update rule for the exploratory vector\nand consider the STE update. The theoretical analysis establishes general\nsufficient conditions of support recovery. The general conditions are\nspecialized to the case where the matrix $A$ performing the linear measurements\nsatisfies the {\\it Restricted Isometry Property (RIP)}.Experiments show that\nSEA can efficiently improve the results of any algorithm. Because of its\nexploratory nature, SEA also performs remarkably well when the columns of $A$\nare strongly coherent.\n","authors":["Mimoun Mohamed","François Malgouyres","Valentin Emiya","Caroline Chaux"],"pdf_url":"https://arxiv.org/pdf/2301.13584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10541v2","updated":"2023-01-31T12:19:31Z","published":"2022-07-21T15:29:35Z","title":"Optimal precision for GANs","summary":"  Many deep generative models are defined as a push-forward of a Gaussian\nmeasure by a continuous generator, such as Generative Adversarial Networks\n(GANs) or Variational Auto-Encoders (VAEs). This work explores the latent space\nof such deep generative models. A key issue with these models is their tendency\nto output samples outside of the support of the target distribution when\nlearning disconnected distributions. We investigate the relationship between\nthe performance of these models and the geometry of their latent space.\nBuilding on recent developments in geometric measure theory, we prove a\nsufficient condition for optimality in the case where the dimension of the\nlatent space is larger than the number of modes. Through experiments on GANs,\nwe demonstrate the validity of our theoretical results and gain new insights\ninto the latent space geometry of these models. Additionally, we propose a\ntruncation method that enforces a simplicial cluster structure in the latent\nspace and improves the performance of GANs.\n","authors":["Thibaut Issenhuth","Ugo Tanielian","Jérémie Mary","David Picard"],"pdf_url":"https://arxiv.org/pdf/2207.10541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13576v1","updated":"2023-01-31T12:03:59Z","published":"2023-01-31T12:03:59Z","title":"Sport Task: Fine Grained Action Detection and Classification of Table\n  Tennis Strokes from Videos for MediaEval 2022","summary":"  Sports video analysis is a widespread research topic. Its applications are\nvery diverse, like events detection during a match, video summary, or\nfine-grained movement analysis of athletes. As part of the MediaEval 2022\nbenchmarking initiative, this task aims at detecting and classifying subtle\nmovements from sport videos. We focus on recordings of table tennis matches.\nConducted since 2019, this task provides a classification challenge from\nuntrimmed videos recorded under natural conditions with known temporal\nboundaries for each stroke. Since 2021, the task also provides a stroke\ndetection challenge from unannotated, untrimmed videos. This year, the\ntraining, validation, and test sets are enhanced to ensure that all strokes are\nrepresented in each dataset. The dataset is now similar to the one used in [1,\n2]. This research is intended to build tools for coaches and athletes who want\nto further evaluate their sport performances.\n","authors":["Pierre-Etienne Martin","Jordan Calandre","Boris Mansencal","Jenny Benois-Pineau","Renaud Péteri","Laurent Mascarilla","Julien Morlier"],"pdf_url":"https://arxiv.org/pdf/2301.13576v1.pdf","comment":"MediaEval 2022 Workshop, Jan 2023, Bergen, Norway. arXiv admin note:\n  substantial text overlap with arXiv:2112.11384"},{"id":"http://arxiv.org/abs/2103.09603v4","updated":"2023-01-31T11:56:52Z","published":"2021-03-17T12:42:41Z","title":"DoubleML -- An Object-Oriented Implementation of Double Machine Learning\n  in R","summary":"  The R package DoubleML implements the double/debiased machine learning\nframework of Chernozhukov et al. (2018). It provides functionalities to\nestimate parameters in causal models based on machine learning methods. The\ndouble machine learning framework consist of three key ingredients: Neyman\northogonality, high-quality machine learning estimation and sample splitting.\nEstimation of nuisance components can be performed by various state-of-the-art\nmachine learning methods that are available in the mlr3 ecosystem. DoubleML\nmakes it possible to perform inference in a variety of causal models, including\npartially linear and interactive regression models and their extensions to\ninstrumental variable estimation. The object-oriented implementation of\nDoubleML enables a high flexibility for the model specification and makes it\neasily extendable. This paper serves as an introduction to the double machine\nlearning framework and the R package DoubleML. In reproducible code examples\nwith simulated and real data sets, we demonstrate how DoubleML users can\nperform valid inference based on machine learning methods.\n","authors":["Philipp Bach","Victor Chernozhukov","Malte S. Kurz","Martin Spindler"],"pdf_url":"https://arxiv.org/pdf/2103.09603v4.pdf","comment":"42 pages, 8 Figures, 1 Table; Updated version for DoubleML > 0.5.0"},{"id":"http://arxiv.org/abs/2212.07231v3","updated":"2023-01-31T11:53:11Z","published":"2022-12-14T14:06:27Z","title":"Cutting Plane Selection with Analytic Centers and Multiregression","summary":"  Cutting planes are a crucial component of state-of-the-art mixed-integer\nprogramming solvers, with the choice of which subset of cuts to add being vital\nfor solver performance. We propose new distance-based measures to qualify the\nvalue of a cut by quantifying the extent to which it separates relevant parts\nof the relaxed feasible set. For this purpose, we use the analytic centers of\nthe relaxation polytope or of its optimal face, as well as alternative optimal\nsolutions of the linear programming relaxation. We assess the impact of the\nchoice of distance measure on root node performance and throughout the whole\nbranch-and-bound tree, comparing our measures against those prevalent in the\nliterature. Finally, by a multi-output regression, we predict the relative\nperformance of each measure, using static features readily available before the\nseparation process. Our results indicate that analytic center-based methods\nhelp to significantly reduce the number of branch-and-bound nodes needed to\nexplore the search space and that our multiregression approach can further\nimprove on any individual method.\n","authors":["Mark Turner","Timo Berthold","Mathieu Besançon","Thorsten Koch"],"pdf_url":"https://arxiv.org/pdf/2212.07231v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13573v1","updated":"2023-01-31T11:52:46Z","published":"2023-01-31T11:52:46Z","title":"Skill Decision Transformer","summary":"  Recent work has shown that Large Language Models (LLMs) can be incredibly\neffective for offline reinforcement learning (RL) by representing the\ntraditional RL problem as a sequence modelling problem (Chen et al., 2021;\nJanner et al., 2021). However many of these methods only optimize for high\nreturns, and may not extract much information from a diverse dataset of\ntrajectories. Generalized Decision Transformers (GDTs) (Furuta et al., 2021)\nhave shown that utilizing future trajectory information, in the form of\ninformation statistics, can help extract more information from offline\ntrajectory data. Building upon this, we propose Skill Decision Transformer\n(Skill DT). Skill DT draws inspiration from hindsight relabelling (Andrychowicz\net al., 2017) and skill discovery methods to discover a diverse set of\nprimitive behaviors, or skills. We show that Skill DT can not only perform\noffline state-marginal matching (SMM), but can discovery descriptive behaviors\nthat can be easily sampled. Furthermore, we show that through purely\nreward-free optimization, Skill DT is still competitive with supervised offline\nRL approaches on the D4RL benchmark. The code and videos can be found on our\nproject page: https://github.com/shyamsn97/skill-dt\n","authors":["Shyam Sudhakaran","Sebastian Risi"],"pdf_url":"https://arxiv.org/pdf/2301.13573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13572v1","updated":"2023-01-31T11:49:26Z","published":"2023-01-31T11:49:26Z","title":"BALANCE: Bayesian Linear Attribution for Root Cause Localization","summary":"  Root Cause Analysis (RCA) plays an indispensable role in distributed data\nsystem maintenance and operations, as it bridges the gap between fault\ndetection and system recovery. Existing works mainly study multidimensional\nlocalization or graph-based root cause localization. This paper opens up the\npossibilities of exploiting the recently developed framework of explainable AI\n(XAI) for the purpose of RCA. In particular, we propose BALANCE (BAyesian\nLinear AttributioN for root CausE localization), which formulates the problem\nof RCA through the lens of attribution in XAI and seeks to explain the\nanomalies in the target KPIs by the behavior of the candidate root causes.\nBALANCE consists of three innovative components. First, we propose a Bayesian\nmulticollinear feature selection (BMFS) model to predict the target KPIs given\nthe candidate root causes in a forward manner while promoting sparsity and\nconcurrently paying attention to the correlation between the candidate root\ncauses. Second, we introduce attribution analysis to compute the attribution\nscore for each candidate in a backward manner. Third, we merge the estimated\nroot causes related to each KPI if there are multiple KPIs. We extensively\nevaluate the proposed BALANCE method on one synthesis dataset as well as three\nreal-world RCA tasks, that is, bad SQL localization, container fault\nlocalization, and fault type diagnosis for Exathlon. Results show that BALANCE\noutperforms the state-of-the-art (SOTA) methods in terms of accuracy with the\nleast amount of running time, and achieves at least $6\\%$ notably higher\naccuracy than SOTA methods for real tasks. BALANCE has been deployed to\nproduction to tackle real-world RCA problems, and the online results further\nadvocate its usage for real-time diagnosis in distributed data systems.\n","authors":["Chaoyu Chen","Hang Yu","Zhichao Lei","Jianguo Li","Shaokang Ren","Tingkai Zhang","Silin Hu","Jianchao Wang","Wenhui Shi"],"pdf_url":"https://arxiv.org/pdf/2301.13572v1.pdf","comment":"Accepted by SIGMOD 2023; 15 pages"},{"id":"http://arxiv.org/abs/2209.07932v2","updated":"2023-01-31T11:45:23Z","published":"2022-09-16T13:46:59Z","title":"Fine-tuning or top-tuning? Transfer learning with pretrained features\n  and fast kernel methods","summary":"  The impressive performances of deep learning architectures is associated to\nmassive increase of models complexity. Millions of parameters need be tuned,\nwith training and inference time scaling accordingly. But is massive\nfine-tuning necessary? In this paper, focusing on image classification, we\nconsider a simple transfer learning approach exploiting pretrained\nconvolutional features as input for a fast kernel method. We refer to this\napproach as top-tuning, since only the kernel classifier is trained. By\nperforming more than 2500 training processes we show that this top-tuning\napproach provides comparable accuracy w.r.t. fine-tuning, with a training time\nthat is between one and two orders of magnitude smaller. These results suggest\nthat top-tuning provides a useful alternative to fine-tuning in small/medium\ndatasets, especially when training efficiency is crucial.\n","authors":["Paolo Didier Alfano","Vito Paolo Pastore","Lorenzo Rosasco","Francesca Odone"],"pdf_url":"https://arxiv.org/pdf/2209.07932v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13569v1","updated":"2023-01-31T11:44:45Z","published":"2023-01-31T11:44:45Z","title":"NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning","summary":"  Semi-supervised learning (SSL) has been widely explored in recent years, and\nit is an effective way of leveraging unlabeled data to reduce the reliance on\nlabeled data. In this work, we adjust neural processes (NPs) to the\nsemi-supervised image classification task, resulting in a new method named\nNP-Match. NP-Match is suited to this task for two reasons. Firstly, NP-Match\nimplicitly compares data points when making predictions, and as a result, the\nprediction of each unlabeled data point is affected by the labeled data points\nthat are similar to it, which improves the quality of pseudo-labels. Secondly,\nNP-Match is able to estimate uncertainty that can be used as a tool for\nselecting unlabeled samples with reliable pseudo-labels. Compared with\nuncertainty-based SSL methods implemented with Monte-Carlo (MC) dropout,\nNP-Match estimates uncertainty with much less computational overhead, which can\nsave time at both the training and the testing phases. We conducted extensive\nexperiments on five public datasets under three semi-supervised image\nclassification settings, namely, the standard semi-supervised image\nclassification, the imbalanced semi-supervised image classification, and the\nmulti-label semi-supervised image classification, and NP-Match outperforms\nstate-of-the-art (SOTA) approaches or achieves competitive results on them,\nwhich shows the effectiveness of NP-Match and its potential for SSL. The codes\nare at https://github.com/Jianf-Wang/NP-Match\n","authors":["Jianfeng Wang","Xiaolin Hu","Thomas Lukasiewicz"],"pdf_url":"https://arxiv.org/pdf/2301.13569v1.pdf","comment":"An journal version of our previous ICML 2022 paper arXiv:2207.01066 .\n  Codes are available at: https://github.com/Jianf-Wang/NP-Match"},{"id":"http://arxiv.org/abs/2211.11865v4","updated":"2023-01-31T11:37:29Z","published":"2022-11-21T21:36:58Z","title":"Bayesian Learning for Neural Networks: an algorithmic survey","summary":"  The last decade witnessed a growing interest in Bayesian learning. Yet, the\ntechnicality of the topic and the multitude of ingredients involved therein,\nbesides the complexity of turning theory into practical implementations, limit\nthe use of the Bayesian learning paradigm, preventing its widespread adoption\nacross different fields and applications. This self-contained survey engages\nand introduces readers to the principles and algorithms of Bayesian Learning\nfor Neural Networks. It provides an introduction to the topic from an\naccessible, practical-algorithmic perspective. Upon providing a general\nintroduction to Bayesian Neural Networks, we discuss and present both standard\nand recent approaches for Bayesian inference, with an emphasis on solutions\nrelying on Variational Inference and the use of Natural gradients. We also\ndiscuss the use of manifold optimization as a state-of-the-art approach to\nBayesian learning. We examine the characteristic properties of all the\ndiscussed methods, and provide pseudo-codes for their implementation, paying\nattention to practical aspects, such as the computation of the gradients.\n","authors":["Martin Magris","Alexandros Iosifidis"],"pdf_url":"https://arxiv.org/pdf/2211.11865v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13565v1","updated":"2023-01-31T11:33:18Z","published":"2023-01-31T11:33:18Z","title":"Learning Against Distributional Uncertainty: On the Trade-off Between\n  Robustness and Specificity","summary":"  Trustworthy machine learning aims at combating distributional uncertainties\nin training data distributions compared to population distributions. Typical\ntreatment frameworks include the Bayesian approach, (min-max) distributionally\nrobust optimization (DRO), and regularization. However, two issues have to be\nraised: 1) All these methods are biased estimators of the true optimal cost; 2)\nthe prior distribution in the Bayesian method, the radius of the distributional\nball in the DRO method, and the regularizer in the regularization method are\ndifficult to specify. This paper studies a new framework that unifies the three\napproaches and that addresses the two challenges mentioned above. The\nasymptotic properties (e.g., consistency and asymptotic normalities),\nnon-asymptotic properties (e.g., unbiasedness and generalization error bound),\nand a Monte--Carlo-based solution method of the proposed model are studied. The\nnew model reveals the trade-off between the robustness to the unseen data and\nthe specificity to the training data.\n","authors":["Shixiong Wang","Haowei Wang","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2301.13565v1.pdf","comment":"23 Pages, 3 Figures"},{"id":"http://arxiv.org/abs/2202.07835v2","updated":"2023-01-31T11:29:18Z","published":"2022-02-16T02:57:10Z","title":"SecGNN: Privacy-Preserving Graph Neural Network Training and Inference\n  as a Cloud Service","summary":"  Graphs are widely used to model the complex relationships among entities. As\na powerful tool for graph analytics, graph neural networks (GNNs) have recently\ngained wide attention due to its end-to-end processing capabilities. With the\nproliferation of cloud computing, it is increasingly popular to deploy the\nservices of complex and resource-intensive model training and inference in the\ncloud due to its prominent benefits. However, GNN training and inference\nservices, if deployed in the cloud, will raise critical privacy concerns about\nthe information-rich and proprietary graph data (and the resulting model).\nWhile there has been some work on secure neural network training and inference,\nthey all focus on convolutional neural networks handling images and text rather\nthan complex graph data with rich structural information. In this paper, we\ndesign, implement, and evaluate SecGNN, the first system supporting\nprivacy-preserving GNN training and inference services in the cloud. SecGNN is\nbuilt from a synergy of insights on lightweight cryptography and machine\nlearning techniques. We deeply examine the procedure of GNN training and\ninference, and devise a series of corresponding secure customized protocols to\nsupport the holistic computation. Extensive experiments demonstrate that SecGNN\nachieves comparable plaintext training and inference accuracy, with promising\nperformance.\n","authors":["Songlei Wang","Yifeng Zheng","Xiaohua Jia"],"pdf_url":"https://arxiv.org/pdf/2202.07835v2.pdf","comment":"Accepted in IEEE Transactions on Services Computing (TSC)"},{"id":"http://arxiv.org/abs/2206.07912v5","updated":"2023-01-31T11:01:19Z","published":"2022-06-16T04:34:28Z","title":"Double Sampling Randomized Smoothing","summary":"  Neural networks (NNs) are known to be vulnerable against adversarial\nperturbations, and thus there is a line of work aiming to provide robustness\ncertification for NNs, such as randomized smoothing, which samples smoothing\nnoises from a certain distribution to certify the robustness for a smoothed\nclassifier. However, as shown by previous work, the certified robust radius in\nrandomized smoothing suffers from scaling to large datasets (\"curse of\ndimensionality\"). To overcome this hurdle, we propose a Double Sampling\nRandomized Smoothing (DSRS) framework, which exploits the sampled probability\nfrom an additional smoothing distribution to tighten the robustness\ncertification of the previous smoothed classifier. Theoretically, under mild\nassumptions, we prove that DSRS can certify $\\Theta(\\sqrt d)$ robust radius\nunder $\\ell_2$ norm where $d$ is the input dimension, implying that DSRS may be\nable to break the curse of dimensionality of randomized smoothing. We\ninstantiate DSRS for a generalized family of Gaussian smoothing and propose an\nefficient and sound computing method based on customized dual optimization\nconsidering sampling error. Extensive experiments on MNIST, CIFAR-10, and\nImageNet verify our theory and show that DSRS certifies larger robust radii\nthan existing baselines consistently under different settings. Code is\navailable at https://github.com/llylly/DSRS.\n","authors":["Linyi Li","Jiawei Zhang","Tao Xie","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2206.07912v5.pdf","comment":"ICML 2022; minor typos fixed; minor data corrected on Page 42 (no\n  influence on conclusions)"},{"id":"http://arxiv.org/abs/2301.13549v1","updated":"2023-01-31T10:59:09Z","published":"2023-01-31T10:59:09Z","title":"Review of methods for automatic cerebral microbleeds detection","summary":"  Cerebral microbleeds detection is an important and challenging task. With the\ngaining popularity of the MRI, the ability to detect cerebral microbleeds also\nraises. Unfortunately, for radiologists, it is a time-consuming and laborious\nprocedure. For this reason, various solutions to automate this process have\nbeen proposed for several years, but none of them is currently used in medical\npractice. In this context, the need to systematize the existing knowledge and\nbest practices has been recognized as a factor facilitating the imminent\nsynthesis of a real CMBs detection system practically applicable in medicine.\nTo the best of our knowledge, all available publications regarding automatic\ncerebral microbleeds detection have been gathered, described, and assessed in\nthis paper in order to distinguish the current research state and provide a\nstarting point for future studies.\n","authors":["Maria Ferlin","Zuzanna Klawikowska","Michał Grochowski","Małgorzata Grzywińska","Edyta Szurowska"],"pdf_url":"https://arxiv.org/pdf/2301.13549v1.pdf","comment":"32 pages, 6 figures, 3 tables, 174 references"},{"id":"http://arxiv.org/abs/2301.13545v1","updated":"2023-01-31T10:46:46Z","published":"2023-01-31T10:46:46Z","title":"Holistic Graph-based Motion Prediction","summary":"  Motion prediction for automated vehicles in complex environments is a\ndifficult task that is to be mastered when automated vehicles are to be used in\narbitrary situations. Many factors influence the future motion of traffic\nparticipants starting with traffic rules and reaching from the interaction\nbetween each other to personal habits of human drivers. Therefore we present a\nnovel approach for a graph-based prediction based on a heterogeneous holistic\ngraph representation that combines temporal information, properties and\nrelations between traffic participants as well as relations with static\nelements like the road network. The information are encoded through different\ntypes of nodes and edges that both are enriched with arbitrary features. We\nevaluated the approach on the INTERACTION and the Argoverse dataset and\nconducted an informative ablation study to demonstrate the benefit of different\ntypes of information for the motion prediction quality.\n","authors":["Daniel Grimm","Philip Schörner","Moritz Dreßler","J. -Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2301.13545v1.pdf","comment":"Accepted on ICRA 2023"},{"id":"http://arxiv.org/abs/2206.08890v2","updated":"2023-01-31T10:40:52Z","published":"2022-06-17T16:53:12Z","title":"Disentangling Model Multiplicity in Deep Learning","summary":"  Model multiplicity is a well-known but poorly understood phenomenon that\nundermines the generalisation guarantees of machine learning models. It appears\nwhen two models with similar training-time performance differ in their\npredictions and real-world performance characteristics. This observed\n'predictive' multiplicity (PM) also implies elusive differences in the\ninternals of the models, their 'representational' multiplicity (RM). We\nintroduce a conceptual and experimental setup for analysing RM by measuring\nactivation similarity via singular vector canonical correlation analysis\n(SVCCA). We show that certain differences in training methods systematically\nresult in larger RM than others and evaluate RM and PM over a finite sample as\npredictors for generalizability. We further correlate RM with PM measured by\nthe variance in i.i.d. and out-of-distribution test predictions in four\nstandard image data sets. Finally, instead of attempting to eliminate RM, we\ncall for its systematic measurement and maximal exposure.\n","authors":["Ari Heljakka","Martin Trapp","Juho Kannala","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2206.08890v2.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.13536v1","updated":"2023-01-31T10:29:11Z","published":"2023-01-31T10:29:11Z","title":"Low Complexity Adaptive Machine Learning Approaches for End-to-End\n  Latency Prediction","summary":"  Software Defined Networks have opened the door to statistical and AI-based\ntechniques to improve efficiency of networking. Especially to ensure a certain\nQuality of Service (QoS) for specific applications by routing packets with\nawareness on content nature (VoIP, video, files, etc.) and its needs (latency,\nbandwidth, etc.) to use efficiently resources of a network. Monitoring and\npredicting various Key Performance Indicators (KPIs) at any level may handle\nsuch problems while preserving network bandwidth. The question addressed in\nthis work is the design of efficient, low-cost adaptive algorithms for KPI\nestimation, monitoring and prediction. We focus on end-to-end latency\nprediction, for which we illustrate our approaches and results on data obtained\nfrom a public generator provided after the recent international challenge on\nGNN [12]. In this paper, we improve our previously proposed low-cost estimators\n[6] by adding the adaptive dimension, and show that the performances are\nminimally modified while gaining the ability to track varying networks.\n","authors":["Pierre Larrenie","Jean-François Bercher","Olivier Venard","Iyad Lahsen-Cherif"],"pdf_url":"https://arxiv.org/pdf/2301.13536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13142v2","updated":"2023-01-31T10:28:52Z","published":"2023-01-30T18:22:28Z","title":"Self-Compressing Neural Networks","summary":"  This work focuses on reducing neural network size, which is a major driver of\nneural network execution time, power consumption, bandwidth, and memory\nfootprint. A key challenge is to reduce size in a manner that can be exploited\nreadily for efficient training and inference without the need for specialized\nhardware. We propose Self-Compression: a simple, general method that\nsimultaneously achieves two goals: (1) removing redundant weights, and (2)\nreducing the number of bits required to represent the remaining weights. This\nis achieved using a generalized loss function to minimize overall network size.\nIn our experiments we demonstrate floating point accuracy with as few as 3% of\nthe bits and 18% of the weights remaining in the network.\n","authors":["Szabolcs Cséfalvay","James Imber"],"pdf_url":"https://arxiv.org/pdf/2301.13142v2.pdf","comment":"Accepted submission to 2023 DL-Hardware Co-Design for AI Acceleration"},{"id":"http://arxiv.org/abs/2301.13532v1","updated":"2023-01-31T10:26:44Z","published":"2023-01-31T10:26:44Z","title":"Population-wise Labeling of Sulcal Graphs using Multi-graph Matching","summary":"  Population-wise matching of the cortical fold is necessary to identify\nbiomarkers of neurological or psychiatric disorders. The difficulty comes from\nthe massive interindividual variations in the morphology and spatial\norganization of the folds. This task is challenging at both methodological and\nconceptual levels. In the widely used registration-based techniques, these\nvariations are considered as noise and the matching of folds is only implicit.\nAlternative approaches are based on the extraction and explicit identification\nof the cortical folds. In particular, representing cortical folding patterns as\ngraphs of sulcal basins-termed sulcal graphs-enables to formalize the task as a\ngraph-matching problem. In this paper, we propose to address the problem of\nsulcal graph matching directly at the population level using multi-graph\nmatching techniques. First, we motivate the relevance of multi-graph matching\nframework in this context. We then introduce a procedure to generate\npopulations of artificial sulcal graphs, which allows us benchmarking several\nstate of the art multi-graph matching methods. Our results on both artificial\nand real data demonstrate the effectiveness of multi-graph matching techniques\nto obtain a population-wise consistent labeling of cortical folds at the sulcal\nbasins level.\n","authors":["Rohit Yadav","François-Xavier Dupé","S. Takerkart","Guillaume Auzias"],"pdf_url":"https://arxiv.org/pdf/2301.13532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13530v1","updated":"2023-01-31T10:24:50Z","published":"2023-01-31T10:24:50Z","title":"Domain-Generalizable Multiple-Domain Clustering","summary":"  Accurately clustering high-dimensional measurements is vital for adequately\nanalyzing scientific data. Deep learning machinery has remarkably improved\nclustering capabilities in recent years due to its ability to extract\nmeaningful representations. In this work, we are given unlabeled samples from\nmultiple source domains, and we aim to learn a shared classifier that assigns\nthe examples to various clusters. Evaluation is done by using the classifier\nfor predicting cluster assignments in a previously unseen domain. This setting\ngeneralizes the problem of unsupervised domain generalization to the case in\nwhich no supervised learning samples are given (completely unsupervised).\nTowards this goal, we present an end-to-end model and evaluate its capabilities\non several multi-domain image datasets. Specifically, we demonstrate that our\nmodel is more accurate than schemes that require fine-tuning using samples from\nthe target domain or some level of supervision.\n","authors":["Amit Rozner","Barak Battash","Lior Wolf","Ofir Lindenbaum"],"pdf_url":"https://arxiv.org/pdf/2301.13530v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.13527v1","updated":"2023-01-31T10:23:02Z","published":"2023-01-31T10:23:02Z","title":"Real-Time Outlier Detection with Dynamic Process Limits","summary":"  Anomaly detection methods are part of the systems where rare events may\nendanger an operation's profitability, safety, and environmental aspects.\nAlthough many state-of-the-art anomaly detection methods were developed to\ndate, their deployment is limited to the operation conditions present during\nthe model training. Online anomaly detection brings the capability to adapt to\ndata drifts and change points that may not be represented during model\ndevelopment resulting in prolonged service life. This paper proposes an online\nanomaly detection algorithm for existing real-time infrastructures where\nlow-latency detection is required and novel patterns in data occur\nunpredictably. The online inverse cumulative distribution-based approach is\nintroduced to eliminate common problems of offline anomaly detectors, meanwhile\nproviding dynamic process limits to normal operation. The benefit of the\nproposed method is the ease of use, fast computation, and deployability as\nshown in two case studies of real microgrid operation data.\n","authors":["Marek Wadinger","Michal Kvasnica"],"pdf_url":"https://arxiv.org/pdf/2301.13527v1.pdf","comment":"7 pages, 4 figures, 24th International Conference on Process Control"},{"id":"http://arxiv.org/abs/2301.13524v1","updated":"2023-01-31T10:17:53Z","published":"2023-01-31T10:17:53Z","title":"Quantum contextual bandits and recommender systems for quantum data","summary":"  We study a recommender system for quantum data using the linear contextual\nbandit framework. In each round, a learner receives an observable (the context)\nand has to recommend from a finite set of unknown quantum states (the actions)\nwhich one to measure. The learner has the goal of maximizing the reward in each\nround, that is the outcome of the measurement on the unknown state. Using this\nmodel we formulate the low energy quantum state recommendation problem where\nthe context is a Hamiltonian and the goal is to recommend the state with the\nlowest energy. For this task, we study two families of contexts: the Ising\nmodel and a generalized cluster model. We observe that if we interpret the\nactions as different phases of the models then the recommendation is done by\nclassifying the correct phase of the given Hamiltonian and the strategy can be\ninterpreted as an online quantum phase classifier.\n","authors":["Shrigyan Brahmachari","Josep Lumbreras","Marco Tomamichel"],"pdf_url":"https://arxiv.org/pdf/2301.13524v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2301.13516v1","updated":"2023-01-31T10:07:23Z","published":"2023-01-31T10:07:23Z","title":"Recurrences reveal shared causal drivers of complex time series","summary":"  Many experimental time series measurements share an unobserved causal driver.\nExamples include genes targeted by transcription factors, ocean flows\ninfluenced by large-scale atmospheric currents, and motor circuits steered by\ndescending neurons. Reliably inferring this unseen driving force is necessary\nto understand the intermittent nature of top-down control schemes in diverse\nbiological and engineered systems. Here, we introduce a new unsupervised\nlearning algorithm that uses recurrences in time series measurements to\ngradually reconstruct an unobserved driving signal. Drawing on the mathematical\ntheory of skew-product dynamical systems, we identify recurrence events shared\nacross response time series, which implicitly define a recurrence graph with\nglass-like structure. As the amount or quality of observed data improves, this\nrecurrence graph undergoes a percolation transition manifesting as weak\nergodicity breaking for random walks on the induced landscape -- revealing the\nshared driver's dynamics, even in the presence of strongly corrupted or noisy\nmeasurements. Across several thousand random dynamical systems, we empirically\nquantify the dependence of reconstruction accuracy on the rate of information\ntransfer from a chaotic driver to the response systems, and we find that\neffective reconstruction proceeds through gradual approximation of the driver's\ndominant unstable periodic orbits. Through extensive benchmarks against\nclassical and neural-network-based signal processing techniques, we demonstrate\nour method's strong ability to extract causal driving signals from diverse\nreal-world datasets spanning neuroscience, genomics, fluid dynamics, and\nphysiology.\n","authors":["William Gilpin"],"pdf_url":"https://arxiv.org/pdf/2301.13516v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.13514v1","updated":"2023-01-31T10:05:35Z","published":"2023-01-31T10:05:35Z","title":"Fourier Sensitivity and Regularization of Computer Vision Models","summary":"  Recent work has empirically shown that deep neural networks latch on to the\nFourier statistics of training data and show increased sensitivity to\nFourier-basis directions in the input. Understanding and modifying this\nFourier-sensitivity of computer vision models may help improve their\nrobustness. Hence, in this paper we study the frequency sensitivity\ncharacteristics of deep neural networks using a principled approach. We first\npropose a basis trick, proving that unitary transformations of the\ninput-gradient of a function can be used to compute its gradient in the basis\ninduced by the transformation. Using this result, we propose a general measure\nof any differentiable model's Fourier-sensitivity using the unitary\nFourier-transform of its input-gradient. When applied to deep neural networks,\nwe find that computer vision models are consistently sensitive to particular\nfrequencies dependent on the dataset, training method and architecture. Based\non this measure, we further propose a Fourier-regularization framework to\nmodify the Fourier-sensitivities and frequency bias of models. Using our\nproposed regularizer-family, we demonstrate that deep neural networks obtain\nimproved classification accuracy on robustness evaluations.\n","authors":["Kiran Krishnamachari","See-Kiong Ng","Chuan-Sheng Foo"],"pdf_url":"https://arxiv.org/pdf/2301.13514v1.pdf","comment":"Published in TMLR, https://openreview.net/forum?id=VmTYgjYloM"},{"id":"http://arxiv.org/abs/2205.07246v3","updated":"2023-01-31T10:04:52Z","published":"2022-05-15T10:07:52Z","title":"FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning","summary":"  Semi-supervised Learning (SSL) has witnessed great success owing to the\nimpressive performances brought by various methods based on pseudo labeling and\nconsistency regularization. However, we argue that existing methods might fail\nto utilize the unlabeled data more effectively since they either use a\npre-defined / fixed threshold or an ad-hoc threshold adjusting scheme,\nresulting in inferior performance and slow convergence. We first analyze a\nmotivating example to obtain intuitions on the relationship between the\ndesirable threshold and model's learning status. Based on the analysis, we\nhence propose FreeMatch to adjust the confidence threshold in a self-adaptive\nmanner according to the model's learning status. We further introduce a\nself-adaptive class fairness regularization penalty to encourage the model for\ndiverse predictions during the early training stage. Extensive experiments\nindicate the superiority of FreeMatch especially when the labeled data are\nextremely rare. FreeMatch achieves 5.78%, 13.59%, and 1.28% error rate\nreduction over the latest state-of-the-art method FlexMatch on CIFAR-10 with 1\nlabel per class, STL-10 with 4 labels per class, and ImageNet with 100 labels\nper class, respectively. Moreover, FreeMatch can also boost the performance of\nimbalanced SSL. The codes can be found at\nhttps://github.com/microsoft/Semi-supervised-learning.\n","authors":["Yidong Wang","Hao Chen","Qiang Heng","Wenxin Hou","Yue Fan","Zhen Wu","Jindong Wang","Marios Savvides","Takahiro Shinozaki","Bhiksha Raj","Bernt Schiele","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2205.07246v3.pdf","comment":"Accepted by ICLR 2023. Code:\n  https://github.com/microsoft/Semi-supervised-learning"},{"id":"http://arxiv.org/abs/2301.11719v2","updated":"2023-01-31T09:55:23Z","published":"2023-01-27T14:05:12Z","title":"Incorporating Knowledge into Document Summarization: an Application of\n  Prefix-Tuning on GPT-2","summary":"  Despite the great development of document summarization techniques nowadays,\nfactual inconsistencies between the generated summaries and the original text\nstill occur from time to time. This paper proposes a prefix-tuning-based\napproach that uses a set of trainable continuous prefix prompt together with\ndiscrete prompts to aid model generation, which makes a significant impact on\nboth CNN/Daily Mail and XSum summaries generated using GPT-2. The improvements\non fact preservation in the generated summaries indicates the effectiveness of\nadopting this prefix-tuning-based method in knowledge-enhanced document\nsummarization, and also shows a great potential on other natural language\nprocessing tasks.\n","authors":["Chen Chen","Wei Emma Zhang","Alireza Seyed Shakeri"],"pdf_url":"https://arxiv.org/pdf/2301.11719v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08609v2","updated":"2023-01-31T09:53:43Z","published":"2022-08-18T03:06:25Z","title":"A Scalable, Interpretable, Verifiable & Differentiable Logic Gate\n  Convolutional Neural Network Architecture From Truth Tables","summary":"  We propose $\\mathcal{T}$ruth $\\mathcal{T}$able net ($\\mathcal{TT}$net), a\nnovel Convolutional Neural Network (CNN) architecture that addresses, by\ndesign, the open challenges of interpretability, formal verification, and logic\ngate conversion. $\\mathcal{TT}$net is built using CNNs' filters that are\nequivalent to tractable truth tables and that we call Learning Truth Table\n(LTT) blocks. The dual form of LTT blocks allows the truth tables to be easily\ntrained with gradient descent and makes these CNNs easy to interpret, verify\nand infer. Specifically, $\\mathcal{TT}$net is a deep CNN model that can be\nautomatically represented, after post-training transformation, as a sum of\nBoolean decision trees, or as a sum of Disjunctive/Conjunctive Normal Form\n(DNF/CNF) formulas, or as a compact Boolean logic circuit. We demonstrate the\neffectiveness and scalability of $\\mathcal{TT}$net on multiple datasets,\nshowing comparable interpretability to decision trees, fast complete/sound\nformal verification, and scalable logic gate representation, all compared to\nstate-of-the-art methods. We believe this work represents a step towards making\nCNNs more transparent and trustworthy for real-world critical applications.\n","authors":["Adrien Benamira","Tristan Guérand","Thomas Peyrin","Trevor Yap","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2208.08609v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.05887v2","updated":"2023-01-31T09:49:55Z","published":"2021-10-12T10:56:54Z","title":"Discovery of Single Independent Latent Variable","summary":"  Latent variable discovery is a central problem in data analysis with a broad\nrange of applications in applied science. In this work, we consider data given\nas an invertible mixture of two statistically independent components, and\nassume that one of the components is observed while the other is hidden. Our\ngoal is to recover the hidden component. For this purpose, we propose an\nautoencoder equipped with a discriminator. Unlike the standard nonlinear ICA\nproblem, which was shown to be non-identifiable, in the special case of ICA we\nconsider here, we show that our approach can recover the component of interest\nup to entropy-preserving transformation. We demonstrate the performance of the\nproposed approach on several datasets, including image synthesis, voice\ncloning, and fetal ECG extraction.\n","authors":["Uri Shaham","Jonathan Svirsky","Ori Katz","Ronen Talmon"],"pdf_url":"https://arxiv.org/pdf/2110.05887v2.pdf","comment":"Published as a conference paper at Neurips 2022"},{"id":"http://arxiv.org/abs/2301.13507v1","updated":"2023-01-31T09:48:53Z","published":"2023-01-31T09:48:53Z","title":"An Analysis of Classification Approaches for Hit Song Prediction using\n  Engineered Metadata Features with Lyrics and Audio Features","summary":"  Hit song prediction, one of the emerging fields in music information\nretrieval (MIR), remains a considerable challenge. Being able to understand\nwhat makes a given song a hit is clearly beneficial to the whole music\nindustry. Previous approaches to hit song prediction have focused on using\naudio features of a record. This study aims to improve the prediction result of\nthe top 10 hits among Billboard Hot 100 songs using more alternative metadata,\nincluding song audio features provided by Spotify, song lyrics, and novel\nmetadata-based features (title topic, popularity continuity and genre class).\nFive machine learning approaches are applied, including: k-nearest neighbours,\nNaive Bayes, Random Forest, Logistic Regression and Multilayer Perceptron. Our\nresults show that Random Forest (RF) and Logistic Regression (LR) with all\nfeatures (including novel features, song audio features and lyrics features)\noutperforms other models, achieving 89.1% and 87.2% accuracy, and 0.91 and 0.93\nAUC, respectively. Our findings also demonstrate the utility of our novel music\nmetadata features, which contributed most to the models' discriminative\nperformance.\n","authors":["Mengyisong Zhao","Morgan Harvey","David Cameron","Frank Hopfgartner","Valerie J. Gillet"],"pdf_url":"https://arxiv.org/pdf/2301.13507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13506v1","updated":"2023-01-31T09:46:37Z","published":"2023-01-31T09:46:37Z","title":"DNN Explanation for Safety Analysis: an Empirical Evaluation of\n  Clustering-based Approaches","summary":"  The adoption of deep neural networks (DNNs) in safety-critical contexts is\noften prevented by the lack of effective means to explain their results,\nespecially when they are erroneous. In our previous work, we proposed a\nwhite-box approach (HUDD) and a black-box approach (SAFE) to automatically\ncharacterize DNN failures. They both identify clusters of similar images from a\npotentially large set of images leading to DNN failures. However, the analysis\npipelines for HUDD and SAFE were instantiated in specific ways according to\ncommon practices, deferring the analysis of other pipelines to future work. In\nthis paper, we report on an empirical evaluation of 99 different pipelines for\nroot cause analysis of DNN failures. They combine transfer learning,\nautoencoders, heatmaps of neuron relevance, dimensionality reduction\ntechniques, and different clustering algorithms. Our results show that the best\npipeline combines transfer learning, DBSCAN, and UMAP. It leads to clusters\nalmost exclusively capturing images of the same failure scenario, thus\nfacilitating root cause analysis. Further, it generates distinct clusters for\neach root cause of failure, thus enabling engineers to detect all the unsafe\nscenarios. Interestingly, these results hold even for failure scenarios that\nare only observed in a small percentage of the failing images.\n","authors":["Mohammed Oualid Attaoui","Hazem Fahmy","Fabrizio Pastore","Lionel Briand"],"pdf_url":"https://arxiv.org/pdf/2301.13506v1.pdf","comment":"10 Tables, 14 Figures"},{"id":"http://arxiv.org/abs/2301.13501v1","updated":"2023-01-31T09:41:39Z","published":"2023-01-31T09:41:39Z","title":"Auxiliary Learning as an Asymmetric Bargaining Game","summary":"  Auxiliary learning is an effective method for enhancing the generalization\ncapabilities of trained models, particularly when dealing with small datasets.\nHowever, this approach may present several difficulties: (i) optimizing\nmultiple objectives can be more challenging, and (ii) how to balance the\nauxiliary tasks to best assist the main task is unclear. In this work, we\npropose a novel approach, named AuxiNash, for balancing tasks in auxiliary\nlearning by formalizing the problem as generalized bargaining game with\nasymmetric task bargaining power. Furthermore, we describe an efficient\nprocedure for learning the bargaining power of tasks based on their\ncontribution to the performance of the main task and derive theoretical\nguarantees for its convergence. Finally, we evaluate AuxiNash on multiple\nmulti-task benchmarks and find that it consistently outperforms competing\nmethods.\n","authors":["Aviv Shamsian","Aviv Navon","Neta Glazer","Kenji Kawaguchi","Gal Chechik","Ethan Fetaya"],"pdf_url":"https://arxiv.org/pdf/2301.13501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14938v4","updated":"2023-01-31T09:36:26Z","published":"2022-05-30T09:03:28Z","title":"Spectral Maps for Learning on Subgraphs","summary":"  In graph learning, maps between graphs and their subgraphs frequently arise.\nFor instance, when coarsening or rewiring operations are present along the\npipeline, one needs to keep track of the corresponding nodes between the\noriginal and modified graphs. Classically, these maps are represented as binary\nnode-to-node correspondence matrices and used as-is to transfer node-wise\nfeatures between the graphs. In this paper, we argue that simply changing this\nmap representation can bring notable benefits to graph learning tasks. Drawing\ninspiration from recent progress in geometry processing, we introduce a\nspectral representation for maps that is easy to integrate into existing graph\nlearning models. This spectral representation is a compact and straightforward\nplug-in replacement and is robust to topological changes of the graphs.\nRemarkably, the representation exhibits structural properties that make it\ninterpretable, drawing an analogy with recent results on smooth manifolds. We\ndemonstrate the benefits of incorporating spectral maps in graph learning\npipelines, addressing scenarios where a node-to-node map is not well defined,\nor in the absence of exact isomorphism. Our approach bears practical benefits\nin knowledge distillation and hierarchical learning, where we show comparable\nor improved performance at a fraction of the computational cost.\n","authors":["Marco Pegoraro","Riccardo Marin","Arianna Rampini","Simone Melzi","Luca Cosmo","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2205.14938v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12231v2","updated":"2023-01-31T09:29:19Z","published":"2023-01-28T15:47:14Z","title":"Rateless Autoencoder Codes: Trading off Decoding Delay and Reliability","summary":"  Most of today's communication systems are designed to target reliable message\nrecovery after receiving the entire encoded message (codeword). However, in\nmany practical scenarios, the transmission process may be interrupted before\nreceiving the complete codeword. This paper proposes a novel rateless\nautoencoder (AE)-based code design suitable for decoding the transmitted\nmessage before the noisy codeword is fully received. Using particular dropout\nstrategies applied during the training process, rateless AE codes allow to\ntrade off between decoding delay and reliability, providing a graceful\nimprovement of the latter with each additionally received codeword symbol. The\nproposed rateless AEs significantly outperform the conventional AE designs for\nscenarios where it is desirable to trade off reliability for lower decoding\ndelay.\n","authors":["Vukan Ninkovic","Dejan Vukobratovic","Christian Häger","Henk Wymeersch","Alexandre Graell i Amat"],"pdf_url":"https://arxiv.org/pdf/2301.12231v2.pdf","comment":"6 pages, 7 figures, to appear at IEEE ICC 2023"},{"id":"http://arxiv.org/abs/2212.09412v2","updated":"2023-01-31T09:21:38Z","published":"2022-12-19T12:44:25Z","title":"Difformer: Empowering Diffusion Models on the Embedding Space for Text\n  Generation","summary":"  Diffusion models have achieved state-of-the-art synthesis quality on both\nvisual and audio tasks, and recent works further adapt them to textual data by\ndiffusing on the embedding space. In this paper, we conduct systematic studies\nand analyze the challenges between the continuous data space and the embedding\nspace which have not been carefully explored. Firstly, the data distribution is\nlearnable for embeddings, which may lead to the collapse of the loss function.\nSecondly, as the norm of embeddings varies between popular and rare words,\nadding the same noise scale will lead to sub-optimal results. In addition, we\nfind the normal level of noise causes insufficient training of the model. To\naddress the above challenges, we propose Difformer, an embedding diffusion\nmodel based on Transformer, which consists of three essential modules including\nan additional anchor loss function, a layer normalization module for\nembeddings, and a noise factor to the Gaussian noise. Experiments on two\nseminal text generation tasks including machine translation and text\nsummarization show the superiority of Difformer over compared embedding\ndiffusion baselines.\n","authors":["Zhujin Gao","Junliang Guo","Xu Tan","Yongxin Zhu","Fang Zhang","Jiang Bian","Linli Xu"],"pdf_url":"https://arxiv.org/pdf/2212.09412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13492v1","updated":"2023-01-31T09:17:13Z","published":"2023-01-31T09:17:13Z","title":"Company-as-Tribe: Company Financial Risk Assessment on Tribe-Style Graph\n  with Hierarchical Graph Neural Networks","summary":"  Company financial risk is ubiquitous and early risk assessment for listed\ncompanies can avoid considerable losses. Traditional methods mainly focus on\nthe financial statements of companies and lack the complex relationships among\nthem. However, the financial statements are often biased and lagged, making it\ndifficult to identify risks accurately and timely. To address the challenges,\nwe redefine the problem as \\textbf{company financial risk assessment on\ntribe-style graph} by taking each listed company and its shareholders as a\ntribe and leveraging financial news to build inter-tribe connections. Such\ntribe-style graphs present different patterns to distinguish risky companies\nfrom normal ones. However, most nodes in the tribe-style graph lack attributes,\nmaking it difficult to directly adopt existing graph learning methods (e.g.,\nGraph Neural Networks(GNNs)). In this paper, we propose a novel Hierarchical\nGraph Neural Network (TH-GNN) for Tribe-style graphs via two levels, with the\nfirst level to encode the structure pattern of the tribes with contrastive\nlearning, and the second level to diffuse information based on the inter-tribe\nrelations, achieving effective and efficient risk assessment. Extensive\nexperiments on the real-world company dataset show that our method achieves\nsignificant improvements on financial risk assessment over previous competing\nmethods. Also, the extensive ablation studies and visualization comprehensively\nshow the effectiveness of our method.\n","authors":["Wendong Bi","Bingbing Xu","Xiaoqian Sun","Zidong Wang","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2301.13492v1.pdf","comment":"accepted by SIGKDD2022"},{"id":"http://arxiv.org/abs/2301.13486v1","updated":"2023-01-31T09:11:59Z","published":"2023-01-31T09:11:59Z","title":"Robust Linear Regression: Gradient-descent, Early-stopping, and Beyond","summary":"  In this work we study the robustness to adversarial attacks, of\nearly-stopping strategies on gradient-descent (GD) methods for linear\nregression. More precisely, we show that early-stopped GD is optimally robust\n(up to an absolute constant) against Euclidean-norm adversarial attacks.\nHowever, we show that this strategy can be arbitrarily sub-optimal in the case\nof general Mahalanobis attacks. This observation is compatible with recent\nfindings in the case of classification~\\cite{Vardi2022GradientMP} that show\nthat GD provably converges to non-robust models. To alleviate this issue, we\npropose to apply instead a GD scheme on a transformation of the data adapted to\nthe attack. This data transformation amounts to apply feature-depending\nlearning rates and we show that this modified GD is able to handle any\nMahalanobis attack, as well as more general attacks under some conditions.\nUnfortunately, choosing such adapted transformations can be hard for general\nattacks. To the rescue, we design a simple and tractable estimator whose\nadversarial risk is optimal up to within a multiplicative constant of 1.1124 in\nthe population regime, and works for any norm.\n","authors":["Meyer Scetbon","Elvis Dohmatob"],"pdf_url":"https://arxiv.org/pdf/2301.13486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13476v1","updated":"2023-01-31T08:56:40Z","published":"2023-01-31T08:56:40Z","title":"An investigation of challenges encountered when specifying training data\n  and runtime monitors for safety critical ML applications","summary":"  Context and motivation: The development and operation of critical software\nthat contains machine learning (ML) models requires diligence and established\nprocesses. Especially the training data used during the development of ML\nmodels have major influences on the later behaviour of the system. Runtime\nmonitors are used to provide guarantees for that behaviour. Question / problem:\nWe see major uncertainty in how to specify training data and runtime monitoring\nfor critical ML models and by this specifying the final functionality of the\nsystem. In this interview-based study we investigate the underlying challenges\nfor these difficulties. Principal ideas/results: Based on ten interviews with\npractitioners who develop ML models for critical applications in the automotive\nand telecommunication sector, we identified 17 underlying challenges in 6\nchallenge groups that relate to the challenge of specifying training data and\nruntime monitoring. Contribution: The article provides a list of the identified\nunderlying challenges related to the difficulties practitioners experience when\nspecifying training data and runtime monitoring for ML models. Furthermore,\ninterconnection between the challenges were found and based on these\nconnections recommendation proposed to overcome the root causes for the\nchallenges.\n","authors":["Hans-Martin Heyn","Eric Knauss","Iswarya Malleswaran","Shruthi Dinakaran"],"pdf_url":"https://arxiv.org/pdf/2301.13476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02129v2","updated":"2023-01-31T08:55:24Z","published":"2022-10-05T10:23:45Z","title":"Personalized Decentralized Bilevel Optimization over Random Directed\n  Networks","summary":"  Personalization and decentralization are two major lines of studies to\nrealize practical federated learning in the real world. The aim of this study\nis to establish a general and unified approach that can solve these two\nproblems simultaneously. In this work, we first propose a bilevel problem that\ncan adapt to various personalization scenarios by allowing an arbitrary choice\nof two parameters: a client-wise outer-parameter representing heterogeneity,\nand a shared inner-parameter representing homogeneity across client data\ndistributions. We then present an algorithm that can solve this bilevel problem\nin a decentralized manner by estimating gradients of clients' outer-costs with\nrespect to their outer-parameters. We show that the proposed algorithm can be\nextended to handle a random directed network, which is one of the most robust\ndecentralized communication classes. The proposed method achieves\nstate-of-the-art performance on a personalization benchmark across various\ncommunication settings.\n","authors":["Naoyuki Terashita","Satoshi Hara"],"pdf_url":"https://arxiv.org/pdf/2210.02129v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2301.05911v2","updated":"2023-01-31T08:29:22Z","published":"2023-01-14T12:51:10Z","title":"Day-Ahead PV Power Forecasting Based on MSTL-TFT","summary":"  In recent years, renewable energy resources have accounted for an increasing\nshare of electricity energy.Among them, photovoltaic (PV) power generation has\nreceived broad attention due to its economic and environmental\nbenefits.Accurate PV generation forecasts can reduce power dispatch from the\ngrid, thus increasing the supplier's profit in the day-ahead electricity\nmarket.The power system of a PV site is affected by solar radiation, PV plant\nproperties and meteorological factors, resulting in uncertainty in its power\noutput.This study used multiple seasonal-trend decomposition using LOESS (MSTL)\nand temporal fusion transformer (TFT) to perform day-ahead PV prediction on the\ndesert knowledge Australia solar centre (DKASC) dataset.We compare the\ndecomposition algorithms (VMD, EEMD and VMD-EEMD) and prediction models (BP,\nLSTM and XGBoost, etc.) which are commonly used in PV prediction presently.The\nresults show that the MSTL-TFT method is more accurate than the aforementioned\nmethods, which have noticeable improvement compared to other recent day-ahead\nPV predictions on desert knowledge Australia solar centre (DKASC).\n","authors":["Xuetao Jiang","Meiyu Jiang","Qingguo Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.05911v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12254v2","updated":"2023-01-31T08:08:32Z","published":"2023-01-28T17:09:50Z","title":"Inference on the Optimal Assortment in the Multinomial Logit Model","summary":"  Assortment optimization has received active explorations in the past few\ndecades due to its practical importance. Despite the extensive literature\ndealing with optimization algorithms and latent score estimation, uncertainty\nquantification for the optimal assortment still needs to be explored and is of\ngreat practical significance. Instead of estimating and recovering the complete\noptimal offer set, decision-makers may only be interested in testing whether a\ngiven property holds true for the optimal assortment, such as whether they\nshould include several products of interest in the optimal set, or how many\ncategories of products the optimal set should include. This paper proposes a\nnovel inferential framework for testing such properties. We consider the widely\nadopted multinomial logit (MNL) model, where we assume that each customer will\npurchase an item within the offered products with a probability proportional to\nthe underlying preference score associated with the product. We reduce\ninferring a general optimal assortment property to quantifying the uncertainty\nassociated with the sign change point detection of the marginal revenue gaps.\nWe show the asymptotic normality of the marginal revenue gap estimator, and\nconstruct a maximum statistic via the gap estimators to detect the sign change\npoint. By approximating the distribution of the maximum statistic with\nmultiplier bootstrap techniques, we propose a valid testing procedure. We also\nconduct numerical experiments to assess the performance of our method.\n","authors":["Shuting Shen","Xi Chen","Ethan X. Fang","Junwei Lu"],"pdf_url":"https://arxiv.org/pdf/2301.12254v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13465v1","updated":"2023-01-31T08:08:24Z","published":"2023-01-31T08:08:24Z","title":"GDOD: Effective Gradient Descent using Orthogonal Decomposition for\n  Multi-Task Learning","summary":"  Multi-task learning (MTL) aims at solving multiple related tasks\nsimultaneously and has experienced rapid growth in recent years. However, MTL\nmodels often suffer from performance degeneration with negative transfer due to\nlearning several tasks simultaneously. Some related work attributed the source\nof the problem is the conflicting gradients. In this case, it is needed to\nselect useful gradient updates for all tasks carefully. To this end, we propose\na novel optimization approach for MTL, named GDOD, which manipulates gradients\nof each task using an orthogonal basis decomposed from the span of all task\ngradients. GDOD decomposes gradients into task-shared and task-conflict\ncomponents explicitly and adopts a general update rule for avoiding\ninterference across all task gradients. This allows guiding the update\ndirections depending on the task-shared components. Moreover, we prove the\nconvergence of GDOD theoretically under both convex and non-convex assumptions.\nExperiment results on several multi-task datasets not only demonstrate the\nsignificant improvement of GDOD performed to existing MTL models but also prove\nthat our algorithm outperforms state-of-the-art optimization methods in terms\nof AUC and Logloss metrics.\n","authors":["Xin Dong","Ruize Wu","Chao Xiong","Hai Li","Lei Cheng","Yong He","Shiyou Qian","Jian Cao","Linjian Mo"],"pdf_url":"https://arxiv.org/pdf/2301.13465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13464v1","updated":"2023-01-31T08:01:35Z","published":"2023-01-31T08:01:35Z","title":"Training with Mixed-Precision Floating-Point Assignments","summary":"  When training deep neural networks, keeping all tensors in high precision\n(e.g., 32-bit or even 16-bit floats) is often wasteful. However, keeping all\ntensors in low precision (e.g., 8-bit floats) can lead to unacceptable accuracy\nloss. Hence, it is important to use a precision assignment -- a mapping from\nall tensors (arising in training) to precision levels (high or low) -- that\nkeeps most of the tensors in low precision and leads to sufficiently accurate\nmodels. We provide a technique that explores this memory-accuracy tradeoff by\ngenerating precision assignments that (i) use less memory and (ii) lead to more\naccurate models at the same time, compared to the precision assignments\nconsidered by prior work in low-precision floating-point training. Our method\ntypically provides > 2x memory reduction over a baseline precision assignment\nwhile preserving training accuracy, and gives further reductions by trading off\naccuracy. Compared to other baselines which sometimes cause training to\ndiverge, our method provides similar or better memory reduction while avoiding\ndivergence.\n","authors":["Wonyeol Lee","Rahul Sharma","Alex Aiken"],"pdf_url":"https://arxiv.org/pdf/2301.13464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13462v1","updated":"2023-01-31T07:54:52Z","published":"2023-01-31T07:54:52Z","title":"Towards Learned Emulation of Interannual Water Isotopologue Variations\n  in General Circulation Models","summary":"  Simulating abundances of stable water isotopologues, i.e. molecules differing\nin their isotopic composition, within climate models allows for comparisons\nwith proxy data and, thus, for testing hypotheses about past climate and\nvalidating climate models under varying climatic conditions. However, many\nmodels are run without explicitly simulating water isotopologues. We\ninvestigate the possibility to replace the explicit physics-based simulation of\noxygen isotopic composition in precipitation using machine learning methods.\nThese methods estimate isotopic composition at each time step for given fields\nof surface temperature and precipitation amount. We implement convolutional\nneural networks (CNNs) based on the successful UNet architecture and test\nwhether a spherical network architecture outperforms the naive approach of\ntreating Earth's latitude-longitude grid as a flat image. Conducting a case\nstudy on a last millennium run with the iHadCM3 climate model, we find that\nroughly 40\\% of the temporal variance in the isotopic composition is explained\nby the emulations on interannual and monthly timescale, with spatially varying\nemulation quality. A modified version of the standard UNet architecture for\nflat images yields results that are equally good as the predictions by the\nspherical CNN. We test generalization to last millennium runs of other climate\nmodels and find that while the tested deep learning methods yield the best\nresults on iHadCM3 data, the performance drops when predicting on other models\nand is comparable to simple pixel-wise linear regression. An extended choice of\npredictor variables and improving the robustness of learned climate--oxygen\nisotope relationships should be explored in future work.\n","authors":["Jonathan Wider","Jakob Kruse","Nils Weitzel","Janica C. Bühler","Ullrich Köthe","Kira Rehfeld"],"pdf_url":"https://arxiv.org/pdf/2301.13462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13459v1","updated":"2023-01-31T07:49:25Z","published":"2023-01-31T07:49:25Z","title":"Learning Generalized Hybrid Proximity Representation for Image\n  Recognition","summary":"  Recently, deep metric learning techniques received attention, as the learned\ndistance representations are useful to capture the similarity relationship\namong samples and further improve the performance of various of supervised or\nunsupervised learning tasks. We propose a novel supervised metric learning\nmethod that can learn the distance metrics in both geometric and probabilistic\nspace for image recognition. In contrast to the previous metric learning\nmethods which usually focus on learning the distance metrics in Euclidean\nspace, our proposed method is able to learn better distance representation in a\nhybrid approach. To achieve this, we proposed a Generalized Hybrid Metric Loss\n(GHM-Loss) to learn the general hybrid proximity features from the image data\nby controlling the trade-off between geometric proximity and probabilistic\nproximity. To evaluate the effectiveness of our method, we first provide\ntheoretical derivations and proofs of the proposed loss function, then we\nperform extensive experiments on two public datasets to show the advantage of\nour method compared to other state-of-the-art metric learning methods.\n","authors":["Zhiyuan Li","Anca Ralescu"],"pdf_url":"https://arxiv.org/pdf/2301.13459v1.pdf","comment":"The paper has been accepted by the IEEE ICTAI 2022"},{"id":"http://arxiv.org/abs/2301.12623v2","updated":"2023-01-31T07:40:05Z","published":"2023-01-30T02:36:23Z","title":"FedPass: Privacy-Preserving Vertical Federated Deep Learning with\n  Adaptive Obfuscation","summary":"  Vertical federated learning (VFL) allows an active party with labeled feature\nto leverage auxiliary features from the passive parties to improve model\nperformance. Concerns about the private feature and label leakage in both the\ntraining and inference phases of VFL have drawn wide research attention. In\nthis paper, we propose a general privacy-preserving vertical federated deep\nlearning framework called FedPass, which leverages adaptive obfuscation to\nprotect the feature and label simultaneously. Strong privacy-preserving\ncapabilities about private features and labels are theoretically proved (in\nTheorems 1 and 2). Extensive experimental result s with different datasets and\nnetwork architectures also justify the superiority of FedPass against existing\nmethods in light of its near-optimal trade-off between privacy and model\nperformance.\n","authors":["Hanlin Gu","Jiahuan Luo","Yan Kang","Lixin Fan","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2301.12623v2.pdf","comment":"6 figures, 9 tables"},{"id":"http://arxiv.org/abs/2301.12386v2","updated":"2023-01-31T07:37:24Z","published":"2023-01-29T07:45:17Z","title":"Learning to reject meets OOD detection: Are all abstentions created\n  equal?","summary":"  Learning to reject (L2R) and out-of-distribution (OOD) detection are two\nclassical problems, each of which involve detecting certain abnormal samples:\nin L2R, the goal is to detect \"hard\" samples on which to abstain, while in OOD\ndetection, the goal is to detect \"outlier\" samples not drawn from the training\ndistribution. Intriguingly, despite being developed in parallel literatures,\nboth problems share a simple baseline: the maximum softmax probability (MSP)\nscore. However, there is limited understanding of precisely how these problems\nrelate. In this paper, we formally relate these problems, and show how they may\nbe jointly solved. We first show that while MSP is theoretically optimal for\nL2R, it can be theoretically sub-optimal for OOD detection in some important\npractical settings. We then characterize the Bayes-optimal classifier for a\nunified formulation that generalizes both L2R and OOD detection. Based on this,\nwe design a plug-in approach for learning to abstain on both inlier and OOD\nsamples, while constraining the total abstention budget. Experiments on\nbenchmark OOD datasets demonstrate that our approach yields competitive\nclassification and OOD detection performance compared to baselines from both\nliteratures.\n","authors":["Harikrishna Narasimhan","Aditya Krishna Menon","Wittawat Jitkrittum","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2301.12386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10206v2","updated":"2023-01-31T07:22:46Z","published":"2022-06-21T09:02:53Z","title":"Personalized Subgraph Federated Learning","summary":"  Subgraphs of a larger global graph may be distributed across multiple\ndevices, and only locally accessible due to privacy restrictions, although\nthere may be links between subgraphs. Recently proposed subgraph Federated\nLearning (FL) methods deal with those missing links across local subgraphs\nwhile distributively training Graph Neural Networks (GNNs) on them. However,\nthey have overlooked the inevitable heterogeneity between subgraphs comprising\ndifferent communities of a global graph, consequently collapsing the\nincompatible knowledge from local GNN models. To this end, we introduce a new\nsubgraph FL problem, personalized subgraph FL, which focuses on the joint\nimprovement of the interrelated local GNNs rather than learning a single global\nmodel, and propose a novel framework, FEDerated Personalized sUBgraph learning\n(FED-PUB), to tackle it. Since the server cannot access the subgraph in each\nclient, FED-PUB utilizes functional embeddings of the local GNNs using random\ngraphs as inputs to compute similarities between them, and use the similarities\nto perform weighted averaging for server-side aggregation. Further, it learns a\npersonalized sparse mask at each client to select and update only the\nsubgraph-relevant subset of the aggregated parameters. We validate our FED-PUB\nfor its subgraph FL performance on six datasets, considering both\nnon-overlapping and overlapping subgraphs, on which it significantly\noutperforms relevant baselines.\n","authors":["Jinheon Baek","Wonyong Jeong","Jiongdao Jin","Jaehong Yoon","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2206.10206v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08379v3","updated":"2023-01-31T07:14:42Z","published":"2022-12-16T10:12:54Z","title":"GeneFormer: Learned Gene Compression using Transformer-based Context\n  Modeling","summary":"  With the development of gene sequencing technology, an explosive growth of\ngene data has been witnessed. And the storage of gene data has become an\nimportant issue. Traditional gene data compression methods rely on general\nsoftware like G-zip, which fails to utilize the interrelation of nucleotide\nsequence. Recently, many researchers begin to investigate deep learning based\ngene data compression method. In this paper, we propose a transformer-based\ngene compression method named GeneFormer. Specifically, we first introduce a\nmodified transformer structure to fully explore the nucleotide sequence\ndependency. Then, we propose fixed-length parallel grouping to accelerate the\ndecoding speed of our autoregressive model. Experimental results on real-world\ndatasets show that our method saves 29.7% bit rate compared with the\nstate-of-the-art method, and the decoding speed is significantly faster than\nall existing learning-based gene compression methods.\n","authors":["Zhanbei Cui","Yu Liao","Tongda Xu","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2212.08379v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13447v1","updated":"2023-01-31T06:55:19Z","published":"2023-01-31T06:55:19Z","title":"A Data-Driven Modeling and Control Framework for Physics-Based Building\n  Emulators","summary":"  We present a data-driven modeling and control framework for physics-based\nbuilding emulators. Our approach comprises: (a) Offline training of\ndifferentiable surrogate models that speed up model evaluations, provide cheap\ngradients, and have good predictive accuracy for the receding horizon in Model\nPredictive Control (MPC) and (b) Formulating and solving nonlinear building\nHVAC MPC problems. We extensively verify the modeling and control performance\nusing multiple surrogate models and optimization frameworks for different\navailable test cases in the Building Optimization Testing Framework (BOPTEST).\nThe framework is compatible with other modeling techniques and customizable\nwith different control formulations. The modularity makes the approach\nfuture-proof for test cases currently in development for physics-based building\nemulators and provides a path toward prototyping predictive controllers in\nlarge buildings.\n","authors":["Chihyeon Song","Aayushman Sharma","Raman Goyal","Alejandro Brito","Saman Mostafavi"],"pdf_url":"https://arxiv.org/pdf/2301.13447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13446v1","updated":"2023-01-31T06:54:06Z","published":"2023-01-31T06:54:06Z","title":"Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both\n  Worlds in Stochastic and Deterministic Environments","summary":"  We study variance-dependent regret bounds for Markov decision processes\n(MDPs). Algorithms with variance-dependent regret guarantees can automatically\nexploit environments with low variance (e.g., enjoying constant regret on\ndeterministic MDPs). The existing algorithms are either variance-independent or\nsuboptimal. We first propose two new environment norms to characterize the\nfine-grained variance properties of the environment. For model-based methods,\nwe design a variant of the MVP algorithm (Zhang et al., 2021a) and use new\nanalysis techniques show to this algorithm enjoys variance-dependent bounds\nwith respect to our proposed norms. In particular, this bound is simultaneously\nminimax optimal for both stochastic and deterministic MDPs, the first result of\nits kind. We further initiate the study on model-free algorithms with\nvariance-dependent regret bounds by designing a reference-function-based\nalgorithm with a novel capped-doubling reference update schedule. Lastly, we\nalso provide lower bounds to complement our upper bounds.\n","authors":["Runlong Zhou","Zihan Zhang","Simon S. Du"],"pdf_url":"https://arxiv.org/pdf/2301.13446v1.pdf","comment":"43 pages, 1 figure"},{"id":"http://arxiv.org/abs/2301.13445v1","updated":"2023-01-31T06:49:42Z","published":"2023-01-31T06:49:42Z","title":"A Survey of Explainable AI in Deep Visual Modeling: Methods and Metrics","summary":"  Deep visual models have widespread applications in high-stake domains. Hence,\ntheir black-box nature is currently attracting a large interest of the research\ncommunity. We present the first survey in Explainable AI that focuses on the\nmethods and metrics for interpreting deep visual models. Covering the landmark\ncontributions along the state-of-the-art, we not only provide a taxonomic\norganization of the existing techniques, but also excavate a range of\nevaluation metrics and collate them as measures of different properties of\nmodel explanations. Along the insightful discussion on the current trends, we\nalso discuss the challenges and future avenues for this research direction.\n","authors":["Naveed Akhtar"],"pdf_url":"https://arxiv.org/pdf/2301.13445v1.pdf","comment":"Short accessible survey (9pgs)"},{"id":"http://arxiv.org/abs/2301.13443v1","updated":"2023-01-31T06:43:55Z","published":"2023-01-31T06:43:55Z","title":"Retiring $Δ$DP: New Distribution-Level Metrics for Demographic\n  Parity","summary":"  Demographic parity is the most widely recognized measure of group fairness in\nmachine learning, which ensures equal treatment of different demographic\ngroups. Numerous works aim to achieve demographic parity by pursuing the\ncommonly used metric $\\Delta DP$. Unfortunately, in this paper, we reveal that\nthe fairness metric $\\Delta DP$ can not precisely measure the violation of\ndemographic parity, because it inherently has the following drawbacks:\n\\textit{i)} zero-value $\\Delta DP$ does not guarantee zero violation of\ndemographic parity, \\textit{ii)} $\\Delta DP$ values can vary with different\nclassification thresholds. To this end, we propose two new fairness metrics,\n\\textsf{A}rea \\textsf{B}etween \\textsf{P}robability density function\n\\textsf{C}urves (\\textsf{ABPC}) and \\textsf{A}rea \\textsf{B}etween\n\\textsf{C}umulative density function \\textsf{C}urves (\\textsf{ABCC}), to\nprecisely measure the violation of demographic parity in distribution level.\nThe new fairness metrics directly measure the difference between the\ndistributions of the prediction probability for different demographic groups.\nThus our proposed new metrics enjoy: \\textit{i)} zero-value\n\\textsf{ABCC}/\\textsf{ABPC} guarantees zero violation of demographic parity;\n\\textit{ii)} \\textsf{ABCC}/\\textsf{ABPC} guarantees demographic parity while\nthe classification threshold adjusted. We further re-evaluate the existing fair\nmodels with our proposed fairness metrics and observe different fairness\nbehaviors of those models under the new metrics.\n","authors":["Xiaotian Han","Zhimeng Jiang","Hongye Jin","Zirui Liu","Na Zou","Qifan Wang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2301.13443v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2301.13442v1","updated":"2023-01-31T06:38:53Z","published":"2023-01-31T06:38:53Z","title":"Scaling laws for single-agent reinforcement learning","summary":"  Recent work has shown that, in generative modeling, cross-entropy loss\nimproves smoothly with model size and training compute, following a power law\nplus constant scaling law. One challenge in extending these results to\nreinforcement learning is that the main performance objective of interest, mean\nepisode return, need not vary smoothly. To overcome this, we introduce\n*intrinsic performance*, a monotonic function of the return defined as the\nminimum compute required to achieve the given return across a family of models\nof different sizes. We find that, across a range of environments, intrinsic\nperformance scales as a power law in model size and environment interactions.\nConsequently, as in generative modeling, the optimal model size scales as a\npower law in the training compute budget. Furthermore, we study how this\nrelationship varies with the environment and with other properties of the\ntraining setup. In particular, using a toy MNIST-based environment, we show\nthat varying the \"horizon length\" of the task mostly changes the coefficient\nbut not the exponent of this relationship.\n","authors":["Jacob Hilton","Jie Tang","John Schulman"],"pdf_url":"https://arxiv.org/pdf/2301.13442v1.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2301.13441v1","updated":"2023-01-31T06:38:05Z","published":"2023-01-31T06:38:05Z","title":"CMLCompiler: A Unified Compiler for Classical Machine Learning","summary":"  Classical machine learning (CML) occupies nearly half of machine learning\npipelines in production applications. Unfortunately, it fails to utilize the\nstate-of-the-practice devices fully and performs poorly. Without a unified\nframework, the hybrid deployments of deep learning (DL) and CML also suffer\nfrom severe performance and portability issues. This paper presents the design\nof a unified compiler, called CMLCompiler, for CML inference. We propose two\nunified abstractions: operator representations and extended computational\ngraphs. The CMLCompiler framework performs the conversion and graph\noptimization based on two unified abstractions, then outputs an optimized\ncomputational graph to DL compilers or frameworks. We implement CMLCompiler on\nTVM. The evaluation shows CMLCompiler's portability and superior performance.\nIt achieves up to 4.38x speedup on CPU, 3.31x speedup on GPU, and 5.09x speedup\non IoT devices, compared to the state-of-the-art solutions -- scikit-learn,\nintel sklearn, and hummingbird. Our performance of CML and DL mixed pipelines\nachieves up to 3.04x speedup compared with cross-framework implementations.\n","authors":["Xu Wen","Wanling Gao","Anzheng Li","Lei Wang","Zihan Jiang","Zihan Jiang"],"pdf_url":"https://arxiv.org/pdf/2301.13441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.07854v2","updated":"2023-01-31T06:09:08Z","published":"2023-01-19T02:51:47Z","title":"FE-TCM: Filter-Enhanced Transformer Click Model for Web Search","summary":"  Constructing click models and extracting implicit relevance feedback\ninformation from the interaction between users and search engines are very\nimportant to improve the ranking of search results. Using neural network to\nmodel users' click behaviors has become one of the effective methods to\nconstruct click models. In this paper, We use Transformer as the backbone\nnetwork of feature extraction, add filter layer innovatively, and propose a new\nFilter-Enhanced Transformer Click Model (FE-TCM) for web search. Firstly, in\norder to reduce the influence of noise on user behavior data, we use the\nlearnable filters to filter log noise. Secondly, following the examination\nhypothesis, we model the attraction estimator and examination predictor\nrespectively to output the attractiveness scores and examination probabilities.\nA novel transformer model is used to learn the deeper representation among\ndifferent features. Finally, we apply the combination functions to integrate\nattractiveness scores and examination probabilities into the click prediction.\nFrom our experiments on two real-world session datasets, it is proved that\nFE-TCM outperforms the existing click models for the click prediction.\n","authors":["Yingfei Wang","Jianping Liu","Jian Wang","Xiaofeng Wang","Meng Wang","Xintao Chu"],"pdf_url":"https://arxiv.org/pdf/2301.07854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13428v1","updated":"2023-01-31T05:51:05Z","published":"2023-01-31T05:51:05Z","title":"Contrast and Clustering: Learning Neighborhood Pair Representation for\n  Source-free Domain Adaptation","summary":"  Domain adaptation has attracted a great deal of attention in the machine\nlearning community, but it requires access to source data, which often raises\nconcerns about data privacy. We are thus motivated to address these issues and\npropose a simple yet efficient method. This work treats domain adaptation as an\nunsupervised clustering problem and trains the target model without access to\nthe source data. Specifically, we propose a loss function called contrast and\nclustering (CaC), where a positive pair term pulls neighbors belonging to the\nsame class together in the feature space to form clusters, while a negative\npair term pushes samples of different classes apart. In addition, extended\nneighbors are taken into account by querying the nearest neighbor indexes in\nthe memory bank to mine for more valuable negative pairs. Extensive experiments\non three common benchmarks, VisDA, Office-Home and Office-31, demonstrate that\nour method achieves state-of-the-art performance. The code will be made\npublicly available at https://github.com/yukilulu/CaC.\n","authors":["Yuqi Chen","Xiangbin Zhu","Yonggang Li","Yingjian Li","Yuanwang Wei","Haojie Fang"],"pdf_url":"https://arxiv.org/pdf/2301.13428v1.pdf","comment":"conference paper"},{"id":"http://arxiv.org/abs/2301.09044v2","updated":"2023-01-31T05:27:02Z","published":"2023-01-22T03:04:19Z","title":"Learning to Reject with a Fixed Predictor: Application to\n  Decontextualization","summary":"  We study the problem of classification with a reject option for a fixed\npredictor, applicable in natural language processing. We introduce a new\nproblem formulation for this scenario, and an algorithm minimizing a new\nsurrogate loss function. We provide a complete theoretical analysis of the\nsurrogate loss function with a strong $H$-consistency guarantee. For\nevaluation, we choose the decontextualization task, and provide a\nmanually-labelled dataset of $2\\mathord,000$ examples. Our algorithm\nsignificantly outperforms the baselines considered, with a $\\sim\\!\\!25\\%$\nimprovement in coverage when halving the error rate, which is only $\\sim\\!\\! 3\n\\%$ away from the theoretical limit.\n","authors":["Christopher Mohri","Daniel Andor","Eunsol Choi","Michael Collins"],"pdf_url":"https://arxiv.org/pdf/2301.09044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13420v1","updated":"2023-01-31T05:23:53Z","published":"2023-01-31T05:23:53Z","title":"Superhuman Fairness","summary":"  The fairness of machine learning-based decisions has become an increasingly\nimportant focus in the design of supervised machine learning methods. Most\nfairness approaches optimize a specified trade-off between performance\nmeasure(s) (e.g., accuracy, log loss, or AUC) and fairness metric(s) (e.g.,\ndemographic parity, equalized odds). This begs the question: are the right\nperformance-fairness trade-offs being specified? We instead re-cast fair\nmachine learning as an imitation learning task by introducing superhuman\nfairness, which seeks to simultaneously outperform human decisions on multiple\npredictive performance and fairness measures. We demonstrate the benefits of\nthis approach given suboptimal decisions.\n","authors":["Omid Memarrast","Linh Vu","Brian Ziebart"],"pdf_url":"https://arxiv.org/pdf/2301.13420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15430v2","updated":"2023-01-31T23:59:22Z","published":"2022-10-27T14:08:25Z","title":"Student-centric Model of Learning Management System Activity and\n  Academic Performance: from Correlation to Causation","summary":"  In recent years, there is a lot of interest in modeling students' digital\ntraces in Learning Management System (LMS) to understand students' learning\nbehavior patterns including aspects of meta-cognition and self-regulation, with\nthe ultimate goal to turn those insights into actionable information to support\nstudents to improve their learning outcomes. In achieving this goal, however,\nthere are two main issues that need to be addressed given the existing\nliterature. Firstly, most of the current work is course-centered (i.e. models\nare built from data for a specific course) rather than student-centered;\nsecondly, a vast majority of the models are correlational rather than causal.\nThose issues make it challenging to identify the most promising actionable\nfactors for intervention at the student level where most of the campus-wide\nacademic support is designed for. In this paper, we explored a student-centric\nanalytical framework for LMS activity data that can provide not only\ncorrelational but causal insights mined from observational data. We\ndemonstrated this approach using a dataset of 1651 computing major students at\na public university in the US during one semester in the Fall of 2019. This\ndataset includes students' fine-grained LMS interaction logs and administrative\ndata, e.g. demographics and academic performance. In addition, we expand the\nrepository of LMS behavior indicators to include those that can characterize\nthe time-of-the-day of login (e.g. chronotype). Our analysis showed that\nstudent login volume, compared with other login behavior indicators, is both\nstrongly correlated and causally linked to student academic performance,\nespecially among students with low academic performance. We envision that those\ninsights will provide convincing evidence for college student support groups to\nlaunch student-centered and targeted interventions that are effective and\nscalable.\n","authors":["Varun Mandalapu","Lujie Karen Chen","Sushruta Shetty","Zhiyuan Chen","Jiaqi Gong"],"pdf_url":"https://arxiv.org/pdf/2210.15430v2.pdf","comment":"Revisions recommended and submission to new venue"},{"id":"http://arxiv.org/abs/2209.05935v2","updated":"2023-01-31T23:37:31Z","published":"2022-09-13T12:31:33Z","title":"Variational Causal Inference","summary":"  Estimating an individual's potential outcomes under counterfactual treatments\nis a challenging task for traditional causal inference and supervised learning\napproaches when the outcome is high-dimensional (e.g. gene expressions, impulse\nresponses, human faces) and covariates are relatively limited. In this case, to\nconstruct one's outcome under a counterfactual treatment, it is crucial to\nleverage individual information contained in its observed factual outcome on\ntop of the covariates. We propose a deep variational Bayesian framework that\nrigorously integrates two main sources of information for outcome construction\nunder a counterfactual treatment: one source is the individual features\nembedded in the high-dimensional factual outcome; the other source is the\nresponse distribution of similar subjects (subjects with the same covariates)\nthat factually received this treatment of interest.\n","authors":["Yulun Wu","Layne C. Price","Zichen Wang","Vassilis N. Ioannidis","Robert A. Barton","George Karypis"],"pdf_url":"https://arxiv.org/pdf/2209.05935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00141v1","updated":"2023-01-31T23:14:25Z","published":"2023-01-31T23:14:25Z","title":"Revisiting Bellman Errors for Offline Model Selection","summary":"  Offline model selection (OMS), that is, choosing the best policy from a set\nof many policies given only logged data, is crucial for applying offline RL in\nreal-world settings. One idea that has been extensively explored is to select\npolicies based on the mean squared Bellman error (MSBE) of the associated\nQ-functions. However, previous work has struggled to obtain adequate OMS\nperformance with Bellman errors, leading many researchers to abandon the idea.\nThrough theoretical and empirical analyses, we elucidate why previous work has\nseen pessimistic results with Bellman errors and identify conditions under\nwhich OMS algorithms based on Bellman errors will perform well. Moreover, we\ndevelop a new estimator of the MSBE that is more accurate than prior methods\nand obtains impressive OMS performance on diverse discrete control tasks,\nincluding Atari games. We open-source our data and code to enable researchers\nto conduct OMS experiments more easily.\n","authors":["Joshua P. Zitovsky","Daniel de Marchi","Rishabh Agarwal","Michael R. Kosorok"],"pdf_url":"https://arxiv.org/pdf/2302.00141v1.pdf","comment":"Main paper: 9 pages, 4 figures, 2 tables Main + Appendix: 31 pages,\n  11 figures, 2 tables For associated source code, please see\n  https://github.com/jzitovsky/SBV"},{"id":"http://arxiv.org/abs/2302.00138v1","updated":"2023-01-31T22:59:41Z","published":"2023-01-31T22:59:41Z","title":"Generating High Fidelity Synthetic Data via Coreset selection and\n  Entropic Regularization","summary":"  Generative models have the ability to synthesize data points drawn from the\ndata distribution, however, not all generated samples are high quality. In this\npaper, we propose using a combination of coresets selection methods and\n``entropic regularization'' to select the highest fidelity samples. We leverage\nan Energy-Based Model which resembles a variational auto-encoder with an\ninference and generator model for which the latent prior is complexified by an\nenergy-based model. In a semi-supervised learning scenario, we show that\naugmenting the labeled data-set, by adding our selected subset of samples,\nleads to better accuracy improvement rather than using all the synthetic\nsamples.\n","authors":["Omead Pooladzandi","Pasha Khosravi","Erik Nijkamp","Baharan Mirzasoleiman"],"pdf_url":"https://arxiv.org/pdf/2302.00138v1.pdf","comment":"NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research"},{"id":"http://arxiv.org/abs/2302.00136v1","updated":"2023-01-31T22:55:04Z","published":"2023-01-31T22:55:04Z","title":"Learning Topology-Preserving Data Representations","summary":"  We propose a method for learning topology-preserving data representations\n(dimensionality reduction). The method aims to provide topological similarity\nbetween the data manifold and its latent representation via enforcing the\nsimilarity in topological features (clusters, loops, 2D voids, etc.) and their\nlocalization. The core of the method is the minimization of the Representation\nTopology Divergence (RTD) between original high-dimensional data and\nlow-dimensional representation in latent space. RTD minimization provides\ncloseness in topological features with strong theoretical guarantees. We\ndevelop a scheme for RTD differentiation and apply it as a loss term for the\nautoencoder. The proposed method ``RTD-AE'' better preserves the global\nstructure and topology of the data manifold than state-of-the-art competitors\nas measured by linear correlation, triplet distance ranking accuracy, and\nWasserstein distance between persistence barcodes.\n","authors":["Ilya Trofimov","Daniil Cherniavskii","Eduard Tulchinskii","Nikita Balabin","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2302.00136v1.pdf","comment":"11th International Conference on Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2210.01989v2","updated":"2023-01-31T22:54:32Z","published":"2022-10-05T02:37:59Z","title":"WISE: Wavelet Transformation for Boosting Transformers' Long Sequence\n  Learning Ability","summary":"  Transformer and its variants are fundamental neural architectures in deep\nlearning. Recent works show that learning attention in the Fourier space can\nimprove the long sequence learning capability of Transformers. We argue that\nwavelet transform shall be a better choice because it captures both position\nand frequency information with a linear time complexity. Therefore, in this\npaper, we systematically study the synergy between wavelet transform and\nTransformers. Specifically, we focus on a new paradigm WISE, which replaces the\nattention in Transformers by (1) applying forward wavelet transform to project\nthe input sequences to multi-resolution bases, (2) conducting non-linear\ntransformations in the wavelet coefficient space, and (3) reconstructing the\nrepresentation in input space via backward wavelet transform. Extensive\nexperiments on the Long Range Arena benchmark demonstrate that learning\nattention in the wavelet space using either fixed or adaptive wavelets can\nconsistently improve Transformer's performance and also significantly\noutperform Fourier-based methods.\n","authors":["Yufan Zhuang","Zihan Wang","Fangbo Tao","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2210.01989v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.13617v1","updated":"2023-01-31T13:21:15Z","published":"2023-01-31T13:21:15Z","title":"A Closer Look into Recent Video-based Learning Research: A Comprehensive\n  Review of Video Characteristics, Tools, Technologies, and Learning\n  Effectiveness","summary":"  People increasingly use videos on the Web as a source for learning. To\nsupport this way of learning, researchers and developers are continuously\ndeveloping tools, proposing guidelines, analyzing data, and conducting\nexperiments. However, it is still not clear what characteristics a video should\nhave to be an effective learning medium. In this paper, we present a\ncomprehensive review of 257 articles on video-based learning for the period\nfrom 2016 to 2021. One of the aims of the review is to identify the video\ncharacteristics that have been explored by previous work. Based on our\nanalysis, we suggest a taxonomy which organizes the video characteristics and\ncontextual aspects into eight categories: (1) audio features, (2) visual\nfeatures, (3) textual features, (4) instructor behavior, (5) learners\nactivities, (6) interactive features (quizzes, etc.), (7) production style, and\n(8) instructional design. Also, we identify four representative research\ndirections: (1) proposals of tools to support video-based learning, (2) studies\nwith controlled experiments, (3) data analysis studies, and (4) proposals of\ndesign guidelines for learning videos. We find that the most explored\ncharacteristics are textual features followed by visual features, learner\nactivities, and interactive features. Text of transcripts, video frames, and\nimages (figures and illustrations) are most frequently used by tools that\nsupport learning through videos. The learner activity is heavily explored\nthrough log files in data analysis studies, and interactive features have been\nfrequently scrutinized in controlled experiments. We complement our review by\ncontrasting research findings that investigate the impact of video\ncharacteristics on the learning effectiveness, report on tasks and technologies\nused to develop tools that support learning, and summarize trends of design\nguidelines to produce learning videos\n","authors":["Evelyn Navarrete","Andreas Nehring","Sascha Schanze","Ralph Ewerth","Anett Hoppe"],"pdf_url":"https://arxiv.org/pdf/2301.13617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13591v1","updated":"2023-01-31T12:43:54Z","published":"2023-01-31T12:43:54Z","title":"Zero3D: Semantic-Driven Multi-Category 3D Shape Generation","summary":"  Semantic-driven 3D shape generation aims to generate 3D objects conditioned\non text. Previous works face problems with single-category generation,\nlow-frequency 3D details, and requiring a large number of paired datasets for\ntraining. To tackle these challenges, we propose a multi-category conditional\ndiffusion model. Specifically, 1) to alleviate the problem of lack of\nlarge-scale paired data, we bridge the text, 2D image and 3D shape based on the\npre-trained CLIP model, and 2) to obtain the multi-category 3D shape feature,\nwe apply the conditional flow model to generate 3D shape vector conditioned on\nCLIP embedding. 3) to generate multi-category 3D shape, we employ the\nhidden-layer diffusion model conditioned on the multi-category shape vector,\nwhich greatly reduces the training time and memory consumption.\n","authors":["Bo Han","Yitong Liu","Yixuan Shen"],"pdf_url":"https://arxiv.org/pdf/2301.13591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13576v1","updated":"2023-01-31T12:03:59Z","published":"2023-01-31T12:03:59Z","title":"Sport Task: Fine Grained Action Detection and Classification of Table\n  Tennis Strokes from Videos for MediaEval 2022","summary":"  Sports video analysis is a widespread research topic. Its applications are\nvery diverse, like events detection during a match, video summary, or\nfine-grained movement analysis of athletes. As part of the MediaEval 2022\nbenchmarking initiative, this task aims at detecting and classifying subtle\nmovements from sport videos. We focus on recordings of table tennis matches.\nConducted since 2019, this task provides a classification challenge from\nuntrimmed videos recorded under natural conditions with known temporal\nboundaries for each stroke. Since 2021, the task also provides a stroke\ndetection challenge from unannotated, untrimmed videos. This year, the\ntraining, validation, and test sets are enhanced to ensure that all strokes are\nrepresented in each dataset. The dataset is now similar to the one used in [1,\n2]. This research is intended to build tools for coaches and athletes who want\nto further evaluate their sport performances.\n","authors":["Pierre-Etienne Martin","Jordan Calandre","Boris Mansencal","Jenny Benois-Pineau","Renaud Péteri","Laurent Mascarilla","Julien Morlier"],"pdf_url":"https://arxiv.org/pdf/2301.13576v1.pdf","comment":"MediaEval 2022 Workshop, Jan 2023, Bergen, Norway. arXiv admin note:\n  substantial text overlap with arXiv:2112.11384"},{"id":"http://arxiv.org/abs/2301.13523v1","updated":"2023-01-31T10:17:38Z","published":"2023-01-31T10:17:38Z","title":"Towards Better Quality of Experience in\\\\HTTP Adaptive Streaming","summary":"  HTTP Adaptive Streaming (HAS) is nowadays a popular solution for multimedia\ndelivery. The novelty of HAS lies in the possibility of continuously adapting\nthe streaming session to current network conditions, facilitated by Adaptive\nBitrate (ABR) algorithms. Various popular streaming and Video on Demand\nservices such as Netflix, Amazon Prime Video, and Twitch use this method. Given\nthis broad consumer base, ABR algorithms continuously improve to increase user\nsatisfaction. The insights for these improvements are, among others, gathered\nwithin the research area of Quality of Experience (QoE). Within this field,\nvarious researchers have dedicated their works to identifying potential\nimpairments and testing their impact on viewers' QoE. Two frequently discussed\nvisual impairments influencing QoE are stalling events and quality switches. So\nfar, it is commonly assumed that those stalling events have the worst impact on\nQoE. This paper challenged this belief and reviewed this assumption by\ncomparing stalling events with multiple quality and high amplitude quality\nswitches. Two subjective studies were conducted. During the first subjective\nstudy, participants received a monetary incentive, while the second subjective\nstudy was carried out with volunteers. The statistical analysis demonstrated\nthat stalling events do not result in the worst degradation of QoE. These\nfindings suggest that a reevaluation of the effect of stalling events in QoE\nresearch is needed. Therefore, these findings may be used for further research\nand to improve current adaptation strategies in ABR algorithms.\n","authors":["Babak Taraghi","Selina Zoë Haack","Christian Timmerer"],"pdf_url":"https://arxiv.org/pdf/2301.13523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12688v2","updated":"2023-01-31T03:02:25Z","published":"2023-01-30T06:37:35Z","title":"Dynamic Storyboard Generation in an Engine-based Virtual Environment for\n  Video Production","summary":"  Amateurs working on mini-films and short-form videos usually spend lots of\ntime and effort on the multi-round complicated process of setting and adjusting\nscenes, plots, and cameras to deliver satisfying video shots. We present\nVirtual Dynamic Storyboard (VDS) to allow users storyboarding shots in virtual\nenvironments, where the filming staff can easily test the settings of shots\nbefore the actual filming. VDS runs on a \"propose-simulate-discriminate\" mode:\nGiven a formatted story script and a camera script as input, it generates\nseveral character animation and camera movement proposals following predefined\nstory and cinematic rules to allow an off-the-shelf simulation engine to render\nvideos. To pick up the top-quality dynamic storyboard from the candidates, we\nequip it with a shot ranking discriminator based on shot quality criteria\nlearned from professional manual-created data. VDS is comprehensively validated\nvia extensive experiments and user studies, demonstrating its efficiency,\neffectiveness, and great potential in assisting amateur video production.\n","authors":["Anyi Rao","Xuekun Jiang","Yuwei Guo","Linning Xu","Lei Yang","Libiao Jin","Dahua Lin","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2301.12688v2.pdf","comment":"Project page: https://virtualfilmstudio.github.io/"},{"id":"http://arxiv.org/abs/2301.12097v2","updated":"2023-01-31T01:58:48Z","published":"2023-01-28T05:40:28Z","title":"Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal\n  Recommendation","summary":"  User interaction data in recommender systems is a form of dyadic relation\nthat reflects the preferences of users with items. Learning the representations\nof these two discrete sets of objects, users and items, is critical for\nrecommendation. Recent multimodal recommendation models leveraging multimodal\nfeatures (e.g., images and text descriptions) have been demonstrated to be\neffective in improving recommendation accuracy. However, state-of-the-art\nmodels enhance the dyadic relations between users and items by considering\neither user-user or item-item relations, leaving the high-order relations of\nthe other side (i.e., users or items) unexplored. Furthermore, we\nexperimentally reveal that the current multimodality fusion methods in the\nstate-of-the-art models may degrade their recommendation performance. That is,\nwithout tainting the model architectures, these models can achieve even better\nrecommendation accuracy with uni-modal information. On top of the finding, we\npropose a model that enhances the dyadic relations by learning Dual\nRepresentAtions of both users and items via constructing homogeneous Graphs for\nmultimOdal recommeNdation. We name our model as DRAGON. Specifically, DRAGON\nconstructs the user-user graph based on the commonly interacted items and the\nitem-item graph from item multimodal features. It then utilizes graph learning\non both the user-item heterogeneous graph and the homogeneous graphs (user-user\nand item-item) to obtain the dual representations of users and items. To\ncapture information from each modality, DRAGON employs a simple yet effective\nfusion method, attentive concatenation, to derive the representations of users\nand items. Extensive experiments on three public datasets and seven baselines\nshow that DRAGON can outperform the strongest baseline by 22.03% on average.\nVarious ablation studies are conducted on DRAGON to validate its effectiveness.\n","authors":["Hongyu Zhou","Xin Zhou","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2301.12097v2.pdf","comment":"modify the format"}]},"2023-02-01T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.00674v1","updated":"2023-02-01T18:59:36Z","published":"2023-02-01T18:59:36Z","title":"Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary\n  Data","summary":"  Few-shot learning involves learning an effective model from only a few\nlabeled datapoints. The use of a small training set makes it difficult to avoid\noverfitting but also makes few-shot learning applicable to many important\nreal-world settings. In this work, we focus on Few-shot Learning with Auxiliary\nData (FLAD), a training paradigm that assumes access to auxiliary data during\nfew-shot learning in hopes of improving generalization. Introducing auxiliary\ndata during few-shot learning leads to essential design choices where\nhand-designed heuristics can lead to sub-optimal performance. In this work, we\nfocus on automated sampling strategies for FLAD and relate them to the\nexplore-exploit dilemma that is central in multi-armed bandit settings. Based\non this connection we propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and\ncompare them with methods that either explore or exploit, finding that the\ncombination of exploration and exploitation is crucial. Using our proposed\nalgorithms to train T5 yields a 9% absolute improvement over the explicitly\nmulti-task pre-trained T0 model across 11 datasets.\n","authors":["Alon Albalak","Colin Raffel","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00674v1.pdf","comment":"19 pages, 7 figures, code available at\n  https://github.com/alon-albalak/FLAD"},{"id":"http://arxiv.org/abs/2302.00672v1","updated":"2023-02-01T18:59:02Z","published":"2023-02-01T18:59:02Z","title":"'Generative CI' through Collective Response Systems","summary":"  How can many people (who may disagree) come together to answer a question or\nmake a decision? \"Collective response systems\" are a type of generative\ncollective intelligence (CI) facilitation process meant to address this\nchallenge. They enable a form of \"generative voting\", where both the votes, and\nthe choices of what to vote on, are provided by the group. Such systems\novercome the traditional limitations of polling, town halls, standard voting,\nreferendums, etc. The generative CI outputs of collective response systems can\nalso be chained together into iterative \"collective dialogues\", analogously to\nsome kinds of generative AI.\n  Technical advances across domains including recommender systems, language\nmodels, and human-computer interaction have led to the development of\ninnovative and scalable collective response systems. For example, Polis has\nbeen used around the world to support policy-making at different levels of\ngovernment, and Remesh has been used by the UN to understand the challenges and\nneeds of ordinary people across war-torn countries. This paper aims to develop\na shared language by defining the structure, processes, properties, and\nprinciples of such systems.\n  Collective response systems allow non-confrontational exploration of divisive\nissues, help identify common ground, and elicit insights from those closest to\nthe issues. As a result, they can help overcome gridlock around conflict and\ngovernance challenges, increase trust, and develop mandates. Continued progress\ntoward their development and adoption could help revitalize democracies,\nreimagine corporate governance, transform conflict, and govern powerful AI\nsystems -- both as a complement to deeper deliberative democratic processes and\nas an option where deeper processes are not applicable or possible.\n","authors":["Aviv Ovadya"],"pdf_url":"https://arxiv.org/pdf/2302.00672v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2302.00667v1","updated":"2023-02-01T18:53:42Z","published":"2023-02-01T18:53:42Z","title":"Does Vision Accelerate Hierarchical Generalization of Neural Language\n  Learners?","summary":"  Neural language models (LMs) are arguably less data-efficient than humans --\nwhy does this gap occur? In this study, we hypothesize that this gap stems from\nthe learners' accessibility to modalities other than text, specifically,\nvision. We conducted two complementary experiments (using noisy, realistic data\nand a simplified, artificial one) toward the advantage of vision in the\nsyntactic generalization of LMs. Our results showed that vision accelerated a\nproper linguistic generalization in the simplified, artificial setting, but LMs\nstruggled with the noisy, realistic setting. These mixed results indicate\nseveral possibilities, e.g., vision can potentially boost language acquisition,\nbut learners' additional visual/linguistic prior knowledge should be needed to\nrobustly make use of raw images for efficient language acquisition.\n","authors":["Tatsuki Kuribayashi"],"pdf_url":"https://arxiv.org/pdf/2302.00667v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.00636v1","updated":"2023-02-01T17:58:28Z","published":"2023-02-01T17:58:28Z","title":"Are UD Treebanks Getting More Consistent? A Report Card for English UD","summary":"  Recent efforts to consolidate guidelines and treebanks in the Universal\nDependencies project raise the expectation that joint training and dataset\ncomparison is increasingly possible for high-resource languages such as\nEnglish, which have multiple corpora. Focusing on the two largest UD English\ntreebanks, we examine progress in data consolidation and answer several\nquestions: Are UD English treebanks becoming more internally consistent? Are\nthey becoming more like each other and to what extent? Is joint training a good\nidea, and if so, since which UD version? Our results indicate that while\nconsolidation has made progress, joint models may still suffer from\ninconsistencies, which hamper their ability to leverage a larger pool of\ntraining data.\n","authors":["Amir Zeldes","Nathan Schneider"],"pdf_url":"https://arxiv.org/pdf/2302.00636v1.pdf","comment":"Proceedings of the Sixth Workshop on Universal Dependencies (UDW\n  2023)"},{"id":"http://arxiv.org/abs/2302.00618v1","updated":"2023-02-01T17:33:12Z","published":"2023-02-01T17:33:12Z","title":"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for\n  Large Language Models","summary":"  Large language models can perform various reasoning tasks by using\nchain-of-thought prompting, which guides them to find answers through\nstep-by-step demonstrations. However, the quality of the prompts depends on the\ndemonstrations given to the models, and creating many of them by hand is\ncostly. We introduce Synthetic prompting, a method that leverages a few\nhandcrafted examples to prompt the model to generate more examples by itself,\nand selects effective demonstrations to elicit better reasoning. Our method\nalternates between a backward and forward process to generate new examples. The\nbackward process generates a question that match a sampled reasoning chain, so\nthat the question is solvable and clear. The forward process produces a more\ndetailed reasoning chain for the question, improving the quality of the\nexample. We evaluate our method on numerical, symbolic, and algorithmic\nreasoning tasks, and show that it outperforms existing prompting techniques.\n","authors":["Zhihong Shao","Yeyun Gong","Yelong Shen","Minlie Huang","Nan Duan","Weizhu Chen"],"pdf_url":"https://arxiv.org/pdf/2302.00618v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2209.04889v2","updated":"2023-02-01T17:25:52Z","published":"2022-09-11T15:04:11Z","title":"Chain of Explanation: New Prompting Method to Generate Higher Quality\n  Natural Language Explanation for Implicit Hate Speech","summary":"  Recent studies have exploited advanced generative language models to generate\nNatural Language Explanations (NLE) for why a certain text could be hateful. We\npropose the Chain of Explanation (CoE) Prompting method, using the target group\nand retrieved social norms, to generate high-quality NLE for implicit hate\nspeech. Providing accurate target information and high-quality related social\nnorms, we improved the BLUE score from 44.0 to 62.3 for NLE generation. We then\nevaluate the quality of generated NLE from various automatic metrics and human\nannotations of informativeness and clarity scores. The correlation analysis\nbetween auto-metrics and human perceptions reveals insights into how to select\nsuitable automatic metrics for Natural Language Generation tasks. To showcase a\npotential application of our proposed CoE method, we demonstrate the f1-score\nimprovements from 0.635 to 0.655 for the implicit hate speech classification\ntask.\n","authors":["Fan Huang","Haewoon Kwak","Jisun An"],"pdf_url":"https://arxiv.org/pdf/2209.04889v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00609v1","updated":"2023-02-01T17:20:52Z","published":"2023-02-01T17:20:52Z","title":"Zero Shot Transfer of Legal Judgement Prediction as Article-aware\n  Entailment for the European Court of Human Rights","summary":"  In this paper, we cast Legal Judgment Prediction (LJP) from text on European\nCourt of Human Rights cases as an entailment task, where the case outcome is\nclassified from a combined input of case facts and convention articles. This\nconfiguration facilitates the model learning legal reasoning ability in mapping\narticle text to specific fact text. It also provides the opportunity to\nevaluate the model's ability to generalize to zero-shot settings when asked to\nclassify the case outcome with respect to articles not seen during training. We\ndevise zero-shot LJP experiments and apply domain adaptation methods based on\ndomain discriminator and Wasserstein distance. Our results demonstrate that the\nentailment architecture outperforms straightforward fact classification. We\nalso find that domain adaptation methods improve zero-shot transfer\nperformance, with article relatedness and encoder pre-training influencing the\neffect.\n","authors":["Santosh T. Y. S. S","Oana Ichim","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2302.00609v1.pdf","comment":"EACL Findings 2023"},{"id":"http://arxiv.org/abs/2302.00606v1","updated":"2023-02-01T17:13:06Z","published":"2023-02-01T17:13:06Z","title":"The RW3D: A multi-modal panel dataset to understand the psychological\n  impact of the pandemic","summary":"  Besides far-reaching public health consequences, the COVID-19 pandemic had a\nsignificant psychological impact on people around the world. To gain further\ninsight into this matter, we introduce the Real World Worry Waves Dataset\n(RW3D). The dataset combines rich open-ended free-text responses with survey\ndata on emotions, significant life events, and psychological stressors in a\nrepeated-measures design in the UK over three years (2020: n=2441, 2021: n=1716\nand 2022: n=1152). This paper provides background information on the data\ncollection procedure, the recorded variables, participants' demographics, and\nhigher-order psychological and text-based derived variables that emerged from\nthe data. The RW3D is a unique primary data resource that could inspire new\nresearch questions on the psychological impact of the pandemic, especially\nthose that connect modalities (here: text data, psychological survey variables\nand demographics) over time.\n","authors":["Isabelle van der Vegt","Bennett Kleinberg"],"pdf_url":"https://arxiv.org/pdf/2302.00606v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2302.00560v1","updated":"2023-02-01T16:26:32Z","published":"2023-02-01T16:26:32Z","title":"Co-Writing with Opinionated Language Models Affects Users' Views","summary":"  If large language models like GPT-3 preferably produce a particular point of\nview, they may influence people's opinions on an unknown scale. This study\ninvestigates whether a language-model-powered writing assistant that generates\nsome opinions more often than others impacts what users write - and what they\nthink. In an online experiment, we asked participants (N=1,506) to write a post\ndiscussing whether social media is good for society. Treatment group\nparticipants used a language-model-powered writing assistant configured to\nargue that social media is good or bad for society. Participants then completed\na social media attitude survey, and independent judges (N=500) evaluated the\nopinions expressed in their writing. Using the opinionated language model\naffected the opinions expressed in participants' writing and shifted their\nopinions in the subsequent attitude survey. We discuss the wider implications\nof our results and argue that the opinions built into AI language technologies\nneed to be monitored and engineered more carefully.\n","authors":["Maurice Jakesch","Advait Bhat","Daniel Buschek","Lior Zalmanson","Mor Naaman"],"pdf_url":"https://arxiv.org/pdf/2302.00560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00509v1","updated":"2023-02-01T15:28:55Z","published":"2023-02-01T15:28:55Z","title":"Exploring Semantic Perturbations on Grover","summary":"  With news and information being as easy to access as they currently are, it\nis more important than ever to ensure that people are not mislead by what they\nread. Recently, the rise of neural fake news (AI-generated fake news) and its\ndemonstrated effectiveness at fooling humans has prompted the development of\nmodels to detect it. One such model is the Grover model, which can both detect\nneural fake news to prevent it, and generate it to demonstrate how a model\ncould be misused to fool human readers. In this work we explore the Grover\nmodel's fake news detection capabilities by performing targeted attacks through\nperturbations on input news articles. Through this we test Grover's resilience\nto these adversarial attacks and expose some potential vulnerabilities which\nshould be addressed in further iterations to ensure it can detect all types of\nfake news accurately.\n","authors":["Pranav Kulkarni","Ziqing Ji","Yan Xu","Marko Neskovic","Kevin Nolan"],"pdf_url":"https://arxiv.org/pdf/2302.00509v1.pdf","comment":"15 pages, 12 figures, 1 table, capstone research in machine learning"},{"id":"http://arxiv.org/abs/2302.00493v1","updated":"2023-02-01T15:04:04Z","published":"2023-02-01T15:04:04Z","title":"You Are What You Talk About: Inducing Evaluative Topics for Personality\n  Analysis","summary":"  Expressing attitude or stance toward entities and concepts is an integral\npart of human behavior and personality. Recently, evaluative language data has\nbecome more accessible with social media's rapid growth, enabling large-scale\nopinion analysis. However, surprisingly little research examines the\nrelationship between personality and evaluative language. To bridge this gap,\nwe introduce the notion of evaluative topics, obtained by applying topic models\nto pre-filtered evaluative text from social media. We then link evaluative\ntopics to individual text authors to build their evaluative profiles. We apply\nevaluative profiling to Reddit comments labeled with personality scores and\nconduct an exploratory study on the relationship between evaluative topics and\nBig Five personality facets, aiming for a more interpretable, facet-level\nanalysis. Finally, we validate our approach by observing correlations\nconsistent with prior research in personality psychology.\n","authors":["Josip Jukić","Iva Vukojević","Jan Šnajder"],"pdf_url":"https://arxiv.org/pdf/2302.00493v1.pdf","comment":"Accepted at EMNLP 2022 (Findings), NLP+CSS"},{"id":"http://arxiv.org/abs/2302.00456v1","updated":"2023-02-01T13:59:47Z","published":"2023-02-01T13:59:47Z","title":"Feed-Forward Blocks Control Contextualization in Masked Language Models","summary":"  Understanding the inner workings of neural network models is a crucial step\nfor rationalizing their output and refining their architecture.\nTransformer-based models are the core of recent natural language processing and\nhave been analyzed typically with attention patterns as their epoch-making\nfeature is contextualizing surrounding input words via attention mechanisms. In\nthis study, we analyze their inner contextualization by considering all the\ncomponents, including the feed-forward block (i.e., a feed-forward layer and\nits surrounding residual and normalization layers) as well as the attention.\nOur experiments with masked language models show that each of the previously\noverlooked components did modify the degree of the contextualization in case of\nprocessing special word-word pairs (e.g., consisting of named entities).\nFurthermore, we find that some components cancel each other's effects. Our\nresults could update the typical view about each component's roles (e.g.,\nattention performs contextualization, and the other components serve different\nroles) in the Transformer layer.\n","authors":["Goro Kobayashi","Tatsuki Kuribayashi","Sho Yokoi","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2302.00456v1.pdf","comment":"13 pages, 15 figures"},{"id":"http://arxiv.org/abs/2302.00455v1","updated":"2023-02-01T13:59:45Z","published":"2023-02-01T13:59:45Z","title":"HunSum-1: an Abstractive Summarization Dataset for Hungarian","summary":"  We introduce HunSum-1: a dataset for Hungarian abstractive summarization,\nconsisting of 1.14M news articles. The dataset is built by collecting, cleaning\nand deduplicating data from 9 major Hungarian news sites through CommonCrawl.\nUsing this dataset, we build abstractive summarizer models based on huBERT and\nmT5. We demonstrate the value of the created dataset by performing a\nquantitative and qualitative analysis on the models' results. The HunSum-1\ndataset, all models used in our experiments and our code are available open\nsource.\n","authors":["Botond Barta","Dorina Lakatos","Attila Nagy","Milán Konor Nyist","Judit Ács"],"pdf_url":"https://arxiv.org/pdf/2302.00455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00444v1","updated":"2023-02-01T13:40:19Z","published":"2023-02-01T13:40:19Z","title":"Improved Knowledge Distillation for Pre-trained Language Models via\n  Knowledge Selection","summary":"  Knowledge distillation addresses the problem of transferring knowledge from a\nteacher model to a student model. In this process, we typically have multiple\ntypes of knowledge extracted from the teacher model. The problem is to make\nfull use of them to train the student model. Our preliminary study shows that:\n(1) not all of the knowledge is necessary for learning a good student model,\nand (2) knowledge distillation can benefit from certain knowledge at different\ntraining steps. In response to these, we propose an actor-critic approach to\nselecting appropriate knowledge to transfer during the process of knowledge\ndistillation. In addition, we offer a refinement of the training algorithm to\nease the computational burden. Experimental results on the GLUE datasets show\nthat our method outperforms several strong knowledge distillation baselines\nsignificantly.\n","authors":["Chenglong Wang","Yi Lu","Yongyu Mu","Yimin Hu","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.00444v1.pdf","comment":"accepted by EMNLP (Findings) 2022"},{"id":"http://arxiv.org/abs/2302.00412v1","updated":"2023-02-01T12:53:31Z","published":"2023-02-01T12:53:31Z","title":"KNNs of Semantic Encodings for Rating Prediction","summary":"  This paper explores a novel application of textual semantic similarity to\nuser-preference representation for rating prediction. The approach represents a\nuser's preferences as a graph of textual snippets from review text, where the\nedges are defined by semantic similarity. This textual, memory-based approach\nto rating prediction enables review-based explanations for recommendations. The\nmethod is evaluated quantitatively, highlighting that leveraging text in this\nway outperforms both strong memory-based and model-based collaborative\nfiltering baselines.\n","authors":["Léo Laugier","Thomas Bonald","Lucas Dixon","Raghuram Vadapalli"],"pdf_url":"https://arxiv.org/pdf/2302.00412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00407v1","updated":"2023-02-01T12:47:09Z","published":"2023-02-01T12:47:09Z","title":"On the Role of Morphological Information for Contextual Lemmatization","summary":"  Lemmatization is a Natural Language Processing (NLP) task which consists of\nproducing, from a given inflected word, its canonical form or lemma.\nLemmatization is one of the basic tasks that facilitate downstream NLP\napplications, and is of particular importance for high-inflected languages.\nGiven that the process to obtain a lemma from an inflected word can be\nexplained by looking at its morphosyntactic category, including fine-grained\nmorphosyntactic information to train contextual lemmatizers has become common\npractice, without analyzing whether that is the optimum in terms of downstream\nperformance. Thus, in this paper we empirically investigate the role of\nmorphological information to develop contextual lemmatizers in six languages\nwithin a varied spectrum of morphological complexity: Basque, Turkish, Russian,\nCzech, Spanish and English. Furthermore, and unlike the vast majority of\nprevious work, we also evaluate lemmatizers in out-of-domain settings, which\nconstitutes, after all, their most common application use. The results of our\nstudy are rather surprising: (i) providing lemmatizers with fine-grained\nmorphological features during training is not that beneficial, not even for\nagglutinative languages; (ii) in fact, modern contextual word representations\nseem to implicitly encode enough morphological information to obtain good\ncontextual lemmatizers without seeing any explicit morphological signal; (iii)\nthe best lemmatizers out-of-domain are those using simple UPOS tags or those\ntrained without morphology; (iv) current evaluation practices for lemmatization\nare not adequate to clearly discriminate between models.\n","authors":["Olia Toporkov","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2302.00407v1.pdf","comment":"24 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2301.11353v2","updated":"2023-02-01T12:44:44Z","published":"2023-01-25T07:44:46Z","title":"Using novel data and ensemble models to improve automated labeling of\n  Sustainable Development Goals","summary":"  A number of labeling systems based on text have been proposed to help monitor\nwork on the United Nations (UN) Sustainable Development Goals (SDGs). Here, we\npresent a systematic comparison of systems using a variety of text sources and\nshow that systems differ considerably in their specificity (i.e., true-positive\nrate) and sensitivity (i.e., true-negative rate), have systematic biases (e.g.,\nare more sensitive to specific SDGs relative to others), and are susceptible to\nthe type and amount of text analyzed. We then show that an ensemble model that\npools labeling systems alleviates some of these limitations, exceeding the\nlabeling performance of all currently available systems. We conclude that\nresearchers and policymakers should care about the choice of labeling system\nand that ensemble methods should be favored when drawing conclusions about the\nabsolute and relative prevalence of work on the SDGs based on automated\nmethods.\n","authors":["Dirk U. Wulff","Dominik S. Meier","Rui Mata"],"pdf_url":"https://arxiv.org/pdf/2301.11353v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00402v1","updated":"2023-02-01T12:40:03Z","published":"2023-02-01T12:40:03Z","title":"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image\n  and Video","summary":"  Recent years have witnessed a big convergence of language, vision, and\nmulti-modal pretraining. In this work, we present mPLUG-2, a new unified\nparadigm with modularized design for multi-modal pretraining, which can benefit\nfrom modality collaboration while addressing the problem of modality\nentanglement. In contrast to predominant paradigms of solely relying on\nsequence-to-sequence generation or encoder-based instance discrimination,\nmPLUG-2 introduces a multi-module composition network by sharing common\nuniversal modules for modality collaboration and disentangling different\nmodality modules to deal with modality entanglement. It is flexible to select\ndifferent modules for different understanding and generation tasks across all\nmodalities including text, image, and video. Empirical study shows that mPLUG-2\nachieves state-of-the-art or competitive results on a broad range of over 30\ndownstream tasks, spanning multi-modal tasks of image-text and video-text\nunderstanding and generation, and uni-modal tasks of text-only, image-only, and\nvideo-only understanding. Notably, mPLUG-2 shows new state-of-the-art results\nof 48.0 top-1 accuracy and 80.3 CIDEr on the challenging MSRVTT video QA and\nvideo caption tasks with a far smaller model size and data scale. It also\ndemonstrates strong zero-shot transferability on vision-language and\nvideo-language tasks. Code and models will be released in\nhttps://github.com/alibaba/AliceMind.\n","authors":["Haiyang Xu","Qinghao Ye","Ming Yan","Yaya Shi","Jiabo Ye","Yuanhong Xu","Chenliang Li","Bin Bi","Qi Qian","Wei Wang","Guohai Xu","Ji Zhang","Songfang Huang","Fei Huang","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00378v1","updated":"2023-02-01T11:20:18Z","published":"2023-02-01T11:20:18Z","title":"An Empirical Study on the Transferability of Transformer Modules in\n  Parameter-Efficient Fine-Tuning","summary":"  Parameter-efficient fine-tuning approaches have recently garnered a lot of\nattention. Having considerably lower number of trainable weights, these methods\ncan bring about scalability and computational effectiveness. In this paper, we\nlook for optimal sub-networks and investigate the capability of different\ntransformer modules in transferring knowledge from a pre-trained model to a\ndownstream task. Our empirical results suggest that every transformer module in\nBERT can act as a winning ticket: fine-tuning each specific module while\nkeeping the rest of the network frozen can lead to comparable performance to\nthe full fine-tuning. Among different modules, LayerNorms exhibit the best\ncapacity for knowledge transfer with limited trainable weights, to the extent\nthat, with only 0.003% of all parameters in the layer-wise analysis, they show\nacceptable performance on various target tasks. On the reasons behind their\neffectiveness, we argue that their notable performance could be attributed to\ntheir high-magnitude weights compared to that of the other modules in the\npre-trained BERT.\n","authors":["Mohammad AkbarTajari","Sara Rajaee","Mohammad Taher Pilehvar"],"pdf_url":"https://arxiv.org/pdf/2302.00378v1.pdf","comment":"Accepted at EMNLP 2022 (main conference)"},{"id":"http://arxiv.org/abs/2302.00340v1","updated":"2023-02-01T09:52:36Z","published":"2023-02-01T09:52:36Z","title":"Attention Link: An Efficient Attention-Based Low Resource Machine\n  Translation Architecture","summary":"  Transformers have achieved great success in machine translation, but\ntransformer-based NMT models often require millions of bilingual parallel\ncorpus for training. In this paper, we propose a novel architecture named as\nattention link (AL) to help improve transformer models' performance, especially\nin low training resources. We theoretically demonstrate the superiority of our\nattention link architecture in low training resources. Besides, we have done a\nlarge number of experiments, including en-de, de-en, en-fr, en-it, it-en, en-ro\ntranslation tasks on the IWSLT14 dataset as well as real low resources scene on\nbn-gu and gu-ta translation tasks on the CVIT PIB dataset. All the experiment\nresults show our attention link is powerful and can lead to a significant\nimprovement. In addition, we achieve a 37.9 BLEU score, a new sota, on the\nIWSLT14 de-en task by combining our attention link and other advanced methods.\n","authors":["Zeping Min"],"pdf_url":"https://arxiv.org/pdf/2302.00340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00326v1","updated":"2023-02-01T09:11:05Z","published":"2023-02-01T09:11:05Z","title":"Evaluating TCFD Reporting: A New Application of Zero-Shot Analysis to\n  Climate-Related Financial Disclosures","summary":"  We examine climate-related disclosures in a large sample of reports published\nby banks that officially endorsed the recommendations of the Task Force for\nClimate-related Financial Disclosures (TCFD). In doing so, we introduce a new\napplication of the zero-shot text classification. By developing a set of\nfine-grained TCFD labels, we show that zero-shot analysis is a useful tool for\nclassifying climate-related disclosures without further model training.\nOverall, our findings indicate that corporate climate-related disclosures grew\ndynamically after the launch of the TCFD recommendations. However, there are\nmarked differences in the extent of reporting by recommended disclosure topic,\nsuggesting that some recommendations have not yet been fully met. Our findings\nyield important conclusions for the design of climate-related disclosure\nframeworks.\n","authors":["Alix Auzepy","Elena Tönjes","David Lenz","Christoph Funk"],"pdf_url":"https://arxiv.org/pdf/2302.00326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00321v1","updated":"2023-02-01T08:55:08Z","published":"2023-02-01T08:55:08Z","title":"An Evaluation of Persian-English Machine Translation Datasets with\n  Transformers","summary":"  Nowadays, many researchers are focusing their attention on the subject of\nmachine translation (MT). However, Persian machine translation has remained\nunexplored despite a vast amount of research being conducted in languages with\nhigh resources, such as English. Moreover, while a substantial amount of\nresearch has been undertaken in statistical machine translation for some\ndatasets in Persian, there is currently no standard baseline for\ntransformer-based text2text models on each corpus. This study collected and\nanalysed the most popular and valuable parallel corpora, which were used for\nPersian-English translation. Furthermore, we fine-tuned and evaluated two\nstate-of-the-art attention-based seq2seq models on each dataset separately (48\nresults). We hope this paper will assist researchers in comparing their Persian\nto English and vice versa machine translation results to a standard baseline.\n","authors":["Amir Sartipi","Meghdad Dehghan","Afsaneh Fatemi"],"pdf_url":"https://arxiv.org/pdf/2302.00321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.16230v3","updated":"2023-02-01T08:42:01Z","published":"2022-03-30T12:06:32Z","title":"Automatic generation of semantic corpora for improving intent estimation\n  of taxonomy-driven search engines","summary":"  With the increasing demand of intelligent systems capable of operating in\ndifferent user contexts (e.g. users on the move) the correct interpretation of\nthe user-need by such systems has become crucial to give a consistent answer to\nthe user query. The most effective techniques which are used to address such\ntask are in the fields of natural language processing and semantic expansion of\nterms. Such systems are aimed at estimating the actual meaning of input\nqueries, addressing the concepts of the words which are expressed within the\nuser questions. The aim of this paper is to demonstrate which semantic relation\nimpacts the most in semantic expansion-based retrieval systems and to identify\nthe best tradeoff between accuracy and noise introduction when combining such\nrelations. The evaluations are made building a simple natural language\nprocessing system capable of querying any taxonomy-driven domain, making use of\nthe combination of different semantic expansions as knowledge resources. The\nproposed evaluation employs a wide and varied taxonomy as a use-case,\nexploiting its labels as basis for the expansions. To build the knowledge\nresources several corpora have been produced and integrated as gazetteers into\nthe NLP infrastructure with the purpose of estimating the pseudo-queries\ncorresponding to the taxonomy labels, considered as the possible intents.\n","authors":["Lorenzo Massai"],"pdf_url":"https://arxiv.org/pdf/2203.16230v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2205.05989v3","updated":"2023-02-01T07:25:10Z","published":"2022-05-12T09:52:59Z","title":"Towards Answering Open-ended Ethical Quandary Questions","summary":"  Considerable advancements have been made in various NLP tasks based on the\nimpressive power of large language models (LLMs) and many NLP applications are\ndeployed in our daily lives. In this work, we challenge the capability of LLMs\nwith the new task of Ethical Quandary Generative Question Answering. Ethical\nquandary questions are more challenging to address because multiple conflicting\nanswers may exist to a single quandary. We explore the current capability of\nLLMs in providing an answer with a deliberative exchange of different\nperspectives to an ethical quandary, in the approach of Socratic philosophy,\ninstead of providing a closed answer like an oracle. We propose a model that\nsearches for different ethical principles applicable to the ethical quandary\nand generates an answer conditioned on the chosen principles through\nprompt-based few-shot learning. We also discuss the remaining challenges and\nethical issues involved in this task and suggest the direction toward\ndeveloping responsible NLP systems by incorporating human values explicitly.\n","authors":["Yejin Bang","Nayeon Lee","Tiezheng Yu","Leila Khalatbari","Yan Xu","Samuel Cahyawijaya","Dan Su","Bryan Wilie","Romain Barraud","Elham J. Barezi","Andrea Madotto","Hayden Kee","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2205.05989v3.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2301.11004v4","updated":"2023-02-01T06:45:46Z","published":"2023-01-26T09:26:01Z","title":"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental\n  Health on Social Media","summary":"  Interactions among humans on social media often convey intentions behind\ntheir actions, yielding a psychological language resource for Mental Health\nAnalysis (MHA) of online users. The success of Computational Intelligence\nTechniques (CIT) for inferring mental illness from such social media resources\npoints to NLP as a lens for causal analysis and perception mining. However, we\nargue that more consequential and explainable research is required for optimal\nimpact on clinical psychology practice and personalized mental healthcare. To\nbridge this gap, we posit two significant dimensions: (1) Causal analysis to\nillustrate a cause and effect relationship in the user generated text; (2)\nPerception mining to infer psychological perspectives of social effects on\nonline users intentions. Within the scope of Natural Language Processing (NLP),\nwe further explore critical areas of inquiry associated with these two\ndimensions, specifically through recent advancements in discourse analysis.\nThis position paper guides the community to explore solutions in this space and\nadvance the state of practice in developing conversational agents for inferring\nmental health from social media. We advocate for a more explainable approach\ntoward modeling computational psychology problems through the lens of language\nas we observe an increased number of research contributions in dataset and\nproblem formulation for causal relation extraction and perception enhancements\nwhile inferring mental states.\n","authors":["Muskan Garg","Chandni Saxena","Usman Naseem","Bonnie J Dorr"],"pdf_url":"https://arxiv.org/pdf/2301.11004v4.pdf","comment":"Will revise work"},{"id":"http://arxiv.org/abs/2302.00239v1","updated":"2023-02-01T04:34:48Z","published":"2023-02-01T04:34:48Z","title":"Filtering Context Mitigates Scarcity and Selection Bias in Political\n  Ideology Prediction","summary":"  We propose a novel supervised learning approach for political ideology\nprediction (PIP) that is capable of predicting out-of-distribution inputs. This\nproblem is motivated by the fact that manual data-labeling is expensive, while\nself-reported labels are often scarce and exhibit significant selection bias.\nWe propose a novel statistical model that decomposes the document embeddings\ninto a linear superposition of two vectors; a latent neutral \\emph{context}\nvector independent of ideology, and a latent \\emph{position} vector aligned\nwith ideology. We train an end-to-end model that has intermediate contextual\nand positional vectors as outputs. At deployment time, our model predicts\nlabels for input documents by exclusively leveraging the predicted positional\nvectors. On two benchmark datasets we show that our model is capable of\noutputting predictions even when trained with as little as 5\\% biased data, and\nis significantly more accurate than the state-of-the-art. Through\ncrowd-sourcing we validate the neutrality of contextual vectors, and show that\ncontext filtering results in ideological concentration, allowing for prediction\non out-of-distribution examples.\n","authors":["Chen Chen","Dylan Walker","Venkatesh Saligrama"],"pdf_url":"https://arxiv.org/pdf/2302.00239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00250v2","updated":"2023-02-01T03:46:32Z","published":"2022-11-01T03:37:30Z","title":"FADO: Feedback-Aware Double COntrolling Network for Emotional Support\n  Conversation","summary":"  Emotional Support Conversation (ESConv) aims to reduce help-seekers'emotional\ndistress with the supportive strategy and response. It is essential for the\nsupporter to select an appropriate strategy with the feedback of the\nhelp-seeker (e.g., emotion change during dialog turns, etc) in ESConv. However,\nprevious methods mainly focus on the dialog history to select the strategy and\nignore the help-seeker's feedback, leading to the wrong and user-irrelevant\nstrategy prediction. In addition, these approaches only model the\ncontext-to-strategy flow and pay less attention to the strategy-to-context flow\nthat can focus on the strategy-related context for generating the\nstrategy-constrain response. In this paper, we propose a Feedback-Aware Double\nCOntrolling Network (FADO) to make a strategy schedule and generate the\nsupportive response. The core module in FADO consists of a dual-level feedback\nstrategy selector and a double control reader. Specifically, the dual-level\nfeedback strategy selector leverages the turn-level and conversation-level\nfeedback to encourage or penalize strategies. The double control reader\nconstructs the novel strategy-to-context flow for generating the\nstrategy-constrain response. Furthermore, a strategy dictionary is designed to\nenrich the semantic information of the strategy and improve the quality of\nstrategy-constrain response. Experimental results on ESConv show that the\nproposed FADO has achieved the state-of-the-art performance in terms of both\nstrategy selection and response generation. Our code is available at\nhttps://github/after/reviewing.\n","authors":["Wei Peng","Ziyuan Qin","Yue Hu","Yuqiang Xie","Yunpeng Li"],"pdf_url":"https://arxiv.org/pdf/2211.00250v2.pdf","comment":"Accepted on Knowl. Based Syst. (SCI I)"},{"id":"http://arxiv.org/abs/2302.00200v1","updated":"2023-02-01T03:05:14Z","published":"2023-02-01T03:05:14Z","title":"A Transaction Represented with Weighted Finite-State Transducers","summary":"  Not all contracts are good, but all good contracts can be expressed as a\nfinite-state transition system (\"State-Transition Contracts\"). Contracts that\ncan be represented as State-Transition Contracts discretize fat-tailed risk to\nforeseeable, managed risk, define the boundary of relevant events governed by\nthe relationship, and eliminate the potential of inconsistent contractual\nprovisions. Additionally, State-Transition Contracts reap the substantial\nbenefit of being able to be analyzed under the rules governing the science of\nthe theory of computation. Simple State-Transition Contracts can be represented\nas discrete finite automata; more complicated State-Transition Contracts, such\nas those that have downstream effects on other agreements or complicated\npathways of performance, benefit from representation as weighted finite-state\ntransducers, with weights assigned as costs, penalties, or probabilities of\ntransitions. This research paper (the \"Research\" or \"Paper\") presents a complex\nlegal transaction represented as weighted finite-state transducers.\nFurthermore, we show that the mathematics/algorithms permitted by the algebraic\nstructure of weighted finite-state transducers provides actionable, legal\ninsight into the transaction.\n","authors":["J. Nathaniel Holmes","Homayoon Beigi"],"pdf_url":"https://arxiv.org/pdf/2302.00200v1.pdf","comment":"2 figures, 3 tables, 2 appendices, Recognition Technologies, Inc.\n  Technical Report"},{"id":"http://arxiv.org/abs/2302.00189v1","updated":"2023-02-01T02:44:28Z","published":"2023-02-01T02:44:28Z","title":"Detecting Lexical Borrowings from Dominant Languages in Multilingual\n  Wordlists","summary":"  Language contact is a pervasive phenomenon reflected in the borrowing of\nwords from donor to recipient languages. Most computational approaches to\nborrowing detection treat all languages under study as equally important, even\nthough dominant languages have a stronger impact on heritage languages than\nvice versa. We test new methods for lexical borrowing detection in contact\nsituations where dominant languages play an important role, applying two\nclassical sequence comparison methods and one machine learning method to a\nsample of seven Latin American languages which have all borrowed extensively\nfrom Spanish. All methods perform well, with the supervised machine learning\nsystem outperforming the classical systems. A review of detection errors shows\nthat borrowing detection could be substantially improved by taking into account\ndonor words with divergent meanings from recipient words.\n","authors":["John E. Miller","Johann-Mattis List"],"pdf_url":"https://arxiv.org/pdf/2302.00189v1.pdf","comment":"To appear at The 17th Conference of the European Chapter of the\n  Association for Computational Linguistics. See\n  https://www.aclweb.org/portal/content/17th-conference-european-chapter-association-computational-linguistics"},{"id":"http://arxiv.org/abs/2302.00178v1","updated":"2023-02-01T01:51:45Z","published":"2023-02-01T01:51:45Z","title":"Program Generation from Diverse Video Demonstrations","summary":"  The ability to use inductive reasoning to extract general rules from multiple\nobservations is a vital indicator of intelligence. As humans, we use this\nability to not only interpret the world around us, but also to predict the\noutcomes of the various interactions we experience. Generalising over multiple\nobservations is a task that has historically presented difficulties for\nmachines to grasp, especially when requiring computer vision. In this paper, we\npropose a model that can extract general rules from video demonstrations by\nsimultaneously performing summarisation and translation. Our approach differs\nfrom prior works by framing the problem as a multi-sequence-to-sequence task,\nwherein summarisation is learnt by the model. This allows our model to utilise\nedge cases that would otherwise be suppressed or discarded by traditional\nsummarisation techniques. Additionally, we show that our approach can handle\nnoisy specifications without the need for additional filtering methods. We\nevaluate our model by synthesising programs from video demonstrations in the\nVizdoom environment achieving state-of-the-art results with a relative increase\nof 11.75% program accuracy on prior works\n","authors":["Anthony Manchin","Jamie Sherrah","Qi Wu","Anton van den Hengel"],"pdf_url":"https://arxiv.org/pdf/2302.00178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12652v2","updated":"2023-02-01T00:15:18Z","published":"2023-01-30T04:18:09Z","title":"REPLUG: Retrieval-Augmented Black-Box Language Models","summary":"  We introduce REPLUG, a retrieval-augmented language modeling framework that\ntreats the language model (LM) as a black box and augments it with a tuneable\nretrieval model. Unlike prior retrieval-augmented LMs that train language\nmodels with special cross attention mechanisms to encode the retrieved text,\nREPLUG simply prepends retrieved documents to the input for the frozen\nblack-box LM. This simple design can be easily applied to any existing\nretrieval and language models. Furthermore, we show that the LM can be used to\nsupervise the retrieval model, which can then find documents that help the LM\nmake better predictions. Our experiments demonstrate that REPLUG with the tuned\nretriever significantly improves the performance of GPT-3 (175B) on language\nmodeling by 6.3%, as well as the performance of Codex on five-shot MMLU by\n5.1%.\n","authors":["Weijia Shi","Sewon Min","Michihiro Yasunaga","Minjoon Seo","Rich James","Mike Lewis","Luke Zettlemoyer","Wen-tau Yih"],"pdf_url":"https://arxiv.org/pdf/2301.12652v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00796v1","updated":"2023-02-01T23:03:22Z","published":"2023-02-01T23:03:22Z","title":"Unsupervised Entity Alignment for Temporal Knowledge Graphs","summary":"  Entity alignment (EA) is a fundamental data integration task that identifies\nequivalent entities between different knowledge graphs (KGs). Temporal\nKnowledge graphs (TKGs) extend traditional knowledge graphs by introducing\ntimestamps, which have received increasing attention. State-of-the-art\ntime-aware EA studies have suggested that the temporal information of TKGs\nfacilitates the performance of EA. However, existing studies have not\nthoroughly exploited the advantages of temporal information in TKGs. Also, they\nperform EA by pre-aligning entity pairs, which can be labor-intensive and thus\ninefficient.\n  In this paper, we present DualMatch which effectively fuses the relational\nand temporal information for EA. DualMatch transfers EA on TKGs into a weighted\ngraph matching problem. More specifically, DualMatch is equipped with an\nunsupervised method, which achieves EA without necessitating seed alignment.\nDualMatch has two steps: (i) encoding temporal and relational information into\nembeddings separately using a novel label-free encoder, Dual-Encoder; and (ii)\nfusing both information and transforming it into alignment using a novel\ngraph-matching-based decoder, GM-Decoder. DualMatch is able to perform EA on\nTKGs with or without supervision, due to its capability of effectively\ncapturing temporal information. Extensive experiments on three real-world TKG\ndatasets offer the insight that DualMatch outperforms the state-of-the-art\nmethods in terms of H@1 by 2.4% - 10.7% and MRR by 1.7% - 7.6%, respectively.\n","authors":["Xiaoze Liu","Junyang Wu","Tianyi Li","Lu Chen","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2302.00796v1.pdf","comment":"Accepted by The Web Conference (WWW) 2023 Research Track"},{"id":"http://arxiv.org/abs/2302.00778v1","updated":"2023-02-01T22:22:03Z","published":"2023-02-01T22:22:03Z","title":"User Study for Improving Tools for Bible Translation","summary":"  Technology has increasingly become an integral part of the Bible translation\nprocess. Over time, both the translation process and relevant technology have\nevolved greatly. More recently, the field of Natural Language Processing (NLP)\nhas made great progress in solving some problems previously thought\nimpenetrable. Through this study we endeavor to better understand and\ncommunicate about a segment of the current landscape of the Bible translation\nprocess as it relates to technology and identify pertinent issues. We conduct\nseveral interviews with individuals working in different levels of the Bible\ntranslation process from multiple organizations to identify gaps and\nbottlenecks where technology (including recent advances in AI) could\npotentially play a pivotal role in reducing translation time and improving\noverall quality.\n","authors":["Joel Mathew","Ulf Hermjakob"],"pdf_url":"https://arxiv.org/pdf/2302.00778v1.pdf","comment":"5 pages, Report of user-study"},{"id":"http://arxiv.org/abs/2302.00768v1","updated":"2023-02-01T21:38:47Z","published":"2023-02-01T21:38:47Z","title":"Leveraging task dependency and contrastive learning for Legal Judgement\n  Prediction on the European Court of Human Rights","summary":"  We report on an experiment in legal judgement prediction on European Court of\nHuman Rights cases where our model first learns to predict the convention\narticles allegedly violated by the state from case facts descriptions, and\nsubsequently utilizes that information to predict a finding of a violation by\nthe court. We assess the dependency between these two tasks at the feature and\noutcome level. Furthermore, we leverage a hierarchical contrastive loss to pull\ntogether article specific representations of cases at the higher level level,\nleading to distinctive article clusters, and further pulls the cases in each\narticle cluster based on their outcome leading to sub-clusters of cases with\nsimilar outcomes. Our experiment results demonstrate that, given a static\npre-trained encoder, our models produce a small but consistent improvement in\nprediction performance over single-task and joint models without contrastive\nloss.\n","authors":["Santosh T. Y. S. S","Marcel Perez San Blas","Phillip Kemper","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2302.00768v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2302.00765v1","updated":"2023-02-01T21:32:15Z","published":"2023-02-01T21:32:15Z","title":"Visually Grounded Keyword Detection and Localisation for Low-Resource\n  Languages","summary":"  This study investigates the use of Visually Grounded Speech (VGS) models for\nkeyword localisation in speech. The study focusses on two main research\nquestions: (1) Is keyword localisation possible with VGS models and (2) Can\nkeyword localisation be done cross-lingually in a real low-resource setting?\nFour methods for localisation are proposed and evaluated on an English dataset,\nwith the best-performing method achieving an accuracy of 57%. A new dataset\ncontaining spoken captions in Yoruba language is also collected and released\nfor cross-lingual keyword localisation. The cross-lingual model obtains a\nprecision of 16% in actual keyword localisation and this performance can be\nimproved by initialising from a model pretrained on English data. The study\npresents a detailed analysis of the model's success and failure modes and\nhighlights the challenges of using VGS models for keyword localisation in\nlow-resource settings.\n","authors":["Kayode Kolawole Olaleye"],"pdf_url":"https://arxiv.org/pdf/2302.00765v1.pdf","comment":"PhD dissertation, University of Stellenbosch, 108 pages, submitted\n  and accepted 2023"},{"id":"http://arxiv.org/abs/2302.00763v1","updated":"2023-02-01T21:26:32Z","published":"2023-02-01T21:26:32Z","title":"Collaborating with language models for embodied reasoning","summary":"  Reasoning in a complex and ambiguous environment is a key goal for\nReinforcement Learning (RL) agents. While some sophisticated RL agents can\nsuccessfully solve difficult tasks, they require a large amount of training\ndata and often struggle to generalize to new unseen environments and new tasks.\nOn the other hand, Large Scale Language Models (LSLMs) have exhibited strong\nreasoning ability and the ability to to adapt to new tasks through in-context\nlearning. However, LSLMs do not inherently have the ability to interrogate or\nintervene on the environment. In this work, we investigate how to combine these\ncomplementary abilities in a single system consisting of three parts: a\nPlanner, an Actor, and a Reporter. The Planner is a pre-trained language model\nthat can issue commands to a simple embodied agent (the Actor), while the\nReporter communicates with the Planner to inform its next command. We present a\nset of tasks that require reasoning, test this system's ability to generalize\nzero-shot and investigate failure cases, and demonstrate how components of this\nsystem can be trained with reinforcement-learning to improve performance.\n","authors":["Ishita Dasgupta","Christine Kaeser-Chen","Kenneth Marino","Arun Ahuja","Sheila Babayan","Felix Hill","Rob Fergus"],"pdf_url":"https://arxiv.org/pdf/2302.00763v1.pdf","comment":"Presented at NeurIPS 2022 Language and Reinforcement Learning\n  Workshop (best paper) and NeurIPS 2022 Foundation Models for Decision Making\n  Workshop. 4 pages main; 14 pages total (including references and appendix); 3\n  figures"},{"id":"http://arxiv.org/abs/2302.00762v1","updated":"2023-02-01T21:25:34Z","published":"2023-02-01T21:25:34Z","title":"AmbiCoref: Evaluating Human and Model Sensitivity to Ambiguous\n  Coreference","summary":"  Given a sentence \"Abby told Brittney that she upset Courtney\", one would\nstruggle to understand who \"she\" refers to, and ask for clarification. However,\nif the word \"upset\" were replaced with \"hugged\", \"she\" unambiguously refers to\nAbby. We study if modern coreference resolution models are sensitive to such\npronominal ambiguity. To this end, we construct AmbiCoref, a diagnostic corpus\nof minimal sentence pairs with ambiguous and unambiguous referents. Our\nexamples generalize psycholinguistic studies of human perception of ambiguity\naround particular arrangements of verbs and their arguments. Analysis shows\nthat (1) humans are less sure of referents in ambiguous AmbiCoref examples than\nunambiguous ones, and (2) most coreference models show little difference in\noutput between ambiguous and unambiguous pairs. We release AmbiCoref as a\ndiagnostic corpus for testing whether models treat ambiguity similarly to\nhuman.\n","authors":["Yuewei Yuan","Chaitanya Malaviya","Mark Yatskar"],"pdf_url":"https://arxiv.org/pdf/2302.00762v1.pdf","comment":"EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2302.00739v1","updated":"2023-02-01T20:22:20Z","published":"2023-02-01T20:22:20Z","title":"Inference of Partial Colexifications from Multilingual Wordlists","summary":"  The past years have seen a drastic rise in studies devoted to the\ninvestigation of colexification patterns in individual languages families in\nparticular and the languages of the world in specific. Specifically\ncomputational studies have profited from the fact that colexification as a\nscientific construct is easy to operationalize, enabling scholars to infer\ncolexification patterns for large collections of cross-linguistic data. Studies\ndevoted to partial colexifications -- colexification patterns that do not\ninvolve entire words, but rather various parts of words--, however, have been\nrarely conducted so far. This is not surprising, since partial colexifications\nare less easy to deal with in computational approaches and may easily suffer\nfrom all kinds of noise resulting from false positive matches. In order to\naddress this problem, this study proposes new approaches to the handling of\npartial colexifications by (1) proposing new models with which partial\ncolexification patterns can be represented, (2) developing new efficient\nmethods and workflows which help to infer various types of partial\ncolexification patterns from multilingual wordlists, and (3) illustrating how\ninferred patterns of partial colexifications can be computationally analyzed\nand interactively visualized.\n","authors":["Johann-Mattis List"],"pdf_url":"https://arxiv.org/pdf/2302.00739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13379v2","updated":"2023-02-01T19:25:24Z","published":"2023-01-31T03:04:26Z","title":"Faithful Chain-of-Thought Reasoning","summary":"  While Chain-of-Thought (CoT) prompting boosts Language Models' (LM)\nperformance on a gamut of complex reasoning tasks, the generated reasoning\nchain does not necessarily reflect how the model arrives at the answer (aka.\nfaithfulness). We propose Faithful CoT, a faithful-by-construction framework\nthat decomposes a reasoning task into two stages: Translation (Natural Language\nquery $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning\nchain $\\rightarrow$ answer), using an LM and a deterministic solver\nrespectively. We demonstrate the efficacy of our approach on 10 reasoning\ndatasets from 4 diverse domains. It outperforms traditional CoT prompting on 9\nout of the 10 datasets, with an average accuracy gain of 4.4 on Math Word\nProblems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1\non Logical Inference, under greedy decoding. Together with self-consistency\ndecoding, we achieve new state-of-the-art few-shot performance on 7 out of the\n10 datasets, showing a strong synergy between faithfulness and accuracy.\n","authors":["Qing Lyu","Shreya Havaldar","Adam Stein","Li Zhang","Delip Rao","Eric Wong","Marianna Apidianaki","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2301.13379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01756v1","updated":"2023-02-01T20:05:53Z","published":"2023-02-01T20:05:53Z","title":"DANES: Deep Neural Network Ensemble Architecture for Social and Textual\n  Context-aware Fake News Detection","summary":"  The growing popularity of social media platforms has simplified the creation\nand distribution of news articles but also creates a conduit for spreading fake\nnews. In consequence, the need arises for effective context-aware fake news\ndetection mechanisms, where the contextual information can be built either from\nthe textual content of posts or from available social data (e.g., information\nabout the users, reactions to posts, or the social network). In this paper, we\npropose DANES, a Deep Neural Network Ensemble Architecture for Social and\nTextual Context-aware Fake News Detection. DANES comprises a Text Branch for a\ntextual content-based context and a Social Branch for the social context. These\ntwo branches are used to create a novel Network Embedding. Preliminary ablation\nresults on 3 real-world datasets, i.e., BuzzFace, Twitter15, and Twitter16, are\npromising, with an accuracy that outperforms state-of-the-art solutions when\nemploying both social and textual content features.\n","authors":["Ciprian-Octavian Truică","Elena-Simona Apostol","Panagiotis Karras"],"pdf_url":"https://arxiv.org/pdf/2302.01756v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.00673v1","updated":"2023-02-01T18:59:19Z","published":"2023-02-01T18:59:19Z","title":"ADAPT: Action-aware Driving Caption Transformer","summary":"  End-to-end autonomous driving has great potential in the transportation\nindustry. However, the lack of transparency and interpretability of the\nautomatic decision-making process hinders its industrial adoption in practice.\nThere have been some early attempts to use attention maps or cost volume for\nbetter model explainability which is difficult for ordinary passengers to\nunderstand. To bridge the gap, we propose an end-to-end transformer-based\narchitecture, ADAPT (Action-aware Driving cAPtion Transformer), which provides\nuser-friendly natural language narrations and reasoning for each decision\nmaking step of autonomous vehicular control and action. ADAPT jointly trains\nboth the driving caption task and the vehicular control prediction task,\nthrough a shared video representation. Experiments on BDD-X (Berkeley DeepDrive\neXplanation) dataset demonstrate state-of-the-art performance of the ADAPT\nframework on both automatic metrics and human evaluation. To illustrate the\nfeasibility of the proposed framework in real-world applications, we build a\nnovel deployable system that takes raw car videos as input and outputs the\naction narrations and reasoning in real time. The code, models and data are\navailable at https://github.com/jxbbb/ADAPT.\n","authors":["Bu Jin","Xinyu Liu","Yupeng Zheng","Pengfei Li","Hao Zhao","Tong Zhang","Yuhang Zheng","Guyue Zhou","Jingjing Liu"],"pdf_url":"https://arxiv.org/pdf/2302.00673v1.pdf","comment":"Accepted to ICRA2023. Code: https://github.com/jxbbb/ADAPT"},{"id":"http://arxiv.org/abs/2302.00670v1","updated":"2023-02-01T18:57:01Z","published":"2023-02-01T18:57:01Z","title":"Stable Target Field for Reduced Variance Score Estimation in Diffusion\n  Models","summary":"  Diffusion models generate samples by reversing a fixed forward diffusion\nprocess. Despite already providing impressive empirical results, these\ndiffusion models algorithms can be further improved by reducing the variance of\nthe training targets in their denoising score-matching objective. We argue that\nthe source of such variance lies in the handling of intermediate noise-variance\nscales, where multiple modes in the data affect the direction of reverse paths.\nWe propose to remedy the problem by incorporating a reference batch which we\nuse to calculate weighted conditional scores as more stable training targets.\nWe show that the procedure indeed helps in the challenging intermediate regime\nby reducing (the trace of) the covariance of training targets. The new stable\ntargets can be seen as trading bias for reduced variance, where the bias\nvanishes with increasing reference batch size. Empirically, we show that the\nnew objective improves the image quality, stability, and training speed of\nvarious popular diffusion models across datasets with both general ODE and SDE\nsolvers. When used in combination with EDM, our method yields a current SOTA\nFID of 1.90 with 35 network evaluations on the unconditional CIFAR-10\ngeneration task. The code is available at https://github.com/Newbeeer/stf\n","authors":["Yilun Xu","Shangyuan Tong","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2302.00670v1.pdf","comment":"Accepted by ICLR 2023. Code available at:\n  https://github.com/Newbeeer/stf"},{"id":"http://arxiv.org/abs/2301.11494v2","updated":"2023-02-01T18:56:20Z","published":"2023-01-27T02:10:05Z","title":"Learning Vortex Dynamics for Fluid Inference and Prediction","summary":"  We propose a novel differentiable vortex particle (DVP) method to infer and\npredict fluid dynamics from a single video. Lying at its core is a\nparticle-based latent space to encapsulate the hidden, Lagrangian vortical\nevolution underpinning the observable, Eulerian flow phenomena. Our\ndifferentiable vortex particles are coupled with a learnable,\nvortex-to-velocity dynamics mapping to effectively capture the complex flow\nfeatures in a physically-constrained, low-dimensional space. This\nrepresentation facilitates the learning of a fluid simulator tailored to the\ninput video that can deliver robust, long-term future predictions. The value of\nour method is twofold: first, our learned simulator enables the inference of\nhidden physics quantities (e.g., velocity field) purely from visual\nobservation; secondly, it also supports future prediction, constructing the\ninput video's sequel along with its future dynamics evolution. We compare our\nmethod with a range of existing methods on both synthetic and real-world\nvideos, demonstrating improved reconstruction quality, visual plausibility, and\nphysical integrity.\n","authors":["Yitong Deng","Hong-Xing Yu","Jiajun Wu","Bo Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.11494v2.pdf","comment":"ICLR 2023, project webpage:\n  https://yitongdeng.github.io/vortex_learning_webpage/"},{"id":"http://arxiv.org/abs/2302.00669v1","updated":"2023-02-01T18:56:09Z","published":"2023-02-01T18:56:09Z","title":"Detecting Histologic Glioblastoma Regions of Prognostic Relevance","summary":"  Glioblastoma is the most common and aggressive malignant adult tumor of the\ncentral nervous system, with grim prognosis and heterogeneous morphologic and\nmolecular profiles. Since the adoption of the current standard of care\ntreatment, 18 years ago, there are no substantial prognostic improvements\nnoticed. Accurate prediction of patient overall survival (OS) from clinical\nhistopathology whole slide images (WSI) using advanced computational methods\ncould contribute to optimization of clinical decision making and patient\nmanagement. Here, we focus on identifying prognostically relevant glioblastoma\nmorphologic patterns on H&E stained WSI. The exact approach capitalizes on the\ncomprehensive WSI curation of apparent artifactual content and on an\ninterpretability mechanism via a weakly supervised attention based multiple\ninstance learning algorithm that further utilizes clustering to constrain the\nsearch space. The automatically identified patterns of high diagnostic value\nare used to classify the WSI as representative of a short or a long survivor.\nIdentifying tumor morphologic patterns associated with short and long OS will\nallow the clinical neuropathologist to provide additional prognostic\ninformation gleaned during microscopic assessment to the treating team, as well\nas suggest avenues of biological investigation for understanding and\npotentially treating glioblastoma.\n","authors":["Bhakti Baheti","Shubham Innani","Garv Mehdiratta","MacLean P. Nasrallah","Spyridon Bakas"],"pdf_url":"https://arxiv.org/pdf/2302.00669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00648v1","updated":"2023-02-01T18:22:23Z","published":"2023-02-01T18:22:23Z","title":"Image-Based Vehicle Classification by Synergizing Features from\n  Supervised and Self-Supervised Learning Paradigms","summary":"  This paper introduces a novel approach to leverage features learned from both\nsupervised and self-supervised paradigms, to improve image classification\ntasks, specifically for vehicle classification. Two state-of-the-art\nself-supervised learning methods, DINO and data2vec, were evaluated and\ncompared for their representation learning of vehicle images. The former\ncontrasts local and global views while the latter uses masked prediction on\nmulti-layered representations. In the latter case, supervised learning is\nemployed to finetune a pretrained YOLOR object detector for detecting vehicle\nwheels, from which definitive wheel positional features are retrieved. The\nrepresentations learned from these self-supervised learning methods were\ncombined with the wheel positional features for the vehicle classification\ntask. Particularly, a random wheel masking strategy was utilized to finetune\nthe previously learned representations in harmony with the wheel positional\nfeatures during the training of the classifier. Our experiments show that the\ndata2vec-distilled representations, which are consistent with our wheel masking\nstrategy, outperformed the DINO counterpart, resulting in a celebrated Top-1\nclassification accuracy of 97.2% for classifying the 13 vehicle classes defined\nby the Federal Highway Administration.\n","authors":["Shihan Ma","Jidong J. Yang"],"pdf_url":"https://arxiv.org/pdf/2302.00648v1.pdf","comment":"15 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2206.00771v2","updated":"2023-02-01T17:58:54Z","published":"2022-06-01T21:15:01Z","title":"Dynamic Linear Transformer for 3D Biomedical Image Segmentation","summary":"  Transformer-based neural networks have surpassed promising performance on\nmany biomedical image segmentation tasks due to a better global information\nmodeling from the self-attention mechanism. However, most methods are still\ndesigned for 2D medical images while ignoring the essential 3D volume\ninformation. The main challenge for 3D transformer-based segmentation methods\nis the quadratic complexity introduced by the self-attention mechanism\n\\cite{vaswani2017attention}. In this paper, we propose a novel transformer\narchitecture for 3D medical image segmentation using an encoder-decoder style\narchitecture with linear complexity. Furthermore, we newly introduce a dynamic\ntoken concept to further reduce the token numbers for self-attention\ncalculation. Taking advantage of the global information modeling, we provide\nuncertainty maps from different hierarchy stages. We evaluate this method on\nmultiple challenging CT pancreas segmentation datasets. Our promising results\nshow that our novel 3D Transformer-based segmentor could provide promising\nhighly feasible segmentation performance and accurate uncertainty\nquantification using single annotation. Code is available\nhttps://github.com/freshman97/LinTransUNet.\n","authors":["Zheyuan Zhang","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2206.00771v2.pdf","comment":"8 Pages"},{"id":"http://arxiv.org/abs/2302.00633v1","updated":"2023-02-01T17:52:40Z","published":"2023-02-01T17:52:40Z","title":"Deep Dependency Networks for Multi-Label Classification","summary":"  We propose a simple approach which combines the strengths of probabilistic\ngraphical models and deep learning architectures for solving the multi-label\nclassification task, focusing specifically on image and video data. First, we\nshow that the performance of previous approaches that combine Markov Random\nFields with neural networks can be modestly improved by leveraging more\npowerful methods such as iterative join graph propagation, integer linear\nprogramming, and $\\ell_1$ regularization-based structure learning. Then we\npropose a new modeling framework called deep dependency networks, which\naugments a dependency network, a model that is easy to train and learns more\naccurate dependencies but is limited to Gibbs sampling for inference, to the\noutput layer of a neural network. We show that despite its simplicity, jointly\nlearning this new architecture yields significant improvements in performance\nover the baseline neural network. In particular, our experimental evaluation on\nthree video activity classification datasets: Charades, Textually Annotated\nCooking Scenes (TACoS), and Wetlab, and three multi-label image classification\ndatasets: MS-COCO, PASCAL VOC, and NUS-WIDE show that deep dependency networks\nare almost always superior to pure neural architectures that do not use\ndependency networks.\n","authors":["Shivvrat Arya","Yu Xiang","Vibhav Gogate"],"pdf_url":"https://arxiv.org/pdf/2302.00633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00626v1","updated":"2023-02-01T17:46:00Z","published":"2023-02-01T17:46:00Z","title":"Continuous U-Net: Faster, Greater and Noiseless","summary":"  Image segmentation is a fundamental task in image analysis and clinical\npractice. The current state-of-the-art techniques are based on U-shape type\nencoder-decoder networks with skip connections, called U-Net. Despite the\npowerful performance reported by existing U-Net type networks, they suffer from\nseveral major limitations. Issues include the hard coding of the receptive\nfield size, compromising the performance and computational cost, as well as the\nfact that they do not account for inherent noise in the data. They have\nproblems associated with discrete layers, and do not offer any theoretical\nunderpinning. In this work we introduce continuous U-Net, a novel family of\nnetworks for image segmentation. Firstly, continuous U-Net is a continuous deep\nneural network that introduces new dynamic blocks modelled by second order\nordinary differential equations. Secondly, we provide theoretical guarantees\nfor our network demonstrating faster convergence, higher robustness and less\nsensitivity to noise. Thirdly, we derive qualitative measures to tailor-made\nsegmentation tasks. We demonstrate, through extensive numerical and visual\nresults, that our model outperforms existing U-Net blocks for several medical\nimage segmentation benchmarking datasets.\n","authors":["Chun-Wun Cheng","Christina Runkel","Lihao Liu","Raymond H Chan","Carola-Bibiane Schönlieb","Angelica I Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2302.00626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00624v1","updated":"2023-02-01T17:44:17Z","published":"2023-02-01T17:44:17Z","title":"Transforming CLIP to an Open-vocabulary Video Model via Interpolated\n  Weight Optimization","summary":"  Contrastive Language-Image Pretraining (CLIP) has demonstrated impressive\nzero-shot learning abilities for image understanding, yet limited effort has\nbeen made to investigate CLIP for zero-shot video recognition. We introduce\nOpen-VCLIP, a simple yet effective approach that transforms CLIP into strong\nzero-shot video classifiers that can recognize unseen actions and events at\ntest time. Our framework extends CLIP with minimal modifications to model\nspatial-temporal relationships in videos, making it a specialized video\nclassifier, while striving for generalization. We formally show that training\nan Open-VCLIP is equivalent to continual learning with zero historical data. To\naddress this problem, we propose Interpolated Weight Optimization, which\nutilizes the benefit of weight interpolation in both training and test time. We\nevaluate our method on three popular and challenging action recognition\ndatasets following various zero-shot evaluation protocols and we demonstrate\nour approach outperforms state-of-the-art methods by clear margins. In\nparticular, we achieve 87.9%, 58.3%, 81.1% zero-shot accuracy on UCF, HMDB and\nKinetics-600 respectively, outperforming state-of-the-art methods by 8.3%, 7.8%\nand 12.2%.\n","authors":["Zejia Weng","Xitong Yang","Ang Li","Zuxuan Wu","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.00624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11445v2","updated":"2023-02-01T17:37:49Z","published":"2023-01-26T22:23:03Z","title":"3DShape2VecSet: A 3D Shape Representation for Neural Fields and\n  Generative Diffusion Models","summary":"  We introduce 3DShape2VecSet, a novel shape representation for neural fields\ndesigned for generative diffusion models. Our shape representation can encode\n3D shapes given as surface models or point clouds, and represents them as\nneural fields. The concept of neural fields has previously been combined with a\nglobal latent vector, a regular grid of latent vectors, or an irregular grid of\nlatent vectors. Our new representation encodes neural fields on top of a set of\nvectors. We draw from multiple concepts, such as the radial basis function\nrepresentation and the cross attention and self-attention function, to design a\nlearnable representation that is especially suitable for processing with\ntransformers. Our results show improved performance in 3D shape encoding and 3D\nshape generative modeling tasks. We demonstrate a wide variety of generative\napplications: unconditioned generation, category-conditioned generation,\ntext-conditioned generation, point-cloud completion, and image-conditioned\ngeneration.\n","authors":["Biao Zhang","Jiapeng Tang","Matthias Niessner","Peter Wonka"],"pdf_url":"https://arxiv.org/pdf/2301.11445v2.pdf","comment":"Project demo: https://youtu.be/KKQsQccpBFk"},{"id":"http://arxiv.org/abs/2206.08182v3","updated":"2023-02-01T16:53:32Z","published":"2022-06-16T13:51:19Z","title":"Nucleus Segmentation and Analysis in Breast Cancer with the MIScnn\n  Framework","summary":"  The NuCLS dataset contains over 220.000 annotations of cell nuclei in breast\ncancers. We show how to use these data to create a multi-rater model with the\nMIScnn Framework to automate the analysis of cell nuclei. For the model\ncreation, we use the widespread U-Net approach embedded in a pipeline. This\npipeline provides besides the high performance convolution neural network,\nseveral preprocessor techniques and a extended data exploration. The final\nmodel is tested in the evaluation phase using a wide variety of metrics with a\nsubsequent visualization. Finally, the results are compared and interpreted\nwith the results of the NuCLS study. As an outlook, indications are given which\nare important for the future development of models in the context of cell\nnuclei.\n","authors":["Adrian Pfleiderer","Dominik Müller","Frank Kramer"],"pdf_url":"https://arxiv.org/pdf/2206.08182v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00573v1","updated":"2023-02-01T16:46:46Z","published":"2023-02-01T16:46:46Z","title":"An automated, geometry-based method for the analysis of hippocampal\n  thickness","summary":"  The hippocampus is one of the most studied neuroanatomical structures due to\nits involvement in attention, learning, and memory as well as its atrophy in\nageing, neurological, and psychiatric diseases. Hippocampal shape changes,\nhowever, are complex and cannot be fully characterized by a single summary\nmetric such as hippocampal volume as determined from MR images. In this work,\nwe propose an automated, geometry-based approach for the unfolding, point-wise\ncorrespondence, and local analysis of hippocampal shape features such as\nthickness and curvature. Starting from an automated segmentation of hippocampal\nsubfields, we create a 3D tetrahedral mesh model as well as a 3D intrinsic\ncoordinate system of the hippocampal body. From this coordinate system, we\nderive local curvature and thickness estimates as well as a 2D sheet for\nhippocampal unfolding. We evaluate the performance of our algorithm with a\nseries of experiments to quantify neurodegenerative changes in Mild Cognitive\nImpairment and Alzheimer's disease dementia. We find that hippocampal thickness\nestimates detect known differences between clinical groups and can determine\nthe location of these effects on the hippocampal sheet. Further, thickness\nestimates improve classification of clinical groups and cognitively unimpaired\ncontrols when added as an additional predictor. Comparable results are obtained\nwith different datasets and segmentation algorithms. Taken together, we\nreplicate canonical findings on hippocampal volume/shape changes in dementia,\nextend them by gaining insight into their spatial localization on the\nhippocampal sheet, and provide additional, complementary information beyond\ntraditional measures. We provide a new set of sensitive processing and analysis\ntools for the analysis of hippocampal geometry that allows comparisons across\nstudies without relying on image registration or requiring manual intervention.\n","authors":["Kersten Diers","Hannah Baumeister","Frank Jessen","Emrah Düzel","David Berron","Martin Reuter"],"pdf_url":"https://arxiv.org/pdf/2302.00573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00556v1","updated":"2023-02-01T16:23:21Z","published":"2023-02-01T16:23:21Z","title":"Correspondence-free online human motion retargeting","summary":"  We present a novel data-driven framework for unsupervised human motion\nretargeting which animates a target body shape with a source motion. This\nallows to retarget motions between different characters by animating a target\nsubject with a motion of a source subject. Our method is\ncorrespondence-free,~\\ie neither spatial correspondences between the source and\ntarget shapes nor temporal correspondences between different frames of the\nsource motion are required. Our proposed method directly animates a target\nshape with arbitrary sequences of humans in motion, possibly captured using 4D\nacquisition platforms or consumer devices. Our framework takes into account\nlong-term temporal context of $1$ second during retargeting while accounting\nfor surface details. To achieve this, we take inspiration from two lines of\nexisting work: skeletal motion retargeting, which leverages long-term temporal\ncontext at the cost of surface detail, and surface-based retargeting, which\npreserves surface details without considering long-term temporal context. We\nunify the advantages of these works by combining a learnt skinning field with a\nskeletal retargeting approach. During inference, our method runs online,~\\ie\nthe input can be processed in a serial way, and retargeting is performed in a\nsingle forward pass per frame. Experiments show that including long-term\ntemporal context during training improves the method's accuracy both in terms\nof the retargeted skeletal motion and the detail preservation. Furthermore, our\nmethod generalizes well on unobserved motions and body shapes. We demonstrate\nthat the proposed framework achieves state-of-the-art results on two test\ndatasets.\n","authors":["Mathieu Marsot","Rim Rekik","Stefanie Wuhrer","Jean-Sébastien Franco","Anne-Hélène Olivier"],"pdf_url":"https://arxiv.org/pdf/2302.00556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00545v1","updated":"2023-02-01T16:08:58Z","published":"2023-02-01T16:08:58Z","title":"An Out-of-Domain Synapse Detection Challenge for Microwasp Brain\n  Connectomes","summary":"  The size of image stacks in connectomics studies now reaches the terabyte and\noften petabyte scales with a great diversity of appearance across brain regions\nand samples. However, manual annotation of neural structures, e.g., synapses,\nis time-consuming, which leads to limited training data often smaller than\n0.001\\% of the test data in size. Domain adaptation and generalization\napproaches were proposed to address similar issues for natural images, which\nwere less evaluated on connectomics data due to a lack of out-of-domain\nbenchmarks.\n","authors":["Jingpeng Wu","Yicong Li","Nishika Gupta","Kazunori Shinomiya","Pat Gunn","Alexey Polilov","Hanspeter Pfister","Dmitri Chklovskii","Donglai Wei"],"pdf_url":"https://arxiv.org/pdf/2302.00545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00528v1","updated":"2023-02-01T15:55:34Z","published":"2023-02-01T15:55:34Z","title":"A latent space for unsupervised MR image quality control via artifact\n  assessment","summary":"  Image quality control (IQC) can be used in automated magnetic resonance (MR)\nimage analysis to exclude erroneous results caused by poorly acquired or\nartifact-laden images. Existing IQC methods for MR imaging generally require\nhuman effort to craft meaningful features or label large datasets for\nsupervised training. The involvement of human labor can be burdensome and\nbiased, as labeling MR images based on their quality is a subjective task. In\nthis paper, we propose an automatic IQC method that evaluates the extent of\nartifacts in MR images without supervision. In particular, we design an\nartifact encoding network that learns representations of artifacts based on\ncontrastive learning. We then use a normalizing flow to estimate the density of\nlearned representations for unsupervised classification. Our experiments on\nlarge-scale multi-cohort MR datasets show that the proposed method accurately\ndetects images with high levels of artifacts, which can inform downstream\nanalysis tasks about potentially flawed data.\n","authors":["Lianrui Zuo","Yuan Xue","Blake E. Dewey","Yihao Liu","Jerry L. Prince","Aaron Carass"],"pdf_url":"https://arxiv.org/pdf/2302.00528v1.pdf","comment":"Accepted at the International Society for Optics and Photonics -\n  Medical Imaging (SPIE-MI) 2023"},{"id":"http://arxiv.org/abs/2302.00523v1","updated":"2023-02-01T15:52:24Z","published":"2023-02-01T15:52:24Z","title":"Uncertainty-Driven Dense Two-View Structure from Motion","summary":"  This work introduces an effective and practical solution to the dense\ntwo-view structure from motion (SfM) problem. One vital question addressed is\nhow to mindfully use per-pixel optical flow correspondence between two frames\nfor accurate pose estimation -- as perfect per-pixel correspondence between two\nimages is difficult, if not impossible, to establish. With the carefully\nestimated camera pose and predicted per-pixel optical flow correspondences, a\ndense depth of the scene is computed. Later, an iterative refinement procedure\nis introduced to further improve optical flow matching confidence, camera pose,\nand depth, exploiting their inherent dependency in rigid SfM. The fundamental\nidea presented is to benefit from per-pixel uncertainty in the optical flow\nestimation and provide robustness to the dense SfM system via an online\nrefinement. Concretely, we introduce a pipeline consisting of (i) an\nuncertainty-aware dense optical flow estimation approach that provides\nper-pixel correspondence with their confidence score of matching; (ii) a\nweighted dense bundle adjustment formulation that depends on optical flow\nuncertainty and bidirectional optical flow consistency to refine both pose and\ndepth; (iii) a depth estimation network that considers its consistency with the\nestimated poses and optical flow respecting epipolar constraint. Extensive\nexperiments show that the proposed approach achieves remarkable depth accuracy\nand state-of-the-art camera pose results superseding SuperPoint and SuperGlue\naccuracy when tested on benchmark datasets such as DeMoN, YFCC100M, and\nScanNet.\n","authors":["Weirong Chen","Suryansh Kumar","Fisher Yu"],"pdf_url":"https://arxiv.org/pdf/2302.00523v1.pdf","comment":"Accepted for publication at IEEE Robotics and Automation Letters\n  (RA-L) 2023"},{"id":"http://arxiv.org/abs/2302.00517v1","updated":"2023-02-01T15:37:35Z","published":"2023-02-01T15:37:35Z","title":"Synthesis-based Imaging-Differentiation Representation Learning for\n  Multi-Sequence 3D/4D MRI","summary":"  Multi-sequence MRIs can be necessary for reliable diagnosis in clinical\npractice due to the complimentary information within sequences. However,\nredundant information exists across sequences, which interferes with mining\nefficient representations by modern machine learning or deep learning models.\nTo handle various clinical scenarios, we propose a sequence-to-sequence\ngeneration framework (Seq2Seq) for imaging-differentiation representation\nlearning. In this study, not only do we propose arbitrary 3D/4D sequence\ngeneration within one model to generate any specified target sequence, but also\nwe are able to rank the importance of each sequence based on a new metric\nestimating the difficulty of a sequence being generated. Furthermore, we also\nexploit the generation inability of the model to extract regions that contain\nunique information for each sequence. We conduct extensive experiments using\nthree datasets including a toy dataset of 20,000 simulated subjects, a brain\nMRI dataset of 1,251 subjects, and a breast MRI dataset of 2,101 subjects, to\ndemonstrate that (1) our proposed Seq2Seq is efficient and lightweight for\ncomplex clinical datasets and can achieve excellent image quality; (2)\ntop-ranking sequences can be used to replace complete sequences with\nnon-inferior performance; (3) combining MRI with our imaging-differentiation\nmap leads to better performance in clinical tasks such as glioblastoma MGMT\npromoter methylation status prediction and breast cancer pathological complete\nresponse status prediction. Our code is available at\nhttps://github.com/fiy2W/mri_seq2seq.\n","authors":["Luyi Han","Tao Tan","Tianyu Zhang","Yunzhi Huang","Xin Wang","Yuan Gao","Jonas Teuwen","Ritse Mann"],"pdf_url":"https://arxiv.org/pdf/2302.00517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00514v1","updated":"2023-02-01T15:34:24Z","published":"2023-02-01T15:34:24Z","title":"Towards Implementing Energy-aware Data-driven Intelligence for Smart\n  Health Applications on Mobile Platforms","summary":"  Recent breakthrough technological progressions of powerful mobile computing\nresources such as low-cost mobile GPUs along with cutting-edge, open-source\nsoftware architectures have enabled high-performance deep learning on mobile\nplatforms. These advancements have revolutionized the capabilities of today's\nmobile applications in different dimensions to perform data-driven intelligence\nlocally, particularly for smart health applications. Unlike traditional machine\nlearning (ML) architectures, modern on-device deep learning frameworks are\nproficient in utilizing computing resources in mobile platforms seamlessly, in\nterms of producing highly accurate results in less inference time. However, on\nthe flip side, energy resources in a mobile device are typically limited.\nHence, whenever a complex Deep Neural Network (DNN) architecture is fed into\nthe on-device deep learning framework, while it achieves high prediction\naccuracy (and performance), it also urges huge energy demands during the\nruntime. Therefore, managing these resources efficiently within the spectrum of\nperformance and energy efficiency is the newest challenge for any mobile\napplication featuring data-driven intelligence beyond experimental evaluations.\nIn this paper, first, we provide a timely review of recent advancements in\non-device deep learning while empirically evaluating the performance metrics of\ncurrent state-of-the-art ML architectures and conventional ML approaches with\nthe emphasis given on energy characteristics by deploying them on a smart\nhealth application. With that, we are introducing a new framework through an\nenergy-aware, adaptive model comprehension and realization (EAMCR) approach\nthat can be utilized to make more robust and efficient inference decisions\nbased on the available computing/energy resources in the mobile device during\nthe runtime.\n","authors":["G. Dumindu Samaraweera","Hung Nguyen","Hadi Zanddizari","Behnam Zeinali","J. Morris Chang"],"pdf_url":"https://arxiv.org/pdf/2302.00514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00509v1","updated":"2023-02-01T15:28:55Z","published":"2023-02-01T15:28:55Z","title":"Exploring Semantic Perturbations on Grover","summary":"  With news and information being as easy to access as they currently are, it\nis more important than ever to ensure that people are not mislead by what they\nread. Recently, the rise of neural fake news (AI-generated fake news) and its\ndemonstrated effectiveness at fooling humans has prompted the development of\nmodels to detect it. One such model is the Grover model, which can both detect\nneural fake news to prevent it, and generate it to demonstrate how a model\ncould be misused to fool human readers. In this work we explore the Grover\nmodel's fake news detection capabilities by performing targeted attacks through\nperturbations on input news articles. Through this we test Grover's resilience\nto these adversarial attacks and expose some potential vulnerabilities which\nshould be addressed in further iterations to ensure it can detect all types of\nfake news accurately.\n","authors":["Pranav Kulkarni","Ziqing Ji","Yan Xu","Marko Neskovic","Kevin Nolan"],"pdf_url":"https://arxiv.org/pdf/2302.00509v1.pdf","comment":"15 pages, 12 figures, 1 table, capstone research in machine learning"},{"id":"http://arxiv.org/abs/2302.00503v1","updated":"2023-02-01T15:17:12Z","published":"2023-02-01T15:17:12Z","title":"Tracking People in Highly Dynamic Industrial Environments","summary":"  To date, the majority of positioning systems have been designed to operate\nwithin environments that have long-term stable macro-structure with potential\nsmall-scale dynamics. These assumptions allow the existing positioning systems\nto produce and utilize stable maps. However, in highly dynamic industrial\nsettings these assumptions are no longer valid and the task of tracking people\nis more challenging due to the rapid large-scale changes in structure. In this\npaper we propose a novel positioning system for tracking people in highly\ndynamic industrial environments, such as construction sites. The proposed\nsystem leverages the existing CCTV camera infrastructure found in many\nindustrial settings along with radio and inertial sensors within each worker's\nmobile phone to accurately track multiple people. This multi-target\nmulti-sensor tracking framework also allows our system to use cross-modality\ntraining in order to deal with the environment dynamics. In particular, we show\nhow our system uses cross-modality training in order to automatically keep\ntrack environmental changes (i.e. new walls) by utilizing occlusion maps. In\naddition, we show how these maps can be used in conjunction with social forces\nto accurately predict human motion and increase the tracking accuracy. We have\nconducted extensive real-world experiments in a construction site showing\nsignificant accuracy improvement via cross-modality training and the use of\nsocial forces.\n","authors":["Savvas Papaioannou","Andrew Markham","Niki Trigoni"],"pdf_url":"https://arxiv.org/pdf/2302.00503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00491v1","updated":"2023-02-01T15:02:58Z","published":"2023-02-01T15:02:58Z","title":"Learning Prototype Classifiers for Long-Tailed Recognition","summary":"  The problem of long-tailed recognition (LTR) has received attention in recent\nyears due to the fundamental power-law distribution of objects in the\nreal-world. Most recent works in LTR use softmax classifiers that have a\ntendency to correlate classifier norm with the amount of training data for a\ngiven class. On the other hand, Prototype classifiers do not suffer from this\nshortcoming and can deliver promising results simply using Nearest-Class-Mean\n(NCM), a special case where prototypes are empirical centroids. However, the\npotential of Prototype classifiers as an alternative to softmax in LTR is\nrelatively underexplored. In this work, we propose Prototype classifiers, which\njointly learn prototypes that minimize average cross-entropy loss based on\nprobability scores from distances to prototypes. We theoretically analyze the\nproperties of Euclidean distance based prototype classifiers that leads to\nstable gradient-based optimization which is robust to outliers. We further\nenhance Prototype classifiers by learning channel-dependent temperature\nparameters to enable independent distance scales along each channel. Our\nanalysis shows that prototypes learned by Prototype classifiers are better\nseparated than empirical centroids. Results on four long-tailed recognition\nbenchmarks show that Prototype classifier outperforms or is comparable to the\nstate-of-the-art methods.\n","authors":["Saurabh Sharma","Yongqin Xian","Ning Yu","Ambuj Singh"],"pdf_url":"https://arxiv.org/pdf/2302.00491v1.pdf","comment":"11 pages, 4 figures and 9 tables"},{"id":"http://arxiv.org/abs/2111.06812v5","updated":"2023-02-01T13:54:51Z","published":"2021-11-12T16:45:20Z","title":"Sci-Net: Scale Invariant Model for Buildings Segmentation from Aerial\n  Imagery","summary":"  Buildings' segmentation is a fundamental task in the field of earth\nobservation and aerial imagery analysis. Most existing deep learning-based\nmethods in the literature can be applied to a fixed or narrow-range spatial\nresolution imagery. In practical scenarios, users deal with a broad spectrum of\nimage resolutions. Thus, a given aerial image often needs to be re-sampled to\nmatch the spatial resolution of the dataset used to train the deep learning\nmodel, which results in a degradation in segmentation performance. To overcome\nthis challenge, we propose, in this manuscript, Scale-invariant Neural Network\n(Sci-Net) architecture that segments buildings from wide-range spatial\nresolution aerial images. Specifically, our approach leverages UNet\nhierarchical representation and Dense Atrous Spatial Pyramid Pooling to extract\nfine-grained multi-scale representations. Sci-Net significantly outperforms\nstate of the art models on the Open Cities AI and the Multi-Scale Building\ndatasets with a steady improvement margin across different spatial resolutions.\n","authors":["Hasan Nasrallah","Mustafa Shukor","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2111.06812v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02357v2","updated":"2023-02-01T13:51:07Z","published":"2022-10-05T15:57:53Z","title":"Image Masking for Robust Self-Supervised Monocular Depth Estimation","summary":"  Self-supervised monocular depth estimation is a salient task for 3D scene\nunderstanding. Learned jointly with monocular ego-motion estimation, several\nmethods have been proposed to predict accurate pixel-wise depth without using\nlabeled data. Nevertheless, these methods focus on improving performance under\nideal conditions without natural or digital corruptions. The general absence of\nocclusions is assumed even for object-specific depth estimation. These methods\nare also vulnerable to adversarial attacks, which is a pertinent concern for\ntheir reliable deployment in robots and autonomous driving systems. We propose\nMIMDepth, a method that adapts masked image modeling (MIM) for self-supervised\nmonocular depth estimation. While MIM has been used to learn generalizable\nfeatures during pre-training, we show how it could be adapted for direct\ntraining of monocular depth estimation. Our experiments show that MIMDepth is\nmore robust to noise, blur, weather conditions, digital artifacts, occlusions,\nas well as untargeted and targeted adversarial attacks.\n","authors":["Hemang Chawla","Kishaan Jeeveswaran","Elahe Arani","Bahram Zonooz"],"pdf_url":"https://arxiv.org/pdf/2210.02357v2.pdf","comment":"Accepted at 2023 IEEE International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2302.00431v1","updated":"2023-02-01T13:25:54Z","published":"2023-02-01T13:25:54Z","title":"Do I Have Your Attention: A Large Scale Engagement Prediction Dataset\n  and Baselines","summary":"  The degree of concentration, enthusiasm, optimism, and passion displayed by\nindividual(s) while interacting with a machine is referred to as `user\nengagement'. Engagement comprises of behavioural, cognitive, and affect related\ncues. To create engagement predictions systems, which can work in real-world\nconditions it is quintessential to learn from rich diverse datasets. To this\nend, a large scale multi-faceted engagement in the wild dataset is proposed. 31\nhours duration data of 127 participants representing different illumination\nconditions is recorded. Thorough experiments are performed exploring\napplicability of different features action units, eye gaze and head pose and\ntransformers. To further validate the rich nature of the dataset, evaluation is\nalso performed on the EngageWild dataset. The experiments show the usefulness\nof the proposed dataset. The code, models and dataset will be made publicly\navailable.\n","authors":["Monisha Singh","Ximi Hoque","Donghuo Zeng","Yanan Wang","Kazushi Ikeda","Abhinav Dhall"],"pdf_url":"https://arxiv.org/pdf/2302.00431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15948v2","updated":"2023-02-01T13:16:22Z","published":"2022-10-28T07:12:00Z","title":"Matching entropy based disparity estimation from light field","summary":"  A major challenge for matching-based depth estimation is to prevent\nmismatches in occlusion and smooth regions. An effective matching window\nsatisfying three characteristics: texture richness, disparity consistency and\nanti-occlusion should be able to prevent mismatches to some extent. According\nto these characteristics, we propose matching entropy in the spatial domain of\nlight field to measure the amount of correct information in a matching window,\nwhich provides the criterion for matching window selection. Based on matching\nentropy regularization, we establish an optimization model for depth estimation\nwith a matching cost fidelity term. To find the optimum, we propose a two-step\nadaptive matching algorithm. First, the region type is adaptively determined to\nidentify occluding, occluded, smooth and textured regions. Then, the matching\nentropy criterion is used to adaptively select the size and shape of matching\nwindows, as well as the visible viewpoints. The two-step process can reduce\nmismatches and redundant calculations by selecting effective matching windows.\nThe experimental results on synthetic and real data show that the proposed\nmethod can effectively improve the accuracy of depth estimation in occlusion\nand smooth regions and has strong robustness for different noise levels.\nTherefore, high-precision depth estimation from 4D light field data is\nachieved.\n","authors":["Ligen Shi","Chang Liu","Di He","Xing Zhao","Jun Qiu"],"pdf_url":"https://arxiv.org/pdf/2210.15948v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00402v1","updated":"2023-02-01T12:40:03Z","published":"2023-02-01T12:40:03Z","title":"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image\n  and Video","summary":"  Recent years have witnessed a big convergence of language, vision, and\nmulti-modal pretraining. In this work, we present mPLUG-2, a new unified\nparadigm with modularized design for multi-modal pretraining, which can benefit\nfrom modality collaboration while addressing the problem of modality\nentanglement. In contrast to predominant paradigms of solely relying on\nsequence-to-sequence generation or encoder-based instance discrimination,\nmPLUG-2 introduces a multi-module composition network by sharing common\nuniversal modules for modality collaboration and disentangling different\nmodality modules to deal with modality entanglement. It is flexible to select\ndifferent modules for different understanding and generation tasks across all\nmodalities including text, image, and video. Empirical study shows that mPLUG-2\nachieves state-of-the-art or competitive results on a broad range of over 30\ndownstream tasks, spanning multi-modal tasks of image-text and video-text\nunderstanding and generation, and uni-modal tasks of text-only, image-only, and\nvideo-only understanding. Notably, mPLUG-2 shows new state-of-the-art results\nof 48.0 top-1 accuracy and 80.3 CIDEr on the challenging MSRVTT video QA and\nvideo caption tasks with a far smaller model size and data scale. It also\ndemonstrates strong zero-shot transferability on vision-language and\nvideo-language tasks. Code and models will be released in\nhttps://github.com/alibaba/AliceMind.\n","authors":["Haiyang Xu","Qinghao Ye","Ming Yan","Yaya Shi","Jiabo Ye","Yuanhong Xu","Chenliang Li","Bin Bi","Qi Qian","Wei Wang","Guohai Xu","Ji Zhang","Songfang Huang","Fei Huang","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11378v2","updated":"2023-02-01T12:24:57Z","published":"2022-07-22T23:48:26Z","title":"Do Perceptually Aligned Gradients Imply Adversarial Robustness?","summary":"  Adversarially robust classifiers possess a trait that non-robust models do\nnot -- Perceptually Aligned Gradients (PAG). Their gradients with respect to\nthe input align well with human perception. Several works have identified PAG\nas a byproduct of robust training, but none have considered it as a standalone\nphenomenon nor studied its own implications. In this work, we focus on this\ntrait and test whether \\emph{Perceptually Aligned Gradients imply Robustness}.\nTo this end, we develop a novel objective to directly promote PAG in training\nclassifiers and examine whether models with such gradients are more robust to\nadversarial attacks. Extensive experiments on multiple datasets and\narchitectures validate that models with aligned gradients exhibit significant\nrobustness, exposing the surprising bidirectional connection between PAG and\nrobustness. Lastly, we show that better gradient alignment leads to increased\nrobustness and harness this observation to boost the robustness of existing\nadversarial training techniques.\n","authors":["Roy Ganz","Bahjat Kawar","Michael Elad"],"pdf_url":"https://arxiv.org/pdf/2207.11378v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13082v3","updated":"2023-02-01T12:19:42Z","published":"2023-01-30T17:22:10Z","title":"PaCaNet: A Study on CycleGAN with Transfer Learning for Diversifying\n  Fused Chinese Painting and Calligraphy","summary":"  AI-Generated Content (AIGC) has recently gained a surge in popularity,\npowered by its high efficiency and consistency in production, and its\ncapability of being customized and diversified. The cross-modality nature of\nthe representation learning mechanism in most AIGC technology allows for more\nfreedom and flexibility in exploring new types of art that would be impossible\nin the past. Inspired by the pictogram subset of Chinese characters, we\nproposed PaCaNet, a CycleGAN-based pipeline for producing novel artworks that\nfuse two different art types, traditional Chinese painting and calligraphy. In\nan effort to produce stable and diversified output, we adopted three main\ntechnical innovations: 1. Using one-shot learning to increase the creativity of\npre-trained models and diversify the content of the fused images. 2.\nControlling the preference over generated Chinese calligraphy by freezing\nrandomly sampled parameters in pre-trained models. 3. Using a regularization\nmethod to encourage the models to produce images similar to Chinese paintings.\nFurthermore, we conducted a systematic study to explore the performance of\nPaCaNet in diversifying fused Chinese painting and calligraphy, which showed\nsatisfying results. In conclusion, we provide a new direction of creating arts\nby fusing the visual information in paintings and the stroke features in\nChinese calligraphy. Our approach creates a unique aesthetic experience rooted\nin the origination of Chinese hieroglyph characters. It is also a unique\nopportunity to delve deeper into traditional artwork and, in doing so, to\ncreate a meaningful impact on preserving and revitalizing traditional heritage.\n","authors":["Zuhao Yang","Huajun Bai","Zhang Luo","Yang Xu","Wei Pang","Yue Wang","Yisheng Yuan","Yingfang Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.13082v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00391v1","updated":"2023-02-01T12:02:04Z","published":"2023-02-01T12:02:04Z","title":"PresSim: An End-to-end Framework for Dynamic Ground Pressure Profile\n  Generation from Monocular Videos Using Physics-based 3D Simulation","summary":"  Ground pressure exerted by the human body is a valuable source of information\nfor human activity recognition (HAR) in unobtrusive pervasive sensing. While\ndata collection from pressure sensors to develop HAR solutions requires\nsignificant resources and effort, we present a novel end-to-end framework,\nPresSim, to synthesize sensor data from videos of human activities to reduce\nsuch effort significantly. PresSim adopts a 3-stage process: first, extract the\n3D activity information from videos with computer vision architectures; then\nsimulate the floor mesh deformation profiles based on the 3D activity\ninformation and gravity-included physics simulation; lastly, generate the\nsimulated pressure sensor data with deep learning models. We explored two\napproaches for the 3D activity information: inverse kinematics with mesh\nre-targeting, and volumetric pose and shape estimation. We validated PresSim\nwith an experimental setup with a monocular camera to provide input and a\npressure-sensing fitness mat (80x28 spatial resolution) to provide the sensor\nground truth, where nine participants performed a set of predefined yoga\nsequences.\n","authors":["Lala Shakti Swarup Ray","Bo Zhou","Sungho Suh","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2302.00391v1.pdf","comment":"Percom2023 workshop(UMUM2023)"},{"id":"http://arxiv.org/abs/2302.00386v1","updated":"2023-02-01T11:46:04Z","published":"2023-02-01T11:46:04Z","title":"EfficientRep:An Efficient Repvgg-style ConvNets with Hardware-aware\n  Neural Network Design","summary":"  We present a hardware-efficient architecture of convolutional neural network,\nwhich has a repvgg-like architecture. Flops or parameters are traditional\nmetrics to evaluate the efficiency of networks which are not sensitive to\nhardware including computing ability and memory bandwidth. Thus, how to design\na neural network to efficiently use the computing ability and memory bandwidth\nof hardware is a critical problem. This paper proposes a method how to design\nhardware-aware neural network. Based on this method, we designed EfficientRep\nseries convolutional networks, which are high-computation hardware(e.g. GPU)\nfriendly and applied in YOLOv6 object detection framework. YOLOv6 has published\nYOLOv6N/YOLOv6S/YOLOv6M/YOLOv6L models in v1 and v2 versions.\n","authors":["Kaiheng Weng","Xiangxiang Chu","Xiaoming Xu","Junshi Huang","Xiaoming Wei"],"pdf_url":"https://arxiv.org/pdf/2302.00386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00384v1","updated":"2023-02-01T11:41:21Z","published":"2023-02-01T11:41:21Z","title":"Alphazzle: Jigsaw Puzzle Solver with Deep Monte-Carlo Tree Search","summary":"  Solving jigsaw puzzles requires to grasp the visual features of a sequence of\npatches and to explore efficiently a solution space that grows exponentially\nwith the sequence length. Therefore, visual deep reinforcement learning (DRL)\nshould answer this problem more efficiently than optimization solvers coupled\nwith neural networks. Based on this assumption, we introduce Alphazzle, a\nreassembly algorithm based on single-player Monte Carlo Tree Search (MCTS). A\nmajor difference with DRL algorithms lies in the unavailability of game reward\nfor MCTS, and we show how to estimate it from the visual input with neural\nnetworks. This constraint is induced by the puzzle-solving task and\ndramatically adds to the task complexity (and interest!). We perform an in-deep\nablation study that shows the importance of MCTS and the neural networks\nworking together. We achieve excellent results and get exciting insights into\nthe combination of DRL and visual feature learning.\n","authors":["Marie-Morgane Paumard","Hedi Tabia","David Picard"],"pdf_url":"https://arxiv.org/pdf/2302.00384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.03702v4","updated":"2023-02-01T11:07:15Z","published":"2021-08-08T18:05:44Z","title":"BIGRoC: Boosting Image Generation via a Robust Classifier","summary":"  The interest of the machine learning community in image synthesis has grown\nsignificantly in recent years, with the introduction of a wide range of deep\ngenerative models and means for training them. In this work, we propose a\ngeneral model-agnostic technique for improving the image quality and the\ndistribution fidelity of generated images obtained by any generative model. Our\nmethod, termed BIGRoC (Boosting Image Generation via a Robust Classifier), is\nbased on a post-processing procedure via the guidance of a given robust\nclassifier and without a need for additional training of the generative model.\nGiven a synthesized image, we propose to update it through projected gradient\nsteps over the robust classifier to refine its recognition. We demonstrate this\npost-processing algorithm on various image synthesis methods and show a\nsignificant quantitative and qualitative improvement on CIFAR-10 and ImageNet.\nSurprisingly, although BIGRoC is the first model agnostic among refinement\napproaches and requires much less information, it outperforms competitive\nmethods. Specifically, BIGRoC improves the image synthesis best performing\ndiffusion model on ImageNet 128x128 by 14.81%, attaining an FID score of 2.53,\nand on 256x256 by 7.87%, achieving an FID of 3.63. Moreover, we conduct an\nopinion survey, according to which humans significantly prefer our method's\noutputs.\n","authors":["Roy Ganz","Michael Elad"],"pdf_url":"https://arxiv.org/pdf/2108.03702v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05616v2","updated":"2023-02-01T11:06:18Z","published":"2022-10-11T17:03:25Z","title":"Neural Shape Deformation Priors","summary":"  We present Neural Shape Deformation Priors, a novel method for shape\nmanipulation that predicts mesh deformations of non-rigid objects from\nuser-provided handle movements. State-of-the-art methods cast this problem as\nan optimization task, where the input source mesh is iteratively deformed to\nminimize an objective function according to hand-crafted regularizers such as\nARAP. In this work, we learn the deformation behavior based on the underlying\ngeometric properties of a shape, while leveraging a large-scale dataset\ncontaining a diverse set of non-rigid deformations. Specifically, given a\nsource mesh and desired target locations of handles that describe the partial\nsurface deformation, we predict a continuous deformation field that is defined\nin 3D space to describe the space deformation. To this end, we introduce\ntransformer-based deformation networks that represent a shape deformation as a\ncomposition of local surface deformations. It learns a set of local latent\ncodes anchored in 3D space, from which we can learn a set of continuous\ndeformation functions for local surfaces. Our method can be applied to\nchallenging deformations and generalizes well to unseen deformations. We\nvalidate our approach in experiments using the DeformingThing4D dataset, and\ncompare to both classic optimization-based and recent neural network-based\nmethods.\n","authors":["Jiapeng Tang","Lev Markhasin","Bi Wang","Justus Thies","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2210.05616v2.pdf","comment":"NeurIPS 2022 Spotlight"},{"id":"http://arxiv.org/abs/2207.01887v2","updated":"2023-02-01T10:59:03Z","published":"2022-07-05T08:32:18Z","title":"Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge\n  Transfer","summary":"  Real-world recognition system often encounters the challenge of unseen\nlabels. To identify such unseen labels, multi-label zero-shot learning (ML-ZSL)\nfocuses on transferring knowledge by a pre-trained textual label embedding\n(e.g., GloVe). However, such methods only exploit single-modal knowledge from a\nlanguage model, while ignoring the rich semantic information inherent in\nimage-text pairs. Instead, recently developed open-vocabulary (OV) based\nmethods succeed in exploiting such information of image-text pairs in object\ndetection, and achieve impressive performance. Inspired by the success of\nOV-based methods, we propose a novel open-vocabulary framework, named\nmulti-modal knowledge transfer (MKT), for multi-label classification.\nSpecifically, our method exploits multi-modal knowledge of image-text pairs\nbased on a vision and language pre-training (VLP) model. To facilitate\ntransferring the image-text matching ability of VLP model, knowledge\ndistillation is employed to guarantee the consistency of image and label\nembeddings, along with prompt tuning to further update the label embeddings. To\nfurther enable the recognition of multiple objects, a simple but effective\ntwo-stream module is developed to capture both local and global features.\nExtensive experimental results show that our method significantly outperforms\nstate-of-the-art methods on public benchmark datasets. The source code is\navailable at https://github.com/sunanhe/MKT.\n","authors":["Sunan He","Taian Guo","Tao Dai","Ruizhi Qiao","Bo Ren","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2207.01887v2.pdf","comment":"AAAI 2023 (Oral presentation paper). Updated version"},{"id":"http://arxiv.org/abs/2302.00368v1","updated":"2023-02-01T10:55:27Z","published":"2023-02-01T10:55:27Z","title":"Test-Time Amendment with a Coarse Classifier for Fine-Grained\n  Classification","summary":"  We investigate the problem of reducing mistake severity for fine-grained\nclassification. Fine-grained classification can be challenging, mainly due to\nthe requirement of knowledge or domain expertise for accurate annotation.\nHowever, humans are particularly adept at performing coarse classification as\nit requires relatively low levels of expertise. To this end, we present a novel\napproach for Post-Hoc Correction called Hierarchical Ensembles (HiE) that\nutilizes label hierarchy to improve the performance of fine-grained\nclassification at test-time using the coarse-grained predictions. By only\nrequiring the parents of leaf nodes, our method significantly reduces avg.\nmistake severity while improving top-1 accuracy on the iNaturalist-19 and\ntieredImageNet-H datasets, achieving a new state-of-the-art on both benchmarks.\nWe also investigate the efficacy of our approach in the semi-supervised\nsetting. Our approach brings notable gains in top-1 accuracy while\nsignificantly decreasing the severity of mistakes as training data decreases\nfor the fine-grained classes. The simplicity and post-hoc nature of HiE render\nit practical to be used with any off-the-shelf trained model to improve its\npredictions further.\n","authors":["Kanishk Jain","Shyamgopal Karthik","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2302.00368v1.pdf","comment":"8 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.00362v1","updated":"2023-02-01T10:40:05Z","published":"2023-02-01T10:40:05Z","title":"A Flexible Framework for Virtual Omnidirectional Vision to Improve\n  Operator Situation Awareness","summary":"  During teleoperation of a mobile robot, providing good operator situation\nawareness is a major concern as a single mistake can lead to mission failure.\nCamera streams are widely used for teleoperation but offer limited\nfield-of-view. In this paper, we present a flexible framework for virtual\nprojections to increase situation awareness based on a novel method to fuse\nmultiple cameras mounted anywhere on the robot. Moreover, we propose a\ncomplementary approach to improve scene understanding by fusing camera images\nand geometric 3D Lidar data to obtain a colorized point cloud. The\nimplementation on a compact omnidirectional camera reduces system complexity\nconsiderably and solves multiple use-cases on a much smaller footprint compared\nto traditional approaches such as actuated pan-tilt units. Finally, we\ndemonstrate the generality of the approach by application to the multi-camera\nsystem of the Boston Dynamics Spot. The software implementation is available as\nopen-source ROS packages on the project page\nhttps://tu-darmstadt-ros-pkg.github.io/omnidirectional_vision.\n","authors":["Martin Oehler","Oskar von Stryk"],"pdf_url":"https://arxiv.org/pdf/2302.00362v1.pdf","comment":"Accepted to European Conference on Mobile Robots (ECMR) 2021. Video\n  link: https://youtu.be/7pocpdsMxOM Project page:\n  https://tu-darmstadt-ros-pkg.github.io/omnidirectional_vision"},{"id":"http://arxiv.org/abs/2209.15264v2","updated":"2023-02-01T10:27:16Z","published":"2022-09-30T06:44:37Z","title":"Diffusion-based Image Translation using Disentangled Style and Content\n  Representation","summary":"  Diffusion-based image translation guided by semantic texts or a single target\nimage has enabled flexible style transfer which is not limited to the specific\ndomains. Unfortunately, due to the stochastic nature of diffusion models, it is\noften difficult to maintain the original content of the image during the\nreverse diffusion. To address this, here we present a novel diffusion-based\nunsupervised image translation method using disentangled style and content\nrepresentation.\n  Specifically, inspired by the splicing Vision Transformer, we extract\nintermediate keys of multihead self attention layer from ViT model and used\nthem as the content preservation loss. Then, an image guided style transfer is\nperformed by matching the [CLS] classification token from the denoised samples\nand target image, whereas additional CLIP loss is used for the text-driven\nstyle transfer. To further accelerate the semantic change during the reverse\ndiffusion, we also propose a novel semantic divergence loss and resampling\nstrategy. Our experimental results show that the proposed method outperforms\nstate-of-the-art baseline models in both text-guided and image-guided\ntranslation tasks.\n","authors":["Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2209.15264v2.pdf","comment":"ICLR 2023 camera ready"},{"id":"http://arxiv.org/abs/2302.00353v1","updated":"2023-02-01T10:24:55Z","published":"2023-02-01T10:24:55Z","title":"Towards Label-Efficient Incremental Learning: A Survey","summary":"  The current dominant paradigm when building a machine learning model is to\niterate over a dataset over and over until convergence. Such an approach is\nnon-incremental, as it assumes access to all images of all categories at once.\nHowever, for many applications, non-incremental learning is unrealistic. To\nthat end, researchers study incremental learning, where a learner is required\nto adapt to an incoming stream of data with a varying distribution while\npreventing forgetting of past knowledge. Significant progress has been made,\nhowever, the vast majority of works focus on the fully supervised setting,\nmaking these algorithms label-hungry thus limiting their real-life deployment.\nTo that end, in this paper, we make the first attempt to survey recently\ngrowing interest in label-efficient incremental learning. We identify three\nsubdivisions, namely semi-, few-shot- and self-supervised learning to reduce\nlabeling efforts. Finally, we identify novel directions that can further\nenhance label-efficiency and improve incremental learning scalability. Project\nwebsite: {https://github.com/kilickaya/label-efficient-il.\n","authors":["Mert Kilickaya","Joost van de Weijer","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2302.00353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.09151v5","updated":"2023-02-01T10:12:11Z","published":"2021-03-16T15:47:34Z","title":"Adversarial Driving: Attacking End-to-End Autonomous Driving","summary":"  As research in deep neural networks advances, deep convolutional networks\nbecome promising for autonomous driving tasks. In particular, there is an\nemerging trend of employing end-to-end neural network models for autonomous\ndriving. However, previous research has shown that deep neural network\nclassifiers are vulnerable to adversarial attacks. While for regression tasks,\nthe effect of adversarial attacks is not as well understood. In this research,\nwe devise two white-box targeted attacks against end-to-end autonomous driving\nmodels. The driving system uses a regression model that takes an image as input\nand outputs the steering angle. Our attacks manipulate the behavior of the\nautonomous driving system by perturbing the input image. Both attacks can be\ninitiated in real-time on CPUs without employing GPUs. The efficiency of the\nattacks is illustrated using experiments conducted in Udacity Simulator. Demo\nvideo: https://youtu.be/I0i8uN2oOP0.\n","authors":["Han Wu","Syed Yunas","Sareh Rowlands","Wenjie Ruan","Johan Wahlstrom"],"pdf_url":"https://arxiv.org/pdf/2103.09151v5.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2209.01962v3","updated":"2023-02-01T10:10:02Z","published":"2022-09-05T13:32:41Z","title":"Adversarial Detection: Attacking Object Detection in Real Time","summary":"  Intelligent robots rely on object detection models to perceive the\nenvironment. Following advances in deep learning security it has been revealed\nthat object detection models are vulnerable to adversarial attacks. However,\nprior research primarily focuses on attacking static images or offline videos.\nTherefore, it is still unclear if such attacks could jeopardize real-world\nrobotic applications in dynamic environments. This paper bridges this gap by\npresenting the first real-time online attack against object detection models.\nWe devise three attacks that fabricate bounding boxes for nonexistent objects\nat desired locations. The attacks achieve a success rate of about 90\\% within\nabout 20 iterations. The demo video is available at\nhttps://youtu.be/zJZ1aNlXsMU.\n","authors":["Han Wu","Syed Yunas","Sareh Rowlands","Wenjie Ruan","Johan Wahlstrom"],"pdf_url":"https://arxiv.org/pdf/2209.01962v3.pdf","comment":"7 pages, 9 figures"},{"id":"http://arxiv.org/abs/2208.12055v5","updated":"2023-02-01T09:56:45Z","published":"2022-08-25T12:33:31Z","title":"Combating Mode Collapse in GANs via Manifold Entropy Estimation","summary":"  Generative Adversarial Networks (GANs) have shown compelling results in\nvarious tasks and applications in recent years. However, mode collapse remains\na critical problem in GANs. In this paper, we propose a novel training pipeline\nto address the mode collapse issue of GANs. Different from existing methods, we\npropose to generalize the discriminator as feature embedding and maximize the\nentropy of distributions in the embedding space learned by the discriminator.\nSpecifically, two regularization terms, i.e., Deep Local Linear Embedding\n(DLLE) and Deep Isometric feature Mapping (DIsoMap), are designed to encourage\nthe discriminator to learn the structural information embedded in the data,\nsuch that the embedding space learned by the discriminator can be well-formed.\nBased on the well-learned embedding space supported by the discriminator, a\nnon-parametric entropy estimator is designed to efficiently maximize the\nentropy of embedding vectors, playing as an approximation of maximizing the\nentropy of the generated distribution. By improving the discriminator and\nmaximizing the distance of the most similar samples in the embedding space, our\npipeline effectively reduces the mode collapse without sacrificing the quality\nof generated samples. Extensive experimental results show the effectiveness of\nour method, which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs.\n12.43 in FID) and surpasses the recent state-of-the-art energy-based model on\nthe ANIME-FACE dataset (2.80 vs. 2.26 in Inception score). The code is\navailable at https://github.com/HaozheLiu-ST/MEE\n","authors":["Haozhe Liu","Bing Li","Haoqian Wu","Hanbang Liang","Yawen Huang","Yuexiang Li","Bernard Ghanem","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2208.12055v5.pdf","comment":"Accepted by AAAI'2023 (Oral); Code is released at\n  https://github.com/HaozheLiu-ST/MEE"},{"id":"http://arxiv.org/abs/2302.00332v1","updated":"2023-02-01T09:29:20Z","published":"2023-02-01T09:29:20Z","title":"iPAL: A Machine Learning Based Smart Healthcare Framework For Automatic\n  Diagnosis Of Attention Deficit/Hyperactivity Disorder (ADHD)","summary":"  ADHD is a prevalent disorder among the younger population. Standard\nevaluation techniques currently use evaluation forms, interviews with the\npatient, and more. However, its symptoms are similar to those of many other\ndisorders like depression, conduct disorder, and oppositional defiant disorder,\nand these current diagnosis techniques are not very effective. Thus, a\nsophisticated computing model holds the potential to provide a promising\ndiagnosis solution to this problem. This work attempts to explore methods to\ndiagnose ADHD using combinations of multiple established machine learning\ntechniques like neural networks and SVM models on the ADHD200 dataset and\nexplore the field of neuroscience. In this work, multiclass classification is\nperformed on phenotypic data using an SVM model. The better results have been\nanalyzed on the phenotypic data compared to other supervised learning\ntechniques like Logistic regression, KNN, AdaBoost, etc. In addition, neural\nnetworks have been implemented on functional connectivity from the MRI data of\na sample of 40 subjects provided to achieve high accuracy without prior\nknowledge of neuroscience. It is combined with the phenotypic classifier using\nthe ensemble technique to get a binary classifier. It is further trained and\ntested on 400 out of 824 subjects from the ADHD200 data set and achieved an\naccuracy of 92.5% for binary classification The training and testing accuracy\nhas been achieved upto 99% using ensemble classifier.\n","authors":["Abhishek Sharma","Arpit Jain","Shubhangi Sharma","Ashutosh Gupta","Prateek Jain","Saraju P. Mohanty"],"pdf_url":"https://arxiv.org/pdf/2302.00332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13670v2","updated":"2023-02-01T08:38:14Z","published":"2023-01-31T14:40:05Z","title":"What Makes Good Examples for Visual In-Context Learning?","summary":"  Large-scale models trained on broad data have recently become the mainstream\narchitecture in computer vision due to their strong generalization performance.\nIn this paper, the main focus is on an emergent ability in large vision models,\nknown as in-context learning, which allows inference on unseen tasks by\nconditioning on in-context examples (a.k.a.~prompt) without updating the model\nparameters. This concept has been well-known in natural language processing but\nhas only been studied very recently for large vision models. We for the first\ntime provide a comprehensive investigation on the impact of in-context examples\nin computer vision, and find that the performance is highly sensitive to the\nchoice of in-context examples. To overcome the problem, we propose a prompt\nretrieval framework to automate the selection of in-context examples.\nSpecifically, we present (1) an unsupervised prompt retrieval method based on\nnearest example search using an off-the-shelf model, and (2) a supervised\nprompt retrieval method, which trains a neural network to choose examples that\ndirectly maximize in-context learning performance. The results demonstrate that\nour methods can bring non-trivial improvements to visual in-context learning in\ncomparison to the commonly-used random selection.\n","authors":["Yuanhan Zhang","Kaiyang Zhou","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2301.13670v2.pdf","comment":"code and\n  models:https://github.com/ZhangYuanhan-AI/visual_prompt_retrieval"},{"id":"http://arxiv.org/abs/2211.16762v2","updated":"2023-02-01T08:10:13Z","published":"2022-11-30T06:02:01Z","title":"GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided\n  Distance Representation","summary":"  The recent neural implicit representation-based methods have greatly advanced\nthe state of the art for solving the long-standing and challenging problem of\nreconstructing a discrete surface from a sparse point cloud. These methods\ngenerally learn either a binary occupancy or signed/unsigned distance field\n(SDF/UDF) as surface representation. However, existing SDF/UDF-based methods\nuse neural networks to implicitly regress the distance in a purely data-driven\nmanner, thus limiting the accuracy and generalizability to some extent. In\ncontrast, we propose the first geometry-guided method for UDF and its gradient\nestimation that explicitly formulates the unsigned distance of a query point as\nthe learnable affine averaging of its distances to the tangent planes of\nneighbouring points. Besides, we model the local geometric structure of the\ninput point clouds by explicitly learning a quadratic polynomial for each\npoint. This not only facilitates upsampling the input sparse point cloud but\nalso naturally induces unoriented normal, which further augments UDF\nestimation. Finally, to extract triangle meshes from the predicted UDF we\npropose a customized edge-based marching cube module. We conduct extensive\nexperiments and ablation studies to demonstrate the significant advantages of\nour method over state-of-the-art methods in terms of reconstruction accuracy,\nefficiency, and generalizability. The source code is publicly available at\nhttps://github.com/rsy6318/GeoUDF.\n","authors":["Siyu Ren","Junhui Hou","Xiaodong Chen","Ying He","Wenping Wang"],"pdf_url":"https://arxiv.org/pdf/2211.16762v2.pdf","comment":"1 correct some unclear claim 2 add the results of DOG 3 redraw some\n  figures"},{"id":"http://arxiv.org/abs/2302.00291v1","updated":"2023-02-01T07:45:54Z","published":"2023-02-01T07:45:54Z","title":"Development of Real-time Rendering Technology for High-Precision Models\n  in Autonomous Driving","summary":"  Our autonomous driving simulation lab produces a high-precision 3D model\nsimulating the parking lot. However, the current model still has poor rendering\nquality in some aspects. In this work, we develop a system to improve the\nrendering of the model and evaluate the quality of the rendered model.\n","authors":["Zhang Whencheng","Wang Chengyi"],"pdf_url":"https://arxiv.org/pdf/2302.00291v1.pdf","comment":"3 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.00290v1","updated":"2023-02-01T07:45:10Z","published":"2023-02-01T07:45:10Z","title":"Multispectral Pedestrian Detection via Reference Box Constrained Cross\n  Attention and Modality Balanced Optimization","summary":"  Multispectral pedestrian detection is an important task for many\naround-the-clock applications, since the visible and thermal modalities can\nprovide complementary information especially under low light conditions. To\nreduce the influence of hand-designed components in available multispectral\npedestrian detectors, we propose a MultiSpectral pedestrian DEtection\nTRansformer (MS-DETR), which extends deformable DETR to multi-modal paradigm.\nIn order to facilitate the multi-modal learning process, a Reference box\nConstrained Cross-Attention (RCCA) module is firstly introduced to the\nmulti-modal Transformer decoder, which takes fusion branch together with the\nreference boxes as intermediaries to enable the interaction of visible and\nthermal modalities. To further balance the contribution of different\nmodalities, we design a modality-balanced optimization strategy, which aligns\nthe slots of decoders by adaptively adjusting the instance-level weight of\nthree branches. Our end-to-end MS-DETR shows superior performance on the\nchallenging KAIST and CVC-14 benchmark datasets.\n","authors":["Yinghui Xing","Song Wang","Guoqiang Liang","Qingyi Li","Xiuwei Zhang","Shizhou Zhang","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11696v3","updated":"2023-02-01T07:16:40Z","published":"2022-12-22T13:37:59Z","title":"Reversible Column Networks","summary":"  We propose a new neural network design paradigm Reversible Column Network\n(RevCol). The main body of RevCol is composed of multiple copies of\nsubnetworks, named columns respectively, between which multi-level reversible\nconnections are employed. Such architectural scheme attributes RevCol very\ndifferent behavior from conventional networks: during forward propagation,\nfeatures in RevCol are learned to be gradually disentangled when passing\nthrough each column, whose total information is maintained rather than\ncompressed or discarded as other network does. Our experiments suggest that\nCNN-style RevCol models can achieve very competitive performances on multiple\ncomputer vision tasks such as image classification, object detection and\nsemantic segmentation, especially with large parameter budget and large\ndataset. For example, after ImageNet-22K pre-training, RevCol-XL obtains 88.2%\nImageNet-1K accuracy. Given more pre-training data, our largest model RevCol-H\nreaches 90.0% on ImageNet-1K, 63.8% APbox on COCO detection minival set, 61.0%\nmIoU on ADE20k segmentation. To our knowledge, it is the best COCO detection\nand ADE20k segmentation result among pure (static) CNN models. Moreover, as a\ngeneral macro architecture fashion, RevCol can also be introduced into\ntransformers or other neural networks, which is demonstrated to improve the\nperformances in both computer vision and NLP tasks. We release code and models\nat https://github.com/megvii-research/RevCol\n","authors":["Yuxuan Cai","Yizhuang Zhou","Qi Han","Jianjian Sun","Xiangwen Kong","Jun Li","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11696v3.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.00275v1","updated":"2023-02-01T06:44:07Z","published":"2023-02-01T06:44:07Z","title":"Learning Generalized Zero-Shot Learners for Open-Domain Image\n  Geolocalization","summary":"  Image geolocalization is the challenging task of predicting the geographic\ncoordinates of origin for a given photo. It is an unsolved problem relying on\nthe ability to combine visual clues with general knowledge about the world to\nmake accurate predictions across geographies. We present\n$\\href{https://huggingface.co/geolocal/StreetCLIP}{\\text{StreetCLIP}}$, a\nrobust, publicly available foundation model not only achieving state-of-the-art\nperformance on multiple open-domain image geolocalization benchmarks but also\ndoing so in a zero-shot setting, outperforming supervised models trained on\nmore than 4 million images. Our method introduces a meta-learning approach for\ngeneralized zero-shot learning by pretraining CLIP from synthetic captions,\ngrounding CLIP in a domain of choice. We show that our method effectively\ntransfers CLIP's generalized zero-shot capabilities to the domain of image\ngeolocalization, improving in-domain generalized zero-shot performance without\nfinetuning StreetCLIP on a fixed set of classes.\n","authors":["Lukas Haas","Silas Alberti","Michal Skreta"],"pdf_url":"https://arxiv.org/pdf/2302.00275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00268v1","updated":"2023-02-01T06:20:54Z","published":"2023-02-01T06:20:54Z","title":"Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video\n  Relation Detection","summary":"  Prompt tuning with large-scale pretrained vision-language models empowers\nopen-vocabulary predictions trained on limited base categories, e.g., object\nclassification and detection. In this paper, we propose compositional prompt\ntuning with motion cues: an extended prompt tuning paradigm for compositional\npredictions of video data. In particular, we present Relation Prompt (RePro)\nfor Open-vocabulary Video Visual Relation Detection (Open-VidVRD), where\nconventional prompt tuning is easily biased to certain subject-object\ncombinations and motion patterns. To this end, RePro addresses the two\ntechnical challenges of Open-VidVRD: 1) the prompt tokens should respect the\ntwo different semantic roles of subject and object, and 2) the tuning should\naccount for the diverse spatio-temporal motion patterns of the subject-object\ncompositions. Without bells and whistles, our RePro achieves a new\nstate-of-the-art performance on two VidVRD benchmarks of not only the base\ntraining object and predicate categories, but also the unseen ones. Extensive\nablations also demonstrate the effectiveness of the proposed compositional and\nmulti-mode design of prompts. Code is available at\nhttps://github.com/Dawn-LX/OpenVoc-VidVRD.\n","authors":["Kaifeng Gao","Long Chen","Hanwang Zhang","Jun Xiao","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2302.00268v1.pdf","comment":"accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2210.01112v2","updated":"2023-02-01T06:12:26Z","published":"2022-10-03T17:51:54Z","title":"Generative Category-Level Shape and Pose Estimation with Semantic\n  Primitives","summary":"  Empowering autonomous agents with 3D understanding for daily objects is a\ngrand challenge in robotics applications. When exploring in an unknown\nenvironment, existing methods for object pose estimation are still not\nsatisfactory due to the diversity of object shapes. In this paper, we propose a\nnovel framework for category-level object shape and pose estimation from a\nsingle RGB-D image. To handle the intra-category variation, we adopt a semantic\nprimitive representation that encodes diverse shapes into a unified latent\nspace, which is the key to establish reliable correspondences between observed\npoint clouds and estimated shapes. Then, by using a SIM(3)-invariant shape\ndescriptor, we gracefully decouple the shape and pose of an object, thus\nsupporting latent shape optimization of target objects in arbitrary poses.\nExtensive experiments show that the proposed method achieves SOTA pose\nestimation performance and better generalization in the real-world dataset.\nCode and video are available at https://zju3dv.github.io/gCasp.\n","authors":["Guanglin Li","Yifeng Li","Zhichao Ye","Qihang Zhang","Tao Kong","Zhaopeng Cui","Guofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.01112v2.pdf","comment":"CoRL 2022, 18 pages, 13 figures, typos corrected, references added"},{"id":"http://arxiv.org/abs/2106.10689v3","updated":"2023-02-01T06:00:21Z","published":"2021-06-20T12:59:42Z","title":"NeuS: Learning Neural Implicit Surfaces by Volume Rendering for\n  Multi-view Reconstruction","summary":"  We present a novel neural surface reconstruction method, called NeuS, for\nreconstructing objects and scenes with high fidelity from 2D image inputs.\nExisting neural surface reconstruction approaches, such as DVR and IDR, require\nforeground mask as supervision, easily get trapped in local minima, and\ntherefore struggle with the reconstruction of objects with severe\nself-occlusion or thin structures. Meanwhile, recent neural methods for novel\nview synthesis, such as NeRF and its variants, use volume rendering to produce\na neural scene representation with robustness of optimization, even for highly\ncomplex objects. However, extracting high-quality surfaces from this learned\nimplicit representation is difficult because there are not sufficient surface\nconstraints in the representation. In NeuS, we propose to represent a surface\nas the zero-level set of a signed distance function (SDF) and develop a new\nvolume rendering method to train a neural SDF representation. We observe that\nthe conventional volume rendering method causes inherent geometric errors (i.e.\nbias) for surface reconstruction, and therefore propose a new formulation that\nis free of bias in the first order of approximation, thus leading to more\naccurate surface reconstruction even without the mask supervision. Experiments\non the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the\nstate-of-the-arts in high-quality surface reconstruction, especially for\nobjects and scenes with complex structures and self-occlusion.\n","authors":["Peng Wang","Lingjie Liu","Yuan Liu","Christian Theobalt","Taku Komura","Wenping Wang"],"pdf_url":"https://arxiv.org/pdf/2106.10689v3.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2209.03139v2","updated":"2023-02-01T05:44:42Z","published":"2022-09-04T18:01:09Z","title":"Pixel-Level Equalized Matching for Video Object Segmentation","summary":"  Feature similarity matching, which transfers the information of the reference\nframe to the query frame, is a key component in semi-supervised video object\nsegmentation. If surjective matching is adopted, background distractors can\neasily occur and degrade the performance. Bijective matching mechanisms try to\nprevent this by restricting the amount of information being transferred to the\nquery frame, but have two limitations: 1) surjective matching cannot be fully\nleveraged as it is transformed to bijective matching at test time; and 2)\ntest-time manual tuning is required for searching the optimal hyper-parameters.\nTo overcome these limitations while ensuring reliable information transfer, we\nintroduce an equalized matching mechanism. To prevent the reference frame\ninformation from being overly referenced, the potential contribution to the\nquery frame is equalized by simply applying a softmax operation along with the\nquery. On public benchmark datasets, our proposed approach achieves a\ncomparable performance to state-of-the-art methods.\n","authors":["Suhwan Cho","Woo Jin Kim","MyeongAh Cho","Seunghoon Lee","Minhyeok Lee","Chaewon Park","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2209.03139v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06642v3","updated":"2023-02-01T04:41:44Z","published":"2022-10-13T00:48:18Z","title":"What's in a Decade? Transforming Faces Through Time","summary":"  How can one visually characterize people in a decade? In this work, we\nassemble the Faces Through Time dataset, which contains over a thousand\nportrait images from each decade, spanning the 1880s to the present day. Using\nour new dataset, we present a framework for resynthesizing portrait images\nacross time, imagining how a portrait taken during a particular decade might\nhave looked like, had it been taken in other decades. Our framework optimizes a\nfamily of per-decade generators that reveal subtle changes that differentiate\ndecade--such as different hairstyles or makeup--while maintaining the identity\nof the input portrait. Experiments show that our method is more effective in\nresynthesizing portraits across time compared to state-of-the-art\nimage-to-image translation methods, as well as attribute-based and\nlanguage-guided portrait editing models. Our code and data will be available at\nhttps://facesthroughtime.github.io\n","authors":["Eric Ming Chen","Jin Sun","Apoorv Khandelwal","Dani Lischinski","Noah Snavely","Hadar Averbuch-Elor"],"pdf_url":"https://arxiv.org/pdf/2210.06642v3.pdf","comment":"Project Page: https://facesthroughtime.github.io"},{"id":"http://arxiv.org/abs/2302.00232v1","updated":"2023-02-01T04:22:59Z","published":"2023-02-01T04:22:59Z","title":"SPIDE: A Purely Spike-based Method for Training Feedback Spiking Neural\n  Networks","summary":"  Spiking neural networks (SNNs) with event-based computation are promising\nbrain-inspired models for energy-efficient applications on neuromorphic\nhardware. However, most supervised SNN training methods, such as conversion\nfrom artificial neural networks or direct training with surrogate gradients,\nrequire complex computation rather than spike-based operations of spiking\nneurons during training. In this paper, we study spike-based implicit\ndifferentiation on the equilibrium state (SPIDE) that extends the recently\nproposed training method, implicit differentiation on the equilibrium state\n(IDE), for supervised learning with purely spike-based computation, which\ndemonstrates the potential for energy-efficient training of SNNs. Specifically,\nwe introduce ternary spiking neuron couples and prove that implicit\ndifferentiation can be solved by spikes based on this design, so the whole\ntraining procedure, including both forward and backward passes, is made as\nevent-driven spike computation, and weights are updated locally with two-stage\naverage firing rates. Then we propose to modify the reset membrane potential to\nreduce the approximation error of spikes. With these key components, we can\ntrain SNNs with flexible structures in a small number of time steps and with\nfiring sparsity during training, and the theoretical estimation of energy costs\ndemonstrates the potential for high efficiency. Meanwhile, experiments show\nthat even with these constraints, our trained models can still achieve\ncompetitive results on MNIST, CIFAR-10, CIFAR-100, and CIFAR10-DVS. Our code is\navailable at https://github.com/pkuxmq/SPIDE-FSNN.\n","authors":["Mingqing Xiao","Qingyan Meng","Zongpeng Zhang","Yisen Wang","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2302.00232v1.pdf","comment":"Accepted by Neural Networks"},{"id":"http://arxiv.org/abs/2302.00225v1","updated":"2023-02-01T04:07:11Z","published":"2023-02-01T04:07:11Z","title":"The Past, Current, and Future of Neonatal Intensive Care Units with\n  Artificial Intelligence","summary":"  Artificial intelligence (AI), specifically a branch of AI called deep\nlearning (DL), has proven revolutionary developments in almost all fields, from\ncomputer vision to health sciences, and its effects in medicine have changed\nclinical applications significantly. Although some sub-fields of medicine such\nas pediatrics have been relatively slow in receiving critical benefits of AI,\nrelated research in pediatrics started to be accumulated to a significant level\ntoo. Hence, in this paper, we review recently developed machine learning and\ndeep learning based systems for neonatology applications. We systematically\nevaluate the role of AI in neonatology applications, define the methodologies,\nincluding algorithmic developments, and describe the remaining challenges in\nneonatal diseases. To date, survival analysis, neuroimaging, EEG, pattern\nanalysis of vital parameters, and retinopathy of prematurity diagnosis with AI\nhave been the main focus in neonatology. We have categorically summarized 96\nresearch articles, from 1996 to 2022, and discussed their pros and cons,\nrespectively. We also discuss possible directions for new AI models and the\nfuture of neonatology with the rising power of AI, suggesting roadmaps for\nintegration of AI into neonatal intensive care units.\n","authors":["Elif Keles","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2302.00225v1.pdf","comment":"58 pages, review article"},{"id":"http://arxiv.org/abs/2302.00224v1","updated":"2023-02-01T04:05:14Z","published":"2023-02-01T04:05:14Z","title":"Human Fall Detection- Multimodality Approach","summary":"  Falls have become more frequent in recent years, which has been harmful for\nsenior citizens.Therefore detecting falls have become important and several\ndata sets and machine learning model have been introduced related to fall\ndetection. In this project report, a human fall detection method is proposed\nusing a multi modality approach. We used the UP-FALL detection data set which\nis collected by dozens of volunteers using different sensors and two cameras.\nWe use wrist sensor with acclerometer data keeping labels to binary\nclassification, namely fall and no fall from the data set.We used fusion of\ncamera and sensor data to increase performance. The experimental results shows\nthat using only wrist data as compared to multi sensor for binary\nclassification did not impact the model prediction performance for fall\ndetection.\n","authors":["Xi Wang","Ramya Penta","Bhavya Sehgal","Dale Chen-Song"],"pdf_url":"https://arxiv.org/pdf/2302.00224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00220v1","updated":"2023-02-01T03:51:27Z","published":"2023-02-01T03:51:27Z","title":"Efficient Scopeformer: Towards Scalable and Rich Feature Extraction for\n  Intracranial Hemorrhage Detection","summary":"  The quality and richness of feature maps extracted by convolution neural\nnetworks (CNNs) and vision Transformers (ViTs) directly relate to the robust\nmodel performance. In medical computer vision, these information-rich features\nare crucial for detecting rare cases within large datasets. This work presents\nthe \"Scopeformer,\" a novel multi-CNN-ViT model for intracranial hemorrhage\nclassification in computed tomography (CT) images. The Scopeformer architecture\nis scalable and modular, which allows utilizing various CNN architectures as\nthe backbone with diversified output features and pre-training strategies. We\npropose effective feature projection methods to reduce redundancies among\nCNN-generated features and to control the input size of ViTs. Extensive\nexperiments with various Scopeformer models show that the model performance is\nproportional to the number of convolutional blocks employed in the feature\nextractor. Using multiple strategies, including diversifying the pre-training\nparadigms for CNNs, different pre-training datasets, and style transfer\ntechniques, we demonstrate an overall improvement in the model performance at\nvarious computational budgets. Later, we propose smaller compute-efficient\nScopeformer versions with three different types of input and output ViT\nconfigurations. Efficient Scopeformers use four different pre-trained CNN\narchitectures as feature extractors to increase feature richness. Our best\nEfficient Scopeformer model achieved an accuracy of 96.94\\% and a weighted\nlogarithmic loss of 0.083 with an eight times reduction in the number of\ntrainable parameters compared to the base Scopeformer. Another version of the\nEfficient Scopeformer model further reduced the parameter space by almost 17\ntimes with negligible performance reduction. Hybrid CNNs and ViTs might provide\nthe desired feature richness for developing accurate medical computer vision\nmodels\n","authors":["Yassine Barhoumi","Nidhal C. Bouaynaya","Ghulam Rasool"],"pdf_url":"https://arxiv.org/pdf/2302.00220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13721v2","updated":"2023-02-01T03:44:24Z","published":"2023-01-31T15:58:32Z","title":"DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models","summary":"  In this paper, targeting to understand the underlying explainable factors\nbehind observations and modeling the conditional generation process on these\nfactors, we propose a new task, disentanglement of diffusion probabilistic\nmodels (DPMs), to take advantage of the remarkable modeling ability of DPMs. To\ntackle this task, we further devise an unsupervised approach named DisDiff. For\nthe first time, we achieve disentangled representation learning in the\nframework of diffusion probabilistic models. Given a pre-trained DPM, DisDiff\ncan automatically discover the inherent factors behind the image data and\ndisentangle the gradient fields of DPM into sub-gradient fields, each\nconditioned on the representation of each discovered factor. We propose a novel\nDisentangling Loss for DisDiff to facilitate the disentanglement of the\nrepresentation and sub-gradients. The extensive experiments on synthetic and\nreal-world datasets demonstrate the effectiveness of DisDiff.\n","authors":["Tao Yang","Yuwang Wang","Yan Lv","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2301.13721v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00209v1","updated":"2023-02-01T03:25:43Z","published":"2023-02-01T03:25:43Z","title":"QCRS: Improve Randomized Smoothing using Quasi-Concave Optimization","summary":"  Randomized smoothing is currently the state-of-the-art method that provides\ncertified robustness for deep neural networks. However, it often cannot achieve\nan adequate certified region on real-world datasets. One way to obtain a larger\ncertified region is to use an input-specific algorithm instead of using a fixed\nGaussian filter for all data points. Several methods based on this idea have\nbeen proposed, but they either suffer from high computational costs or gain\nmarginal improvement in certified radius. In this work, we show that by\nexploiting the quasiconvex problem structure, we can find the optimal certified\nradii for most data points with slight computational overhead. This observation\nleads to an efficient and effective input-specific randomized smoothing\nalgorithm. We conduct extensive experiments and empirical analysis on Cifar10\nand ImageNet. The results show that the proposed method significantly enhances\nthe certified radii with low computational overhead.\n","authors":["Bo-Han Kung","Shang-Tse Chen"],"pdf_url":"https://arxiv.org/pdf/2302.00209v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2209.11820v3","updated":"2023-02-01T03:25:21Z","published":"2022-09-23T19:23:07Z","title":"Expanding the Deployment Envelope of Behavior Prediction via Adaptive\n  Meta-Learning","summary":"  Learning-based behavior prediction methods are increasingly being deployed in\nreal-world autonomous systems, e.g., in fleets of self-driving vehicles, which\nare beginning to commercially operate in major cities across the world. Despite\ntheir advancements, however, the vast majority of prediction systems are\nspecialized to a set of well-explored geographic regions or operational design\ndomains, complicating deployment to additional cities, countries, or\ncontinents. Towards this end, we present a novel method for efficiently\nadapting behavior prediction models to new environments. Our approach leverages\nrecent advances in meta-learning, specifically Bayesian regression, to augment\nexisting behavior prediction models with an adaptive layer that enables\nefficient domain transfer via offline fine-tuning, online adaptation, or both.\nExperiments across multiple real-world datasets demonstrate that our method can\nefficiently adapt to a variety of unseen environments.\n","authors":["Boris Ivanovic","James Harrison","Marco Pavone"],"pdf_url":"https://arxiv.org/pdf/2209.11820v3.pdf","comment":"12 pages, 13 figures, 2 tables. To appear at ICRA 2023"},{"id":"http://arxiv.org/abs/2208.05516v4","updated":"2023-02-01T03:18:41Z","published":"2022-08-10T18:24:23Z","title":"Quality Not Quantity: On the Interaction between Dataset Design and\n  Robustness of CLIP","summary":"  Web-crawled datasets have enabled remarkable generalization capabilities in\nrecent image-text models such as CLIP (Contrastive Language-Image pre-training)\nor Flamingo, but little is known about the dataset creation processes. In this\nwork, we introduce a testbed of six publicly available data sources - YFCC,\nLAION, Conceptual Captions, WIT, RedCaps, Shutterstock - to investigate how\npre-training distributions induce robustness in CLIP. We find that the\nperformance of the pre-training data varies substantially across distribution\nshifts, with no single data source dominating. Moreover, we systematically\nstudy the interactions between these data sources and find that combining\nmultiple sources does not necessarily yield better models, but rather dilutes\nthe robustness of the best individual data source. We complement our empirical\nfindings with theoretical insights from a simple setting, where combining the\ntraining data also results in diluted robustness. In addition, our theoretical\nmodel provides a candidate explanation for the success of the CLIP-based data\nfiltering technique recently employed in the LAION dataset. Overall our results\ndemonstrate that simply gathering a large amount of data from the web is not\nthe most effective way to build a pre-training dataset for robust\ngeneralization, necessitating further study into dataset design. Code is\navailable at https://github.com/mlfoundations/clip_quality_not_quantity.\n","authors":["Thao Nguyen","Gabriel Ilharco","Mitchell Wortsman","Sewoong Oh","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2208.05516v4.pdf","comment":"Oral paper at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.06384v2","updated":"2023-02-01T02:57:14Z","published":"2022-12-13T05:42:44Z","title":"PV3D: A 3D Generative Model for Portrait Video Generation","summary":"  Recent advances in generative adversarial networks (GANs) have demonstrated\nthe capabilities of generating stunning photo-realistic portrait images. While\nsome prior works have applied such image GANs to unconditional 2D portrait\nvideo generation and static 3D portrait synthesis, there are few works\nsuccessfully extending GANs for generating 3D-aware portrait videos. In this\nwork, we propose PV3D, the first generative framework that can synthesize\nmulti-view consistent portrait videos. Specifically, our method extends the\nrecent static 3D-aware image GAN to the video domain by generalizing the 3D\nimplicit neural representation to model the spatio-temporal space. To introduce\nmotion dynamics to the generation process, we develop a motion generator by\nstacking multiple motion layers to generate motion features via modulated\nconvolution. To alleviate motion ambiguities caused by camera/human motions, we\npropose a simple yet effective camera condition strategy for PV3D, enabling\nboth temporal and multi-view consistent video generation. Moreover, PV3D\nintroduces two discriminators for regularizing the spatial and temporal domains\nto ensure the plausibility of the generated portrait videos. These elaborated\ndesigns enable PV3D to generate 3D-aware motion-plausible portrait videos with\nhigh-quality appearance and geometry, significantly outperforming prior works.\nAs a result, PV3D is able to support many downstream applications such as\nanimating static portraits and view-consistent video motion editing. Code and\nmodels are released at https://showlab.github.io/pv3d.\n","authors":["Eric Zhongcong Xu","Jianfeng Zhang","Jun Hao Liew","Wenqing Zhang","Song Bai","Jiashi Feng","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2212.06384v2.pdf","comment":"Accepted to ICLR2023, Project Page https://showlab.github.io/pv3d"},{"id":"http://arxiv.org/abs/2302.00192v1","updated":"2023-02-01T02:53:34Z","published":"2023-02-01T02:53:34Z","title":"Density peak clustering using tensor network","summary":"  Tensor networks, which have been traditionally used to simulate many-body\nphysics, have recently gained significant attention in the field of machine\nlearning due to their powerful representation capabilities. In this work, we\npropose a density-based clustering algorithm inspired by tensor networks. We\nencode classical data into tensor network states on an extended Hilbert space\nand train the tensor network states to capture the features of the clusters.\nHere, we define density and related concepts in terms of fidelity, rather than\nusing a classical distance measure. We evaluate the performance of our\nalgorithm on six synthetic data sets, four real world data sets, and three\ncommonly used computer vision data sets. The results demonstrate that our\nmethod provides state-of-the-art performance on several synthetic data sets and\nreal world data sets, even when the number of clusters is unknown.\nAdditionally, our algorithm performs competitively with state-of-the-art\nalgorithms on the MNIST, USPS, and Fashion-MNIST image data sets. These\nfindings reveal the great potential of tensor networks for machine learning\napplications.\n","authors":["Xiao Shi","Yun Shang"],"pdf_url":"https://arxiv.org/pdf/2302.00192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00190v1","updated":"2023-02-01T02:47:53Z","published":"2023-02-01T02:47:53Z","title":"Neural Wavelet-domain Diffusion for 3D Shape Generation, Inversion, and\n  Manipulation","summary":"  This paper presents a new approach for 3D shape generation, inversion, and\nmanipulation, through a direct generative modeling on a continuous implicit\nrepresentation in wavelet domain. Specifically, we propose a compact wavelet\nrepresentation with a pair of coarse and detail coefficient volumes to\nimplicitly represent 3D shapes via truncated signed distance functions and\nmulti-scale biorthogonal wavelets. Then, we design a pair of neural networks: a\ndiffusion-based generator to produce diverse shapes in the form of the coarse\ncoefficient volumes and a detail predictor to produce compatible detail\ncoefficient volumes for introducing fine structures and details. Further, we\nmay jointly train an encoder network to learn a latent space for inverting\nshapes, allowing us to enable a rich variety of whole-shape and region-aware\nshape manipulations. Both quantitative and qualitative experimental results\nmanifest the compelling shape generation, inversion, and manipulation\ncapabilities of our approach over the state-of-the-art methods.\n","authors":["Jingyu Hu","Ka-Hei Hui","Zhengzhe Liu","Ruihui Li","Chi-Wing Fu"],"pdf_url":"https://arxiv.org/pdf/2302.00190v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.08725"},{"id":"http://arxiv.org/abs/2301.13384v2","updated":"2023-02-01T01:59:23Z","published":"2023-01-31T03:21:08Z","title":"GaitSADA: Self-Aligned Domain Adaptation for mmWave Gait Recognition","summary":"  mmWave radar-based gait recognition is a novel user identification method\nthat captures human gait biometrics from mmWave radar return signals. This\ntechnology offers privacy protection and is resilient to weather and lighting\nconditions. However, its generalization performance is yet unknown and limits\nits practical deployment. To address this problem, in this paper, a\nnon-synthetic dataset is collected and analyzed to reveal the presence of\nspatial and temporal domain shifts in mmWave gait biometric data, which\nsignificantly impacts identification accuracy. To address this issue, a novel\nself-aligned domain adaptation method called GaitSADA is proposed. GaitSADA\nimproves system generalization performance by using a two-stage semi-supervised\nmodel training approach. The first stage uses semi-supervised contrastive\nlearning and the second stage uses semi-supervised consistency training with\ncentroid alignment. Extensive experiments show that GaitSADA outperforms\nrepresentative domain adaptation methods by an average of 15.41% in low data\nregimes.\n","authors":["Ekkasit Pinyoanuntapong","Ayman Ali","Kalvik Jakkala","Pu Wang","Minwoo Lee","Qucheng Peng","Chen Chen","Zhi Sun"],"pdf_url":"https://arxiv.org/pdf/2301.13384v2.pdf","comment":"Submitted to ACM Transactions on Sensor Networks (TOSN)"},{"id":"http://arxiv.org/abs/2302.00179v1","updated":"2023-02-01T01:51:47Z","published":"2023-02-01T01:51:47Z","title":"Stable Attribute Group Editing for Reliable Few-shot Image Generation","summary":"  Few-shot image generation aims to generate data of an unseen category based\non only a few samples. Apart from basic content generation, a bunch of\ndownstream applications hopefully benefit from this task, such as low-data\ndetection and few-shot classification. To achieve this goal, the generated\nimages should guarantee category retention for classification beyond the visual\nquality and diversity. In our preliminary work, we present an ``editing-based''\nframework Attribute Group Editing (AGE) for reliable few-shot image generation,\nwhich largely improves the generation performance. Nevertheless, AGE's\nperformance on downstream classification is not as satisfactory as expected.\nThis paper investigates the class inconsistency problem and proposes Stable\nAttribute Group Editing (SAGE) for more stable class-relevant image generation.\nSAGE takes use of all given few-shot images and estimates a class center\nembedding based on the category-relevant attribute dictionary. Meanwhile,\naccording to the projection weights on the category-relevant attribute\ndictionary, we can select category-irrelevant attributes from the similar seen\ncategories. Consequently, SAGE injects the whole distribution of the novel\nclass into StyleGAN's latent space, thus largely remains the category retention\nand stability of the generated images. Going one step further, we find that\nclass inconsistency is a common problem in GAN-generated images for downstream\nclassification. Even though the generated images look photo-realistic and\nrequires no category-relevant editing, they are usually of limited help for\ndownstream classification. We systematically discuss this issue from both the\ngenerative model and classification model perspectives, and propose to boost\nthe downstream classification performance of SAGE by enhancing the pixel and\nfrequency components.\n","authors":["Guanqi Ding","Xinzhe Han","Shuhui Wang","Xin Jin","Dandan Tu","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2302.00179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00178v1","updated":"2023-02-01T01:51:45Z","published":"2023-02-01T01:51:45Z","title":"Program Generation from Diverse Video Demonstrations","summary":"  The ability to use inductive reasoning to extract general rules from multiple\nobservations is a vital indicator of intelligence. As humans, we use this\nability to not only interpret the world around us, but also to predict the\noutcomes of the various interactions we experience. Generalising over multiple\nobservations is a task that has historically presented difficulties for\nmachines to grasp, especially when requiring computer vision. In this paper, we\npropose a model that can extract general rules from video demonstrations by\nsimultaneously performing summarisation and translation. Our approach differs\nfrom prior works by framing the problem as a multi-sequence-to-sequence task,\nwherein summarisation is learnt by the model. This allows our model to utilise\nedge cases that would otherwise be suppressed or discarded by traditional\nsummarisation techniques. Additionally, we show that our approach can handle\nnoisy specifications without the need for additional filtering methods. We\nevaluate our model by synthesising programs from video demonstrations in the\nVizdoom environment achieving state-of-the-art results with a relative increase\nof 11.75% program accuracy on prior works\n","authors":["Anthony Manchin","Jamie Sherrah","Qi Wu","Anton van den Hengel"],"pdf_url":"https://arxiv.org/pdf/2302.00178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00164v1","updated":"2023-02-01T00:57:58Z","published":"2023-02-01T00:57:58Z","title":"Detection of Tomato Ripening Stages using Yolov3-tiny","summary":"  One of the most important agricultural products in Mexico is the tomato\n(Solanum lycopersicum), which occupies the 4th place national most produced\nproduct . Therefore, it is necessary to improve its production, building\nautomatic detection system that detect, classify an keep tacks of the fruits is\none way to archieve it. So, in this paper, we address the design of a computer\nvision system to detect tomatoes at different ripening stages. To solve the\nproblem, we use a neural network-based model for tomato classification and\ndetection. Specifically, we use the YOLOv3-tiny model because it is one of the\nlightest current deep neural networks. To train it, we perform two grid\nsearches testing several combinations of hyperparameters. Our experiments\nshowed an f1-score of 90.0% in the localization and classification of ripening\nstages in a custom dataset.\n","authors":["Gerardo Antonio Alvarez Hernández","Juan Carlos Olguin","Juan Irving Vasquez","Abril Valeria Uriarte","Maria Claudia Villicaña Torres"],"pdf_url":"https://arxiv.org/pdf/2302.00164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00162v1","updated":"2023-02-01T00:49:21Z","published":"2023-02-01T00:49:21Z","title":"Continual Segment: Towards a Single, Unified and Accessible Continual\n  Segmentation Model of 143 Whole-body Organs in CT Scans","summary":"  Deep learning empowers the mainstream medical image segmentation methods.\nNevertheless current deep segmentation approaches are not capable of\nefficiently and effectively adapting and updating the trained models when new\nincremental segmentation classes (along with new training datasets or not) are\nrequired to be added. In real clinical environment, it can be preferred that\nsegmentation models could be dynamically extended to segment new organs/tumors\nwithout the (re-)access to previous training datasets due to obstacles of\npatient privacy and data storage. This process can be viewed as a continual\nsemantic segmentation (CSS) problem, being understudied for multi-organ\nsegmentation. In this work, we propose a new architectural CSS learning\nframework to learn a single deep segmentation model for segmenting a total of\n143 whole-body organs. Using the encoder/decoder network structure, we\ndemonstrate that a continually-trained then frozen encoder coupled with\nincrementally-added decoders can extract and preserve sufficiently\nrepresentative image features for new classes to be subsequently and validly\nsegmented. To maintain a single network model complexity, we trim each decoder\nprogressively using neural architecture search and teacher-student based\nknowledge distillation. To incorporate with both healthy and pathological\norgans appearing in different datasets, a novel anomaly-aware and confidence\nlearning module is proposed to merge the overlapped organ predictions,\noriginated from different decoders. Trained and validated on 3D CT scans of\n2500+ patients from four datasets, our single network can segment total 143\nwhole-body organs with very high accuracy, closely reaching the upper bound\nperformance level by training four separate segmentation models (i.e., one\nmodel per dataset/task).\n","authors":["Zhanghexuan Ji","Dazhou Guo","Puyang Wang","Ke Yan","Jia Ge","Xianghua Ye","Minfeng Xu","Jingren Zhou","Le Lu","Mingchen Gao","Dakai Jin"],"pdf_url":"https://arxiv.org/pdf/2302.00162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.02342v2","updated":"2023-02-01T00:15:36Z","published":"2021-09-06T10:29:52Z","title":"Automated Cardiac Resting Phase Detection Targeted on the Right Coronary\n  Artery","summary":"  Static cardiac imaging such as late gadolinium enhancement, mapping, or 3-D\ncoronary angiography require prior information, e.g., the phase during a\ncardiac cycle with least motion, called resting phase (RP). The purpose of this\nwork is to propose a fully automated framework that allows the detection of the\nright coronary artery (RCA) RP within CINE series. The proposed prototype\nsystem consists of three main steps. First, the localization of the regions of\ninterest (ROI) is performed. Second, the cropped ROI series are taken for\ntracking motions over all time points. Third, the output motion values are used\nto classify RPs. In this work, we focused on the detection of the area with the\nouter edge of the cross-section of the RCA as our target. The proposed\nframework was evaluated on 102 clinically acquired dataset at 1.5T and 3T. The\nautomatically classified RPs were compared with the reference RPs annotated\nmanually by a expert for testing the robustness and feasibility of the\nframework. The predicted RCA RPs showed high agreement with the experts\nannotated RPs with 92.7% accuracy, 90.5% sensitivity and 95.0% specificity for\nthe unseen study dataset. The mean absolute difference of the start and end RP\nwas 13.6 $\\pm$ 18.6 ms for the validation study dataset (n=102). In this work,\nautomated RP detection has been introduced by the proposed framework and\ndemonstrated feasibility, robustness, and applicability for static imaging\nacquisitions.\n","authors":["Seung Su Yoon","Elisabeth Preuhs","Michaela Schmidt","Christoph Forman","Teodora Chitiboi","Puneet Sharma","Juliano Lara Fernandes","Christoph Tillmanns","Jens Wetzl","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2109.02342v2.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2023:001"},{"id":"http://arxiv.org/abs/2302.00785v1","updated":"2023-02-01T22:39:51Z","published":"2023-02-01T22:39:51Z","title":"SkinCon: A skin disease dataset densely annotated by domain experts for\n  fine-grained model debugging and analysis","summary":"  For the deployment of artificial intelligence (AI) in high-risk settings,\nsuch as healthcare, methods that provide interpretability/explainability or\nallow fine-grained error analysis are critical. Many recent methods for\ninterpretability/explainability and fine-grained error analysis use concepts,\nwhich are meta-labels that are semantically meaningful to humans. However,\nthere are only a few datasets that include concept-level meta-labels and most\nof these meta-labels are relevant for natural images that do not require domain\nexpertise. Densely annotated datasets in medicine focused on meta-labels that\nare relevant to a single disease such as melanoma. In dermatology, skin disease\nis described using an established clinical lexicon that allows clinicians to\ndescribe physical exam findings to one another. To provide a medical dataset\ndensely annotated by domain experts with annotations useful across multiple\ndisease processes, we developed SkinCon: a skin disease dataset densely\nannotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick\n17k dataset densely annotated with 48 clinical concepts, 22 of which have at\nleast 50 images representing the concept. The concepts used were chosen by two\ndermatologists considering the clinical descriptor terms used to describe skin\nlesions. Examples include \"plaque\", \"scale\", and \"erosion\". The same concepts\nwere also used to label 656 skin disease images from the Diverse Dermatology\nImages dataset, providing an additional external dataset with diverse skin tone\nrepresentations. We review the potential applications for the SkinCon dataset,\nsuch as probing models, concept-based explanations, and concept bottlenecks.\nFurthermore, we use SkinCon to demonstrate two of these use cases: debugging\nmistakes of an existing dermatology AI model with concepts and developing\ninterpretable models with post-hoc concept bottleneck models.\n","authors":["Roxana Daneshjou","Mert Yuksekgonul","Zhuo Ran Cai","Roberto Novoa","James Zou"],"pdf_url":"https://arxiv.org/pdf/2302.00785v1.pdf","comment":"NeurIPS 2022 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2209.09359v2","updated":"2023-02-01T22:10:17Z","published":"2022-09-19T21:40:32Z","title":"E-VFIA : Event-Based Video Frame Interpolation with Attention","summary":"  Video frame interpolation (VFI) is a fundamental vision task that aims to\nsynthesize several frames between two consecutive original video images. Most\nalgorithms aim to accomplish VFI by using only keyframes, which is an ill-posed\nproblem since the keyframes usually do not yield any accurate precision about\nthe trajectories of the objects in the scene. On the other hand, event-based\ncameras provide more precise information between the keyframes of a video. Some\nrecent state-of-the-art event-based methods approach this problem by utilizing\nevent data for better optical flow estimation to interpolate for video frame by\nwarping. Nonetheless, those methods heavily suffer from the ghosting effect. On\nthe other hand, some of kernel-based VFI methods that only use frames as input,\nhave shown that deformable convolutions, when backed up with transformers, can\nbe a reliable way of dealing with long-range dependencies. We propose\nevent-based video frame interpolation with attention (E-VFIA), as a lightweight\nkernel-based method. E-VFIA fuses event information with standard video frames\nby deformable convolutions to generate high quality interpolated frames. The\nproposed method represents events with high temporal resolution and uses a\nmulti-head self-attention mechanism to better encode event-based information,\nwhile being less vulnerable to blurring and ghosting artifacts; thus,\ngenerating crispier frames. The simulation results show that the proposed\ntechnique outperforms current state-of-the-art methods (both frame and\nevent-based) with a significantly smaller model size.\n","authors":["Onur Selim Kılıç","Ahmet Akman","A. Aydın Alatan"],"pdf_url":"https://arxiv.org/pdf/2209.09359v2.pdf","comment":"Accepted to 2023 IEEE International Conference on Robotics and\n  Automation (ICRA 2023)"},{"id":"http://arxiv.org/abs/2207.01685v2","updated":"2023-02-01T20:53:18Z","published":"2022-07-04T19:30:41Z","title":"Interaction Transformer for Human Reaction Generation","summary":"  We address the challenging task of human reaction generation, which aims to\ngenerate a corresponding reaction based on an input action. Most of the\nexisting works do not focus on generating and predicting the reaction and\ncannot generate the motion when only the action is given as input. To address\nthis limitation, we propose a novel interaction Transformer (InterFormer)\nconsisting of a Transformer network with both temporal and spatial attention.\nSpecifically, temporal attention captures the temporal dependencies of the\nmotion of both characters and of their interaction, while spatial attention\nlearns the dependencies between the different body parts of each character and\nthose which are part of the interaction. Moreover, we propose using graphs to\nincrease the performance of spatial attention via an interaction distance\nmodule that helps focus on nearby joints from both characters. Extensive\nexperiments on the SBU interaction, K3HI, and DuetDance datasets demonstrate\nthe effectiveness of InterFormer. Our method is general and can be used to\ngenerate more complex and long-term interactions. We also provide videos of\ngenerated reactions and the code with pre-trained models at\nhttps://github.com/CRISTAL-3DSAM/InterFormer\n","authors":["Baptiste Chopin","Hao Tang","Naima Otberdout","Mohamed Daoudi","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2207.01685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04575v2","updated":"2023-02-01T20:48:47Z","published":"2022-12-08T21:43:56Z","title":"DDM-NET: End-to-end learning of keypoint feature Detection, Description\n  and Matching for 3D localization","summary":"  In this paper, we propose an end-to-end framework that jointly learns\nkeypoint detection, descriptor representation and cross-frame matching for the\ntask of image-based 3D localization. Prior art has tackled each of these\ncomponents individually, purportedly aiming to alleviate difficulties in\neffectively train a holistic network. We design a self-supervised image warping\ncorrespondence loss for both feature detection and matching, a\nweakly-supervised epipolar constraints loss on relative camera pose learning,\nand a directional matching scheme that detects key-point features in a source\nimage and performs coarse-to-fine correspondence search on the target image. We\nleverage this framework to enforce cycle consistency in our matching module. In\naddition, we propose a new loss to robustly handle both definite inlier/outlier\nmatches and less-certain matches. The integration of these learning mechanisms\nenables end-to-end training of a single network performing all three\nlocalization components. Bench-marking our approach on public data-sets,\nexemplifies how such an end-to-end framework is able to yield more accurate\nlocalization that out-performs both traditional methods as well as\nstate-of-the-art weakly supervised methods.\n","authors":["Xiangyu Xu","Li Guan","Enrique Dunn","Haoxiang Li","Gang Hua"],"pdf_url":"https://arxiv.org/pdf/2212.04575v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.00672v1","updated":"2023-02-01T18:59:02Z","published":"2023-02-01T18:59:02Z","title":"'Generative CI' through Collective Response Systems","summary":"  How can many people (who may disagree) come together to answer a question or\nmake a decision? \"Collective response systems\" are a type of generative\ncollective intelligence (CI) facilitation process meant to address this\nchallenge. They enable a form of \"generative voting\", where both the votes, and\nthe choices of what to vote on, are provided by the group. Such systems\novercome the traditional limitations of polling, town halls, standard voting,\nreferendums, etc. The generative CI outputs of collective response systems can\nalso be chained together into iterative \"collective dialogues\", analogously to\nsome kinds of generative AI.\n  Technical advances across domains including recommender systems, language\nmodels, and human-computer interaction have led to the development of\ninnovative and scalable collective response systems. For example, Polis has\nbeen used around the world to support policy-making at different levels of\ngovernment, and Remesh has been used by the UN to understand the challenges and\nneeds of ordinary people across war-torn countries. This paper aims to develop\na shared language by defining the structure, processes, properties, and\nprinciples of such systems.\n  Collective response systems allow non-confrontational exploration of divisive\nissues, help identify common ground, and elicit insights from those closest to\nthe issues. As a result, they can help overcome gridlock around conflict and\ngovernance challenges, increase trust, and develop mandates. Continued progress\ntoward their development and adoption could help revitalize democracies,\nreimagine corporate governance, transform conflict, and govern powerful AI\nsystems -- both as a complement to deeper deliberative democratic processes and\nas an option where deeper processes are not applicable or possible.\n","authors":["Aviv Ovadya"],"pdf_url":"https://arxiv.org/pdf/2302.00672v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2212.13937v2","updated":"2023-02-01T15:59:43Z","published":"2022-12-28T16:29:52Z","title":"Towards Disentangling Relevance and Bias in Unbiased Learning to Rank","summary":"  Unbiased learning to rank (ULTR) studies the problem of mitigating various\nbiases from implicit user feedback data such as clicks, and has been receiving\nconsiderable attention recently. A popular ULTR approach for real-world\napplications uses a two-tower architecture, where click modeling is factorized\ninto a relevance tower with regular input features, and a bias tower with\nbias-relevant inputs such as the position of a document. A successful\nfactorization will allow the relevance tower to be exempt from biases. In this\nwork, we identify a critical issue that existing ULTR methods ignored - the\nbias tower can be confounded with the relevance tower via the underlying true\nrelevance. In particular, the positions were determined by the logging policy,\ni.e., the previous production model, which would possess relevance information.\nWe give both theoretical analysis and empirical results to show the negative\neffects on relevance tower due to such a correlation. We then propose three\nmethods to mitigate the negative confounding effects by better disentangling\nrelevance and bias. Empirical results on both controlled public datasets and a\nlarge-scale industry dataset show the effectiveness of the proposed approaches.\n","authors":["Yunan Zhang","Le Yan","Zhen Qin","Honglei Zhuang","Jiaming Shen","Xuanhui Wang","Michael Bendersky","Marc Najork"],"pdf_url":"https://arxiv.org/pdf/2212.13937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11223v2","updated":"2023-02-01T15:21:22Z","published":"2023-01-26T16:56:52Z","title":"CitationSum: Citation-aware Graph Contrastive Learning for Scientific\n  Paper Summarization","summary":"  The citation graph is essential for generating high-quality summaries of\nscientific papers, in which references of a scientific paper and their\ncorrelations provide extra knowledge for understanding its background and main\ncontributions. Despite the promising role of the citation graph, effectively\nincorporating it still remains a big challenge, given the difficulty of\naccurately identifying and leveraging relevant contents in references for a\nsource paper, as well as modelling their correlations of different intensities.\nExisting methods either ignore or utilize only abstracts indiscriminately from\nreferences, failing to tackle the challenge mentioned above. To fill the gap,\nwe propose a novel citation-aware scientific paper summarization framework\nbased on the citation graph, with the ability to accurately locate and\nincorporate the salient contents from references, as well as capture varying\nrelevance between source papers and their references. Specifically, we first\nbuild a domain-specific dataset PubMedCite with about 192K biomedical\nscientific papers and a large citation graph preserving 917K citation\nrelationships between them. It is characterized by preserving the salient\ncontents extracted from full texts of references, and the weighted correlation\nbetween the salient contents of references and the source paper. Based on it,\nwe design a self-supervised citation-aware summarization framework\n(CitationSum) with graph contrastive learning, which boosts the summarization\ngeneration by efficiently fusing the salient information in references with\nsource paper contents under the guidance of their correlations. Experimental\nresults show that our model outperforms the state-of-the-art methods, due to\nefficiently leveraging the information of references and citation correlations.\n","authors":["Zheheng Luo","Qianqian Xie","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2301.11223v2.pdf","comment":"accepted to WWW2023"},{"id":"http://arxiv.org/abs/2206.02593v3","updated":"2023-02-01T13:08:09Z","published":"2022-06-06T12:58:28Z","title":"Pessimistic Off-Policy Optimization for Learning to Rank","summary":"  Off-policy learning is a framework for optimizing policies without deploying\nthem, using data collected by another policy. In recommender systems, this is\nespecially challenging due to the imbalance in logged data: some items are\nrecommended and thus logged more frequently than others. This is further\nperpetuated when recommending a list of items, as the action space is\ncombinatorial. To address this challenge, we study pessimistic off-policy\noptimization for learning to rank. The key idea is to compute lower confidence\nbounds on parameters of click models and then return the list with the highest\npessimistic estimate of its value. This approach is computationally efficient\nand we analyze it. We study its Bayesian and frequentist variants, and overcome\nthe limitation of unknown prior by incorporating empirical Bayes. To show the\nempirical effectiveness of our approach, we compare it to off-policy optimizers\nthat use inverse propensity scores or neglect uncertainty. Our approach\noutperforms all baselines, is robust, and is also general.\n","authors":["Matej Cief","Branislav Kveton","Michal Kompan"],"pdf_url":"https://arxiv.org/pdf/2206.02593v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00360v1","updated":"2023-02-01T10:38:47Z","published":"2023-02-01T10:38:47Z","title":"Faster maximal clique enumeration in large real-world link streams","summary":"  Link streams offer a good model for representing interactions over time. They\nconsist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during\nthe whole time interval $[b,e]$. In this paper, we deal with the problem of\nenumerating maximal cliques in link streams. A clique is a pair\n$(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise\nduring the full interval $[t_0,t_1]$. It is maximal when neither its set of\nvertices nor its time interval can be increased. Some of the main works solving\nthis problem are based on the famous Bron-Kerbosch algorithm for enumerating\nmaximal cliques in graphs. We take this idea as a starting point to propose a\nnew algorithm which matches the cliques of the instantaneous graphs formed by\nlinks existing at a given time $t$ to the maximal cliques of the link stream.\nWe prove its validity and compute its complexity, which is better than the\nstate-of-the art ones in many cases of interest. We also study the\noutput-sensitive complexity, which is close to the output size, thereby showing\nthat our algorithm is efficient. To confirm this, we perform experiments on\nlink streams used in the state of the art, and on massive link streams, up to\n100 million links. In all cases our algorithm is faster, mostly by a factor of\nat least 10 and up to a factor of $10^4$. Moreover, it scales to massive link\nstreams for which the existing algorithms are not able to provide the solution.\n","authors":["Alexis Baudin","Clémence Magnien","Lionel Tabourier"],"pdf_url":"https://arxiv.org/pdf/2302.00360v1.pdf","comment":"27 pages, 6 figure, 5 tables, submitted to Journal of Graph\n  Algorithms and Applications"},{"id":"http://arxiv.org/abs/2206.05731v3","updated":"2023-02-01T07:47:28Z","published":"2022-06-12T13:03:47Z","title":"Human Mobility Prediction with Causal and Spatial-constrained Multi-task\n  Network","summary":"  Modeling human mobility helps to understand how people are accessing\nresources and physically contacting with each other in cities, and thus\ncontributes to various applications such as urban planning, epidemic control,\nand location-based advertisement. Next location prediction is one decisive task\nin individual human mobility modeling and is usually viewed as sequence\nmodeling, solved with Markov or RNN-based methods. However, the existing models\npaid little attention to the logic of individual travel decisions and the\nreproducibility of the collective behavior of population. To this end, we\npropose a Causal and Spatial-constrained Long and Short-term Learner (CSLSL)\nfor next location prediction. CSLSL utilizes a causal structure based on\nmulti-task learning to explicitly model the\n\"\\textit{when$\\rightarrow$what$\\rightarrow$where}\", a.k.a.\n\"\\textit{time$\\rightarrow$activity$\\rightarrow$location}\" decision logic. We\nnext propose a spatial-constrained loss function as an auxiliary task, to\nensure the consistency between the predicted and actual spatial distribution of\ntravelers' destinations. Moreover, CSLSL adopts modules named Long and\nShort-term Capturer (LSC) to learn the transition regularities across different\ntime spans. Extensive experiments on three real-world datasets show promising\nperformance improvements of CSLSL over baselines and confirm the effectiveness\nof introducing the causality and consistency constraints. The implementation is\navailable at https://github.com/urbanmobility/CSLSL.\n","authors":["Zongyuan Huang","Shengyuan Xu","Menghan Wang","Hansi Wu","Yanyan Xu","Yaohui Jin"],"pdf_url":"https://arxiv.org/pdf/2206.05731v3.pdf","comment":"Updated version"},{"id":"http://arxiv.org/abs/2302.00158v1","updated":"2023-02-01T00:35:35Z","published":"2023-02-01T00:35:35Z","title":"Fairness-aware Cross-Domain Recommendation","summary":"  Cross-Domain Recommendation (CDR) is an effective way to alleviate the\ncold-start problem. However, previous work severely ignores fairness and bias\nwhen learning the mapping function, which is used to obtain the representations\nfor fresh users in the target domain. To study this problem, in this paper, we\npropose a Fairness-aware Cross-Domain Recommendation model, called FairCDR. Our\nmethod achieves user-oriented group fairness by learning the fairness-aware\nmapping function. Since the overlapping data are quite limited and\ndistributionally biased, FairCDR leverages abundant non-overlapping users and\ninteractions to help alleviate these problems. Considering that each individual\nhas different influence on model fairness, we propose a new reweighing method\nbased on Influence Function (IF) to reduce unfairness while maintaining\nrecommendation accuracy. Extensive experiments are conducted to demonstrate the\neffectiveness of our model.\n","authors":["Jiakai Tang","Xu Chen","Xueyang Feng"],"pdf_url":"https://arxiv.org/pdf/2302.00158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00796v1","updated":"2023-02-01T23:03:22Z","published":"2023-02-01T23:03:22Z","title":"Unsupervised Entity Alignment for Temporal Knowledge Graphs","summary":"  Entity alignment (EA) is a fundamental data integration task that identifies\nequivalent entities between different knowledge graphs (KGs). Temporal\nKnowledge graphs (TKGs) extend traditional knowledge graphs by introducing\ntimestamps, which have received increasing attention. State-of-the-art\ntime-aware EA studies have suggested that the temporal information of TKGs\nfacilitates the performance of EA. However, existing studies have not\nthoroughly exploited the advantages of temporal information in TKGs. Also, they\nperform EA by pre-aligning entity pairs, which can be labor-intensive and thus\ninefficient.\n  In this paper, we present DualMatch which effectively fuses the relational\nand temporal information for EA. DualMatch transfers EA on TKGs into a weighted\ngraph matching problem. More specifically, DualMatch is equipped with an\nunsupervised method, which achieves EA without necessitating seed alignment.\nDualMatch has two steps: (i) encoding temporal and relational information into\nembeddings separately using a novel label-free encoder, Dual-Encoder; and (ii)\nfusing both information and transforming it into alignment using a novel\ngraph-matching-based decoder, GM-Decoder. DualMatch is able to perform EA on\nTKGs with or without supervision, due to its capability of effectively\ncapturing temporal information. Extensive experiments on three real-world TKG\ndatasets offer the insight that DualMatch outperforms the state-of-the-art\nmethods in terms of H@1 by 2.4% - 10.7% and MRR by 1.7% - 7.6%, respectively.\n","authors":["Xiaoze Liu","Junyang Wu","Tianyi Li","Lu Chen","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2302.00796v1.pdf","comment":"Accepted by The Web Conference (WWW) 2023 Research Track"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.00674v1","updated":"2023-02-01T18:59:36Z","published":"2023-02-01T18:59:36Z","title":"Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary\n  Data","summary":"  Few-shot learning involves learning an effective model from only a few\nlabeled datapoints. The use of a small training set makes it difficult to avoid\noverfitting but also makes few-shot learning applicable to many important\nreal-world settings. In this work, we focus on Few-shot Learning with Auxiliary\nData (FLAD), a training paradigm that assumes access to auxiliary data during\nfew-shot learning in hopes of improving generalization. Introducing auxiliary\ndata during few-shot learning leads to essential design choices where\nhand-designed heuristics can lead to sub-optimal performance. In this work, we\nfocus on automated sampling strategies for FLAD and relate them to the\nexplore-exploit dilemma that is central in multi-armed bandit settings. Based\non this connection we propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and\ncompare them with methods that either explore or exploit, finding that the\ncombination of exploration and exploitation is crucial. Using our proposed\nalgorithms to train T5 yields a 9% absolute improvement over the explicitly\nmulti-task pre-trained T0 model across 11 datasets.\n","authors":["Alon Albalak","Colin Raffel","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00674v1.pdf","comment":"19 pages, 7 figures, code available at\n  https://github.com/alon-albalak/FLAD"},{"id":"http://arxiv.org/abs/2302.00671v1","updated":"2023-02-01T18:58:20Z","published":"2023-02-01T18:58:20Z","title":"Efficient Multi-Task Reinforcement Learning via Selective Behavior\n  Sharing","summary":"  The ability to leverage shared behaviors between tasks is critical for\nsample-efficient multi-task reinforcement learning (MTRL). While prior methods\nhave primarily explored parameter and data sharing, direct behavior-sharing has\nbeen limited to task families requiring similar behaviors. Our goal is to\nextend the efficacy of behavior-sharing to more general task families that\ncould require a mix of shareable and conflicting behaviors. Our key insight is\nan agent's behavior across tasks can be used for mutually beneficial\nexploration. To this end, we propose a simple MTRL framework for identifying\nshareable behaviors over tasks and incorporating them to guide exploration. We\nempirically demonstrate how behavior sharing improves sample efficiency and\nfinal performance on manipulation and navigation MTRL tasks and is even\ncomplementary to parameter sharing. Result videos are available at\nhttps://sites.google.com/view/qmp-mtrl.\n","authors":["Grace Zhang","Ayush Jain","Injune Hwang","Shao-Hua Sun","Joseph J. Lim"],"pdf_url":"https://arxiv.org/pdf/2302.00671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10815v4","updated":"2023-02-01T18:57:31Z","published":"2022-06-22T02:42:04Z","title":"FedBC: Calibrating Global and Local Models via Federated Learning Beyond\n  Consensus","summary":"  In this work, we quantitatively calibrate the performance of global and local\nmodels in federated learning through a multi-criterion optimization-based\nframework, which we cast as a constrained program. The objective of a device is\nits local objective, which it seeks to minimize while satisfying nonlinear\nconstraints that quantify the proximity between the local and the global model.\nBy considering the Lagrangian relaxation of this problem, we develop a novel\nprimal-dual method called Federated Learning Beyond Consensus (\\texttt{FedBC}).\nTheoretically, we establish that \\texttt{FedBC} converges to a first-order\nstationary point at rates that matches the state of the art, up to an\nadditional error term that depends on a tolerance parameter introduced to\nscalarize the multi-criterion formulation. Finally, we demonstrate that\n\\texttt{FedBC} balances the global and local model test accuracy metrics across\na suite of datasets (Synthetic, MNIST, CIFAR-10, Shakespeare), achieving\ncompetitive performance with state-of-the-art.\n","authors":["Amrit Singh Bedi","Chen Fan","Alec Koppel","Anit Kumar Sahu","Brian M. Sadler","Furong Huang","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2206.10815v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00670v1","updated":"2023-02-01T18:57:01Z","published":"2023-02-01T18:57:01Z","title":"Stable Target Field for Reduced Variance Score Estimation in Diffusion\n  Models","summary":"  Diffusion models generate samples by reversing a fixed forward diffusion\nprocess. Despite already providing impressive empirical results, these\ndiffusion models algorithms can be further improved by reducing the variance of\nthe training targets in their denoising score-matching objective. We argue that\nthe source of such variance lies in the handling of intermediate noise-variance\nscales, where multiple modes in the data affect the direction of reverse paths.\nWe propose to remedy the problem by incorporating a reference batch which we\nuse to calculate weighted conditional scores as more stable training targets.\nWe show that the procedure indeed helps in the challenging intermediate regime\nby reducing (the trace of) the covariance of training targets. The new stable\ntargets can be seen as trading bias for reduced variance, where the bias\nvanishes with increasing reference batch size. Empirically, we show that the\nnew objective improves the image quality, stability, and training speed of\nvarious popular diffusion models across datasets with both general ODE and SDE\nsolvers. When used in combination with EDM, our method yields a current SOTA\nFID of 1.90 with 35 network evaluations on the unconditional CIFAR-10\ngeneration task. The code is available at https://github.com/Newbeeer/stf\n","authors":["Yilun Xu","Shangyuan Tong","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2302.00670v1.pdf","comment":"Accepted by ICLR 2023. Code available at:\n  https://github.com/Newbeeer/stf"},{"id":"http://arxiv.org/abs/2301.11494v2","updated":"2023-02-01T18:56:20Z","published":"2023-01-27T02:10:05Z","title":"Learning Vortex Dynamics for Fluid Inference and Prediction","summary":"  We propose a novel differentiable vortex particle (DVP) method to infer and\npredict fluid dynamics from a single video. Lying at its core is a\nparticle-based latent space to encapsulate the hidden, Lagrangian vortical\nevolution underpinning the observable, Eulerian flow phenomena. Our\ndifferentiable vortex particles are coupled with a learnable,\nvortex-to-velocity dynamics mapping to effectively capture the complex flow\nfeatures in a physically-constrained, low-dimensional space. This\nrepresentation facilitates the learning of a fluid simulator tailored to the\ninput video that can deliver robust, long-term future predictions. The value of\nour method is twofold: first, our learned simulator enables the inference of\nhidden physics quantities (e.g., velocity field) purely from visual\nobservation; secondly, it also supports future prediction, constructing the\ninput video's sequel along with its future dynamics evolution. We compare our\nmethod with a range of existing methods on both synthetic and real-world\nvideos, demonstrating improved reconstruction quality, visual plausibility, and\nphysical integrity.\n","authors":["Yitong Deng","Hong-Xing Yu","Jiajun Wu","Bo Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.11494v2.pdf","comment":"ICLR 2023, project webpage:\n  https://yitongdeng.github.io/vortex_learning_webpage/"},{"id":"http://arxiv.org/abs/2301.12083v2","updated":"2023-02-01T18:55:32Z","published":"2023-01-28T04:12:56Z","title":"Beyond Exponentially Fast Mixing in Average-Reward Reinforcement\n  Learning via Multi-Level Monte Carlo Actor-Critic","summary":"  Many existing reinforcement learning (RL) methods employ stochastic gradient\niteration on the back end, whose stability hinges upon a hypothesis that the\ndata-generating process mixes exponentially fast with a rate parameter that\nappears in the step-size selection. Unfortunately, this assumption is violated\nfor large state spaces or settings with sparse rewards, and the mixing time is\nunknown, making the step size inoperable. In this work, we propose an RL\nmethodology attuned to the mixing time by employing a multi-level Monte Carlo\nestimator for the critic, the actor, and the average reward embedded within an\nactor-critic (AC) algorithm. This method, which we call \\textbf{M}ulti-level\n\\textbf{A}ctor-\\textbf{C}ritic (MAC), is developed especially for\ninfinite-horizon average-reward settings and neither relies on oracle knowledge\nof the mixing time in its parameter selection nor assumes its exponential\ndecay; it, therefore, is readily applicable to applications with slower mixing\ntimes. Nonetheless, it achieves a convergence rate comparable to the\nstate-of-the-art AC algorithms. We experimentally show that these alleviated\nrestrictions on the technical conditions required for stability translate to\nsuperior performance in practice for RL problems with sparse rewards.\n","authors":["Wesley A. Suttle","Amrit Singh Bedi","Bhrij Patel","Brian M. Sadler","Alec Koppel","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2301.12083v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00662v1","updated":"2023-02-01T18:40:53Z","published":"2023-02-01T18:40:53Z","title":"Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous\n  Unobserved Confounders","summary":"  Offline reinforcement learning is important in domains such as medicine,\neconomics, and e-commerce where online experimentation is costly, dangerous or\nunethical, and where the true model is unknown. However, most methods assume\nall covariates used in the behavior policy's action decisions are observed.\nThis untestable assumption may be incorrect. We study robust policy evaluation\nand policy optimization in the presence of unobserved confounders. We assume\nthe extent of possible unobserved confounding can be bounded by a sensitivity\nmodel, and that the unobserved confounders are sequentially exogenous. We\npropose and analyze an (orthogonalized) robust fitted-Q-iteration that uses\nclosed-form solutions of the robust Bellman operator to derive a loss\nminimization problem for the robust Q function. Our algorithm enjoys the\ncomputational ease of fitted-Q-iteration and statistical improvements (reduced\ndependence on quantile estimation error) from orthogonalization. We provide\nsample complexity bounds, insights, and show effectiveness in simulations.\n","authors":["David Bruns-Smith","Angela Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.09932v3","updated":"2023-02-01T18:34:23Z","published":"2022-01-24T19:47:10Z","title":"Learning Optimal Fair Classification Trees: Trade-offs Between\n  Interpretability, Fairness, and Accuracy","summary":"  The increasing use of machine learning in high-stakes domains -- where\npeople's livelihoods are impacted -- creates an urgent need for interpretable,\nfair, and highly accurate algorithms. With these needs in mind, we propose a\nmixed integer optimization (MIO) framework for learning optimal classification\ntrees -- one of the most interpretable models -- that can be augmented with\narbitrary fairness constraints. In order to better quantify the \"price of\ninterpretability\", we also propose a new measure of model interpretability\ncalled decision complexity that allows for comparisons across different classes\nof machine learning models. We benchmark our method against state-of-the-art\napproaches for fair classification on popular datasets; in doing so, we conduct\none of the first comprehensive analyses of the trade-offs between\ninterpretability, fairness, and predictive accuracy. Given a fixed disparity\nthreshold, our method has a price of interpretability of about 4.2 percentage\npoints in terms of out-of-sample accuracy compared to the best performing,\ncomplex models. However, our method consistently finds decisions with almost\nfull parity, while other methods rarely do.\n","authors":["Nathanael Jo","Sina Aghaei","Andrés Gómez","Phebe Vayanos"],"pdf_url":"https://arxiv.org/pdf/2201.09932v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00658v1","updated":"2023-02-01T18:32:06Z","published":"2023-02-01T18:32:06Z","title":"Graph Neural Operators for Classification of Spatial Transcriptomics\n  Data","summary":"  The inception of spatial transcriptomics has allowed improved comprehension\nof tissue architectures and the disentanglement of complex underlying\nbiological, physiological, and pathological processes through their positional\ncontexts. Recently, these contexts, and by extension the field, have seen much\npromise and elucidation with the application of graph learning approaches. In\nparticular, neural operators have risen in regards to learning the mapping\nbetween infinite-dimensional function spaces. With basic to deep neural network\narchitectures being data-driven, i.e. dependent on quality data for prediction,\nneural operators provide robustness by offering generalization among different\nresolutions despite low quality data. Graph neural operators are a variant that\nutilize graph networks to learn this mapping between function spaces. The aim\nof this research is to identify robust machine learning architectures that\nintegrate spatial information to predict tissue types. Under this notion, we\npropose a study incorporating various graph neural network approaches to\nvalidate the efficacy of applying neural operators towards prediction of brain\nregions in mouse brain tissue samples as a proof of concept towards our\npurpose. We were able to achieve an F1 score of nearly 72% for the graph neural\noperator approach which outperformed all baseline and other graph network\napproaches.\n","authors":["Junaid Ahmed","Alhassan S. Yasin"],"pdf_url":"https://arxiv.org/pdf/2302.00658v1.pdf","comment":"5 pages, 8 figures, 1 table. To appear in conference proceedings and\n  journal publications"},{"id":"http://arxiv.org/abs/2211.15931v2","updated":"2023-02-01T18:26:37Z","published":"2022-11-29T05:09:35Z","title":"Posterior Sampling for Continuing Environments","summary":"  We develop an extension of posterior sampling for reinforcement learning\n(PSRL) that is suited for a continuing agent-environment interface and\nintegrates naturally into agent designs that scale to complex environments. The\napproach, continuing PSRL, maintains a statistically plausible model of the\nenvironment and follows a policy that maximizes expected $\\gamma$-discounted\nreturn in that model. At each time, with probability $1-\\gamma$, the model is\nreplaced by a sample from the posterior distribution over environments. For a\nchoice of discount factor that suitably depends on the horizon $T$, we\nestablish an $\\tilde{O}(\\tau S \\sqrt{A T})$ bound on the Bayesian regret, where\n$S$ is the number of environment states, $A$ is the number of actions, and\n$\\tau$ denotes the reward averaging time, which is a bound on the duration\nrequired to accurately estimate the average reward of any policy. Our work is\nthe first to formalize and rigorously analyze the resampling approach with\nrandomized exploration.\n","authors":["Wanqiao Xu","Shi Dong","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2211.15931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00646v1","updated":"2023-02-01T18:19:37Z","published":"2023-02-01T18:19:37Z","title":"Epic-Sounds: A Large-scale Dataset of Actions That Sound","summary":"  We introduce EPIC-SOUNDS, a large-scale dataset of audio annotations\ncapturing temporal extents and class labels within the audio stream of the\negocentric videos. We propose an annotation pipeline where annotators\ntemporally label distinguishable audio segments and describe the action that\ncould have caused this sound. We identify actions that can be discriminated\npurely from audio, through grouping these free-form descriptions of audio into\nclasses. For actions that involve objects colliding, we collect human\nannotations of the materials of these objects (e.g. a glass object being placed\non a wooden surface), which we verify from visual labels, discarding\nambiguities. Overall, EPIC-SOUNDS includes 78.4k categorised segments of\naudible events and actions, distributed across 44 classes as well as 39.2k\nnon-categorised segments. We train and evaluate two state-of-the-art audio\nrecognition models on our dataset, highlighting the importance of audio-only\nlabels and the limitations of current models to recognise actions that sound.\n","authors":["Jaesung Huh","Jacob Chalk","Evangelos Kazakos","Dima Damen","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2302.00646v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.07503v2","updated":"2023-02-01T18:12:24Z","published":"2023-01-12T19:18:07Z","title":"Model-agnostic machine learning of conservation laws from data","summary":"  We present a machine learning based method for learning first integrals of\nsystems of ordinary differential equations from given trajectory data. The\nmethod is model-agnostic in that it does not require explicit knowledge of the\nunderlying system of differential equations that generated the trajectories. As\na by-product, once the first integrals have been learned, also the system of\ndifferential equations will be known. We illustrate our method by considering\nseveral classical problems from the mathematical sciences.\n","authors":["Shivam Arora","Alex Bihlo","Rüdiger Brecht","Pavel Holba"],"pdf_url":"https://arxiv.org/pdf/2301.07503v2.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.00633v1","updated":"2023-02-01T17:52:40Z","published":"2023-02-01T17:52:40Z","title":"Deep Dependency Networks for Multi-Label Classification","summary":"  We propose a simple approach which combines the strengths of probabilistic\ngraphical models and deep learning architectures for solving the multi-label\nclassification task, focusing specifically on image and video data. First, we\nshow that the performance of previous approaches that combine Markov Random\nFields with neural networks can be modestly improved by leveraging more\npowerful methods such as iterative join graph propagation, integer linear\nprogramming, and $\\ell_1$ regularization-based structure learning. Then we\npropose a new modeling framework called deep dependency networks, which\naugments a dependency network, a model that is easy to train and learns more\naccurate dependencies but is limited to Gibbs sampling for inference, to the\noutput layer of a neural network. We show that despite its simplicity, jointly\nlearning this new architecture yields significant improvements in performance\nover the baseline neural network. In particular, our experimental evaluation on\nthree video activity classification datasets: Charades, Textually Annotated\nCooking Scenes (TACoS), and Wetlab, and three multi-label image classification\ndatasets: MS-COCO, PASCAL VOC, and NUS-WIDE show that deep dependency networks\nare almost always superior to pure neural architectures that do not use\ndependency networks.\n","authors":["Shivvrat Arya","Yu Xiang","Vibhav Gogate"],"pdf_url":"https://arxiv.org/pdf/2302.00633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00628v1","updated":"2023-02-01T17:46:47Z","published":"2023-02-01T17:46:47Z","title":"Training Normalizing Flows with the Precision-Recall Divergence","summary":"  Generative models can have distinct mode of failures like mode dropping and\nlow quality samples, which cannot be captured by a single scalar metric. To\naddress this, recent works propose evaluating generative models using precision\nand recall, where precision measures quality of samples and recall measures the\ncoverage of the target distribution. Although a variety of discrepancy measures\nbetween the target and estimated distribution are used to train generative\nmodels, it is unclear what precision-recall trade-offs are achieved by various\nchoices of the discrepancy measures. In this paper, we show that achieving a\nspecified precision-recall trade-off corresponds to minimising -divergences\nfrom a family we call the {\\em PR-divergences }. Conversely, any -divergence\ncan be written as a linear combination of PR-divergences and therefore\ncorrespond to minimising a weighted precision-recall trade-off. Further, we\npropose a novel generative model that is able to train a normalizing flow to\nminimise any -divergence, and in particular, achieve a given precision-recall\ntrade-off.\n","authors":["Alexandre Verine","Benjamin Negrevergne","Muni Sreenivas Pydi","Yann Chevaleyre"],"pdf_url":"https://arxiv.org/pdf/2302.00628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.01205v3","updated":"2023-02-01T17:36:34Z","published":"2022-04-04T02:12:03Z","title":"Model-Parallel Fourier Neural Operators as Learned Surrogates for\n  Large-Scale Parametric PDEs","summary":"  Fourier neural operators (FNOs) are a recently introduced neural network\narchitecture for learning solution operators of partial differential equations\n(PDEs), which have been shown to perform significantly better than comparable\ndeep learning approaches. Once trained, FNOs can achieve speed-ups of multiple\norders of magnitude over conventional numerical PDE solvers. However, due to\nthe high dimensionality of their input data and network weights, FNOs have so\nfar only been applied to two-dimensional or small three-dimensional problems.\nTo remove this limited problem-size barrier, we propose a model-parallel\nversion of FNOs based on domain-decomposition of both the input data and\nnetwork weights. We demonstrate that our model-parallel FNO is able to predict\ntime-varying PDE solutions of over 2.6 billion variables on Perlmutter using up\nto 512 A100 GPUs and show an example of training a distributed FNO on the Azure\ncloud for simulating multiphase CO$_2$ dynamics in the Earth's subsurface.\n","authors":["Thomas J. Grady II","Rishi Khan","Mathias Louboutin","Ziyi Yin","Philipp A. Witte","Ranveer Chandra","Russell J. Hewett","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2204.01205v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00617v1","updated":"2023-02-01T17:32:16Z","published":"2023-02-01T17:32:16Z","title":"Efficient Meta-Learning via Error-based Context Pruning for Implicit\n  Neural Representations","summary":"  We introduce an efficient optimization-based meta-learning technique for\nlearning large-scale implicit neural representations (INRs). Our main idea is\ndesigning an online selection of context points, which can significantly reduce\nmemory requirements for meta-learning in any established setting. By doing so,\nwe expect additional memory savings which allows longer per-signal adaptation\nhorizons (at a given memory budget), leading to better meta-initializations by\nreducing myopia and, more crucially, enabling learning on high-dimensional\nsignals. To implement such context pruning, our technical novelty is\nthree-fold. First, we propose a selection scheme that adaptively chooses a\nsubset at each adaptation step based on the predictive error, leading to the\nmodeling of the global structure of the signal in early steps and enabling the\nlater steps to capture its high-frequency details. Second, we counteract any\npossible information loss from context pruning by minimizing the parameter\ndistance to a bootstrapped target model trained on a full context set. Finally,\nwe suggest using the full context set with a gradient scaling scheme at\ntest-time. Our technique is model-agnostic, intuitive, and straightforward to\nimplement, showing significant reconstruction improvements for a wide range of\nsignals. Code is available at https://github.com/jihoontack/ECoP\n","authors":["Jihoon Tack","Subin Kim","Sihyun Yu","Jaeho Lee","Jinwoo Shin","Jonathan Richard Schwarz"],"pdf_url":"https://arxiv.org/pdf/2302.00617v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2302.00615v1","updated":"2023-02-01T17:29:43Z","published":"2023-02-01T17:29:43Z","title":"GFlowNets for AI-Driven Scientific Discovery","summary":"  Tackling the most pressing problems for humanity, such as the climate crisis\nand the threat of global pandemics, requires accelerating the pace of\nscientific discovery. While science has traditionally relied on trial and error\nand even serendipity to a large extent, the last few decades have seen a surge\nof data-driven scientific discoveries. However, in order to truly leverage\nlarge-scale data sets and high-throughput experimental setups, machine learning\nmethods will need to be further improved and better integrated in the\nscientific discovery pipeline. A key challenge for current machine learning\nmethods in this context is the efficient exploration of very large search\nspaces, which requires techniques for estimating reducible (epistemic)\nuncertainty and generating sets of diverse and informative experiments to\nperform. This motivated a new probabilistic machine learning framework called\nGFlowNets, which can be applied in the modeling, hypotheses generation and\nexperimental design stages of the experimental science loop. GFlowNets learn to\nsample from a distribution given indirectly by a reward function corresponding\nto an unnormalized probability, which enables sampling diverse, high-reward\ncandidates. GFlowNets can also be used to form efficient and amortized Bayesian\nposterior estimators for causal models conditioned on the already acquired\nexperimental data. Having such posterior models can then provide estimators of\nepistemic uncertainty and information gain that can drive an experimental\ndesign policy. Altogether, here we will argue that GFlowNets can become a\nvaluable tool for AI-driven scientific discovery, especially in scenarios of\nvery large candidate spaces where we have access to cheap but inaccurate\nmeasurements or to expensive but accurate measurements. This is a common\nsetting in the context of drug and material discovery, which we use as examples\nthroughout the paper.\n","authors":["Moksh Jain","Tristan Deleu","Jason Hartford","Cheng-Hao Liu","Alex Hernandez-Garcia","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2302.00615v1.pdf","comment":"26 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.00610v1","updated":"2023-02-01T17:21:40Z","published":"2023-02-01T17:21:40Z","title":"Uniswap Liquidity Provision: An Online Learning Approach","summary":"  Decentralized Exchanges (DEXs) are new types of marketplaces leveraging\nBlockchain technology. They allow users to trade assets with Automatic Market\nMakers (AMM), using funds provided by liquidity providers, removing the need\nfor order books. One such DEX, Uniswap v3, allows liquidity providers to\nallocate funds more efficiently by specifying an active price interval for\ntheir funds. This introduces the problem of finding an optimal strategy for\nchoosing price intervals. We formalize this problem as an online learning\nproblem with non-stochastic rewards. We use regret-minimization methods to show\na liquidity provision strategy that guarantees a lower bound on the reward.\nThis is true even for non-stochastic changes to asset pricing, and we express\nthis bound in terms of the trading volume.\n","authors":["Yogev Bar-On","Yishay Mansour"],"pdf_url":"https://arxiv.org/pdf/2302.00610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00600v1","updated":"2023-02-01T17:09:46Z","published":"2023-02-01T17:09:46Z","title":"Two for One: Diffusion Models and Force Fields for Coarse-Grained\n  Molecular Dynamics","summary":"  Coarse-grained (CG) molecular dynamics enables the study of biological\nprocesses at temporal and spatial scales that would be intractable at an\natomistic resolution. However, accurately learning a CG force field remains a\nchallenge. In this work, we leverage connections between score-based generative\nmodels, force fields and molecular dynamics to learn a CG force field without\nrequiring any force inputs during training. Specifically, we train a diffusion\ngenerative model on protein structures from molecular dynamics simulations, and\nwe show that its score function approximates a force field that can directly be\nused to simulate CG molecular dynamics. While having a vastly simplified\ntraining setup compared to previous work, we demonstrate that our approach\nleads to improved performance across several small- to medium-sized protein\nsimulations, reproducing the CG equilibrium distribution, and preserving\ndynamics of all-atom simulations such as protein folding events.\n","authors":["Marloes Arts","Victor Garcia Satorras","Chin-Wei Huang","Daniel Zuegner","Marco Federici","Cecilia Clementi","Frank Noé","Robert Pinsler","Rianne van den Berg"],"pdf_url":"https://arxiv.org/pdf/2302.00600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.08792v3","updated":"2023-02-01T17:01:51Z","published":"2021-09-18T00:30:43Z","title":"Learning to be Fair: A Consequentialist Approach to Equitable\n  Decision-Making","summary":"  In the dominant paradigm for designing equitable machine learning systems,\none works to ensure that model predictions satisfy various fairness criteria,\nsuch as parity in error rates across race, gender, and other legally protected\ntraits. That approach, however, typically ignores the downstream decisions and\noutcomes that predictions affect, and, as a result, can induce unexpected\nharms. Here we present an alternative framework for fairness that directly\nanticipates the consequences of decisions. Stakeholders first specify\npreferences over the possible outcomes of an algorithmically informed\ndecision-making process. For example, lenders may prefer extending credit to\nthose most likely to repay a loan, while also preferring similar lending rates\nacross neighborhoods. One then searches the space of decision policies to\nmaximize the specified utility. We develop and describe a method for\nefficiently learning these optimal policies from data for a large family of\nexpressive utility functions, facilitating a more holistic approach to\nequitable decision-making.\n","authors":["Alex Chohlas-Wood","Madison Coots","Henry Zhu","Emma Brunskill","Sharad Goel"],"pdf_url":"https://arxiv.org/pdf/2109.08792v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03345v2","updated":"2023-02-01T16:56:30Z","published":"2023-01-09T13:56:59Z","title":"CaSpeR: Latent Spectral Regularization for Continual Learning","summary":"  While biological intelligence grows organically as new knowledge is gathered\nthroughout life, Artificial Neural Networks forget catastrophically whenever\nthey face a changing training data distribution. Rehearsal-based Continual\nLearning (CL) approaches have been established as a versatile and reliable\nsolution to overcome this limitation; however, sudden input disruptions and\nmemory constraints are known to alter the consistency of their predictions. We\nstudy this phenomenon by investigating the geometric characteristics of the\nlearner's latent space and find that replayed data points of different classes\nincreasingly mix up, interfering with classification. Hence, we propose a\ngeometric regularizer that enforces weak requirements on the Laplacian spectrum\nof the latent space, promoting a partitioning behavior. We show that our\nproposal, called Continual Spectral Regularizer (CaSpeR), can be easily\ncombined with any rehearsal-based CL approach and improves the performance of\nSOTA methods on standard benchmarks. Finally, we conduct additional analysis to\nprovide insights into CaSpeR's effects and applicability.\n","authors":["Emanuele Frascaroli","Riccardo Benaglia","Matteo Boschini","Luca Moschella","Cosimo Fiorini","Emanuele Rodolà","Simone Calderara"],"pdf_url":"https://arxiv.org/pdf/2301.03345v2.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.00577v1","updated":"2023-02-01T16:51:56Z","published":"2023-02-01T16:51:56Z","title":"MB-DECTNet: A Model-Based Unrolled Network for Accurate 3D DECT\n  Reconstruction","summary":"  Numerous dual-energy CT (DECT) techniques have been developed in the past few\ndecades. Dual-energy CT (DECT) statistical iterative reconstruction (SIR) has\ndemonstrated its potential for reducing noise and increasing accuracy. Our lab\nproposed a joint statistical DECT algorithm for stopping power estimation and\nshowed that it outperforms competing image-based material-decomposition\nmethods. However, due to its slow convergence and the high computational cost\nof projections, the elapsed time of 3D DECT SIR is often not clinically\nacceptable. Therefore, to improve its convergence, we have embedded DECT SIR\ninto a deep learning model-based unrolled network for 3D DECT reconstruction\n(MB-DECTNet) that can be trained in an end-to-end fashion. This deep\nlearning-based method is trained to learn the shortcuts between the initial\nconditions and the stationary points of iterative algorithms while preserving\nthe unbiased estimation property of model-based algorithms. MB-DECTNet is\nformed by stacking multiple update blocks, each of which consists of a data\nconsistency layer (DC) and a spatial mixer layer, where the spatial mixer layer\nis the shrunken U-Net, and the DC layer is a one-step update of an arbitrary\ntraditional iterative method. Although the proposed network can be combined\nwith numerous iterative DECT algorithms, we demonstrate its performance with\nthe dual-energy alternating minimization (DEAM). The qualitative result shows\nthat MB-DECTNet with DEAM significantly reduces noise while increasing the\nresolution of the test image. The quantitative result shows that MB-DECTNet has\nthe potential to estimate attenuation coefficients accurately as traditional\nstatistical algorithms but with a much lower computational cost.\n","authors":["Tao Ge","Maria Medrano","Rui Liao","David G. Politte","Jeffrey F. Williamson","Bruce R. Whiting","Joseph A. O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2302.00577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00569v1","updated":"2023-02-01T16:44:39Z","published":"2023-02-01T16:44:39Z","title":"Machine Learning for Visualization Recommendation Systems: Open\n  Challenges and Future Directions","summary":"  Visualization Recommendation Systems (VRS) are a novel and challenging field\nof study, whose aim is to automatically generate insightful visualizations from\ndata, to support non-expert users in the process of information discovery.\nDespite its enormous application potential in the era of big data, progress in\nthis area of research is being held back by several obstacles among which are\nthe absence of standardized datasets to train recommendation algorithms, and\nthe difficulty in defining quantitative criteria to assess the effectiveness of\nthe generated plots. In this paper, we aim not only to summarize the\nstate-of-the-art of VRS, but also to outline promising future research\ndirections.\n","authors":["Luca Podo","Bardh Prenkaj","Paola Velardi"],"pdf_url":"https://arxiv.org/pdf/2302.00569v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2302.00564v1","updated":"2023-02-01T16:34:07Z","published":"2023-02-01T16:34:07Z","title":"Automatically Marginalized MCMC in Probabilistic Programming","summary":"  Hamiltonian Monte Carlo (HMC) is a powerful algorithm to sample latent\nvariables from Bayesian models. The advent of probabilistic programming\nlanguages (PPLs) frees users from writing inference algorithms and lets users\nfocus on modeling. However, many models are difficult for HMC to solve\ndirectly, which often require tricks like model reparameterization. We are\nmotivated by the fact that many of those models could be simplified by\nmarginalization. We propose to use automatic marginalization as part of the\nsampling process using HMC in a graphical model extracted from a PPL, which\nsubstantially improves sampling from real-world hierarchical models.\n","authors":["Jinlin Lai","Javier Burroni","Hui Guan","Daniel Sheldon"],"pdf_url":"https://arxiv.org/pdf/2302.00564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.07898v2","updated":"2023-02-01T16:33:32Z","published":"2022-05-16T18:00:01Z","title":"Fast and realistic large-scale structure from machine-learning-augmented\n  random field simulations","summary":"  Producing thousands of simulations of the dark matter distribution in the\nUniverse with increasing precision is a challenging but critical task to\nfacilitate the exploitation of current and forthcoming cosmological surveys.\nMany inexpensive substitutes to full $N$-body simulations have been proposed,\neven though they often fail to reproduce the statistics of the smaller,\nnon-linear scales. Among these alternatives, a common approximation is\nrepresented by the lognormal distribution, which comes with its own limitations\nas well, while being extremely fast to compute even for high-resolution density\nfields. In this work, we train a generative deep learning model, mainly made of\nconvolutional layers, to transform projected lognormal dark matter density\nfields to more realistic dark matter maps, as obtained from full $N$-body\nsimulations. We detail the procedure that we follow to generate highly\ncorrelated pairs of lognormal and simulated maps, which we use as our training\ndata, exploiting the information of the Fourier phases. We demonstrate the\nperformance of our model comparing various statistical tests with different\nfield resolutions, redshifts and cosmological parameters, proving its\nrobustness and explaining its current limitations. When evaluated on 100 test\nmaps, the augmented lognormal random fields reproduce the power spectrum up to\nwavenumbers of $1 \\ h \\ \\rm{Mpc}^{-1}$, and the bispectrum within 10%, and\nalways within the error bars, of the fiducial target simulations. Finally, we\ndescribe how we plan to integrate our proposed model with existing tools to\nyield more accurate spherical random fields for weak lensing analysis.\n","authors":["Davide Piras","Benjamin Joachimi","Francisco Villaescusa-Navarro"],"pdf_url":"https://arxiv.org/pdf/2205.07898v2.pdf","comment":"16 pages, 11 figures. Matches MNRAS published version, which includes\n  more tests with e.g. varying cosmological parameters"},{"id":"http://arxiv.org/abs/2302.00557v1","updated":"2023-02-01T16:23:29Z","published":"2023-02-01T16:23:29Z","title":"Graph Neural Network Based Surrogate Model of Physics Simulations for\n  Geometry Design","summary":"  Computational Intelligence (CI) techniques have shown great potential as a\nsurrogate model of expensive physics simulation, with demonstrated ability to\nmake fast predictions, albeit at the expense of accuracy in some cases. For\nmany scientific and engineering problems involving geometrical design, it is\ndesirable for the surrogate models to precisely describe the change in geometry\nand predict the consequences. In that context, we develop graph neural networks\n(GNNs) as fast surrogate models for physics simulation, which allow us to\ndirectly train the models on 2/3D geometry designs that are represented by an\nunstructured mesh or point cloud, without the need for any explicit or\nhand-crafted parameterization. We utilize an encoder-processor-decoder-type\narchitecture which can flexibly make prediction at both node level and graph\nlevel. The performance of our proposed GNN-based surrogate model is\ndemonstrated on 2 example applications: feature designs in the domain of\nadditive engineering and airfoil design in the domain of aerodynamics. The\nmodels show good accuracy in their predictions on a separate set of test\ngeometries after training, with almost instant prediction speeds, as compared\nto O(hour) for the high-fidelity simulations required otherwise.\n","authors":["Jian Cheng Wong","Chin Chun Ooi","Joyjit Chattoraj","Lucas Lestandi","Guoying Dong","Umesh Kizhakkinan","David William Rosen","Mark Hyunpong Jhon","My Ha Dao"],"pdf_url":"https://arxiv.org/pdf/2302.00557v1.pdf","comment":"7 pages, 5 figures, 2022 IEEE Symposium Series on Computational\n  Intelligence"},{"id":"http://arxiv.org/abs/2301.11562v2","updated":"2023-02-01T16:15:43Z","published":"2023-01-27T06:52:04Z","title":"Variance, Self-Consistency, and Arbitrariness in Fair Classification","summary":"  In fair classification, it is common to train a model, and to compare and\ncorrect subgroup-specific error rates for disparities. However, even if a\nmodel's classification decisions satisfy a fairness metric, it is not\nnecessarily the case that these decisions are equally confident. This becomes\nclear if we measure variance: We can fix everything in the learning process\nexcept the subset of training data, train multiple models, measure\n(dis)agreement in predictions for each test example, and interpret disagreement\nto mean that the learning process is more unstable with respect to its\nclassification decision. Empirically, some decisions can in fact be so unstable\nthat they are effectively arbitrary. To reduce this arbitrariness, we formalize\na notion of self-consistency of a learning process, develop an ensembling\nalgorithm that provably increases self-consistency, and empirically demonstrate\nits utility to often improve both fairness and accuracy. Further, our\nevaluation reveals a startling observation: Applying ensembling to common fair\nclassification benchmarks can significantly reduce subgroup error rate\ndisparities, without employing common pre-, in-, or post-processing fairness\ninterventions. Taken together, our results indicate that variance, particularly\non small datasets, can muddle the reliability of conclusions about fairness.\nOne solution is to develop larger benchmark tasks. To this end, we release a\ntoolkit that makes the Home Mortgage Disclosure Act datasets easily usable for\nfuture research.\n","authors":["A. Feder Cooper","Solon Barocas","Christopher De Sa","Siddhartha Sen"],"pdf_url":"https://arxiv.org/pdf/2301.11562v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00543v1","updated":"2023-02-01T16:08:54Z","published":"2023-02-01T16:08:54Z","title":"$\\texttt{DoCoFL}$: Downlink Compression for Cross-Device Federated\n  Learning","summary":"  Many compression techniques have been proposed to reduce the communication\noverhead of Federated Learning training procedures. However, these are\ntypically designed for compressing model updates, which are expected to decay\nthroughout training. As a result, such methods are inapplicable to downlink\n(i.e., from the parameter server to clients) compression in the cross-device\nsetting, where heterogeneous clients $\\textit{may appear only once}$ during\ntraining and thus must download the model parameters.\n  In this paper, we propose a new framework ($\\texttt{DoCoFL}$) for downlink\ncompression in the cross-device federated learning setting. Importantly,\n$\\texttt{DoCoFL}$ can be seamlessly combined with many uplink compression\nschemes, rendering it suitable for bi-directional compression. Through\nextensive evaluation, we demonstrate that $\\texttt{DoCoFL}$ offers significant\nbi-directional bandwidth reduction while achieving competitive accuracy to that\nof $\\texttt{FedAvg}$ without compression.\n","authors":["Ron Dorfman","Shay Vargaftik","Yaniv Ben-Itzhak","Kfir Y. Levy"],"pdf_url":"https://arxiv.org/pdf/2302.00543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00539v1","updated":"2023-02-01T16:04:48Z","published":"2023-02-01T16:04:48Z","title":"Analyzing Leakage of Personally Identifiable Information in Language\n  Models","summary":"  Language Models (LMs) have been shown to leak information about training data\nthrough sentence-level membership inference and reconstruction attacks.\nUnderstanding the risk of LMs leaking Personally Identifiable Information (PII)\nhas received less attention, which can be attributed to the false assumption\nthat dataset curation techniques such as scrubbing are sufficient to prevent\nPII leakage. Scrubbing techniques reduce but do not prevent the risk of PII\nleakage: in practice scrubbing is imperfect and must balance the trade-off\nbetween minimizing disclosure and preserving the utility of the dataset. On the\nother hand, it is unclear to which extent algorithmic defenses such as\ndifferential privacy, designed to guarantee sentence- or user-level privacy,\nprevent PII disclosure. In this work, we propose (i) a taxonomy of PII leakage\nin LMs, (ii) metrics to quantify PII leakage, and (iii) attacks showing that\nPII leakage is a threat in practice. Our taxonomy provides rigorous game-based\ndefinitions for PII leakage via black-box extraction, inference, and\nreconstruction attacks with only API access to an LM. We empirically evaluate\nattacks against GPT-2 models fine-tuned on three domains: case law, health\ncare, and e-mails. Our main contributions are (i) novel attacks that can\nextract up to 10 times more PII sequences as existing attacks, (ii) showing\nthat sentence-level differential privacy reduces the risk of PII disclosure but\nstill leaks about 3% of PII sequences, and (iii) a subtle connection between\nrecord-level membership inference and PII reconstruction.\n","authors":["Nils Lukas","Ahmed Salem","Robert Sim","Shruti Tople","Lukas Wutschitz","Santiago Zanella-Béguelin"],"pdf_url":"https://arxiv.org/pdf/2302.00539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00538v1","updated":"2023-02-01T16:03:41Z","published":"2023-02-01T16:03:41Z","title":"Experimental observation on a low-rank tensor model for eigenvalue\n  problems","summary":"  Here we utilize a low-rank tensor model (LTM) as a function approximator,\ncombined with the gradient descent method, to solve eigenvalue problems\nincluding the Laplacian operator and the harmonic oscillator. Experimental\nresults show the superiority of the polynomial-based low-rank tensor model\n(PLTM) compared to the tensor neural network (TNN). We also test such low-rank\narchitectures for the classification problem on the MNIST dataset.\n","authors":["Jun Hu","Pengzhan Jin"],"pdf_url":"https://arxiv.org/pdf/2302.00538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00537v1","updated":"2023-02-01T16:03:34Z","published":"2023-02-01T16:03:34Z","title":"Effectiveness of Moving Target Defenses for Adversarial Attacks in\n  ML-based Malware Detection","summary":"  Several moving target defenses (MTDs) to counter adversarial ML attacks have\nbeen proposed in recent years. MTDs claim to increase the difficulty for the\nattacker in conducting attacks by regularly changing certain elements of the\ndefense, such as cycling through configurations. To examine these claims, we\nstudy for the first time the effectiveness of several recent MTDs for\nadversarial ML attacks applied to the malware detection domain. Under different\nthreat models, we show that transferability and query attack strategies can\nachieve high levels of evasion against these defenses through existing and\nnovel attack strategies across Android and Windows. We also show that\nfingerprinting and reconnaissance are possible and demonstrate how attackers\nmay obtain critical defense hyperparameters as well as information about how\npredictions are produced. Based on our findings, we present key recommendations\nfor future work on the development of effective MTDs for adversarial attacks in\nML-based malware detection.\n","authors":["Aqib Rashid","Jose Such"],"pdf_url":"https://arxiv.org/pdf/2302.00537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.03658v3","updated":"2023-02-01T16:02:48Z","published":"2020-10-07T21:18:46Z","title":"How Out-of-Distribution Data Hurts Semi-Supervised Learning","summary":"  Recent semi-supervised learning algorithms have demonstrated greater success\nwith higher overall performance due to better-unlabeled data representations.\nNonetheless, recent research suggests that the performance of the SSL algorithm\ncan be degraded when the unlabeled set contains out-of-distribution examples\n(OODs). This work addresses the following question: How do out-of-distribution\n(OOD) data adversely affect semi-supervised learning algorithms? To answer this\nquestion, we investigate the critical causes of OOD's negative effect on SSL\nalgorithms. In particular, we found that 1) certain kinds of OOD data instances\nthat are close to the decision boundary have a more significant impact on\nperformance than those that are further away, and 2) Batch Normalization (BN),\na popular module, may degrade rather than improve performance when the\nunlabeled set contains OODs. In this context, we developed a unified weighted\nrobust SSL framework that can be easily extended to many existing SSL\nalgorithms and improve their robustness against OODs. More specifically, we\ndeveloped an efficient bi-level optimization algorithm that could accommodate\nhigh-order approximations of the objective and scale to multiple inner\noptimization steps to learn a massive number of weight parameters while\noutperforming existing low-order approximations of bi-level optimization.\nFurther, we conduct a theoretical study of the impact of faraway OODs in the BN\nstep and propose a weighted batch normalization (WBN) procedure for improved\nperformance. Finally, we discuss the connection between our approach and\nlow-order approximation techniques. Our experiments on synthetic and real-world\ndatasets demonstrate that our proposed approach significantly enhances the\nrobustness of four representative SSL algorithms against OODs compared to four\nstate-of-the-art robust SSL strategies.\n","authors":["Xujiang Zhao","Killamsetty Krishnateja","Rishabh Iyer","Feng Chen"],"pdf_url":"https://arxiv.org/pdf/2010.03658v3.pdf","comment":"Accepted to ICDM'22"},{"id":"http://arxiv.org/abs/2302.00533v1","updated":"2023-02-01T15:59:57Z","published":"2023-02-01T15:59:57Z","title":"Distillation Policy Optimization","summary":"  On-policy algorithms are supposed to be stable, however, sample-intensive\nyet. Off-policy algorithms utilizing past experiences are deemed to be\nsample-efficient, nevertheless, unstable in general. Can we design an algorithm\nthat can employ the off-policy data, while exploit the stable learning by\nsailing along the course of the on-policy walkway? In this paper, we present an\nactor-critic learning framework that borrows the distributional perspective of\ninterest to evaluate, and cross-breeds two sources of the data for policy\nimprovement, which enables fast learning and can be applied to a wide class of\nalgorithms. In its backbone, the variance reduction mechanisms, such as unified\nadvantage estimator (UAE), that extends generalized advantage estimator (GAE)\nto be applicable on any state-dependent baseline, and a learned baseline, that\nis competent to stabilize the policy gradient, are firstly put forward to not\nmerely be a bridge to the action-value function but also distill the\nadvantageous learning signal. Lastly, it is empirically shown that our method\nimproves sample efficiency and interpolates different levels well. Being of an\norganic whole, its mixture places more inspiration to the algorithm design.\n","authors":["Jianfei Ma"],"pdf_url":"https://arxiv.org/pdf/2302.00533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00521v1","updated":"2023-02-01T15:41:27Z","published":"2023-02-01T15:41:27Z","title":"Off-the-Grid MARL: a Framework for Dataset Generation with Baselines for\n  Cooperative Offline Multi-Agent Reinforcement Learning","summary":"  Being able to harness the power of large, static datasets for developing\nautonomous multi-agent systems could unlock enormous value for real-world\napplications. Many important industrial systems are multi-agent in nature and\nare difficult to model using bespoke simulators. However, in industry,\ndistributed system processes can often be recorded during operation, and large\nquantities of demonstrative data can be stored. Offline multi-agent\nreinforcement learning (MARL) provides a promising paradigm for building\neffective online controllers from static datasets. However, offline MARL is\nstill in its infancy, and, therefore, lacks standardised benchmarks, baselines\nand evaluation protocols typically found in more mature subfields of RL. This\ndeficiency makes it difficult for the community to sensibly measure progress.\nIn this work, we aim to fill this gap by releasing \\emph{off-the-grid MARL\n(OG-MARL)}: a framework for generating offline MARL datasets and algorithms. We\nrelease an initial set of datasets and baselines for cooperative offline MARL,\ncreated using the framework, along with a standardised evaluation protocol. Our\ndatasets provide settings that are characteristic of real-world systems,\nincluding complex dynamics, non-stationarity, partial observability,\nsuboptimality and sparse rewards, and are generated from popular online MARL\nbenchmarks. We hope that OG-MARL will serve the community and help steer\nprogress in offline MARL, while also providing an easy entry point for\nresearchers new to the field.\n","authors":["Claude Formanek","Asad Jeewa","Jonathan Shock","Arnu Pretorius"],"pdf_url":"https://arxiv.org/pdf/2302.00521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00514v1","updated":"2023-02-01T15:34:24Z","published":"2023-02-01T15:34:24Z","title":"Towards Implementing Energy-aware Data-driven Intelligence for Smart\n  Health Applications on Mobile Platforms","summary":"  Recent breakthrough technological progressions of powerful mobile computing\nresources such as low-cost mobile GPUs along with cutting-edge, open-source\nsoftware architectures have enabled high-performance deep learning on mobile\nplatforms. These advancements have revolutionized the capabilities of today's\nmobile applications in different dimensions to perform data-driven intelligence\nlocally, particularly for smart health applications. Unlike traditional machine\nlearning (ML) architectures, modern on-device deep learning frameworks are\nproficient in utilizing computing resources in mobile platforms seamlessly, in\nterms of producing highly accurate results in less inference time. However, on\nthe flip side, energy resources in a mobile device are typically limited.\nHence, whenever a complex Deep Neural Network (DNN) architecture is fed into\nthe on-device deep learning framework, while it achieves high prediction\naccuracy (and performance), it also urges huge energy demands during the\nruntime. Therefore, managing these resources efficiently within the spectrum of\nperformance and energy efficiency is the newest challenge for any mobile\napplication featuring data-driven intelligence beyond experimental evaluations.\nIn this paper, first, we provide a timely review of recent advancements in\non-device deep learning while empirically evaluating the performance metrics of\ncurrent state-of-the-art ML architectures and conventional ML approaches with\nthe emphasis given on energy characteristics by deploying them on a smart\nhealth application. With that, we are introducing a new framework through an\nenergy-aware, adaptive model comprehension and realization (EAMCR) approach\nthat can be utilized to make more robust and efficient inference decisions\nbased on the available computing/energy resources in the mobile device during\nthe runtime.\n","authors":["G. Dumindu Samaraweera","Hung Nguyen","Hadi Zanddizari","Behnam Zeinali","J. Morris Chang"],"pdf_url":"https://arxiv.org/pdf/2302.00514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00511v1","updated":"2023-02-01T15:33:51Z","published":"2023-02-01T15:33:51Z","title":"Iterative Deepening Hyperband","summary":"  Hyperparameter optimization (HPO) is concerned with the automated search for\nthe most appropriate hyperparameter configuration (HPC) of a parameterized\nmachine learning algorithm. A state-of-the-art HPO method is Hyperband, which,\nhowever, has its own parameters that influence its performance. One of these\nparameters, the maximal budget, is especially problematic: If chosen too small,\nthe budget needs to be increased in hindsight and, as Hyperband is not\nincremental by design, the entire algorithm must be re-run. This is not only\ncostly but also comes with a loss of valuable knowledge already accumulated. In\nthis paper, we propose incremental variants of Hyperband that eliminate these\ndrawbacks, and show that these variants satisfy theoretical guarantees\nqualitatively similar to those for the original Hyperband with the \"right\"\nbudget. Moreover, we demonstrate their practical utility in experiments with\nbenchmark data sets.\n","authors":["Jasmin Brandt","Marcel Wever","Dimitrios Iliadis","Viktor Bengs","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2302.00511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00509v1","updated":"2023-02-01T15:28:55Z","published":"2023-02-01T15:28:55Z","title":"Exploring Semantic Perturbations on Grover","summary":"  With news and information being as easy to access as they currently are, it\nis more important than ever to ensure that people are not mislead by what they\nread. Recently, the rise of neural fake news (AI-generated fake news) and its\ndemonstrated effectiveness at fooling humans has prompted the development of\nmodels to detect it. One such model is the Grover model, which can both detect\nneural fake news to prevent it, and generate it to demonstrate how a model\ncould be misused to fool human readers. In this work we explore the Grover\nmodel's fake news detection capabilities by performing targeted attacks through\nperturbations on input news articles. Through this we test Grover's resilience\nto these adversarial attacks and expose some potential vulnerabilities which\nshould be addressed in further iterations to ensure it can detect all types of\nfake news accurately.\n","authors":["Pranav Kulkarni","Ziqing Ji","Yan Xu","Marko Neskovic","Kevin Nolan"],"pdf_url":"https://arxiv.org/pdf/2302.00509v1.pdf","comment":"15 pages, 12 figures, 1 table, capstone research in machine learning"},{"id":"http://arxiv.org/abs/2302.00491v1","updated":"2023-02-01T15:02:58Z","published":"2023-02-01T15:02:58Z","title":"Learning Prototype Classifiers for Long-Tailed Recognition","summary":"  The problem of long-tailed recognition (LTR) has received attention in recent\nyears due to the fundamental power-law distribution of objects in the\nreal-world. Most recent works in LTR use softmax classifiers that have a\ntendency to correlate classifier norm with the amount of training data for a\ngiven class. On the other hand, Prototype classifiers do not suffer from this\nshortcoming and can deliver promising results simply using Nearest-Class-Mean\n(NCM), a special case where prototypes are empirical centroids. However, the\npotential of Prototype classifiers as an alternative to softmax in LTR is\nrelatively underexplored. In this work, we propose Prototype classifiers, which\njointly learn prototypes that minimize average cross-entropy loss based on\nprobability scores from distances to prototypes. We theoretically analyze the\nproperties of Euclidean distance based prototype classifiers that leads to\nstable gradient-based optimization which is robust to outliers. We further\nenhance Prototype classifiers by learning channel-dependent temperature\nparameters to enable independent distance scales along each channel. Our\nanalysis shows that prototypes learned by Prototype classifiers are better\nseparated than empirical centroids. Results on four long-tailed recognition\nbenchmarks show that Prototype classifier outperforms or is comparable to the\nstate-of-the-art methods.\n","authors":["Saurabh Sharma","Yongqin Xian","Ning Yu","Ambuj Singh"],"pdf_url":"https://arxiv.org/pdf/2302.00491v1.pdf","comment":"11 pages, 4 figures and 9 tables"},{"id":"http://arxiv.org/abs/2302.00485v1","updated":"2023-02-01T14:48:18Z","published":"2023-02-01T14:48:18Z","title":"Equivariant Message Passing Neural Network for Crystal Material\n  Discovery","summary":"  Automatic material discovery with desired properties is a fundamental\nchallenge for material sciences. Considerable attention has recently been\ndevoted to generating stable crystal structures. While existing work has shown\nimpressive success on supervised tasks such as property prediction, the\nprogress on unsupervised tasks such as material generation is still hampered by\nthe limited extent to which the equivalent geometric representations of the\nsame crystal are considered. To address this challenge, we propose EMPNN a\nperiodic equivariant message-passing neural network that learns crystal lattice\ndeformation in an unsupervised fashion. Our model equivalently acts on lattice\naccording to the deformation action that must be performed, making it suitable\nfor crystal generation, relaxation and optimisation. We present experimental\nevaluations that demonstrate the effectiveness of our approach.\n","authors":["Astrid Klipfel","Olivier Peltre","Najwa Harrati","Yaël Fregier","Adlane Sayede","Zied Bouraoui"],"pdf_url":"https://arxiv.org/pdf/2302.00485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00482v1","updated":"2023-02-01T14:47:17Z","published":"2023-02-01T14:47:17Z","title":"Conditional Flow Matching: Simulation-Free Dynamic Optimal Transport","summary":"  Continuous normalizing flows (CNFs) are an attractive generative modeling\ntechnique, but they have thus far been held back by limitations in their\nsimulation-based maximum likelihood training. In this paper, we introduce a new\ntechnique called conditional flow matching (CFM), a simulation-free training\nobjective for CNFs. CFM features a stable regression objective like that used\nto train the stochastic flow in diffusion models but enjoys the efficient\ninference of deterministic flow models. In contrast to both diffusion models\nand prior CNF training algorithms, our CFM objective does not require the\nsource distribution to be Gaussian or require evaluation of its density. Based\non this new objective, we also introduce optimal transport CFM (OT-CFM), which\ncreates simpler flows that are more stable to train and lead to faster\ninference, as evaluated in our experiments. Training CNFs with CFM improves\nresults on a variety of conditional and unconditional generation tasks such as\ninferring single cell dynamics, unsupervised image translation, and\nSchr\\\"odinger bridge inference. Code is available at\nhttps://github.com/atong01/conditional-flow-matching .\n","authors":["Alexander Tong","Nikolay Malkin","Guillaume Huguet","Yanlei Zhang","Jarrid Rector-Brooks","Kilian Fatras","Guy Wolf","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2302.00482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03463v2","updated":"2023-02-01T14:41:15Z","published":"2022-12-07T05:07:27Z","title":"Sequential Predictive Conformal Inference for Time Series","summary":"  We present a new distribution-free conformal prediction algorithm for\nsequential data (e.g., time series), called the \\textit{sequential predictive\nconformal inference} (\\texttt{SPCI}). We specifically account for the nature\nthat time series data are non-exchangeable, and thus many existing conformal\nprediction algorithms are not applicable. The main idea is to exploit the\ntemporal dependence of non-conformity scores (e.g., prediction residuals);\nthus, the past residuals contain information about future ones. Then we cast\nthe problem of conformal prediction interval as predicting the quantile of a\nfuture residual, given a user-specified point prediction algorithm.\nTheoretically, we establish asymptotic valid conditional coverage upon\nextending consistency analyses in quantile regression. Using simulation and\nreal-data experiments, we demonstrate a significant reduction in interval width\nof \\texttt{SPCI} compared to other existing methods under the desired empirical\ncoverage.\n","authors":["Chen Xu","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2212.03463v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.01793v3","updated":"2023-02-01T14:37:52Z","published":"2022-02-03T19:00:04Z","title":"Incorporating Sum Constraints into Multitask Gaussian Processes","summary":"  Machine learning models can be improved by adapting them to respect existing\nbackground knowledge. In this paper we consider multitask Gaussian processes,\nwith background knowledge in the form of constraints that require a specific\nsum of the outputs to be constant. This is achieved by conditioning the prior\ndistribution on the constraint fulfillment. The approach allows for both linear\nand nonlinear constraints. We demonstrate that the constraints are fulfilled\nwith high precision and that the construction can improve the overall\nprediction accuracy as compared to the standard Gaussian process.\n","authors":["Philipp Pilar","Carl Jidling","Thomas B. Schön","Niklas Wahlström"],"pdf_url":"https://arxiv.org/pdf/2202.01793v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08974v2","updated":"2023-02-01T14:19:52Z","published":"2023-01-21T16:54:05Z","title":"Soft Sensing Regression Model: from Sensor to Wafer Metrology\n  Forecasting","summary":"  The semiconductor industry is one of the most technology-evolving and\ncapital-intensive market sectors. Effective inspection and metrology are\nnecessary to improve product yield, increase product quality and reduce costs.\nIn recent years, many semiconductor manufacturing equipments are equipped with\nsensors to facilitate real-time monitoring of the production process. These\nproduction-state and equipment-state sensor data provide an opportunity to\npractice machine-learning technologies in various domains, such as\nanomaly/fault detection, maintenance scheduling, quality prediction, etc. In\nthis work, we focus on the task of soft sensing regression, which uses sensor\ndata to predict impending inspection measurements that used to be measured in\nwafer inspection and metrology systems. We proposed an LSTM-based regressor and\ndesigned two loss functions for model training. Although engineers may look at\nour prediction errors in a subjective manner, a new piece-wise evaluation\nmetric was proposed for assessing model accuracy in a mathematical way. The\nexperimental results demonstrated that the proposed model can achieve accurate\nand early prediction of various types of inspections in complicated\nmanufacturing processes.\n","authors":["Angzhi Fan","Yu Huang","Fei Xu","Sthitie Bom"],"pdf_url":"https://arxiv.org/pdf/2301.08974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00458v1","updated":"2023-02-01T14:02:06Z","published":"2023-02-01T14:02:06Z","title":"Improved Exact and Heuristic Algorithms for Maximum Weight Clique","summary":"  We propose improved exact and heuristic algorithms for solving the maximum\nweight clique problem, a well-known problem in graph theory with many\napplications. Our algorithms interleave successful techniques from related work\nwith novel data reduction rules that use local graph structure to identify and\nremove vertices and edges while retaining the optimal solution. We evaluate our\nalgorithms on a range of synthetic and real-world graphs, and find that they\noutperform the current state of the art on most inputs. Our data reductions\nalways produce smaller reduced graphs than existing data reductions alone. As a\nresult, our exact algorithm, MWCRedu, finds solutions orders of magnitude\nfaster on naturally weighted, medium-sized map labeling graphs and random\nhyperbolic graphs. Our heuristic algorithm, MWCPeel, outperforms its\ncompetitors on these instances, but is slightly less effective on extremely\ndense or large instances.\n","authors":["Roman Erhardt","Kathrin Hanauer","Nils Kriege","Christian Schulz","Darren Strash"],"pdf_url":"https://arxiv.org/pdf/2302.00458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00457v1","updated":"2023-02-01T14:00:35Z","published":"2023-02-01T14:00:35Z","title":"Simplicity Bias in 1-Hidden Layer Neural Networks","summary":"  Recent works have demonstrated that neural networks exhibit extreme\nsimplicity bias(SB). That is, they learn only the simplest features to solve a\ntask at hand, even in the presence of other, more robust but more complex\nfeatures. Due to the lack of a general and rigorous definition of features,\nthese works showcase SB on semi-synthetic datasets such as Color-MNIST,\nMNIST-CIFAR where defining features is relatively easier.\n  In this work, we rigorously define as well as thoroughly establish SB for one\nhidden layer neural networks. More concretely, (i) we define SB as the network\nessentially being a function of a low dimensional projection of the inputs (ii)\ntheoretically, we show that when the data is linearly separable, the network\nprimarily depends on only the linearly separable ($1$-dimensional) subspace\neven in the presence of an arbitrarily large number of other, more complex\nfeatures which could have led to a significantly more robust classifier, (iii)\nempirically, we show that models trained on real datasets such as Imagenette\nand Waterbirds-Landbirds indeed depend on a low dimensional projection of the\ninputs, thereby demonstrating SB on these datasets, iv) finally, we present a\nnatural ensemble approach that encourages diversity in models by training\nsuccessive models on features not used by earlier models, and demonstrate that\nit yields models that are significantly more robust to Gaussian noise.\n","authors":["Depen Morwani","Jatin Batra","Prateek Jain","Praneeth Netrapalli"],"pdf_url":"https://arxiv.org/pdf/2302.00457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00453v1","updated":"2023-02-01T13:57:32Z","published":"2023-02-01T13:57:32Z","title":"Width and Depth Limits Commute in Residual Networks","summary":"  We show that taking the width and depth to infinity in a deep neural network\nwith skip connections, when branches are scaled by $1/\\sqrt{depth}$ (the only\nnontrivial scaling), result in the same covariance structure no matter how that\nlimit is taken. This explains why the standard infinite-width-then-depth\napproach provides practical insights even for networks with depth of the same\norder as width. We also demonstrate that the pre-activations, in this case,\nhave Gaussian distributions which has direct applications in Bayesian deep\nlearning. We conduct extensive simulations that show an excellent match with\nour theoretical findings.\n","authors":["Soufiane Hayou","Greg Yang"],"pdf_url":"https://arxiv.org/pdf/2302.00453v1.pdf","comment":"28 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2210.00688"},{"id":"http://arxiv.org/abs/2302.00441v1","updated":"2023-02-01T13:39:07Z","published":"2023-02-01T13:39:07Z","title":"Deep Power Laws for Hyperparameter Optimization","summary":"  Hyperparameter optimization is an important subfield of machine learning that\nfocuses on tuning the hyperparameters of a chosen algorithm to achieve peak\nperformance. Recently, there has been a stream of methods that tackle the issue\nof hyperparameter optimization, however, most of the methods do not exploit the\nscaling law property of learning curves. In this work, we propose Deep Power\nLaws (DPL), an ensemble of neural network models conditioned to yield\npredictions that follow a power-law scaling pattern. Our method dynamically\ndecides which configurations to pause and train incrementally by making use of\ngray-box evaluations. We compare our method against 7 state-of-the-art\ncompetitors on 3 benchmarks related to tabular, image, and NLP datasets\ncovering 57 diverse tasks. Our method achieves the best results across all\nbenchmarks by obtaining the best any-time results compared to all competitors.\n","authors":["Arlind Kadra","Maciej Janowski","Martin Wistuba","Josif Grabocka"],"pdf_url":"https://arxiv.org/pdf/2302.00441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07092v3","updated":"2023-02-01T13:31:47Z","published":"2022-11-14T03:39:59Z","title":"Offline Estimation of Controlled Markov Chains: Minimaxity and Sample\n  Complexity","summary":"  In this work, we study a natural nonparametric estimator of the transition\nprobability matrices of a finite controlled Markov chain. We consider an\noffline setting with a fixed dataset, collected using a so-called logging\npolicy. We develop sample complexity bounds for the estimator and establish\nconditions for minimaxity. Our statistical bounds depend on the logging policy\nthrough its mixing properties. We show that achieving a particular statistical\nrisk bound involves a subtle and interesting trade-off between the strength of\nthe mixing properties and the number of samples. We demonstrate the validity of\nour results under various examples, such as ergodic Markov chains, weakly\nergodic inhomogeneous Markov chains, and controlled Markov chains with\nnon-stationary Markov, episodic, and greedy controls. Lastly, we use these\nsample complexity bounds to establish concomitant ones for offline evaluation\nof stationary Markov control policies.\n","authors":["Imon Banerjee","Harsha Honnappa","Vinayak Rao"],"pdf_url":"https://arxiv.org/pdf/2211.07092v3.pdf","comment":"67 pages, 23 main-47 appendix"},{"id":"http://arxiv.org/abs/2302.00422v1","updated":"2023-02-01T13:14:26Z","published":"2023-02-01T13:14:26Z","title":"Robust online active learning","summary":"  In many industrial applications, obtaining labeled observations is not\nstraightforward as it often requires the intervention of human experts or the\nuse of expensive testing equipment. In these circumstances, active learning can\nbe highly beneficial in suggesting the most informative data points to be used\nwhen fitting a model. Reducing the number of observations needed for model\ndevelopment alleviates both the computational burden required for training and\nthe operational expenses related to labeling. Online active learning, in\nparticular, is useful in high-volume production processes where the decision\nabout the acquisition of the label for a data point needs to be taken within an\nextremely short time frame. However, despite the recent efforts to develop\nonline active learning strategies, the behavior of these methods in the\npresence of outliers has not been thoroughly examined. In this work, we\ninvestigate the performance of online active linear regression in contaminated\ndata streams. Our study shows that the currently available query strategies are\nprone to sample outliers, whose inclusion in the training set eventually\ndegrades the predictive performance of the models. To address this issue, we\npropose a solution that bounds the search area of a conditional D-optimal\nalgorithm and uses a robust estimator. Our approach strikes a balance between\nexploring unseen regions of the input space and protecting against outliers.\nThrough numerical simulations, we show that the proposed method is effective in\nimproving the performance of online active learning in the presence of\noutliers, thus expanding the potential applications of this powerful tool.\n","authors":["Davide Cacciarelli","Murat Kulahci","John Sølve Tyssedal"],"pdf_url":"https://arxiv.org/pdf/2302.00422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02593v3","updated":"2023-02-01T13:08:09Z","published":"2022-06-06T12:58:28Z","title":"Pessimistic Off-Policy Optimization for Learning to Rank","summary":"  Off-policy learning is a framework for optimizing policies without deploying\nthem, using data collected by another policy. In recommender systems, this is\nespecially challenging due to the imbalance in logged data: some items are\nrecommended and thus logged more frequently than others. This is further\nperpetuated when recommending a list of items, as the action space is\ncombinatorial. To address this challenge, we study pessimistic off-policy\noptimization for learning to rank. The key idea is to compute lower confidence\nbounds on parameters of click models and then return the list with the highest\npessimistic estimate of its value. This approach is computationally efficient\nand we analyze it. We study its Bayesian and frequentist variants, and overcome\nthe limitation of unknown prior by incorporating empirical Bayes. To show the\nempirical effectiveness of our approach, we compare it to off-policy optimizers\nthat use inverse propensity scores or neglect uncertainty. Our approach\noutperforms all baselines, is robust, and is also general.\n","authors":["Matej Cief","Branislav Kveton","Michal Kompan"],"pdf_url":"https://arxiv.org/pdf/2206.02593v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09874v3","updated":"2023-02-01T13:00:50Z","published":"2022-07-20T13:15:23Z","title":"Stream-based active learning with linear models","summary":"  The proliferation of automated data collection schemes and the advances in\nsensorics are increasing the amount of data we are able to monitor in\nreal-time. However, given the high annotation costs and the time required by\nquality inspections, data is often available in an unlabeled form. This is\nfostering the use of active learning for the development of soft sensors and\npredictive models. In production, instead of performing random inspections to\nobtain product information, labels are collected by evaluating the information\ncontent of the unlabeled data. Several query strategy frameworks for regression\nhave been proposed in the literature but most of the focus has been dedicated\nto the static pool-based scenario. In this work, we propose a new strategy for\nthe stream-based scenario, where instances are sequentially offered to the\nlearner, which must instantaneously decide whether to perform the quality check\nto obtain the label or discard the instance. The approach is inspired by the\noptimal experimental design theory and the iterative aspect of the\ndecision-making process is tackled by setting a threshold on the\ninformativeness of the unlabeled data points. The proposed approach is\nevaluated using numerical simulations and the Tennessee Eastman Process\nsimulator. The results confirm that selecting the examples suggested by the\nproposed algorithm allows for a faster reduction in the prediction error.\n","authors":["Davide Cacciarelli","Murat Kulahci","John Sølve Tyssedal"],"pdf_url":"https://arxiv.org/pdf/2207.09874v3.pdf","comment":"Published in Knowledge-Based Systems, final paper available at\n  https://doi.org/10.1016/j.knosys.2022.109664"},{"id":"http://arxiv.org/abs/2302.00406v1","updated":"2023-02-01T12:46:43Z","published":"2023-02-01T12:46:43Z","title":"Learning Choice Functions with Gaussian Processes","summary":"  In consumer theory, ranking available objects by means of preference\nrelations yields the most common description of individual choices. However,\npreference-based models assume that individuals: (1) give their preferences\nonly between pairs of objects; (2) are always able to pick the best preferred\nobject. In many situations, they may be instead choosing out of a set with more\nthan two elements and, because of lack of information and/or incomparability\n(objects with contradictory characteristics), they may not able to select a\nsingle most preferred object. To address these situations, we need a\nchoice-model which allows an individual to express a set-valued choice. Choice\nfunctions provide such a mathematical framework. We propose a Gaussian Process\nmodel to learn choice functions from choice-data. The proposed model assumes a\nmultiple utility representation of a choice function based on the concept of\nPareto rationalization, and derives a strategy to learn both the number and the\nvalues of these latent multiple utilities. Simulation experiments demonstrate\nthat the proposed model outperforms the state-of-the-art methods.\n","authors":["Alessio Benavoli","Dario Azzimonti","Dario Piga"],"pdf_url":"https://arxiv.org/pdf/2302.00406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00401v1","updated":"2023-02-01T12:37:10Z","published":"2023-02-01T12:37:10Z","title":"Deterministic equivalent and error universality of deep random features\n  learning","summary":"  This manuscript considers the problem of learning a random Gaussian network\nfunction using a fully connected network with frozen intermediate layers and\ntrainable readout layer. This problem can be seen as a natural generalization\nof the widely studied random features model to deeper architectures. First, we\nprove Gaussian universality of the test error in a ridge regression setting\nwhere the learner and target networks share the same intermediate layers, and\nprovide a sharp asymptotic formula for it. Establishing this result requires\nproving a deterministic equivalent for traces of the deep random features\nsample covariance matrices which can be of independent interest. Second, we\nconjecture the asymptotic Gaussian universality of the test error in the more\ngeneral setting of arbitrary convex losses and generic learner/target\narchitectures. We provide extensive numerical evidence for this conjecture,\nwhich requires the derivation of closed-form expressions for the layer-wise\npost-activation population covariances. In light of our results, we investigate\nthe interplay between architecture design and implicit regularization.\n","authors":["Dominik Schröder","Hugo Cui","Daniil Dmitriev","Bruno Loureiro"],"pdf_url":"https://arxiv.org/pdf/2302.00401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06434v2","updated":"2023-02-01T12:30:54Z","published":"2022-10-12T17:33:47Z","title":"Cross-client Label Propagation for Transductive Federated Learning","summary":"  We present Cross-Client Label Propagation(XCLP), a new method for\ntransductive federated learning. XCLP estimates a data graph jointly from the\ndata of multiple clients and computes labels for the unlabeled data by\npropagating label information across the graph. To avoid clients having to\nshare their data with anyone, XCLP employs two cryptographically secure\nprotocols: secure Hamming distance computation and secure summation. We\ndemonstrate two distinct applications of XCLP within federated learning. In the\nfirst, we use it in a one-shot way to predict labels for unseen test points. In\nthe second, we use it to repeatedly pseudo-label unlabeled training data in a\nfederated semi-supervised setting. Experiments on both real federated and\nstandard benchmark datasets show that in both applications XCLP achieves higher\nclassification accuracy than alternative approaches.\n","authors":["Jonathan Scott","Michelle Yeo","Christoph H. Lampert"],"pdf_url":"https://arxiv.org/pdf/2210.06434v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00392v1","updated":"2023-02-01T12:03:19Z","published":"2023-02-01T12:03:19Z","title":"Delayed Feedback in Kernel Bandits","summary":"  Black box optimisation of an unknown function from expensive and noisy\nevaluations is a ubiquitous problem in machine learning, academic research and\nindustrial production. An abstraction of the problem can be formulated as a\nkernel based bandit problem (also known as Bayesian optimisation), where a\nlearner aims at optimising a kernelized function through sequential noisy\nobservations. The existing work predominantly assumes feedback is immediately\navailable; an assumption which fails in many real world situations, including\nrecommendation systems, clinical trials and hyperparameter tuning. We consider\na kernel bandit problem under stochastically delayed feedback, and propose an\nalgorithm with $\\tilde{\\mathcal{O}}(\\sqrt{\\Gamma_k(T)T}+\\mathbb{E}[\\tau])$\nregret, where $T$ is the number of time steps, $\\Gamma_k(T)$ is the maximum\ninformation gain of the kernel with $T$ observations, and $\\tau$ is the delay\nrandom variable. This represents a significant improvement over the state of\nthe art regret bound of\n$\\tilde{\\mathcal{O}}(\\Gamma_k(T)\\sqrt{T}+\\mathbb{E}[\\tau]\\Gamma_k(T))$ reported\nin Verma et al. (2022). In particular, for very non-smooth kernels, the\ninformation gain grows almost linearly in time, trivializing the existing\nresults. We also validate our theoretical results with simulations.\n","authors":["Sattar Vakili","Danyal Ahmed","Alberto Bernacchia","Ciara Pike-Burke"],"pdf_url":"https://arxiv.org/pdf/2302.00392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00390v1","updated":"2023-02-01T11:59:17Z","published":"2023-02-01T11:59:17Z","title":"Hierarchical Classification of Research Fields in the \"Web of Science\"\n  Using Deep Learning","summary":"  The scholarly publication space is growing steadily not just in numbers but\nalso in complexity due to collaboration between individuals from within and\nacross fields of research. This paper presents a hierarchical classification\nsystem that automatically categorizes a scholarly publication using its\nabstract into a three-tier hierarchical label set of fields\n(discipline-field-subfield). This system enables a holistic view about the\ninterdependence of research activities in the mentioned hierarchical tiers in\nterms of knowledge production through articles and impact through citations.\n  The classification system (44 disciplines - 738 fields - 1,501 subfields)\nutilizes and is able to cope with 160 million abstract snippets in Microsoft\nAcademic Graph (Version 2018-05-17) using batch training in a modularized and\ndistributed fashion to address and assess interdisciplinarity and inter-field\nclassifications. In addition, we have explored multi-class classifications in\nboth the single-label and multi-label settings. In total, we have conducted\n3,140 experiments, in all models (Convolutional Neural Networks, Recurrent\nNeural Networks, Transformers), the classification accuracy is > 90% in 77.84%\nand 78.83% of the single-label and multi-label classifications, respectively.\nWe examine the advantages of our classification by its ability to better align\nresearch texts and output with disciplines, to adequately classify them in an\nautomated way, as well as to capture the degree of interdisciplinarity in a\npublication which enables downstream analytics such as field\ninterdisciplinarity. This system (a set of pretrained models) can serve as a\nbackbone to an interactive system of indexing scientific publications.\n","authors":["Susie Xi Rao","Peter H. Egger","Ce Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00390v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.00388v1","updated":"2023-02-01T11:48:10Z","published":"2023-02-01T11:48:10Z","title":"Short-term Prediction and Filtering of Solar Power Using State-Space\n  Gaussian Processes","summary":"  Short-term forecasting of solar photovoltaic energy (PV) production is\nimportant for powerplant management. Ideally these forecasts are equipped with\nerror bars, so that downstream decisions can account for uncertainty. To\nproduce predictions with error bars in this setting, we consider Gaussian\nprocesses (GPs) for modelling and predicting solar photovoltaic energy\nproduction in the UK. A standard application of GP regression on the PV\ntimeseries data is infeasible due to the large data size and non-Gaussianity of\nPV readings. However, this is made possible by leveraging recent advances in\nscalable GP inference, in particular, by using the state-space form of GPs,\ncombined with modern variational inference techniques. The resulting model is\nnot only scalable to large datasets but can also handle continuous data streams\nvia Kalman filtering.\n","authors":["Sean Nassimiha","Peter Dudfield","Jack Kelly","Marc Peter Deisenroth","So Takao"],"pdf_url":"https://arxiv.org/pdf/2302.00388v1.pdf","comment":"Workshop paper submitted to \"Tackling Climate Change with Machine\n  Learning: workshop at NeurIPS 2022\""},{"id":"http://arxiv.org/abs/2301.13821v2","updated":"2023-02-01T11:35:52Z","published":"2023-01-31T18:07:26Z","title":"Complete Neural Networks for Euclidean Graphs","summary":"  We propose a 2-WL-like geometric graph isomorphism test and prove it is\ncomplete when applied to Euclidean Graphs in $\\mathbb{R}^3$. We then use recent\nresults on multiset embeddings to devise an efficient geometric GNN model with\nequivalent separation power. We verify empirically that our GNN model is able\nto separate particularly challenging synthetic examples, and demonstrate its\nusefulness for a chemical property prediction problem.\n","authors":["Snir Hordan","Tal Amir","Steven J. Gortler","Nadav Dym"],"pdf_url":"https://arxiv.org/pdf/2301.13821v2.pdf","comment":"19 pages, updated 3 figures"},{"id":"http://arxiv.org/abs/2211.14594v3","updated":"2023-02-01T11:22:57Z","published":"2022-11-26T15:35:36Z","title":"Direct-Effect Risk Minimization for Domain Generalization","summary":"  We study the problem of out-of-distribution (o.o.d.) generalization where\nspurious correlations of attributes vary across training and test domains. This\nis known as the problem of correlation shift and has posed concerns on the\nreliability of machine learning. In this work, we introduce the concepts of\ndirect and indirect effects from causal inference to the domain generalization\nproblem. We argue that models that learn direct effects minimize the worst-case\nrisk across correlation-shifted domains. To eliminate the indirect effects, our\nalgorithm consists of two stages: in the first stage, we learn an\nindirect-effect representation by minimizing the prediction error of domain\nlabels using the representation and the class label; in the second stage, we\nremove the indirect effects learned in the first stage by matching each data\nwith another data of similar indirect-effect representation but of different\nclass label. We also propose a new model selection method by matching the\nvalidation set in the same way, which is shown to improve the generalization\nperformance of existing models on correlation-shifted datasets. Experiments on\n5 correlation-shifted datasets and the DomainBed benchmark verify the\neffectiveness of our approach.\n","authors":["Yuhui Li","Zejia Wu","Chao Zhang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.14594v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00375v1","updated":"2023-02-01T11:14:08Z","published":"2023-02-01T11:14:08Z","title":"Optimal Learning of Deep Random Networks of Extensive-width","summary":"  We consider the problem of learning a target function corresponding to a\ndeep, extensive-width, non-linear neural network with random Gaussian weights.\nWe consider the asymptotic limit where the number of samples, the input\ndimension and the network width are proportionally large. We derive a\nclosed-form expression for the Bayes-optimal test error, for regression and\nclassification tasks. We contrast these Bayes-optimal errors with the test\nerrors of ridge regression, kernel and random features regression. We find, in\nparticular, that optimally regularized ridge regression, as well as kernel\nregression, achieve Bayes-optimal performances, while the logistic loss yields\na near-optimal test error for classification. We further show numerically that\nwhen the number of samples grows faster than the dimension, ridge and kernel\nmethods become suboptimal, while neural networks achieve test error close to\nzero from quadratically many samples.\n","authors":["Hugo Cui","Florent Krzakala","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2302.00375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00374v1","updated":"2023-02-01T11:12:35Z","published":"2023-02-01T11:12:35Z","title":"HOAX: A Hyperparameter Optimization Algorithm Explorer for Neural\n  Networks","summary":"  Computational chemistry has become an important tool to predict and\nunderstand molecular properties and reactions. Even though recent years have\nseen a significant growth in new algorithms and computational methods that\nspeed up quantum chemical calculations, the bottleneck for trajectory-based\nmethods to study photoinduced processes is still the huge number of electronic\nstructure calculations. In this work, we present an innovative solution, in\nwhich the amount of electronic structure calculations is drastically reduced,\nby employing machine learning algorithms and methods borrowed from the realm of\nartificial intelligence. However, applying these algorithms effectively\nrequires finding optimal hyperparameters, which remains a challenge itself.\nHere we present an automated user-friendly framework, HOAX, to perform the\nhyperparameter optimization for neural networks, which bypasses the need for a\nlengthy manual process. The neural network generated potential energy surfaces\n(PESs) reduces the computational costs compared to the ab initio-based PESs. We\nperform a comparative investigation on the performance of different\nhyperparameter optimiziation algorithms, namely grid search, simulated\nannealing, genetic algorithm, and bayesian optimizer in finding the optimal\nhyperparameters necessary for constructing the well-performing neural network\nin order to fit the PESs of small organic molecules. Our results show that this\nautomated toolkit not only facilitate a straightforward way to perform the\nhyperparameter optimization but also the resulting neural networks-based\ngenerated PESs are in reasonable agreement with the ab initio-based PESs.\n","authors":["Albert Thie","Maximilian F. S. J. Menger","Shirin Faraji"],"pdf_url":"https://arxiv.org/pdf/2302.00374v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2302.00371v1","updated":"2023-02-01T11:00:24Z","published":"2023-02-01T11:00:24Z","title":"Simple yet Effective Gradient-Free Graph Convolutional Networks","summary":"  Linearized Graph Neural Networks (GNNs) have attracted great attention in\nrecent years for graph representation learning. Compared with nonlinear Graph\nNeural Network (GNN) models, linearized GNNs are much more time-efficient and\ncan achieve comparable performances on typical downstream tasks such as node\nclassification. Although some linearized GNN variants are purposely crafted to\nmitigate ``over-smoothing\", empirical studies demonstrate that they still\nsomehow suffer from this issue. In this paper, we instead relate over-smoothing\nwith the vanishing gradient phenomenon and craft a gradient-free training\nframework to achieve more efficient and effective linearized GNNs which can\nsignificantly overcome over-smoothing and enhance the generalization of the\nmodel. The experimental results demonstrate that our methods achieve better and\nmore stable performances on node classification tasks with varying depths and\ncost much less training time.\n","authors":["Yulin Zhu","Xing Ai","Qimai Li","Xiao-Ming Wu","Kai Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00370v1","updated":"2023-02-01T10:58:55Z","published":"2023-02-01T10:58:55Z","title":"How to select predictive models for causal inference?","summary":"  Predictive models -- as with machine learning -- can underpin causal\ninference, to estimate the effects of an intervention at the population or\nindividual level. This opens the door to a plethora of models, useful to match\nthe increasing complexity of health data, but also the Pandora box of model\nselection: which of these models yield the most valid causal estimates? Classic\nmachine-learning cross-validation procedures are not directly applicable.\nIndeed, an appropriate selection procedure for causal inference should equally\nweight both outcome errors for each individual, treated or not treated, whereas\none outcome may be seldom observed for a sub-population. We study how more\nelaborate risks benefit causal model selection. We show theoretically that\nsimple risks are brittle to weak overlap between treated and non-treated\nindividuals as well as to heterogeneous errors between populations. Rather a\nmore elaborate metric, the R-risk appears as a proxy of the oracle error on\ncausal estimates, observable at the cost of an overlap re-weighting. As the\nR-risk is defined not only from model predictions but also by using the\nconditional mean outcome and the treatment probability, using it for model\nselection requires adapting cross validation. Extensive experiments show that\nthe resulting procedure gives the best causal model selection.\n","authors":["Doutreligne Matthieu","Varoquaux Gaël"],"pdf_url":"https://arxiv.org/pdf/2302.00370v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2302.00368v1","updated":"2023-02-01T10:55:27Z","published":"2023-02-01T10:55:27Z","title":"Test-Time Amendment with a Coarse Classifier for Fine-Grained\n  Classification","summary":"  We investigate the problem of reducing mistake severity for fine-grained\nclassification. Fine-grained classification can be challenging, mainly due to\nthe requirement of knowledge or domain expertise for accurate annotation.\nHowever, humans are particularly adept at performing coarse classification as\nit requires relatively low levels of expertise. To this end, we present a novel\napproach for Post-Hoc Correction called Hierarchical Ensembles (HiE) that\nutilizes label hierarchy to improve the performance of fine-grained\nclassification at test-time using the coarse-grained predictions. By only\nrequiring the parents of leaf nodes, our method significantly reduces avg.\nmistake severity while improving top-1 accuracy on the iNaturalist-19 and\ntieredImageNet-H datasets, achieving a new state-of-the-art on both benchmarks.\nWe also investigate the efficacy of our approach in the semi-supervised\nsetting. Our approach brings notable gains in top-1 accuracy while\nsignificantly decreasing the severity of mistakes as training data decreases\nfor the fine-grained classes. The simplicity and post-hoc nature of HiE render\nit practical to be used with any off-the-shelf trained model to improve its\npredictions further.\n","authors":["Kanishk Jain","Shyamgopal Karthik","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2302.00368v1.pdf","comment":"8 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.00358v1","updated":"2023-02-01T10:37:34Z","published":"2023-02-01T10:37:34Z","title":"Bandit Convex Optimisation Revisited: FTRL Achieves $\\tilde{O}(t^{1/2})$\n  Regret","summary":"  We show that a kernel estimator using multiple function evaluations can be\neasily converted into a sampling-based bandit estimator with expectation equal\nto the original kernel estimate. Plugging such a bandit estimator into the\nstandard FTRL algorithm yields a bandit convex optimisation algorithm that\nachieves $\\tilde{O}(t^{1/2})$ regret against adversarial time-varying convex\nloss functions.\n","authors":["David Young","Douglas Leith","George Iosifidis"],"pdf_url":"https://arxiv.org/pdf/2302.00358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10194v2","updated":"2023-02-01T10:31:45Z","published":"2023-01-24T18:10:11Z","title":"WEASEL 2.0 -- A Random Dilated Dictionary Transform for Fast, Accurate\n  and Memory Constrained Time Series Classification","summary":"  A time series is a sequence of sequentially ordered real values in time. Time\nseries classification (TSC) is the task of assigning a time series to one of a\nset of predefined classes, usually based on a model learned from examples.\nDictionary-based methods for TSC rely on counting the frequency of certain\npatterns in time series and are important components of the currently most\naccurate TSC ensembles. One of the early dictionary-based methods was WEASEL,\nwhich at its time achieved SotA results while also being very fast. However, it\nis outperformed both in terms of speed and accuracy by other methods.\nFurthermore, its design leads to an unpredictably large memory footprint,\nmaking it inapplicable for many applications.\n  In this paper, we present WEASEL 2.0, a complete overhaul of WEASEL based on\ntwo recent advancements in TSC: Dilation and ensembling of randomized\nhyper-parameter settings. These two techniques allow WEASEL 2.0 to work with a\nfixed-size memory footprint while at the same time improving accuracy. Compared\nto 15 other SotA methods on the UCR benchmark set, WEASEL 2.0 is significantly\nmore accurate than other dictionary methods and not significantly worse than\nthe currently best methods. Actually, it achieves the highest median accuracy\nover all data sets, and it performs best in 5 out of 12 problem classes. We\nthus believe that WEASEL 2.0 is a viable alternative for current TSC and also a\npotentially interesting input for future ensembles.\n","authors":["Patrick Schäfer","Ulf Leser"],"pdf_url":"https://arxiv.org/pdf/2301.10194v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15264v2","updated":"2023-02-01T10:27:16Z","published":"2022-09-30T06:44:37Z","title":"Diffusion-based Image Translation using Disentangled Style and Content\n  Representation","summary":"  Diffusion-based image translation guided by semantic texts or a single target\nimage has enabled flexible style transfer which is not limited to the specific\ndomains. Unfortunately, due to the stochastic nature of diffusion models, it is\noften difficult to maintain the original content of the image during the\nreverse diffusion. To address this, here we present a novel diffusion-based\nunsupervised image translation method using disentangled style and content\nrepresentation.\n  Specifically, inspired by the splicing Vision Transformer, we extract\nintermediate keys of multihead self attention layer from ViT model and used\nthem as the content preservation loss. Then, an image guided style transfer is\nperformed by matching the [CLS] classification token from the denoised samples\nand target image, whereas additional CLIP loss is used for the text-driven\nstyle transfer. To further accelerate the semantic change during the reverse\ndiffusion, we also propose a novel semantic divergence loss and resampling\nstrategy. Our experimental results show that the proposed method outperforms\nstate-of-the-art baseline models in both text-guided and image-guided\ntranslation tasks.\n","authors":["Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2209.15264v2.pdf","comment":"ICLR 2023 camera ready"},{"id":"http://arxiv.org/abs/2302.00353v1","updated":"2023-02-01T10:24:55Z","published":"2023-02-01T10:24:55Z","title":"Towards Label-Efficient Incremental Learning: A Survey","summary":"  The current dominant paradigm when building a machine learning model is to\niterate over a dataset over and over until convergence. Such an approach is\nnon-incremental, as it assumes access to all images of all categories at once.\nHowever, for many applications, non-incremental learning is unrealistic. To\nthat end, researchers study incremental learning, where a learner is required\nto adapt to an incoming stream of data with a varying distribution while\npreventing forgetting of past knowledge. Significant progress has been made,\nhowever, the vast majority of works focus on the fully supervised setting,\nmaking these algorithms label-hungry thus limiting their real-life deployment.\nTo that end, in this paper, we make the first attempt to survey recently\ngrowing interest in label-efficient incremental learning. We identify three\nsubdivisions, namely semi-, few-shot- and self-supervised learning to reduce\nlabeling efforts. Finally, we identify novel directions that can further\nenhance label-efficiency and improve incremental learning scalability. Project\nwebsite: {https://github.com/kilickaya/label-efficient-il.\n","authors":["Mert Kilickaya","Joost van de Weijer","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2302.00353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00347v1","updated":"2023-02-01T10:11:03Z","published":"2023-02-01T10:11:03Z","title":"Anderson Acceleration For Bioinformatics-Based Machine Learning","summary":"  Anderson acceleration (AA) is a well-known method for accelerating the\nconvergence of iterative algorithms, with applications in various fields\nincluding deep learning and optimization. Despite its popularity in these\nareas, the effectiveness of AA in classical machine learning classifiers has\nnot been thoroughly studied. Tabular data, in particular, presents a unique\nchallenge for deep learning models, and classical machine learning models are\nknown to perform better in these scenarios. However, the convergence analysis\nof these models has received limited attention. To address this gap in\nresearch, we implement a support vector machine (SVM) classifier variant that\nincorporates AA to speed up convergence. We evaluate the performance of our SVM\nwith and without Anderson acceleration on several datasets from the biology\ndomain and demonstrate that the use of AA significantly improves convergence\nand reduces the training loss as the number of iterations increases. Our\nfindings provide a promising perspective on the potential of Anderson\nacceleration in the training of simple machine learning classifiers and\nunderscore the importance of further research in this area. By showing the\neffectiveness of AA in this setting, we aim to inspire more studies that\nexplore the applications of AA in classical machine learning.\n","authors":["Sarwan Ali","Prakash Chourasia","Murray Patterson"],"pdf_url":"https://arxiv.org/pdf/2302.00347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00341v1","updated":"2023-02-01T09:53:57Z","published":"2023-02-01T09:53:57Z","title":"Predicting CSI Sequences With Attention-Based Neural Networks","summary":"  In this work, we consider the problem of multi-step channel prediction in\nwireless communication systems. In existing works, autoregressive (AR) models\nare either replaced or combined with feed-forward neural networks(NNs) or,\nalternatively, with recurrent neural networks (RNNs). This paper explores the\npossibility of using sequence-to-sequence (Seq2Seq) and transformer neural\nnetwork (TNN) models for channel state information (CSI) prediction. Simulation\nresults show that both, Seq2Seq and TNNs, represent an appealing alternative to\nRNNs and feed-forward NNs in the context of CSI prediction. Additionally, the\nTNN with a few adaptations can extrapolate better than other models to CSI\nsequences that are either shorter or longer than the ones the model saw during\ntraining.\n","authors":["Valentina Rizzello","Benedikt Böck","Michael Joham","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2302.00341v1.pdf","comment":"Submitted to IEEE for publication"},{"id":"http://arxiv.org/abs/2206.12543v2","updated":"2023-02-01T09:51:54Z","published":"2022-06-25T03:02:35Z","title":"A Fast, Well-Founded Approximation to the Empirical Neural Tangent\n  Kernel","summary":"  Empirical neural tangent kernels (eNTKs) can provide a good understanding of\na given network's representation: they are often far less expensive to compute\nand applicable more broadly than infinite width NTKs. For networks with O\noutput units (e.g. an O-class classifier), however, the eNTK on N inputs is of\nsize $NO \\times NO$, taking $O((NO)^2)$ memory and up to $O((NO)^3)$\ncomputation. Most existing applications have therefore used one of a handful of\napproximations yielding $N \\times N$ kernel matrices, saving orders of\nmagnitude of computation, but with limited to no justification. We prove that\none such approximation, which we call \"sum of logits\", converges to the true\neNTK at initialization for any network with a wide final \"readout\" layer. Our\nexperiments demonstrate the quality of this approximation for various uses\nacross a range of settings.\n","authors":["Mohamad Amin Mohamadi","Danica J. Sutherland"],"pdf_url":"https://arxiv.org/pdf/2206.12543v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01295v3","updated":"2023-02-01T09:35:46Z","published":"2022-10-04T00:46:49Z","title":"Max-Quantile Grouped Infinite-Arm Bandits","summary":"  In this paper, we consider a bandit problem in which there are a number of\ngroups each consisting of infinitely many arms. Whenever a new arm is requested\nfrom a given group, its mean reward is drawn from an unknown reservoir\ndistribution (different for each group), and the uncertainty in the arm's mean\nreward can only be reduced via subsequent pulls of the arm. The goal is to\nidentify the infinite-arm group whose reservoir distribution has the highest\n$(1-\\alpha)$-quantile (e.g., median if $\\alpha = \\frac{1}{2}$), using as few\ntotal arm pulls as possible. We introduce a two-step algorithm that first\nrequests a fixed number of arms from each group and then runs a finite-arm\ngrouped max-quantile bandit algorithm. We characterize both the\ninstance-dependent and worst-case regret, and provide a matching lower bound\nfor the latter, while discussing various strengths, weaknesses, algorithmic\nimprovements, and potential lower bounds associated with our instance-dependent\nupper bounds.\n","authors":["Ivan Lau","Yan Hao Ling","Mayank Shrivastava","Jonathan Scarlett"],"pdf_url":"https://arxiv.org/pdf/2210.01295v3.pdf","comment":"ALT 2023"},{"id":"http://arxiv.org/abs/2205.14515v2","updated":"2023-02-01T09:34:27Z","published":"2022-05-28T19:50:52Z","title":"Additive Higher-Order Factorization Machines","summary":"  In the age of big data and interpretable machine learning, approaches need to\nwork at scale and at the same time allow for a clear mathematical understanding\nof the method's inner workings. While there exist inherently interpretable\nsemi-parametric regression techniques for large-scale applications to account\nfor non-linearity in the data, their model complexity is still often\nrestricted. One of the main limitations are missing interactions in these\nmodels, which are not included for the sake of better interpretability, but\nalso due to untenable computational costs. To address this shortcoming, we\nderive a scalable high-order tensor product spline model using a factorization\napproach. Our method allows to include all (higher-order) interactions of\nnon-linear feature effects while having computational costs proportional to a\nmodel without interactions. We prove both theoretically and empirically that\nour methods scales notably better than existing approaches, derive meaningful\npenalization schemes and also discuss further theoretical aspects. We finally\ninvestigate predictive and estimation performance both with synthetic and real\ndata.\n","authors":["David Rügamer"],"pdf_url":"https://arxiv.org/pdf/2205.14515v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.03049v2","updated":"2023-02-01T09:31:50Z","published":"2021-07-07T07:20:21Z","title":"ADAPT : Awesome Domain Adaptation Python Toolbox","summary":"  In this paper, we introduce the ADAPT library, an open source Python API\nproviding the implementation of the main transfer learning and domain\nadaptation methods. The library is designed with a user friendly approach to\nfacilitate the access to domain adaptation for a wide public. ADAPT is\ncompatible with scikit-learn and TensorFlow and a full documentation is\nproposed online https://adapt-python.github.io/adapt/ with a substantial\ngallery of examples.\n","authors":["Antoine de Mathelin","Mounir Atiq","Guillaume Richard","Alejandro de la Concha","Mouad Yachouti","François Deheeger","Mathilde Mougeot","Nicolas Vayatis"],"pdf_url":"https://arxiv.org/pdf/2107.03049v2.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.00333v1","updated":"2023-02-01T09:31:15Z","published":"2023-02-01T09:31:15Z","title":"Deep learning for $ψ$-weakly dependent processes","summary":"  In this paper, we perform deep neural networks for learning $\\psi$-weakly\ndependent processes. Such weak-dependence property includes a class of weak\ndependence conditions such as mixing, association,$\\cdots$ and the setting\nconsidered here covers many commonly used situations such as: regression\nestimation, time series prediction, time series classification,$\\cdots$ The\nconsistency of the empirical risk minimization algorithm in the class of deep\nneural networks predictors is established. We achieve the generalization bound\nand obtain a learning rate, which is less than $\\mathcal{O}(n^{-1/\\alpha})$,\nfor all $\\alpha > 2 $. Applications to binary time series classification and\nprediction in affine causal models with exogenous covariates are carried out.\nSome simulation results are provided, as well as an application to the US\nrecession data.\n","authors":["William Kengne","Wade Modou"],"pdf_url":"https://arxiv.org/pdf/2302.00333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.13162v3","updated":"2023-02-01T09:20:08Z","published":"2021-10-25T18:00:02Z","title":"Quantum machine learning beyond kernel methods","summary":"  Machine learning algorithms based on parametrized quantum circuits are prime\ncandidates for near-term applications on noisy quantum computers. In this\ndirection, various types of quantum machine learning models have been\nintroduced and studied extensively. Yet, our understanding of how these models\ncompare, both mutually and to classical models, remains limited. In this work,\nwe identify a constructive framework that captures all standard models based on\nparametrized quantum circuits: that of linear quantum models. In particular, we\nshow using tools from quantum information theory how data re-uploading\ncircuits, an apparent outlier of this framework, can be efficiently mapped into\nthe simpler picture of linear models in quantum Hilbert spaces. Furthermore, we\nanalyze the experimentally-relevant resource requirements of these models in\nterms of qubit number and amount of data needed to learn. Based on recent\nresults from classical machine learning, we prove that linear quantum models\nmust utilize exponentially more qubits than data re-uploading models in order\nto solve certain learning tasks, while kernel methods additionally require\nexponentially more data points. Our results provide a more comprehensive view\nof quantum machine learning models as well as insights on the compatibility of\ndifferent models with NISQ constraints.\n","authors":["Sofiene Jerbi","Lukas J. Fiderer","Hendrik Poulsen Nautrup","Jonas M. Kübler","Hans J. Briegel","Vedran Dunjko"],"pdf_url":"https://arxiv.org/pdf/2110.13162v3.pdf","comment":"10+10 pages, 14 figures; significant changes in the main text,\n  corrections in the numerical simulations"},{"id":"http://arxiv.org/abs/2302.00328v1","updated":"2023-02-01T09:14:28Z","published":"2023-02-01T09:14:28Z","title":"Learning Functional Transduction","summary":"  Research in Machine Learning has polarized into two general regression\napproaches: Transductive methods derive estimates directly from available data\nbut are usually problem unspecific. Inductive methods can be much more\nparticular, but generally require tuning and compute-intensive searches for\nsolutions. In this work, we adopt a hybrid approach: We leverage the theory of\nReproducing Kernel Banach Spaces (RKBS) and show that transductive principles\ncan be induced through gradient descent to form efficient \\textit{in-context}\nneural approximators. We apply this approach to RKBS of function-valued\noperators and show that once trained, our \\textit{Transducer} model can capture\non-the-fly relationships between infinite-dimensional input and output\nfunctions, given a few example pairs, and return new function estimates. We\ndemonstrate the benefit of our transductive approach to model complex physical\nsystems influenced by varying external factors with little data at a fraction\nof the usual deep learning training computation cost for partial differential\nequations and climate modeling applications.\n","authors":["Mathieu Chalvidal","Thomas Serre","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2302.00328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00319v1","updated":"2023-02-01T08:54:00Z","published":"2023-02-01T08:54:00Z","title":"Development of deep biological ages aware of morbidity and mortality\n  based on unsupervised and semi-supervised deep learning approaches","summary":"  Background: While deep learning technology, which has the capability of\nobtaining latent representations based on large-scale data, can be a potential\nsolution for the discovery of a novel aging biomarker, existing deep learning\nmethods for biological age estimation usually depend on chronological ages and\nlack of consideration of mortality and morbidity that are the most significant\noutcomes of aging. Methods: This paper proposes a novel deep learning model to\nlearn latent representations of biological aging in regard to subjects'\nmorbidity and mortality. The model utilizes health check-up data in addition to\nmorbidity and mortality information to learn the complex relationships between\naging and measured clinical attributes. Findings: The proposed model is\nevaluated on a large dataset of general populations compared with KDM and other\nlearning-based models. Results demonstrate that biological ages obtained by the\nproposed model have superior discriminability of subjects' morbidity and\nmortality.\n","authors":["Seong-Eun Moon","Ji Won Yoon","Shinyoung Joo","Yoohyung Kim","Jae Hyun Bae","Seokho Yoon","Haanju Yoo","Young Min Cho"],"pdf_url":"https://arxiv.org/pdf/2302.00319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00316v1","updated":"2023-02-01T08:50:48Z","published":"2023-02-01T08:50:48Z","title":"Accelerated First-Order Optimization under Nonlinear Constraints","summary":"  We exploit analogies between first-order algorithms for constrained\noptimization and non-smooth dynamical systems to design a new class of\naccelerated first-order algorithms for constrained optimization. Unlike\nFrank-Wolfe or projected gradients, these algorithms avoid optimization over\nthe entire feasible set at each iteration. We prove convergence to stationary\npoints even in a nonconvex setting and we derive rates for the convex setting.\nAn important property of these algorithms is that constraints are expressed in\nterms of velocities instead of positions, which naturally leads to sparse,\nlocal and convex approximations of the feasible set (even if the feasible set\nis nonconvex). Thus, the complexity tends to grow mildly in the number of\ndecision variables and in the number of constraints, which makes the algorithms\nsuitable for machine learning applications. We apply our algorithms to a\ncompressed sensing and a sparse regression problem, showing that we can treat\nnonconvex $\\ell^p$ constraints ($p<1$) efficiently, while recovering\nstate-of-the-art performance for $p=1$.\n","authors":["Michael Muehlebach","Michael I. Jordan"],"pdf_url":"https://arxiv.org/pdf/2302.00316v1.pdf","comment":"25 pages, 5 figures"},{"id":"http://arxiv.org/abs/2111.01097v3","updated":"2023-02-01T08:17:01Z","published":"2021-11-01T17:07:02Z","title":"Code2Snapshot: Using Code Snapshots for Learning Representations of\n  Source Code","summary":"  There are several approaches for encoding source code in the input vectors of\nneural models. These approaches attempt to include various syntactic and\nsemantic features of input programs in their encoding. In this paper, we\ninvestigate Code2Snapshot, a novel representation of the source code that is\nbased on the snapshots of input programs. We evaluate several variations of\nthis representation and compare its performance with state-of-the-art\nrepresentations that utilize the rich syntactic and semantic features of input\nprograms. Our preliminary study on the utility of Code2Snapshot in the code\nsummarization and code classification tasks suggests that simple snapshots of\ninput programs have comparable performance to state-of-the-art representations.\nInterestingly, obscuring input programs have insignificant impacts on the\nCode2Snapshot performance, suggesting that, for some tasks, neural models may\nprovide high performance by relying merely on the structure of input programs.\n","authors":["Md Rafiqul Islam Rabin","Mohammad Amin Alipour"],"pdf_url":"https://arxiv.org/pdf/2111.01097v3.pdf","comment":"The 21st IEEE International Conference on Machine Learning and\n  Applications (ICMLA'22)"},{"id":"http://arxiv.org/abs/2210.16940v2","updated":"2023-02-01T08:10:24Z","published":"2022-10-30T20:30:19Z","title":"FI-ODE: Certified and Robust Forward Invariance in Neural ODEs","summary":"  Forward invariance is a long-studied property in control theory that is used\nto certify that a dynamical system stays within some pre-specified set of\nstates for all time, and also admits robustness guarantees (e.g., the\ncertificate holds under perturbations). We propose a general framework for\ntraining and provably certifying robust forward invariance in Neural ODEs. We\napply this framework in two settings: certified adversarial robustness for\nimage classification, and certified safety in continuous control. Notably, our\nmethod empirically produces superior adversarial robustness guarantees compared\nto prior work on certifiably robust Neural ODEs (including implicit-depth\nmodels).\n","authors":["Yujia Huang","Ivan Dario Jimenez Rodriguez","Huan Zhang","Yuanyuan Shi","Yisong Yue"],"pdf_url":"https://arxiv.org/pdf/2210.16940v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03845v3","updated":"2023-02-01T08:06:08Z","published":"2022-04-08T05:18:51Z","title":"Decompositional Generation Process for Instance-Dependent Partial Label\n  Learning","summary":"  Partial label learning (PLL) is a typical weakly supervised learning problem,\nwhere each training example is associated with a set of candidate labels among\nwhich only one is true. Most existing PLL approaches assume that the incorrect\nlabels in each training example are randomly picked as the candidate labels and\nmodel the generation process of the candidate labels in a simple way. However,\nthese approaches usually do not perform as well as expected due to the fact\nthat the generation process of the candidate labels is always\ninstance-dependent. Therefore, it deserves to be modeled in a refined way. In\nthis paper, we consider instance-dependent PLL and assume that the generation\nprocess of the candidate labels could decompose into two sequential parts,\nwhere the correct label emerges first in the mind of the annotator but then the\nincorrect labels related to the feature are also selected with the correct\nlabel as candidate labels due to uncertainty of labeling. Motivated by this\nconsideration, we propose a novel PLL method that performs Maximum A Posterior\n(MAP) based on an explicitly modeled generation process of candidate labels via\ndecomposed probability distribution models. Extensive experiments on manually\ncorrupted benchmark datasets and real-world datasets validate the effectiveness\nof the proposed method. Source code is available at\nhttps://github.com/palm-ml/idgp.\n","authors":["Congyu Qiao","Ning Xu","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2204.03845v3.pdf","comment":"ICLR 2023 Spotlight"},{"id":"http://arxiv.org/abs/2302.00299v1","updated":"2023-02-01T08:04:27Z","published":"2023-02-01T08:04:27Z","title":"Learning from Stochastic Labels","summary":"  Annotating multi-class instances is a crucial task in the field of machine\nlearning. Unfortunately, identifying the correct class label from a long\nsequence of candidate labels is time-consuming and laborious. To alleviate this\nproblem, we design a novel labeling mechanism called stochastic label. In this\nsetting, stochastic label includes two cases: 1) identify a correct class label\nfrom a small number of randomly given labels; 2) annotate the instance with\nNone label when given labels do not contain correct class label. In this paper,\nwe propose a novel suitable approach to learn from these stochastic labels. We\nobtain an unbiased estimator that utilizes less supervised information in\nstochastic labels to train a multi-class classifier. Additionally, it is\ntheoretically justifiable by deriving the estimation error bound of the\nproposed method. Finally, we conduct extensive experiments on widely-used\nbenchmark datasets to validate the superiority of our method by comparing it\nwith existing state-of-the-art methods.\n","authors":["Meng Wei","Zhongnian Li","Yong Zhou","Qiaoyu Guo","Xinzheng Xu"],"pdf_url":"https://arxiv.org/pdf/2302.00299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00294v1","updated":"2023-02-01T07:50:26Z","published":"2023-02-01T07:50:26Z","title":"The geometry of hidden representations of large transformer models","summary":"  Large transformers are powerful architectures for self-supervised analysis of\ndata of various nature, ranging from protein sequences to text to images. In\nthese models, the data representation in the hidden layers live in the same\nspace, and the semantic structure of the dataset emerges by a sequence of\nfunctionally identical transformations between one representation and the next.\nWe here characterize the geometric and statistical properties of these\nrepresentations, focusing on the evolution of such proprieties across the\nlayers. By analyzing geometric properties such as the intrinsic dimension (ID)\nand the neighbor composition we find that the representations evolve in a\nstrikingly similar manner in transformers trained on protein language tasks and\nimage reconstruction tasks. In the first layers, the data manifold expands,\nbecoming high-dimensional, and then it contracts significantly in the\nintermediate layers. In the last part of the model, the ID remains\napproximately constant or forms a second shallow peak. We show that the\nsemantic complexity of the dataset emerges at the end of the first peak. This\nphenomenon can be observed across many models trained on diverse datasets.\nBased on these observations, we suggest using the ID profile as an unsupervised\nproxy to identify the layers which are more suitable for downstream learning\ntasks.\n","authors":["Lucrezia Valeriani","Diego Doimo","Francesca Cuturello","Alessandro Laio","Alessio Ansuini","Alberto Cazzaniga"],"pdf_url":"https://arxiv.org/pdf/2302.00294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00293v1","updated":"2023-02-01T07:47:26Z","published":"2023-02-01T07:47:26Z","title":"A Survey of Methods, Challenges and Perspectives in Causality","summary":"  The Causality field aims to find systematic methods for uncovering\ncause-effect relationships. Such methods can find applications in many research\nfields, justifying a great interest in this domain. Machine Learning models\nhave shown success in a large variety of tasks by extracting correlation\npatterns from high-dimensional data but still struggle when generalizing out of\ntheir initial distribution. As causal engines aim to learn mechanisms that are\nindependent from a data distribution, combining Machine Learning with Causality\nhas the potential to bring benefits to the two fields. In our work, we motivate\nthis assumption and provide applications. We first perform an extensive\noverview of the theories and methods for Causality from different perspectives.\nWe then provide a deeper look at the connections between Causality and Machine\nLearning and describe the challenges met by the two domains. We show the early\nattempts to bring the fields together and the possible perspectives for the\nfuture. We finish by providing a large variety of applications for techniques\nfrom Causality.\n","authors":["Gaël Gendron","Michael Witbrock","Gillian Dobbie"],"pdf_url":"https://arxiv.org/pdf/2302.00293v1.pdf","comment":"42 pages, 35 pages for the main paper and 7 pages for the supplement,\n  10 figures, submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2301.13758v2","updated":"2023-02-01T07:45:40Z","published":"2023-01-31T16:47:09Z","title":"Learning, Fast and Slow: A Goal-Directed Memory-Based Approach for\n  Dynamic Environments","summary":"  Model-based next state prediction and state value prediction are slow to\nconverge. To address these challenges, we do the following: i) Instead of a\nneural network, we do model-based planning using a parallel memory retrieval\nsystem (which we term the slow mechanism); ii) Instead of learning state\nvalues, we guide the agent's actions using goal-directed exploration, by using\na neural network to choose the next action given the current state and the goal\nstate (which we term the fast mechanism). The goal-directed exploration is\ntrained online using hippocampal replay of visited states and future imagined\nstates every single time step, leading to fast and efficient training.\nEmpirical studies show that our proposed method has a 92% solve rate across 100\nepisodes in a dynamically changing grid world, significantly outperforming\nstate-of-the-art actor critic mechanisms such as PPO (54%), TRPO (50%) and A2C\n(24%). Ablation studies demonstrate that both mechanisms are crucial. We posit\nthat the future of Reinforcement Learning (RL) will be to model goals and\nsub-goals for various tasks, and plan it out in a goal-directed memory-based\napproach.\n","authors":["John Chong Min Tan","Mehul Motani"],"pdf_url":"https://arxiv.org/pdf/2301.13758v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2302.00286v1","updated":"2023-02-01T07:35:02Z","published":"2023-02-01T07:35:02Z","title":"Jointist: Simultaneous Improvement of Multi-instrument Transcription and\n  Music Source Separation via Joint Training","summary":"  In this paper, we introduce Jointist, an instrument-aware multi-instrument\nframework that is capable of transcribing, recognizing, and separating multiple\nmusical instruments from an audio clip. Jointist consists of an instrument\nrecognition module that conditions the other two modules: a transcription\nmodule that outputs instrument-specific piano rolls, and a source separation\nmodule that utilizes instrument information and transcription results. The\njoint training of the transcription and source separation modules serves to\nimprove the performance of both tasks. The instrument module is optional and\ncan be directly controlled by human users. This makes Jointist a flexible\nuser-controllable framework.\n  Our challenging problem formulation makes the model highly useful in the real\nworld given that modern popular music typically consists of multiple\ninstruments. Its novelty, however, necessitates a new perspective on how to\nevaluate such a model. In our experiments, we assess the proposed model from\nvarious aspects, providing a new evaluation perspective for multi-instrument\ntranscription. Our subjective listening study shows that Jointist achieves\nstate-of-the-art performance on popular music, outperforming existing\nmulti-instrument transcription models such as MT3. %We also argue that\ntranscription models can be used as a preprocessing module for other music\nanalysis tasks. We conducted experiments on several downstream tasks and found\nthat the proposed method improved transcription by more than 1 percentage\npoints (ppt.), source separation by 5 SDR, downbeat detection by 1.8 ppt.,\nchord recognition by 1.4 ppt., and key estimation by 1.4 ppt., when utilizing\ntranscription results obtained from Jointist.\n","authors":["Kin Wai Cheuk","Keunwoo Choi","Qiuqiang Kong","Bochen Li","Minz Won","Ju-Chiang Wang","Yun-Ning Hung Dorien Herremans"],"pdf_url":"https://arxiv.org/pdf/2302.00286v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2206.10805"},{"id":"http://arxiv.org/abs/2302.00284v1","updated":"2023-02-01T07:31:25Z","published":"2023-02-01T07:31:25Z","title":"Selective Uncertainty Propagation in Offline RL","summary":"  We study the finite-horizon offline reinforcement learning (RL) problem.\nSince actions at any state can affect next-state distributions, the related\ndistributional shift challenges can make this problem far more statistically\ncomplex than offline policy learning for a finite sequence of stochastic\ncontextual bandit environments. We formalize this insight by showing that the\nstatistical hardness of offline RL instances can be measured by estimating the\nsize of actions' impact on next-state distributions. Furthermore, this\nestimated impact allows us to propagate just enough value function uncertainty\nfrom future steps to avoid model exploitation, enabling us to develop\nalgorithms that improve upon traditional pessimistic approaches for offline RL\non statistically simple instances. Our approach is supported by theory and\nsimulations.\n","authors":["Sanath Kumar Krishnamurthy","Tanmay Gangwani","Sumeet Katariya","Branislav Kveton","Anshuka Rangi"],"pdf_url":"https://arxiv.org/pdf/2302.00284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05989v3","updated":"2023-02-01T07:25:10Z","published":"2022-05-12T09:52:59Z","title":"Towards Answering Open-ended Ethical Quandary Questions","summary":"  Considerable advancements have been made in various NLP tasks based on the\nimpressive power of large language models (LLMs) and many NLP applications are\ndeployed in our daily lives. In this work, we challenge the capability of LLMs\nwith the new task of Ethical Quandary Generative Question Answering. Ethical\nquandary questions are more challenging to address because multiple conflicting\nanswers may exist to a single quandary. We explore the current capability of\nLLMs in providing an answer with a deliberative exchange of different\nperspectives to an ethical quandary, in the approach of Socratic philosophy,\ninstead of providing a closed answer like an oracle. We propose a model that\nsearches for different ethical principles applicable to the ethical quandary\nand generates an answer conditioned on the chosen principles through\nprompt-based few-shot learning. We also discuss the remaining challenges and\nethical issues involved in this task and suggest the direction toward\ndeveloping responsible NLP systems by incorporating human values explicitly.\n","authors":["Yejin Bang","Nayeon Lee","Tiezheng Yu","Leila Khalatbari","Yan Xu","Samuel Cahyawijaya","Dan Su","Bryan Wilie","Romain Barraud","Elham J. Barezi","Andrea Madotto","Hayden Kee","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2205.05989v3.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2301.02312v2","updated":"2023-02-01T07:08:58Z","published":"2023-01-05T21:58:46Z","title":"Training trajectories, mini-batch losses and the curious role of the\n  learning rate","summary":"  Stochastic gradient descent plays a fundamental role in nearly all\napplications of deep learning. However its ability to converge to a global\nminimum remains shrouded in mystery. In this paper we propose to study the\nbehavior of the loss function on fixed mini-batches along SGD trajectories. We\nshow that the loss function on a fixed batch appears to be remarkably\nconvex-like. In particular for ResNet the loss for any fixed mini-batch can be\naccurately modeled by a quadratic function and a very low loss value can be\nreached in just one step of gradient descent with sufficiently large learning\nrate. We propose a simple model that allows to analyze the relationship between\nthe gradients of stochastic mini-batches and the full batch. Our analysis\nallows us to discover the equivalency between iterate aggregates and specific\nlearning rate schedules. In particular, for Exponential Moving Average (EMA)\nand Stochastic Weight Averaging we show that our proposed model matches the\nobserved training trajectories on ImageNet. Our theoretical model predicts that\nan even simpler averaging technique, averaging just two points a many steps\napart, significantly improves accuracy compared to the baseline. We validated\nour findings on ImageNet and other datasets using ResNet architecture.\n","authors":["Mark Sandler","Andrey Zhmoginov","Max Vladymyrov","Nolan Miller"],"pdf_url":"https://arxiv.org/pdf/2301.02312v2.pdf","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2302.00275v1","updated":"2023-02-01T06:44:07Z","published":"2023-02-01T06:44:07Z","title":"Learning Generalized Zero-Shot Learners for Open-Domain Image\n  Geolocalization","summary":"  Image geolocalization is the challenging task of predicting the geographic\ncoordinates of origin for a given photo. It is an unsolved problem relying on\nthe ability to combine visual clues with general knowledge about the world to\nmake accurate predictions across geographies. We present\n$\\href{https://huggingface.co/geolocal/StreetCLIP}{\\text{StreetCLIP}}$, a\nrobust, publicly available foundation model not only achieving state-of-the-art\nperformance on multiple open-domain image geolocalization benchmarks but also\ndoing so in a zero-shot setting, outperforming supervised models trained on\nmore than 4 million images. Our method introduces a meta-learning approach for\ngeneralized zero-shot learning by pretraining CLIP from synthetic captions,\ngrounding CLIP in a domain of choice. We show that our method effectively\ntransfers CLIP's generalized zero-shot capabilities to the domain of image\ngeolocalization, improving in-domain generalized zero-shot performance without\nfinetuning StreetCLIP on a fixed set of classes.\n","authors":["Lukas Haas","Silas Alberti","Michal Skreta"],"pdf_url":"https://arxiv.org/pdf/2302.00275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00272v1","updated":"2023-02-01T06:30:41Z","published":"2023-02-01T06:30:41Z","title":"W2SAT: Learning to generate SAT instances from Weighted Literal\n  Incidence Graphs","summary":"  The Boolean Satisfiability (SAT) problem stands out as an attractive\nNP-complete problem in theoretic computer science and plays a central role in a\nbroad spectrum of computing-related applications. Exploiting and tuning SAT\nsolvers under numerous scenarios require massive high-quality industry-level\nSAT instances, which unfortunately are quite limited in the real world. To\naddress the data insufficiency issue, in this paper, we propose W2SAT, a\nframework to generate SAT formulas by learning intrinsic structures and\nproperties from given real-world/industrial instances in an implicit fashion.\nTo this end, we introduce a novel SAT representation called Weighted Literal\nIncidence Graph (WLIG), which exhibits strong representation ability and\ngeneralizability against existing counterparts, and can be efficiently\ngenerated via a specialized learning-based graph generative model. Decoding\nfrom WLIGs into SAT problems is then modeled as finding overlapping cliques\nwith a novel hill-climbing optimization method termed Optimal Weight Coverage\n(OWC). Experiments demonstrate the superiority of our WLIG-induced approach in\nterms of graph metrics, efficiency, and scalability in comparison to previous\nmethods. Additionally, we discuss the limitations of graph-based SAT generation\nfor real-world applications, especially when utilizing generated instances for\nSAT solver parameter-tuning, and pose some potential directions.\n","authors":["Weihuang Wen","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2302.00272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00271v1","updated":"2023-02-01T06:26:44Z","published":"2023-02-01T06:26:44Z","title":"CATFL: Certificateless Authentication-based Trustworthy Federated\n  Learning for 6G Semantic Communications","summary":"  Federated learning (FL) provides an emerging approach for collaboratively\ntraining semantic encoder/decoder models of semantic communication systems,\nwithout private user data leaving the devices. Most existing studies on\ntrustworthy FL aim to eliminate data poisoning threats that are produced by\nmalicious clients, but in many cases, eliminating model poisoning attacks\nbrought by fake servers is also an important objective. In this paper, a\ncertificateless authentication-based trustworthy federated learning (CATFL)\nframework is proposed, which mutually authenticates the identity of clients and\nserver. In CATFL, each client verifies the server's signature information\nbefore accepting the delivered global model to ensure that the global model is\nnot delivered by false servers. On the contrary, the server also verifies the\nserver's signature information before accepting the delivered model updates to\nensure that they are submitted by authorized clients. Compared to PKI-based\nmethods, the CATFL can avoid too high certificate management overheads.\nMeanwhile, the anonymity of clients shields data poisoning attacks, while\nreal-name registration may suffer from user-specific privacy leakage risks.\nTherefore, a pseudonym generation strategy is also presented in CATFL to\nachieve a trade-off between identity traceability and user anonymity, which is\nessential to conditionally prevent from user-specific privacy leakage.\nTheoretical security analysis and evaluation results validate the superiority\nof CATFL.\n","authors":["Gaolei Li","Yuanyuan Zhao","Yi Li"],"pdf_url":"https://arxiv.org/pdf/2302.00271v1.pdf","comment":"Accepted by WCNC workshop 2023"},{"id":"http://arxiv.org/abs/2302.00270v1","updated":"2023-02-01T06:25:46Z","published":"2023-02-01T06:25:46Z","title":"Internally Rewarded Reinforcement Learning","summary":"  We study a class of reinforcement learning problems where the reward signals\nfor policy learning are generated by a discriminator that is dependent on and\njointly optimized with the policy. This interdependence between the policy and\nthe discriminator leads to an unstable learning process because reward signals\nfrom an immature discriminator are noisy and impede policy learning, and\nconversely, an untrained policy impedes discriminator learning. We call this\nlearning setting $\\textit{Internally Rewarded Reinforcement Learning}$ (IRRL)\nas the reward is not provided directly by the environment but\n$\\textit{internally}$ by the discriminator. In this paper, we formally\nformulate IRRL and present a class of problems that belong to IRRL. We\ntheoretically derive and empirically analyze the effect of the reward function\nin IRRL and based on these analyses propose the clipped linear reward function.\nExperimental results show that the proposed reward function can consistently\nstabilize the training process by reducing the impact of reward noise, which\nleads to faster convergence and higher performance compared with baselines in\ndiverse tasks.\n","authors":["Mengdi Li","Xufeng Zhao","Jae Hee Lee","Cornelius Weber","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2302.00270v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2212.08049v4","updated":"2023-02-01T06:24:08Z","published":"2022-12-15T18:55:23Z","title":"Sliced Optimal Partial Transport","summary":"  Optimal transport (OT) has become exceedingly popular in machine learning,\ndata science, and computer vision. The core assumption in the OT problem is the\nequal total amount of mass in source and target measures, which limits its\napplication. Optimal Partial Transport (OPT) is a recently proposed solution to\nthis limitation. Similar to the OT problem, the computation of OPT relies on\nsolving a linear programming problem (often in high dimensions), which can\nbecome computationally prohibitive. In this paper, we propose an efficient\nalgorithm for calculating the OPT problem between two non-negative measures in\none dimension. Next, following the idea of sliced OT distances, we utilize\nslicing to define the sliced OPT distance. Finally, we demonstrate the\ncomputational and accuracy benefits of the sliced OPT-based method in various\nnumerical experiments. In particular, we show an application of our proposed\nSliced-OPT in noisy point cloud registration.\n","authors":["Yikun Bai","Bernard Schmitzer","Mathew Thorpe","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2212.08049v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.14442v2","updated":"2023-02-01T06:17:58Z","published":"2021-07-30T06:13:56Z","title":"Distribution free optimality intervals for clustering","summary":"  We address the problem of validating the ouput of clustering algorithms.\nGiven data $\\mathcal{D}$ and a partition $\\mathcal{C}$ of these data into $K$\nclusters, when can we say that the clusters obtained are correct or meaningful\nfor the data? This paper introduces a paradigm in which a clustering\n$\\mathcal{C}$ is considered meaningful if it is good with respect to a loss\nfunction such as the K-means distortion, and stable, i.e. the only good\nclustering up to small perturbations. Furthermore, we present a generic method\nto obtain post-inference guarantees of near-optimality and stability for a\nclustering $\\mathcal{C}$. The method can be instantiated for a variety of\nclustering criteria (also called loss functions) for which convex relaxations\nexist. Obtaining the guarantees amounts to solving a convex optimization\nproblem. We demonstrate the practical relevance of this method by obtaining\nguarantees for the K-means and the Normalized Cut clustering criteria on\nrealistic data sets. We also prove that asymptotic instability implies finite\nsample instability w.h.p., allowing inferences about the population\nclusterability from a sample. The guarantees do not depend on any\ndistributional assumptions, but they depend on the data set $\\mathcal{D}$\nadmitting a stable clustering.\n","authors":["Marina Meilă","Hanyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2107.14442v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00263v1","updated":"2023-02-01T06:13:09Z","published":"2023-02-01T06:13:09Z","title":"Dictionary-based Manifold Learning","summary":"  We propose a paradigm for interpretable Manifold Learning for scientific data\nanalysis, whereby we parametrize a manifold with $d$ smooth functions from a\nscientist-provided dictionary of meaningful, domain-related functions. When\nsuch a parametrization exists, we provide an algorithm for finding it based on\nsparse non-linear regression in the manifold tangent bundle, bypassing more\nstandard manifold learning algorithms. We also discuss conditions for the\nexistence of such parameterizations in function space and for successful\nrecovery from finite samples. We demonstrate our method with experimental\nresults from a real scientific domain.\n","authors":["Hanyu Zhang","Samson Joelle","Marina Meila"],"pdf_url":"https://arxiv.org/pdf/2302.00263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05428v2","updated":"2023-02-01T06:08:00Z","published":"2022-12-11T06:47:28Z","title":"ezDPS: An Efficient and Zero-Knowledge Machine Learning Inference\n  Pipeline","summary":"  Machine Learning as a service (MLaaS) permits resource-limited clients to\naccess powerful data analytics services ubiquitously. Despite its merits, MLaaS\nposes significant concerns regarding the integrity of delegated computation and\nthe privacy of the server's model parameters. To address this issue, Zhang et\nal. (CCS'20) initiated the study of zero-knowledge Machine Learning (zkML). Few\nzkML schemes have been proposed afterward; however, they focus on sole ML\nclassification algorithms that may not offer satisfactory accuracy or require\nlarge-scale training data and model parameters, which may not be desirable for\nsome applications. We propose ezDPS, a new efficient and zero-knowledge ML\ninference scheme. Unlike prior works, ezDPS is a zkML pipeline in which the\ndata is processed in multiple stages for high accuracy. Each stage of ezDPS is\nharnessed with an established ML algorithm that is shown to be effective in\nvarious applications, including Discrete Wavelet Transformation, Principal\nComponents Analysis, and Support Vector Machine. We design new gadgets to prove\nML operations effectively. We fully implemented ezDPS and assessed its\nperformance on real datasets. Experimental results showed that ezDPS achieves\none-to-three orders of magnitude more efficient than the generic circuit-based\napproach in all metrics while maintaining more desirable accuracy than single\nML classification approaches.\n","authors":["Haodi Wang","Thang Hoang"],"pdf_url":"https://arxiv.org/pdf/2212.05428v2.pdf","comment":"This paper is to appear in Privacy-Enhancing Technologies Symposium\n  (PETS) 2023"},{"id":"http://arxiv.org/abs/2302.00257v1","updated":"2023-02-01T05:41:41Z","published":"2023-02-01T05:41:41Z","title":"Implicit Regularization Leads to Benign Overfitting for Sparse Linear\n  Regression","summary":"  In deep learning, often the training process finds an interpolator (a\nsolution with 0 training loss), but the test loss is still low. This\nphenomenon, known as benign overfitting, is a major mystery that received a lot\nof recent attention. One common mechanism for benign overfitting is implicit\nregularization, where the training process leads to additional properties for\nthe interpolator, often characterized by minimizing certain norms. However,\neven for a simple sparse linear regression problem $y = \\beta^{*\\top} x +\\xi$\nwith sparse $\\beta^*$, neither minimum $\\ell_1$ or $\\ell_2$ norm interpolator\ngives the optimal test loss. In this work, we give a different parametrization\nof the model which leads to a new implicit regularization effect that combines\nthe benefit of $\\ell_1$ and $\\ell_2$ interpolators. We show that training our\nnew model via gradient descent leads to an interpolator with near-optimal test\nloss. Our result is based on careful analysis of the training dynamics and\nprovides another example of implicit regularization effect that goes beyond\nnorm minimization.\n","authors":["Mo Zhou","Rong Ge"],"pdf_url":"https://arxiv.org/pdf/2302.00257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00252v1","updated":"2023-02-01T05:29:10Z","published":"2023-02-01T05:29:10Z","title":"QLAB: Quadratic Loss Approximation-Based Optimal Learning Rate for Deep\n  Learning","summary":"  We propose a learning rate adaptation scheme, called QLAB, for descent\noptimizers. We derive QLAB by optimizing the quadratic approximation of the\nloss function and QLAB can be combined with any optimizer who can provide the\ndescent update direction. The computation of an adaptive learning rate with\nQLAB requires only computing an extra loss function value. We theoretically\nprove the convergence of the descent optimizers with QLAB. We demonstrate the\neffectiveness of QLAB in a range of optimization problems by combining with\nconclusively stochastic gradient descent, stochastic gradient descent with\nmomentum, and Adam. The performance is validated on multi-layer neural\nnetworks, CNN, VGG-Net, ResNet and ShuffleNet with two datasets, MNIST and\nCIFAR10.\n","authors":["Minghan Fu","Fang-Xiang Wu"],"pdf_url":"https://arxiv.org/pdf/2302.00252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00250v1","updated":"2023-02-01T05:27:34Z","published":"2023-02-01T05:27:34Z","title":"Quickest Change Detection for Unnormalized Statistical Models","summary":"  Classical quickest change detection algorithms require modeling pre-change\nand post-change distributions. Such an approach may not be feasible for various\nmachine learning models because of the complexity of computing the explicit\ndistributions. Additionally, these methods may suffer from a lack of robustness\nto model mismatch and noise. This paper develops a new variant of the classical\nCumulative Sum (CUSUM) algorithm for the quickest change detection. This\nvariant is based on Fisher divergence and the Hyv\\\"arinen score and is called\nthe Score-based CUSUM (SCUSUM) algorithm. The SCUSUM algorithm allows the\napplications of change detection for unnormalized statistical models, i.e.,\nmodels for which the probability density function contains an unknown\nnormalization constant. The asymptotic optimality of the proposed algorithm is\ninvestigated by deriving expressions for average detection delay and the mean\nrunning time to a false alarm. Numerical results are provided to demonstrate\nthe performance of the proposed algorithm.\n","authors":["Suya Wu","Enmao Diao","Taposh Banerjee","Jie Ding","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2302.00250v1.pdf","comment":"A version of this paper has been accepted by the 26th International\n  Conference on Artificial Intelligence and Statistics (AISTATS 2023)"},{"id":"http://arxiv.org/abs/2302.00248v1","updated":"2023-02-01T05:22:40Z","published":"2023-02-01T05:22:40Z","title":"A Nearly-Optimal Bound for Fast Regression with $\\ell_\\infty$ Guarantee","summary":"  Given a matrix $A\\in \\mathbb{R}^{n\\times d}$ and a vector $b\\in\n\\mathbb{R}^n$, we consider the regression problem with $\\ell_\\infty$\nguarantees: finding a vector $x'\\in \\mathbb{R}^d$ such that $ \\|x'-x^*\\|_\\infty\n\\leq \\frac{\\epsilon}{\\sqrt{d}}\\cdot \\|Ax^*-b\\|_2\\cdot \\|A^\\dagger\\|$ where\n$x^*=\\arg\\min_{x\\in \\mathbb{R}^d}\\|Ax-b\\|_2$. One popular approach for solving\nsuch $\\ell_2$ regression problem is via sketching: picking a structured random\nmatrix $S\\in \\mathbb{R}^{m\\times n}$ with $m\\ll n$ and $SA$ can be quickly\ncomputed, solve the ``sketched'' regression problem $\\arg\\min_{x\\in\n\\mathbb{R}^d} \\|SAx-Sb\\|_2$. In this paper, we show that in order to obtain\nsuch $\\ell_\\infty$ guarantee for $\\ell_2$ regression, one has to use sketching\nmatrices that are dense. To the best of our knowledge, this is the first user\ncase in which dense sketching matrices are necessary. On the algorithmic side,\nwe prove that there exists a distribution of dense sketching matrices with\n$m=\\epsilon^{-2}d\\log^3(n/\\delta)$ such that solving the sketched regression\nproblem gives the $\\ell_\\infty$ guarantee, with probability at least\n$1-\\delta$. Moreover, the matrix $SA$ can be computed in time $O(nd\\log n)$.\nOur row count is nearly-optimal up to logarithmic factors, and significantly\nimproves the result in [Price, Song and Woodruff, ICALP'17], in which a\nsuper-linear in $d$ rows, $m=\\Omega(\\epsilon^{-2}d^{1+\\gamma})$ for\n$\\gamma=\\Theta(\\sqrt{\\frac{\\log\\log n}{\\log d}})$ is required. We also develop\na novel analytical framework for $\\ell_\\infty$ guarantee regression that\nutilizes the Oblivious Coordinate-wise Embedding (OCE) property introduced in\n[Song and Yu, ICML'21]. Our analysis is arguably much simpler and more general\nthan [Price, Song and Woodruff, ICALP'17], and it extends to dense sketches for\ntensor product of vectors.\n","authors":["Zhao Song","Mingquan Ye","Junze Yin","Lichen Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00248v1.pdf","comment":"Abstract shortened to meet arxiv requirement"},{"id":"http://arxiv.org/abs/2302.00247v1","updated":"2023-02-01T05:22:28Z","published":"2023-02-01T05:22:28Z","title":"TAP: Accelerating Large-Scale DNN Training Through Tensor Automatic\n  Parallelisation","summary":"  Model parallelism has become necessary to train large neural networks.\nHowever, finding a suitable model parallel schedule for an arbitrary neural\nnetwork is a non-trivial task due to the exploding search space. In this work,\nwe present a model parallelism framework TAP that automatically searches for\nthe best data and tensor parallel schedules. Leveraging the key insight that a\nneural network can be represented as a directed acyclic graph, within which may\nonly exist a limited set of frequent subgraphs, we design a graph pruning\nalgorithm to fold the search space efficiently. TAP runs at sub-linear\ncomplexity concerning the neural network size. Experiments show that TAP is\n$20\\times- 160\\times$ faster than the state-of-the-art automatic parallelism\nframework, and the performance of its discovered schedules is competitive with\nthe expert-engineered ones.\n","authors":["Ziji Shi","Le Jiang","Ang Wang","Jie Zhang","Xianyan Jia","Yong Li","Chencan Wu","Jialin Li","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2302.00247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08800v3","updated":"2023-02-01T05:09:10Z","published":"2022-12-17T05:11:34Z","title":"Cognitive Level-$k$ Meta-Learning for Safe and Pedestrian-Aware\n  Autonomous Driving","summary":"  The potential market for modern self-driving cars is enormous, as they are\ndeveloping remarkably rapidly. At the same time, however, accidents of\npedestrian fatalities caused by autonomous driving have been recorded in the\ncase of street crossing. To ensure traffic safety in self-driving environments\nand respond to vehicle-human interaction challenges such as jaywalking, we\npropose Level-$k$ Meta Reinforcement Learning (LK-MRL) algorithm. It takes into\naccount the cognitive hierarchy of pedestrian responses and enables\nself-driving vehicles to adapt to various human behaviors. %which takes into\naccount pedestrian responses while learning the optimal strategies. As a\nself-driving vehicle algorithm, the LK-MRL combines level-$k$ thinking into\nMAML to prepare for heterogeneous pedestrians and improve intersection safety\nbased on the combination of meta-reinforcement learning and human cognitive\nhierarchy framework. We evaluate the algorithm in two cognitive confrontation\nhierarchy scenarios in an urban traffic simulator and illustrate its role in\nensuring road safety by demonstrating its capability of conjectural and\nhigher-level reasoning.\n","authors":["Haozhe Lei","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.08800v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00244v1","updated":"2023-02-01T04:59:55Z","published":"2023-02-01T04:59:55Z","title":"Learning Cut Selection for Mixed-Integer Linear Programming via\n  Hierarchical Sequence Model","summary":"  Cutting planes (cuts) are important for solving mixed-integer linear programs\n(MILPs), which formulate a wide range of important real-world applications. Cut\nselection -- which aims to select a proper subset of the candidate cuts to\nimprove the efficiency of solving MILPs -- heavily depends on (P1) which cuts\nshould be preferred, and (P2) how many cuts should be selected. Although many\nmodern MILP solvers tackle (P1)-(P2) by manually designed heuristics, machine\nlearning offers a promising approach to learn more effective heuristics from\nMILPs collected from specific applications. However, many existing\nlearning-based methods focus on learning which cuts should be preferred,\nneglecting the importance of learning the number of cuts that should be\nselected. Moreover, we observe from extensive empirical results that (P3) what\norder of selected cuts should be preferred has a significant impact on the\nefficiency of solving MILPs as well. To address this challenge, we propose a\nnovel hierarchical sequence model (HEM) to learn cut selection policies via\nreinforcement learning. Specifically, HEM consists of a two-level model: (1) a\nhigher-level model to learn the number of cuts that should be selected, (2) and\na lower-level model -- that formulates the cut selection task as a sequence to\nsequence learning problem -- to learn policies selecting an ordered subset with\nthe size determined by the higher-level model. To the best of our knowledge,\nHEM is the first method that can tackle (P1)-(P3) in cut selection\nsimultaneously from a data-driven perspective. Experiments show that HEM\nsignificantly improves the efficiency of solving MILPs compared to\nhuman-designed and learning-based baselines on both synthetic and large-scale\nreal-world MILPs, including MIPLIB 2017. Moreover, experiments demonstrate that\nHEM well generalizes to MILPs that are significantly larger than those seen\nduring training.\n","authors":["Zhihai Wang","Xijun Li","Jie Wang","Yufei Kuang","Mingxuan Yuan","Jia Zeng","Yongdong Zhang","Feng Wu"],"pdf_url":"https://arxiv.org/pdf/2302.00244v1.pdf","comment":"Accepted to ICLR2023"},{"id":"http://arxiv.org/abs/2106.11428v2","updated":"2023-02-01T04:52:28Z","published":"2021-06-21T22:08:17Z","title":"Local convexity of the TAP free energy and AMP convergence for\n  Z2-synchronization","summary":"  We study mean-field variational Bayesian inference using the TAP approach,\nfor Z2-synchronization as a prototypical example of a high-dimensional Bayesian\nmodel. We show that for any signal strength $\\lambda > 1$ (the weak-recovery\nthreshold), there exists a unique local minimizer of the TAP free energy\nfunctional near the mean of the Bayes posterior law. Furthermore, the TAP free\nenergy in a local neighborhood of this minimizer is strongly convex.\nConsequently, a natural-gradient/mirror-descent algorithm achieves linear\nconvergence to this minimizer from a local initialization, which may be\nobtained by a constant number of iterates of Approximate Message Passing (AMP).\nThis provides a rigorous foundation for variational inference in high\ndimensions via minimization of the TAP free energy.\n  We also analyze the finite-sample convergence of AMP, showing that AMP is\nasymptotically stable at the TAP minimizer for any $\\lambda > 1$, and is\nlinearly convergent to this minimizer from a spectral initialization for\nsufficiently large $\\lambda$. Such a guarantee is stronger than results\nobtainable by state evolution analyses, which only describe a fixed number of\nAMP iterations in the infinite-sample limit.\n  Our proofs combine the Kac-Rice formula and Sudakov-Fernique Gaussian\ncomparison inequality to analyze the complexity of critical points that satisfy\nstrong convexity and stability conditions within their local neighborhoods.\n","authors":["Michael Celentano","Zhou Fan","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2106.11428v2.pdf","comment":"62 pages"},{"id":"http://arxiv.org/abs/2302.00242v1","updated":"2023-02-01T04:52:13Z","published":"2023-02-01T04:52:13Z","title":"The Parametric Stability of Well-separated Spherical Gaussian Mixtures","summary":"  We quantify the parameter stability of a spherical Gaussian Mixture Model\n(sGMM) under small perturbations in distribution space. Namely, we derive the\nfirst explicit bound to show that for a mixture of spherical Gaussian $P$\n(sGMM) in a pre-defined model class, all other sGMM close to $P$ in this model\nclass in total variation distance has a small parameter distance to $P$.\nFurther, this upper bound only depends on $P$. The motivation for this work\nlies in providing guarantees for fitting Gaussian mixtures; with this aim in\nmind, all the constants involved are well defined and distribution free\nconditions for fitting mixtures of spherical Gaussians. Our results tighten\nconsiderably the existing computable bounds, and asymptotically match the known\nsharp thresholds for this problem.\n","authors":["Hanyu Zhang","Marina Meila"],"pdf_url":"https://arxiv.org/pdf/2302.00242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15230v2","updated":"2023-02-01T04:50:19Z","published":"2022-09-30T04:54:29Z","title":"The Replicator Dynamic, Chain Components and the Response Graph","summary":"  In this paper we examine the relationship between the flow of the replicator\ndynamic, the continuum limit of Multiplicative Weights Update, and a game's\nresponse graph. We settle an open problem establishing that under the\nreplicator, sink chain components -- a topological notion of long-run outcome\nof a dynamical system -- always exist and are approximated by the sink\nconnected components of the game's response graph. More specifically, each sink\nchain component contains a sink connected component of the response graph, as\nwell as all mixed strategy profiles whose support consists of pure profiles in\nthe same connected component, a set we call the content of the connected\ncomponent. As a corollary, all profiles are chain recurrent in games with\nstrongly connected response graphs. In any two-player game sharing a response\ngraph with a zero-sum game, the sink chain component is unique. In two-player\nzero-sum and potential games the sink chain components and sink connected\ncomponents are in a one-to-one correspondence, and we conjecture that this\nholds in all games.\n","authors":["Oliver Biggar","Iman Shames"],"pdf_url":"https://arxiv.org/pdf/2209.15230v2.pdf","comment":"22 pages, 2 figures. Accepted version. To appear in Algorithmic\n  Learning Theory 2023"},{"id":"http://arxiv.org/abs/2302.00239v1","updated":"2023-02-01T04:34:48Z","published":"2023-02-01T04:34:48Z","title":"Filtering Context Mitigates Scarcity and Selection Bias in Political\n  Ideology Prediction","summary":"  We propose a novel supervised learning approach for political ideology\nprediction (PIP) that is capable of predicting out-of-distribution inputs. This\nproblem is motivated by the fact that manual data-labeling is expensive, while\nself-reported labels are often scarce and exhibit significant selection bias.\nWe propose a novel statistical model that decomposes the document embeddings\ninto a linear superposition of two vectors; a latent neutral \\emph{context}\nvector independent of ideology, and a latent \\emph{position} vector aligned\nwith ideology. We train an end-to-end model that has intermediate contextual\nand positional vectors as outputs. At deployment time, our model predicts\nlabels for input documents by exclusively leveraging the predicted positional\nvectors. On two benchmark datasets we show that our model is capable of\noutputting predictions even when trained with as little as 5\\% biased data, and\nis significantly more accurate than the state-of-the-art. Through\ncrowd-sourcing we validate the neutrality of contextual vectors, and show that\ncontext filtering results in ideological concentration, allowing for prediction\non out-of-distribution examples.\n","authors":["Chen Chen","Dylan Walker","Venkatesh Saligrama"],"pdf_url":"https://arxiv.org/pdf/2302.00239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00237v1","updated":"2023-02-01T04:33:06Z","published":"2023-02-01T04:33:06Z","title":"Bridging Physics-Informed Neural Networks with Reinforcement Learning:\n  Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO)","summary":"  This paper introduces the Hamilton-Jacobi-Bellman Proximal Policy\nOptimization (HJBPPO) algorithm into reinforcement learning. The\nHamilton-Jacobi-Bellman (HJB) equation is used in control theory to evaluate\nthe optimality of the value function. Our work combines the HJB equation with\nreinforcement learning in continuous state and action spaces to improve the\ntraining of the value network. We treat the value network as a Physics-Informed\nNeural Network (PINN) to solve for the HJB equation by computing its\nderivatives with respect to its inputs exactly. The Proximal Policy\nOptimization (PPO)-Clipped algorithm is improvised with this implementation as\nit uses a value network to compute the objective function for its policy\nnetwork. The HJBPPO algorithm shows an improved performance compared to PPO on\nthe MuJoCo environments.\n","authors":["Amartya Mukherjee","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2302.00237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00236v1","updated":"2023-02-01T04:28:36Z","published":"2023-02-01T04:28:36Z","title":"Generative Adversarial Symmetry Discovery","summary":"  Despite the success of equivariant neural networks in scientific\napplications, they require knowing the symmetry group a priori. However, it may\nbe difficult to know the right symmetry to use as an inductive bias in practice\nand enforcing the wrong symmetry could hurt the performance. In this paper, we\npropose a framework, LieGAN, to automatically discover equivariances from a\ndataset using a paradigm akin to generative adversarial training. Specifically,\na generator learns a group of transformations applied to the data, which\npreserves the original distribution and fools the discriminator. LieGAN\nrepresents symmetry as interpretable Lie algebra basis and can discover various\nsymmetries such as rotation group $\\mathrm{SO}(n)$ and restricted Lorentz group\n$\\mathrm{SO}(1,3)^+$ in trajectory prediction and top quark tagging tasks. The\nlearned symmetry can also be readily used in several existing equivariant\nneural networks to improve accuracy and generalization in prediction.\n","authors":["Jianke Yang","Robin Walters","Nima Dehmamy","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2302.00236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00232v1","updated":"2023-02-01T04:22:59Z","published":"2023-02-01T04:22:59Z","title":"SPIDE: A Purely Spike-based Method for Training Feedback Spiking Neural\n  Networks","summary":"  Spiking neural networks (SNNs) with event-based computation are promising\nbrain-inspired models for energy-efficient applications on neuromorphic\nhardware. However, most supervised SNN training methods, such as conversion\nfrom artificial neural networks or direct training with surrogate gradients,\nrequire complex computation rather than spike-based operations of spiking\nneurons during training. In this paper, we study spike-based implicit\ndifferentiation on the equilibrium state (SPIDE) that extends the recently\nproposed training method, implicit differentiation on the equilibrium state\n(IDE), for supervised learning with purely spike-based computation, which\ndemonstrates the potential for energy-efficient training of SNNs. Specifically,\nwe introduce ternary spiking neuron couples and prove that implicit\ndifferentiation can be solved by spikes based on this design, so the whole\ntraining procedure, including both forward and backward passes, is made as\nevent-driven spike computation, and weights are updated locally with two-stage\naverage firing rates. Then we propose to modify the reset membrane potential to\nreduce the approximation error of spikes. With these key components, we can\ntrain SNNs with flexible structures in a small number of time steps and with\nfiring sparsity during training, and the theoretical estimation of energy costs\ndemonstrates the potential for high efficiency. Meanwhile, experiments show\nthat even with these constraints, our trained models can still achieve\ncompetitive results on MNIST, CIFAR-10, CIFAR-100, and CIFAR10-DVS. Our code is\navailable at https://github.com/pkuxmq/SPIDE-FSNN.\n","authors":["Mingqing Xiao","Qingyan Meng","Zongpeng Zhang","Yisen Wang","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2302.00232v1.pdf","comment":"Accepted by Neural Networks"},{"id":"http://arxiv.org/abs/2302.00220v1","updated":"2023-02-01T03:51:27Z","published":"2023-02-01T03:51:27Z","title":"Efficient Scopeformer: Towards Scalable and Rich Feature Extraction for\n  Intracranial Hemorrhage Detection","summary":"  The quality and richness of feature maps extracted by convolution neural\nnetworks (CNNs) and vision Transformers (ViTs) directly relate to the robust\nmodel performance. In medical computer vision, these information-rich features\nare crucial for detecting rare cases within large datasets. This work presents\nthe \"Scopeformer,\" a novel multi-CNN-ViT model for intracranial hemorrhage\nclassification in computed tomography (CT) images. The Scopeformer architecture\nis scalable and modular, which allows utilizing various CNN architectures as\nthe backbone with diversified output features and pre-training strategies. We\npropose effective feature projection methods to reduce redundancies among\nCNN-generated features and to control the input size of ViTs. Extensive\nexperiments with various Scopeformer models show that the model performance is\nproportional to the number of convolutional blocks employed in the feature\nextractor. Using multiple strategies, including diversifying the pre-training\nparadigms for CNNs, different pre-training datasets, and style transfer\ntechniques, we demonstrate an overall improvement in the model performance at\nvarious computational budgets. Later, we propose smaller compute-efficient\nScopeformer versions with three different types of input and output ViT\nconfigurations. Efficient Scopeformers use four different pre-trained CNN\narchitectures as feature extractors to increase feature richness. Our best\nEfficient Scopeformer model achieved an accuracy of 96.94\\% and a weighted\nlogarithmic loss of 0.083 with an eight times reduction in the number of\ntrainable parameters compared to the base Scopeformer. Another version of the\nEfficient Scopeformer model further reduced the parameter space by almost 17\ntimes with negligible performance reduction. Hybrid CNNs and ViTs might provide\nthe desired feature richness for developing accurate medical computer vision\nmodels\n","authors":["Yassine Barhoumi","Nidhal C. Bouaynaya","Ghulam Rasool"],"pdf_url":"https://arxiv.org/pdf/2302.00220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00219v1","updated":"2023-02-01T03:51:05Z","published":"2023-02-01T03:51:05Z","title":"Knowledge Distillation on Graphs: A Survey","summary":"  Graph Neural Networks (GNNs) have attracted tremendous attention by\ndemonstrating their capability to handle graph data. However, they are\ndifficult to be deployed in resource-limited devices due to model sizes and\nscalability constraints imposed by the multi-hop data dependency. In addition,\nreal-world graphs usually possess complex structural information and features.\nTherefore, to improve the applicability of GNNs and fully encode the\ncomplicated topological information, knowledge distillation on graphs (KDG) has\nbeen introduced to build a smaller yet effective model and exploit more\nknowledge from data, leading to model compression and performance improvement.\nRecently, KDG has achieved considerable progress with many studies proposed. In\nthis survey, we systematically review these works. Specifically, we first\nintroduce KDG challenges and bases, then categorize and summarize existing\nworks of KDG by answering the following three questions: 1) what to distillate,\n2) who to whom, and 3) how to distillate. Finally, we share our thoughts on\nfuture research directions.\n","authors":["Yijun Tian","Shichao Pei","Xiangliang Zhang","Chuxu Zhang","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2302.00219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02504v3","updated":"2023-02-01T03:32:08Z","published":"2022-11-04T15:05:40Z","title":"Geometry-Complete Perceptron Networks for 3D Molecular Graphs","summary":"  The field of geometric deep learning has had a profound impact on the\ndevelopment of innovative and powerful graph neural network architectures.\nDisciplines such as computer vision and computational biology have benefited\nsignificantly from such methodological advances, which has led to breakthroughs\nin scientific domains such as protein structure prediction and design. In this\nwork, we introduce GCPNet, a new geometry-complete, SE(3)-equivariant graph\nneural network designed for 3D molecular graph representation learning. We\ndemonstrate the state-of-the-art utility and expressiveness of our method on\nsix independent datasets designed for three distinct geometric tasks:\nprotein-ligand binding affinity prediction, protein structure ranking, and\nNewtonian many-body systems modeling. Our results suggest that GCPNet is a\npowerful, general method for capturing complex geometric and physical\ninteractions within 3D molecular graphs for downstream prediction tasks. The\nsource code, data, and instructions to train new models or reproduce our\nresults are freely available at\nhttps://github.com/BioinfoMachineLearning/GCPNet.\n","authors":["Alex Morehead","Jianlin Cheng"],"pdf_url":"https://arxiv.org/pdf/2211.02504v3.pdf","comment":"18 pages, 3 figures, 11 tables. Under review. Also accepted to\n  DLG-AAAI 2023 and AI2ASE-AAAI 2023. Code available at\n  https://github.com/BioinfoMachineLearning/GCPNet"},{"id":"http://arxiv.org/abs/2302.00209v1","updated":"2023-02-01T03:25:43Z","published":"2023-02-01T03:25:43Z","title":"QCRS: Improve Randomized Smoothing using Quasi-Concave Optimization","summary":"  Randomized smoothing is currently the state-of-the-art method that provides\ncertified robustness for deep neural networks. However, it often cannot achieve\nan adequate certified region on real-world datasets. One way to obtain a larger\ncertified region is to use an input-specific algorithm instead of using a fixed\nGaussian filter for all data points. Several methods based on this idea have\nbeen proposed, but they either suffer from high computational costs or gain\nmarginal improvement in certified radius. In this work, we show that by\nexploiting the quasiconvex problem structure, we can find the optimal certified\nradii for most data points with slight computational overhead. This observation\nleads to an efficient and effective input-specific randomized smoothing\nalgorithm. We conduct extensive experiments and empirical analysis on Cifar10\nand ImageNet. The results show that the proposed method significantly enhances\nthe certified radii with low computational overhead.\n","authors":["Bo-Han Kung","Shang-Tse Chen"],"pdf_url":"https://arxiv.org/pdf/2302.00209v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2209.11820v3","updated":"2023-02-01T03:25:21Z","published":"2022-09-23T19:23:07Z","title":"Expanding the Deployment Envelope of Behavior Prediction via Adaptive\n  Meta-Learning","summary":"  Learning-based behavior prediction methods are increasingly being deployed in\nreal-world autonomous systems, e.g., in fleets of self-driving vehicles, which\nare beginning to commercially operate in major cities across the world. Despite\ntheir advancements, however, the vast majority of prediction systems are\nspecialized to a set of well-explored geographic regions or operational design\ndomains, complicating deployment to additional cities, countries, or\ncontinents. Towards this end, we present a novel method for efficiently\nadapting behavior prediction models to new environments. Our approach leverages\nrecent advances in meta-learning, specifically Bayesian regression, to augment\nexisting behavior prediction models with an adaptive layer that enables\nefficient domain transfer via offline fine-tuning, online adaptation, or both.\nExperiments across multiple real-world datasets demonstrate that our method can\nefficiently adapt to a variety of unseen environments.\n","authors":["Boris Ivanovic","James Harrison","Marco Pavone"],"pdf_url":"https://arxiv.org/pdf/2209.11820v3.pdf","comment":"12 pages, 13 figures, 2 tables. To appear at ICRA 2023"},{"id":"http://arxiv.org/abs/2302.00207v1","updated":"2023-02-01T03:23:11Z","published":"2023-02-01T03:23:11Z","title":"Distributed Traffic Synthesis and Classification in Edge Networks: A\n  Federated Self-supervised Learning Approach","summary":"  With the rising demand for wireless services and increased awareness of the\nneed for data protection, existing network traffic analysis and management\narchitectures are facing unprecedented challenges in classifying and\nsynthesizing the increasingly diverse services and applications. This paper\nproposes FS-GAN, a federated self-supervised learning framework to support\nautomatic traffic analysis and synthesis over a large number of heterogeneous\ndatasets. FS-GAN is composed of multiple distributed Generative Adversarial\nNetworks (GANs), with a set of generators, each being designed to generate\nsynthesized data samples following the distribution of an individual service\ntraffic, and each discriminator being trained to differentiate the synthesized\ndata samples and the real data samples of a local dataset. A federated\nlearning-based framework is adopted to coordinate local model training\nprocesses of different GANs across different datasets. FS-GAN can classify data\nof unknown types of service and create synthetic samples that capture the\ntraffic distribution of the unknown types. We prove that FS-GAN can minimize\nthe Jensen-Shannon Divergence (JSD) between the distribution of real data\nacross all the datasets and that of the synthesized data samples. FS-GAN also\nmaximizes the JSD among the distributions of data samples created by different\ngenerators, resulting in each generator producing synthetic data samples that\nfollow the same distribution as one particular service type. Extensive\nsimulation results show that the classification accuracy of FS-GAN achieves\nover 20% improvement in average compared to the state-of-the-art\nclustering-based traffic analysis algorithms. FS-GAN also has the capability to\nsynthesize highly complex mixtures of traffic types without requiring any\nhuman-labeled data samples.\n","authors":["Yong Xiao","Rong Xia","Yingyu Li","Guangming Shi","Diep N. Nguyen","Dinh Thai Hoang","Dusit Niyato","Marwan Krunz"],"pdf_url":"https://arxiv.org/pdf/2302.00207v1.pdf","comment":"published as early access at IEEE Transactions on Mobile Computing,\n  January 2023"},{"id":"http://arxiv.org/abs/2302.00206v1","updated":"2023-02-01T03:22:27Z","published":"2023-02-01T03:22:27Z","title":"Electrode Selection for Noninvasive Fetal Electrocardiogram Extraction\n  using Mutual Information Criteria","summary":"  Blind source separation (BSS) techniques have revealed to be promising\napproaches for, among other, biomedical signal processing applications.\nSpecifically, for the noninvasive extraction of fetal cardiac signals from\nmaternal abdominal recordings, where conventional filtering schemes have failed\nto extract the complete fetal ECG components. From previous studies, it is now\nbelieved that a carefully selected array of electrodes well-placed over the\nabdomen of a pregnant woman contains the required `information' for BSS, to\nextract the complete fetal components. Based on this idea, in previous works\narray recording systems and sensor selection strategies based on the Mutual\nInformation (MI) criterion have been developed. In this paper the previous\nworks have been extended, by considering the 3-dimensional aspects of the\ncardiac electrical activity. The proposed method has been tested on simulated\nand real maternal abdominal recordings. The results show that the new sensor\nselection strategy together with the MI criterion, can be effectively used to\nselect the channels containing the most `information' concerning the fetal ECG\ncomponents from an array of 72 recordings. The method is hence believed to be\nuseful for the selection of the most informative channels in online\napplications, considering the different fetal positions and movements.\n","authors":["Reza Sameni","Frédéric Vrins","Fabienne Parmentier","Christophe Hérail","Vincent Vigneron","Michel Verleysen","Christian Jutten","Mohammad B. Shamsollahi"],"pdf_url":"https://arxiv.org/pdf/2302.00206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.05516v4","updated":"2023-02-01T03:18:41Z","published":"2022-08-10T18:24:23Z","title":"Quality Not Quantity: On the Interaction between Dataset Design and\n  Robustness of CLIP","summary":"  Web-crawled datasets have enabled remarkable generalization capabilities in\nrecent image-text models such as CLIP (Contrastive Language-Image pre-training)\nor Flamingo, but little is known about the dataset creation processes. In this\nwork, we introduce a testbed of six publicly available data sources - YFCC,\nLAION, Conceptual Captions, WIT, RedCaps, Shutterstock - to investigate how\npre-training distributions induce robustness in CLIP. We find that the\nperformance of the pre-training data varies substantially across distribution\nshifts, with no single data source dominating. Moreover, we systematically\nstudy the interactions between these data sources and find that combining\nmultiple sources does not necessarily yield better models, but rather dilutes\nthe robustness of the best individual data source. We complement our empirical\nfindings with theoretical insights from a simple setting, where combining the\ntraining data also results in diluted robustness. In addition, our theoretical\nmodel provides a candidate explanation for the success of the CLIP-based data\nfiltering technique recently employed in the LAION dataset. Overall our results\ndemonstrate that simply gathering a large amount of data from the web is not\nthe most effective way to build a pre-training dataset for robust\ngeneralization, necessitating further study into dataset design. Code is\navailable at https://github.com/mlfoundations/clip_quality_not_quantity.\n","authors":["Thao Nguyen","Gabriel Ilharco","Mitchell Wortsman","Sewoong Oh","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2208.05516v4.pdf","comment":"Oral paper at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2302.00205v1","updated":"2023-02-01T03:18:07Z","published":"2023-02-01T03:18:07Z","title":"Gradient Descent in Neural Networks as Sequential Learning in RKBS","summary":"  The study of Neural Tangent Kernels (NTKs) has provided much needed insight\ninto convergence and generalization properties of neural networks in the\nover-parametrized (wide) limit by approximating the network using a first-order\nTaylor expansion with respect to its weights in the neighborhood of their\ninitialization values. This allows neural network training to be analyzed from\nthe perspective of reproducing kernel Hilbert spaces (RKHS), which is\ninformative in the over-parametrized regime, but a poor approximation for\nnarrower networks as the weights change more during training. Our goal is to\nextend beyond the limits of NTK toward a more general theory. We construct an\nexact power-series representation of the neural network in a finite\nneighborhood of the initial weights as an inner product of two feature maps,\nrespectively from data and weight-step space, to feature space, allowing neural\nnetwork training to be analyzed from the perspective of reproducing kernel {\\em\nBanach} space (RKBS). We prove that, regardless of width, the training sequence\nproduced by gradient descent can be exactly replicated by regularized\nsequential learning in RKBS. Using this, we present novel bound on uniform\nconvergence where the iterations count and learning rate play a central role,\ngiving new theoretical insight into neural network training.\n","authors":["Alistair Shilton","Sunil Gupta","Santu Rana","Svetha Venkatesh"],"pdf_url":"https://arxiv.org/pdf/2302.00205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00203v1","updated":"2023-02-01T03:13:19Z","published":"2023-02-01T03:13:19Z","title":"End-to-End Full-Atom Antibody Design","summary":"  Antibody design is an essential yet challenging task in various domains like\ntherapeutics and biology. There are two major defects in current learning-based\nmethods: 1) tackling only a certain subtask of the whole antibody design\npipeline, making them suboptimal or resource-intensive. 2) omitting either the\nframework regions or side chains, thus incapable of capturing the full-atom\ngeometry. To address these pitfalls, we propose dynamic Multi-channel\nEquivariant grAph Network (dyMEAN), an end-to-end full-atom model for\nE(3)-equivariant antibody design given the epitope and the incomplete sequence\nof the antibody. Specifically, we first explore structural initialization as a\nknowledgeable guess of the antibody structure and then propose shadow paratope\nto bridge the epitope-antibody connections. Both 1D sequences and 3D structures\nare updated via an adaptive multi-channel equivariant encoder that is able to\nprocess protein residues of variable sizes when considering full atoms.\nFinally, the updated antibody is docked to the epitope via the alignment of the\nshadow paratope. Experiments on epitope-binding CDR-H3 design, complex\nstructure prediction, and affinity optimization demonstrate the superiority of\nour end-to-end framework and full-atom modeling.\n","authors":["Xiangzhe Kong","Wenbing Huang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2302.00203v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2302.00200v1","updated":"2023-02-01T03:05:14Z","published":"2023-02-01T03:05:14Z","title":"A Transaction Represented with Weighted Finite-State Transducers","summary":"  Not all contracts are good, but all good contracts can be expressed as a\nfinite-state transition system (\"State-Transition Contracts\"). Contracts that\ncan be represented as State-Transition Contracts discretize fat-tailed risk to\nforeseeable, managed risk, define the boundary of relevant events governed by\nthe relationship, and eliminate the potential of inconsistent contractual\nprovisions. Additionally, State-Transition Contracts reap the substantial\nbenefit of being able to be analyzed under the rules governing the science of\nthe theory of computation. Simple State-Transition Contracts can be represented\nas discrete finite automata; more complicated State-Transition Contracts, such\nas those that have downstream effects on other agreements or complicated\npathways of performance, benefit from representation as weighted finite-state\ntransducers, with weights assigned as costs, penalties, or probabilities of\ntransitions. This research paper (the \"Research\" or \"Paper\") presents a complex\nlegal transaction represented as weighted finite-state transducers.\nFurthermore, we show that the mathematics/algorithms permitted by the algebraic\nstructure of weighted finite-state transducers provides actionable, legal\ninsight into the transaction.\n","authors":["J. Nathaniel Holmes","Homayoon Beigi"],"pdf_url":"https://arxiv.org/pdf/2302.00200v1.pdf","comment":"2 figures, 3 tables, 2 appendices, Recognition Technologies, Inc.\n  Technical Report"},{"id":"http://arxiv.org/abs/2302.00195v1","updated":"2023-02-01T02:58:29Z","published":"2023-02-01T02:58:29Z","title":"Weight Prediction Boosts the Convergence of AdamW","summary":"  In this paper, we introduce weight prediction into the AdamW optimizer to\nboost its convergence when training the deep neural network (DNN) models. In\nparticular, ahead of each mini-batch training, we predict the future weights\naccording to the update rule of AdamW and then apply the predicted future\nweights to do both forward pass and backward propagation. In this way, the\nAdamW optimizer always utilizes the gradients w.r.t. the future weights instead\nof current weights to update the DNN parameters, making the AdamW optimizer\nachieve better convergence. Our proposal is simple and straightforward to\nimplement but effective in boosting the convergence of DNN training. We\nperformed extensive experimental evaluations on image classification and\nlanguage modeling tasks to verify the effectiveness of our proposal. The\nexperimental results validate that our proposal can boost the convergence of\nAdamW and achieve better accuracy than AdamW when training the DNN models.\n","authors":["Lei Guan"],"pdf_url":"https://arxiv.org/pdf/2302.00195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00194v1","updated":"2023-02-01T02:55:26Z","published":"2023-02-01T02:55:26Z","title":"Free Lunch for Domain Adversarial Training: Environment Label Smoothing","summary":"  A fundamental challenge for machine learning models is how to generalize\nlearned models for out-of-distribution (OOD) data. Among various approaches,\nexploiting invariant features by Domain Adversarial Training (DAT) received\nwidespread attention. Despite its success, we observe training instability from\nDAT, mostly due to over-confident domain discriminator and environment label\nnoise. To address this issue, we proposed Environment Label Smoothing (ELS),\nwhich encourages the discriminator to output soft probability, which thus\nreduces the confidence of the discriminator and alleviates the impact of noisy\nenvironment labels. We demonstrate, both experimentally and theoretically, that\nELS can improve training stability, local convergence, and robustness to noisy\nenvironment labels. By incorporating ELS with DAT methods, we are able to yield\nstate-of-art results on a wide range of domain generalization/adaptation tasks,\nparticularly when the environment labels are highly noisy.\n","authors":["YiFan Zhang","Xue Wang","Jian Liang","Zhang Zhang","Liang Wang","Rong Jin","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2302.00194v1.pdf","comment":"ICLR 2023, 38 pages, 8 figures, 18 tables"},{"id":"http://arxiv.org/abs/2302.00193v1","updated":"2023-02-01T02:54:35Z","published":"2023-02-01T02:54:35Z","title":"$\\rm A^2Q$: Aggregation-Aware Quantization for Graph Neural Networks","summary":"  As graph data size increases, the vast latency and memory consumption during\ninference pose a significant challenge to the real-world deployment of Graph\nNeural Networks (GNNs). While quantization is a powerful approach to reducing\nGNNs complexity, most previous works on GNNs quantization fail to exploit the\nunique characteristics of GNNs, suffering from severe accuracy degradation.\nThrough an in-depth analysis of the topology of GNNs, we observe that the\ntopology of the graph leads to significant differences between nodes, and most\nof the nodes in a graph appear to have a small aggregation value. Motivated by\nthis, in this paper, we propose the Aggregation-Aware mixed-precision\nQuantization ($\\rm A^2Q$) for GNNs, where an appropriate bitwidth is\nautomatically learned and assigned to each node in the graph. To mitigate the\nvanishing gradient problem caused by sparse connections between nodes, we\npropose a Local Gradient method to serve the quantization error of the node\nfeatures as the supervision during training. We also develop a Nearest Neighbor\nStrategy to deal with the generalization on unseen graphs. Extensive\nexperiments on eight public node-level and graph-level datasets demonstrate the\ngenerality and robustness of our proposed method. Compared to the FP32 models,\nour method can achieve up to a 18.6x (i.e., 1.70bit) compression ratio with\nnegligible accuracy degradation. Morever, compared to the state-of-the-art\nquantization method, our method can achieve up to 11.4\\% and 9.5\\% accuracy\nimprovements on the node-level and graph-level tasks, respectively, and up to\n2x speedup on a dedicated hardware accelerator.\n","authors":["Zeyu Zhu","Fanrong Li","Zitao Mo","Qinghao Hu","Gang Li","Zejian Liu","Xiaoyao Liang","Jian Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.00193v1.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2302.00192v1","updated":"2023-02-01T02:53:34Z","published":"2023-02-01T02:53:34Z","title":"Density peak clustering using tensor network","summary":"  Tensor networks, which have been traditionally used to simulate many-body\nphysics, have recently gained significant attention in the field of machine\nlearning due to their powerful representation capabilities. In this work, we\npropose a density-based clustering algorithm inspired by tensor networks. We\nencode classical data into tensor network states on an extended Hilbert space\nand train the tensor network states to capture the features of the clusters.\nHere, we define density and related concepts in terms of fidelity, rather than\nusing a classical distance measure. We evaluate the performance of our\nalgorithm on six synthetic data sets, four real world data sets, and three\ncommonly used computer vision data sets. The results demonstrate that our\nmethod provides state-of-the-art performance on several synthetic data sets and\nreal world data sets, even when the number of clusters is unknown.\nAdditionally, our algorithm performs competitively with state-of-the-art\nalgorithms on the MNIST, USPS, and Fashion-MNIST image data sets. These\nfindings reveal the great potential of tensor networks for machine learning\napplications.\n","authors":["Xiao Shi","Yun Shang"],"pdf_url":"https://arxiv.org/pdf/2302.00192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13441v2","updated":"2023-02-01T02:49:12Z","published":"2023-01-31T06:38:05Z","title":"CMLCompiler: A Unified Compiler for Classical Machine Learning","summary":"  Classical machine learning (CML) occupies nearly half of machine learning\npipelines in production applications. Unfortunately, it fails to utilize the\nstate-of-the-practice devices fully and performs poorly. Without a unified\nframework, the hybrid deployments of deep learning (DL) and CML also suffer\nfrom severe performance and portability issues. This paper presents the design\nof a unified compiler, called CMLCompiler, for CML inference. We propose two\nunified abstractions: operator representations and extended computational\ngraphs. The CMLCompiler framework performs the conversion and graph\noptimization based on two unified abstractions, then outputs an optimized\ncomputational graph to DL compilers or frameworks. We implement CMLCompiler on\nTVM. The evaluation shows CMLCompiler's portability and superior performance.\nIt achieves up to 4.38x speedup on CPU, 3.31x speedup on GPU, and 5.09x speedup\non IoT devices, compared to the state-of-the-art solutions -- scikit-learn,\nintel sklearn, and hummingbird. Our performance of CML and DL mixed pipelines\nachieves up to 3.04x speedup compared with cross-framework implementations.\n","authors":["Xu Wen","Wanling Gao","Anzheng Li","Lei Wang","Zihan Jiang","Jianfeng Zhan"],"pdf_url":"https://arxiv.org/pdf/2301.13441v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00188v1","updated":"2023-02-01T02:40:00Z","published":"2023-02-01T02:40:00Z","title":"Deep Learning Approach to Predict Hemorrhage in Moyamoya Disease","summary":"  Objective: Reliable tools to predict moyamoya disease (MMD) patients at risk\nfor hemorrhage could have significant value. The aim of this paper is to\ndevelop three machine learning classification algorithms to predict hemorrhage\nin moyamoya disease. Methods: Clinical data of consecutive MMD patients who\nwere admitted to our hospital between 2009 and 2015 were reviewed.\nDemographics, clinical, radiographic data were analyzed to develop artificial\nneural network (ANN), support vector machine (SVM), and random forest models.\nResults: We extracted 33 parameters, including 11 demographic and 22\nradiographic features as input for model development. Of all compared\nclassification results, ANN achieved the highest overall accuracy of 75.7% (95%\nCI, 68.6%-82.8%), followed by SVM with 69.2% (95% CI, 56.9%-81.5%) and random\nforest with 70.0% (95% CI, 57.0%-83.0%). Conclusions: The proposed ANN\nframework can be a potential effective tool to predict the possibility of\nhemorrhage among adult MMD patients based on clinical information and\nradiographic features.\n","authors":["Meng Zhao","Yonggang Ma","Qian Zhang","Jizong Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.00188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.11966v3","updated":"2023-02-01T02:18:49Z","published":"2022-02-24T09:11:45Z","title":"A Fair Empirical Risk Minimization with Generalized Entropy","summary":"  This paper studies a parametric family of algorithmic fairness metrics,\ncalled generalized entropy, which originally has been used in public welfare\nand recently introduced to machine learning community. As a meaningful metric\nto evaluate algorithmic fairness, it requires that generalized entropy specify\nfairness requirements of a classification problem and the fairness requirements\nshould be realized with small deviation by an algorithm. We investigate the\nrole of generalized entropy as a design parameter for fair classification\nalgorithm through a fair empirical risk minimization with a constraint\nspecified in terms of generalized entropy. We theoretically and experimentally\nstudy learnability of the problem.\n","authors":["Youngmi Jin","Jio Gim","Tae-Jin Lee","Young-Joo Suh"],"pdf_url":"https://arxiv.org/pdf/2202.11966v3.pdf","comment":"56pages and 92 figures Revised for adding experimental results"},{"id":"http://arxiv.org/abs/2106.12974v2","updated":"2023-02-01T02:10:03Z","published":"2021-06-24T12:51:00Z","title":"Tensor networks for unsupervised machine learning","summary":"  Modeling the joint distribution of high-dimensional data is a central task in\nunsupervised machine learning. In recent years, many interests have been\nattracted to developing learning models based on tensor networks, which have\nthe advantages of a principle understanding of the expressive power using\nentanglement properties, and as a bridge connecting classical computation and\nquantum computation. Despite the great potential, however, existing tensor\nnetwork models for unsupervised machine learning only work as a proof of\nprinciple, as their performance is much worse than the standard models such as\nrestricted Boltzmann machines and neural networks. In this Letter, we present\nautoregressive matrix product states (AMPS), a tensor network model combining\nmatrix product states from quantum many-body physics and autoregressive\nmodeling from machine learning. Our model enjoys the exact calculation of\nnormalized probability and unbiased sampling. We demonstrate the performance of\nour model using two applications, generative modeling on synthetic and\nreal-world data, and reinforcement learning in statistical physics. Using\nextensive numerical experiments, we show that the proposed model significantly\noutperforms the existing tensor network models and the restricted Boltzmann\nmachines, and is competitive with state-of-the-art neural network models.\n","authors":["Jing Liu","Sujie Li","Jiang Zhang","Pan Zhang"],"pdf_url":"https://arxiv.org/pdf/2106.12974v2.pdf","comment":"v2"},{"id":"http://arxiv.org/abs/2301.12056v3","updated":"2023-02-01T01:57:10Z","published":"2023-01-28T02:20:03Z","title":"Variational Latent Branching Model for Off-Policy Evaluation","summary":"  Model-based methods have recently shown great potential for off-policy\nevaluation (OPE); offline trajectories induced by behavioral policies are\nfitted to transitions of Markov decision processes (MDPs), which are used to\nrollout simulated trajectories and estimate the performance of policies.\nModel-based OPE methods face two key challenges. First, as offline trajectories\nare usually fixed, they tend to cover limited state and action space. Second,\nthe performance of model-based methods can be sensitive to the initialization\nof their parameters. In this work, we propose the variational latent branching\nmodel (VLBM) to learn the transition function of MDPs by formulating the\nenvironmental dynamics as a compact latent space, from which the next states\nand rewards are then sampled. Specifically, VLBM leverages and extends the\nvariational inference framework with the recurrent state alignment (RSA), which\nis designed to capture as much information underlying the limited training\ndata, by smoothing out the information flow between the variational (encoding)\nand generative (decoding) part of VLBM. Moreover, we also introduce the\nbranching architecture to improve the model's robustness against randomly\ninitialized model weights. The effectiveness of the VLBM is evaluated on the\ndeep OPE (DOPE) benchmark, from which the training trajectories are designed to\nresult in varied coverage of the state-action space. We show that the VLBM\noutperforms existing state-of-the-art OPE methods in general.\n","authors":["Qitong Gao","Ge Gao","Min Chi","Miroslav Pajic"],"pdf_url":"https://arxiv.org/pdf/2301.12056v3.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2302.00178v1","updated":"2023-02-01T01:51:45Z","published":"2023-02-01T01:51:45Z","title":"Program Generation from Diverse Video Demonstrations","summary":"  The ability to use inductive reasoning to extract general rules from multiple\nobservations is a vital indicator of intelligence. As humans, we use this\nability to not only interpret the world around us, but also to predict the\noutcomes of the various interactions we experience. Generalising over multiple\nobservations is a task that has historically presented difficulties for\nmachines to grasp, especially when requiring computer vision. In this paper, we\npropose a model that can extract general rules from video demonstrations by\nsimultaneously performing summarisation and translation. Our approach differs\nfrom prior works by framing the problem as a multi-sequence-to-sequence task,\nwherein summarisation is learnt by the model. This allows our model to utilise\nedge cases that would otherwise be suppressed or discarded by traditional\nsummarisation techniques. Additionally, we show that our approach can handle\nnoisy specifications without the need for additional filtering methods. We\nevaluate our model by synthesising programs from video demonstrations in the\nVizdoom environment achieving state-of-the-art results with a relative increase\nof 11.75% program accuracy on prior works\n","authors":["Anthony Manchin","Jamie Sherrah","Qi Wu","Anton van den Hengel"],"pdf_url":"https://arxiv.org/pdf/2302.00178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13324v2","updated":"2023-02-01T01:51:09Z","published":"2023-01-30T23:13:18Z","title":"V2N Service Scaling with Deep Reinforcement Learning","summary":"  The fifth generation (5G) of wireless networks is set out to meet the\nstringent requirements of vehicular use cases. Edge computing resources can aid\nin this direction by moving processing closer to end-users, reducing latency.\nHowever, given the stochastic nature of traffic loads and availability of\nphysical resources, appropriate auto-scaling mechanisms need to be employed to\nsupport cost-efficient and performant services. To this end, we employ Deep\nReinforcement Learning (DRL) for vertical scaling in Edge computing to support\nvehicular-to-network communications. We address the problem using Deep\nDeterministic Policy Gradient (DDPG). As DDPG is a model-free off-policy\nalgorithm for learning continuous actions, we introduce a discretization\napproach to support discrete scaling actions. Thus we address scalability\nproblems inherent to high-dimensional discrete action spaces. Employing a\nreal-world vehicular trace data set, we show that DDPG outperforms existing\nsolutions, reducing (at minimum) the average number of active CPUs by 23% while\nincreasing the long-term reward by 24%.\n","authors":["Cyril Shih-Huan Hsu","Jorge Martín-Pérez","Chrysa Papagianni","Paola Grosso"],"pdf_url":"https://arxiv.org/pdf/2301.13324v2.pdf","comment":"Accepted at the 36th IEEE/IFIP Network Operations and Management\n  Symposium (NOMS 2023)"},{"id":"http://arxiv.org/abs/2302.00171v1","updated":"2023-02-01T01:34:48Z","published":"2023-02-01T01:34:48Z","title":"Active Uncertainty Reduction for Safe and Efficient Interaction\n  Planning: A Shielding-Aware Dual Control Approach","summary":"  The ability to accurately predict the opponent's behavior is central to the\nsafety and efficiency of robotic systems in interactive settings, such as\nhuman-robot interaction and multi-robot teaming tasks. Unfortunately, robots\noften lack access to key information on which these predictions may hinge, such\nas opponent's goals, attention, and willingness to cooperate. Dual control\ntheory addresses this challenge by treating unknown parameters of a predictive\nmodel as hidden states and inferring their values at runtime using information\ngathered during system operation. While able to optimally and automatically\ntrade off exploration and exploitation, dual control is computationally\nintractable for general interactive motion planning. In this paper, we present\na novel algorithmic approach to enable active uncertainty reduction for\ninteractive motion planning based on the implicit dual control paradigm. Our\napproach relies on sampling-based approximation of stochastic dynamic\nprogramming, leading to a model predictive control problem. The resulting\npolicy is shown to preserve the dual control effect for a broad class of\npredictive models with both continuous and categorical uncertainty. To ensure\nthe safe operation of the interacting agents, we leverage a supervisory control\nscheme, oftentimes referred to as ``shielding'', which overrides the ego\nagent's dual control policy with a safety fallback strategy when a\nsafety-critical event is imminent. We then augment the dual control framework\nwith an improved variant of the recently proposed shielding-aware robust\nplanning scheme, which proactively balances the nominal planning performance\nwith the risk of high-cost emergency maneuvers triggered by low-probability\nopponent's behaviors. We demonstrate the efficacy of our approach with both\nsimulated driving examples and hardware experiments using 1/10 scale autonomous\nvehicles.\n","authors":["Haimin Hu","David Isele","Sangjae Bae","Jaime F. Fisac"],"pdf_url":"https://arxiv.org/pdf/2302.00171v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.07720"},{"id":"http://arxiv.org/abs/2302.00170v1","updated":"2023-02-01T01:32:25Z","published":"2023-02-01T01:32:25Z","title":"Diffusion Models for High-Resolution Solar Forecasts","summary":"  Forecasting future weather and climate is inherently difficult. Machine\nlearning offers new approaches to increase the accuracy and computational\nefficiency of forecasts, but current methods are unable to accurately model\nuncertainty in high-dimensional predictions. Score-based diffusion models offer\na new approach to modeling probability distributions over many dependent\nvariables, and in this work, we demonstrate how they provide probabilistic\nforecasts of weather and climate variables at unprecedented resolution, speed,\nand accuracy. We apply the technique to day-ahead solar irradiance forecasts by\ngenerating many samples from a diffusion model trained to super-resolve\ncoarse-resolution numerical weather predictions to high-resolution weather\nsatellite observations.\n","authors":["Yusuke Hatanaka","Yannik Glaser","Geoff Galgon","Giuseppe Torri","Peter Sadowski"],"pdf_url":"https://arxiv.org/pdf/2302.00170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00164v1","updated":"2023-02-01T00:57:58Z","published":"2023-02-01T00:57:58Z","title":"Detection of Tomato Ripening Stages using Yolov3-tiny","summary":"  One of the most important agricultural products in Mexico is the tomato\n(Solanum lycopersicum), which occupies the 4th place national most produced\nproduct . Therefore, it is necessary to improve its production, building\nautomatic detection system that detect, classify an keep tacks of the fruits is\none way to archieve it. So, in this paper, we address the design of a computer\nvision system to detect tomatoes at different ripening stages. To solve the\nproblem, we use a neural network-based model for tomato classification and\ndetection. Specifically, we use the YOLOv3-tiny model because it is one of the\nlightest current deep neural networks. To train it, we perform two grid\nsearches testing several combinations of hyperparameters. Our experiments\nshowed an f1-score of 90.0% in the localization and classification of ripening\nstages in a custom dataset.\n","authors":["Gerardo Antonio Alvarez Hernández","Juan Carlos Olguin","Juan Irving Vasquez","Abril Valeria Uriarte","Maria Claudia Villicaña Torres"],"pdf_url":"https://arxiv.org/pdf/2302.00164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00163v1","updated":"2023-02-01T00:52:55Z","published":"2023-02-01T00:52:55Z","title":"FLSTRA: Federated Learning in Stratosphere","summary":"  We propose a federated learning (FL) in stratosphere (FLSTRA) system, where a\nhigh altitude platform station (HAPS) felicitates a large number of terrestrial\nclients to collaboratively learn a global model without sharing the training\ndata. FLSTRA overcomes the challenges faced by FL in terrestrial networks, such\nas slow convergence and high communication delay due to limited client\nparticipation and multi-hop communications. HAPS leverages its altitude and\nsize to allow the participation of more clients with line-of-sight (LoS) links\nand the placement of a powerful server. However, handling many clients at once\nintroduces computing and transmission delays. Thus, we aim to obtain a\ndelay-accuracy trade-off for FLSTRA. Specifically, we first develop a joint\nclient selection and resource allocation algorithm for uplink and downlink to\nminimize the FL delay subject to the energy and quality-of-service (QoS)\nconstraints. Second, we propose a communication and computation resource-aware\n(CCRA-FL) algorithm to achieve the target FL accuracy while deriving an upper\nbound for its convergence rate. The formulated problem is non-convex; thus, we\npropose an iterative algorithm to solve it. Simulation results demonstrate the\neffectiveness of the proposed FLSTRA system, compared to terrestrial\nbenchmarks, in terms of FL delay and accuracy.\n","authors":["Amin Farajzadeh","Animesh Yadav","Omid Abbasi","Wael Jaafar","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2302.00163v1.pdf","comment":"Submitted to IEEE for possible publication"},{"id":"http://arxiv.org/abs/2302.00160v1","updated":"2023-02-01T00:46:43Z","published":"2023-02-01T00:46:43Z","title":"Local transfer learning from one data space to another","summary":"  A fundamental problem in manifold learning is to approximate a functional\nrelationship in a data chosen randomly from a probability distribution\nsupported on a low dimensional sub-manifold of a high dimensional ambient\nEuclidean space. The manifold is essentially defined by the data set itself\nand, typically, designed so that the data is dense on the manifold in some\nsense. The notion of a data space is an abstraction of a manifold encapsulating\nthe essential properties that allow for function approximation. The problem of\ntransfer learning (meta-learning) is to use the learning of a function on one\ndata set to learn a similar function on a new data set. In terms of function\napproximation, this means lifting a function on one data space (the base data\nspace) to another (the target data space). This viewpoint enables us to connect\nsome inverse problems in applied mathematics (such as inverse Radon transform)\nwith transfer learning. In this paper we examine the question of such lifting\nwhen the data is assumed to be known only on a part of the base data space. We\nare interested in determining subsets of the target data space on which the\nlifting can be defined, and how the local smoothness of the function and its\nlifting are related.\n","authors":["H. N. Mhaskar","Ryan O'Dowd"],"pdf_url":"https://arxiv.org/pdf/2302.00160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07098v2","updated":"2023-02-01T00:46:21Z","published":"2022-02-14T23:48:13Z","title":"Statistical Inference After Adaptive Sampling for Longitudinal Data","summary":"  Online reinforcement learning and other adaptive sampling algorithms are\nincreasingly used in digital intervention experiments to optimize treatment\ndelivery for users over time. In this work, we focus on longitudinal user data\ncollected by a large class of adaptive sampling algorithms that are designed to\noptimize treatment decisions online using accruing data from multiple users.\nCombining or \"pooling\" data across users allows adaptive sampling algorithms to\npotentially learn faster. However, by pooling, these algorithms induce\ndependence between the collected user data trajectories; we show that this can\ncause standard variance estimators for i.i.d. data to underestimate the true\nvariance of common estimators on this data type. We develop novel methods to\nperform a variety of statistical analyses on such adaptively collected data via\nZ-estimation. Specifically, we introduce the adaptive sandwich variance\nestimator, a corrected sandwich estimator that leads to consistent variance\nestimates under adaptive sampling. Additionally, to prove our results we\ndevelop significant theory for empirical processes on non-i.i.d., adaptively\ncollected, longitudinal data. This work is motivated by our efforts in\ndesigning experiments in which online reinforcement learning algorithms pool\ndata across users to learn to optimize treatment decisions, yet reliable\nstatistical inference is essential for conducting a variety of statistical\nanalyses after the experiment is over.\n","authors":["Kelly W Zhang","Lucas Janson","Susan A Murphy"],"pdf_url":"https://arxiv.org/pdf/2202.07098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01407v3","updated":"2023-02-01T00:35:03Z","published":"2022-10-04T06:32:45Z","title":"Homotopy-based training of NeuralODEs for accurate dynamics discovery","summary":"  Conceptually, Neural Ordinary Differential Equations (NeuralODEs) pose an\nattractive way to extract dynamical laws from time series data, as they are\nnatural extensions of the traditional differential equation-based modeling\nparadigm of the physical sciences. In practice, NeuralODEs display long\ntraining times and suboptimal results, especially for longer duration data\nwhere they may fail to fit the data altogether. While methods have been\nproposed to stabilize NeuralODE training, many of these involve placing a\nstrong constraint on the functional form the trained NeuralODE can take that\nthe actual underlying governing equation does not guarantee satisfaction. In\nthis work, we present a novel NeuralODE training algorithm that leverages tools\nfrom the chaos and mathematical optimization communities - synchronization and\nhomotopy optimization - for a breakthrough in tackling the NeuralODE training\nobstacle. We demonstrate architectural changes are unnecessary for effective\nNeuralODE training. Compared to the conventional training methods, our\nalgorithm achieves drastically lower loss values without any changes to the\nmodel architectures. Experiments on both simulated and real systems with\ncomplex temporal behaviors demonstrate NeuralODEs trained with our algorithm\nare able to accurately capture true long term behaviors and correctly\nextrapolate into the future.\n","authors":["Joon-Hyuk Ko","Hankyul Koh","Nojun Park","Wonho Jhe"],"pdf_url":"https://arxiv.org/pdf/2210.01407v3.pdf","comment":"19 pages, 17 figures, submitted to ICML2023"},{"id":"http://arxiv.org/abs/2302.00152v1","updated":"2023-02-01T00:11:18Z","published":"2023-02-01T00:11:18Z","title":"TwinExplainer: Explaining Predictions of an Automotive Digital Twin","summary":"  Vehicles are complex Cyber Physical Systems (CPS) that operate in a variety\nof environments, and the likelihood of failure of one or more subsystems, such\nas the engine, transmission, brakes, and fuel, can result in unscheduled\ndowntime and incur high maintenance or repair costs. In order to prevent these\nissues, it is crucial to continuously monitor the health of various subsystems\nand identify abnormal sensor channel behavior. Data-driven Digital Twin (DT)\nsystems are capable of such a task. Current DT technologies utilize various\nDeep Learning (DL) techniques that are constrained by the lack of justification\nor explanation for their predictions. This inability of these opaque systems\ncan influence decision-making and raises user trust concerns. This paper\npresents a solution to this issue, where the TwinExplainer system, with its\nthree-layered architectural pipeline, explains the predictions of an automotive\nDT. Such a system can assist automotive stakeholders in understanding the\nglobal scale of the sensor channels and how they contribute towards generic DT\npredictions. TwinExplainer can also visualize explanations for both normal and\nabnormal local predictions computed by the DT.\n","authors":["Subash Neupane","Ivan A. Fernandez","Wilson Patterson","Sudip Mittal","Milan Parmar","Shahram Rahimi"],"pdf_url":"https://arxiv.org/pdf/2302.00152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00150v1","updated":"2023-02-01T00:09:56Z","published":"2023-02-01T00:09:56Z","title":"Multi-Grade Deep Learning","summary":"  The current deep learning model is of a single-grade, that is, it learns a\ndeep neural network by solving a single nonconvex optimization problem. When\nthe layer number of the neural network is large, it is computationally\nchallenging to carry out such a task efficiently. Inspired by the human\neducation process which arranges learning in grades, we propose a multi-grade\nlearning model: We successively solve a number of optimization problems of\nsmall sizes, which are organized in grades, to learn a shallow neural network\nfor each grade. Specifically, the current grade is to learn the leftover from\nthe previous grade. In each of the grades, we learn a shallow neural network\nstacked on the top of the neural network, learned in the previous grades, which\nremains unchanged in training of the current and future grades. By dividing the\ntask of learning a deep neural network into learning several shallow neural\nnetworks, one can alleviate the severity of the nonconvexity of the original\noptimization problem of a large size. When all grades of the learning are\ncompleted, the final neural network learned is a stair-shape neural network,\nwhich is the superposition of networks learned from all grades. Such a model\nenables us to learn a deep neural network much more effectively and\nefficiently. Moreover, multi-grade learning naturally leads to adaptive\nlearning. We prove that in the context of function approximation if the neural\nnetwork generated by a new grade is nontrivial, the optimal error of the grade\nis strictly reduced from the optimal error of the previous grade. Furthermore,\nwe provide several proof-of-concept numerical examples which demonstrate that\nthe proposed multi-grade model outperforms significantly the traditional\nsingle-grade model and is much more robust than the traditional model.\n","authors":["Yuesheng Xu"],"pdf_url":"https://arxiv.org/pdf/2302.00150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13537v2","updated":"2023-02-01T00:03:33Z","published":"2022-10-24T18:40:19Z","title":"Private Online Prediction from Experts: Separations and Faster Rates","summary":"  Online prediction from experts is a fundamental problem in machine learning\nand several works have studied this problem under privacy constraints. We\npropose and analyze new algorithms for this problem that improve over the\nregret bounds of the best existing algorithms for non-adaptive adversaries. For\napproximate differential privacy, our algorithms achieve regret bounds of\n$\\tilde{O}(\\sqrt{T \\log d} + \\log d/\\varepsilon)$ for the stochastic setting\nand $\\tilde O(\\sqrt{T \\log d} + T^{1/3} \\log d/\\varepsilon)$ for oblivious\nadversaries (where $d$ is the number of experts). For pure DP, our algorithms\nare the first to obtain sub-linear regret for oblivious adversaries in the\nhigh-dimensional regime $d \\ge T$. Moreover, we prove new lower bounds for\nadaptive adversaries. Our results imply that unlike the non-private setting,\nthere is a strong separation between the optimal regret for adaptive and\nnon-adaptive adversaries for this problem. Our lower bounds also show a\nseparation between pure and approximate differential privacy for adaptive\nadversaries where the latter is necessary to achieve the non-private\n$O(\\sqrt{T})$ regret.\n","authors":["Hilal Asi","Vitaly Feldman","Tomer Koren","Kunal Talwar"],"pdf_url":"https://arxiv.org/pdf/2210.13537v2.pdf","comment":"Remove the results for the realizable setting which we will upload\n  with additional results for that setting in a separate paper"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.00402v1","updated":"2023-02-01T12:40:03Z","published":"2023-02-01T12:40:03Z","title":"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image\n  and Video","summary":"  Recent years have witnessed a big convergence of language, vision, and\nmulti-modal pretraining. In this work, we present mPLUG-2, a new unified\nparadigm with modularized design for multi-modal pretraining, which can benefit\nfrom modality collaboration while addressing the problem of modality\nentanglement. In contrast to predominant paradigms of solely relying on\nsequence-to-sequence generation or encoder-based instance discrimination,\nmPLUG-2 introduces a multi-module composition network by sharing common\nuniversal modules for modality collaboration and disentangling different\nmodality modules to deal with modality entanglement. It is flexible to select\ndifferent modules for different understanding and generation tasks across all\nmodalities including text, image, and video. Empirical study shows that mPLUG-2\nachieves state-of-the-art or competitive results on a broad range of over 30\ndownstream tasks, spanning multi-modal tasks of image-text and video-text\nunderstanding and generation, and uni-modal tasks of text-only, image-only, and\nvideo-only understanding. Notably, mPLUG-2 shows new state-of-the-art results\nof 48.0 top-1 accuracy and 80.3 CIDEr on the challenging MSRVTT video QA and\nvideo caption tasks with a far smaller model size and data scale. It also\ndemonstrates strong zero-shot transferability on vision-language and\nvideo-language tasks. Code and models will be released in\nhttps://github.com/alibaba/AliceMind.\n","authors":["Haiyang Xu","Qinghao Ye","Ming Yan","Yaya Shi","Jiabo Ye","Yuanhong Xu","Chenliang Li","Bin Bi","Qi Qian","Wei Wang","Guohai Xu","Ji Zhang","Songfang Huang","Fei Huang","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13523v2","updated":"2023-02-01T08:59:48Z","published":"2023-01-31T10:17:38Z","title":"Towards Better Quality of Experience in HTTP Adaptive Streaming","summary":"  HTTP Adaptive Streaming (HAS) is nowadays a popular solution for multimedia\ndelivery. The novelty of HAS lies in the possibility of continuously adapting\nthe streaming session to current network conditions, facilitated by Adaptive\nBitrate (ABR) algorithms. Various popular streaming and Video on Demand\nservices such as Netflix, Amazon Prime Video, and Twitch use this method. Given\nthis broad consumer base, ABR algorithms continuously improve to increase user\nsatisfaction. The insights for these improvements are, among others, gathered\nwithin the research area of Quality of Experience (QoE). Within this field,\nvarious researchers have dedicated their works to identifying potential\nimpairments and testing their impact on viewers' QoE. Two frequently discussed\nvisual impairments influencing QoE are stalling events and quality switches. So\nfar, it is commonly assumed that those stalling events have the worst impact on\nQoE. This paper challenged this belief and reviewed this assumption by\ncomparing stalling events with multiple quality and high amplitude quality\nswitches. Two subjective studies were conducted. During the first subjective\nstudy, participants received a monetary incentive, while the second subjective\nstudy was carried out with volunteers. The statistical analysis demonstrated\nthat stalling events do not result in the worst degradation of QoE. These\nfindings suggest that a reevaluation of the effect of stalling events in QoE\nresearch is needed. Therefore, these findings may be used for further research\nand to improve current adaptation strategies in ABR algorithms.\n","authors":["Babak Taraghi","Selina Zoë Haack","Christian Timmerer"],"pdf_url":"https://arxiv.org/pdf/2301.13523v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00078v2","updated":"2023-02-01T19:13:49Z","published":"2022-12-31T00:08:04Z","title":"Image and video compression of fluid flow data","summary":"  We study the compression of spatial and temporal features in fluid flow data\nusing multimedia compression techniques. The efficacy of spatial compression\ntechniques, including JPEG and JPEG2000 (JP2), and spatio-temporal video\ncompression techniques, namely H.264, H.265, and AV1, in limiting the\nintroduction of compression artifacts and preserving underlying flow physics\nare considered for laminar periodic wake around a cylinder, two-dimensional\nturbulence, and turbulent channel flow. These compression techniques\nsignificantly compress flow data while maintaining dominant flow features with\nnegligible error. AV1 and H.265 compressions present the best performance\nacross a variety of canonical flow regimes and outperform traditional\ntechniques such as proper orthogonal decomposition in some cases. These image\nand video compression algorithms are flexible, scalable, and generalizable\nholding potential for a wide range of applications in fluid dynamics in the\ncontext of data storage and transfer.\n","authors":["Vishal Anatharaman","Jason Feldkamp","Kai Fukami","Kunihiko Taira"],"pdf_url":"https://arxiv.org/pdf/2301.00078v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04979v2","updated":"2023-02-01T22:32:31Z","published":"2022-12-09T16:39:09Z","title":"Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners","summary":"  This work explores an efficient approach to establish a foundational\nvideo-text model for tasks including open-vocabulary video classification,\ntext-to-video retrieval, video captioning and video question-answering. We\npresent VideoCoCa that reuses a pretrained image-text contrastive captioner\n(CoCa) model and adapt it to video-text tasks with minimal extra training.\nWhile previous works adapt image-text models with various cross-frame fusion\nmodules (for example, cross-frame attention layer or perceiver resampler) and\nfinetune the modified architecture on video-text data, we surprisingly find\nthat the generative attentional pooling and contrastive attentional pooling\nlayers in the image-text CoCa design are instantly adaptable to \"flattened\nframe embeddings\", yielding a strong zero-shot transfer baseline for many\nvideo-text tasks. Specifically, the frozen image encoder of a pretrained\nimage-text CoCa takes each video frame as inputs and generates $N$ token\nembeddings per frame for totally $T$ video frames. We flatten $(N \\times T)$\ntoken embeddings as a long sequence of frozen video representation and apply\nCoCa's generative attentional pooling and contrastive attentional pooling on\ntop. All model weights including pooling layers are directly loaded from an\nimage-text CoCa pretrained model. Without any video or video-text data,\nVideoCoCa's zero-shot transfer baseline already achieves state-of-the-art\nresults on zero-shot video classification on Kinetics 400/600/700, UCF101,\nHMDB51, and Charades, as well as zero-shot text-to-video retrieval on MSR-VTT,\nActivityNet Captions and VATEX. We also explore lightweight finetuning on top\nof VideoCoCa, and achieve strong results on video question-answering (iVQA,\nMSRVTT-QA, MSVD-QA, ActivityNet-QA) and video captioning (MSR-VTT, ActivityNet,\nVATEX, Youcook2). Our approach establishes a simple video-text baseline for\nfuture research.\n","authors":["Shen Yan","Tao Zhu","Zirui Wang","Yuan Cao","Mi Zhang","Soham Ghosh","Yonghui Wu","Jiahui Yu"],"pdf_url":"https://arxiv.org/pdf/2212.04979v2.pdf","comment":"Tech report. arXiv v2: update results on VATEX, ActivityNet-QA"}]},"2023-02-02T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.01328v1","updated":"2023-02-02T18:58:05Z","published":"2023-02-02T18:58:05Z","title":"$IC^3$: Image Captioning by Committee Consensus","summary":"  If you ask a human to describe an image, they might do so in a thousand\ndifferent ways. Traditionally, image captioning models are trained to\napproximate the reference distribution of image captions, however, doing so\nencourages captions that are viewpoint-impoverished. Such captions often focus\non only a subset of the possible details, while ignoring potentially useful\ninformation in the scene. In this work, we introduce a simple, yet novel,\nmethod: \"Image Captioning by Committee Consensus\" ($IC^3$), designed to\ngenerate a single caption that captures high-level details from several\nviewpoints. Notably, humans rate captions produced by $IC^3$ at least as\nhelpful as baseline SOTA models more than two thirds of the time, and $IC^3$\ncaptions can improve the performance of SOTA automated recall systems by up to\n84%, indicating significant material improvements over existing SOTA approaches\nfor visual description. Our code is publicly available at\nhttps://github.com/DavidMChan/caption-by-committee\n","authors":["David M. Chan","Austin Myers","Sudheendra Vijayanarasimhan","David A. Ross","John Canny"],"pdf_url":"https://arxiv.org/pdf/2302.01328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01318v1","updated":"2023-02-02T18:44:11Z","published":"2023-02-02T18:44:11Z","title":"Accelerating Large Language Model Decoding with Speculative Sampling","summary":"  We present speculative sampling, an algorithm for accelerating transformer\ndecoding by enabling the generation of multiple tokens from each transformer\ncall. Our algorithm relies on the observation that the latency of parallel\nscoring of short continuations, generated by a faster but less powerful draft\nmodel, is comparable to that of sampling a single token from the larger target\nmodel. This is combined with a novel modified rejection sampling scheme which\npreserves the distribution of the target model within hardware numerics. We\nbenchmark speculative sampling with Chinchilla, a 70 billion parameter language\nmodel, achieving a 2-2.5x decoding speedup in a distributed setup, without\ncompromising the sample quality or making modifications to the model itself.\n","authors":["Charlie Chen","Sebastian Borgeaud","Geoffrey Irving","Jean-Baptiste Lespiau","Laurent Sifre","John Jumper"],"pdf_url":"https://arxiv.org/pdf/2302.01318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01313v1","updated":"2023-02-02T18:39:30Z","published":"2023-02-02T18:39:30Z","title":"Double Permutation Equivariance for Knowledge Graph Completion","summary":"  This work provides a formalization of Knowledge Graphs (KGs) as a new class\nof graphs that we denote doubly exchangeable attributed graphs, where node and\npairwise (joint 2-node) representations must be equivariant to permutations of\nboth node ids and edge (& node) attributes (relations & node features).\nDouble-permutation equivariant KG representations open a new research direction\nin KGs. We show that this equivariance imposes a structural representation of\nrelations that allows neural networks to perform complex logical reasoning\ntasks in KGs. Finally, we introduce a general blueprint for such equivariant\nrepresentations and test a simple GNN-based double-permutation equivariant\nneural architecture that achieve 100% Hits@10 test accuracy in both the\nWN18RRv1 and NELL995v1 inductive KG completion tasks, and can accurately\nperform logical reasoning tasks that no existing methods can perform, to the\nbest of our knowledge.\n","authors":["Jianfei Gao","Yangze Zhou","Bruno Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2302.01313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01308v1","updated":"2023-02-02T18:32:46Z","published":"2023-02-02T18:32:46Z","title":"What Language Reveals about Perception: Distilling Psychophysical\n  Knowledge from Large Language Models","summary":"  Understanding the extent to which the perceptual world can be recovered from\nlanguage is a fundamental problem in cognitive science. We reformulate this\nproblem as that of distilling psychophysical information from text and show how\nthis can be done by combining large language models (LLMs) with a classic\npsychophysical method based on similarity judgments. Specifically, we use the\nprompt auto-completion functionality of GPT3, a state-of-the-art LLM, to elicit\nsimilarity scores between stimuli and then apply multidimensional scaling to\nuncover their underlying psychological space. We test our approach on six\nperceptual domains and show that the elicited judgments strongly correlate with\nhuman data and successfully recover well-known psychophysical structures such\nas the color wheel and pitch spiral. We also explore meaningful divergences\nbetween LLM and human representations. Our work showcases how combining\nstate-of-the-art machine models with well-known cognitive paradigms can shed\nnew light on fundamental questions in perception and language research.\n","authors":["Raja Marjieh","Ilia Sucholutsky","Pol van Rijn","Nori Jacoby","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2302.01308v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2202.13649v2","updated":"2023-02-02T16:41:48Z","published":"2022-02-28T09:44:43Z","title":"GausSetExpander: A Simple Approach for Entity Set Expansion","summary":"  Entity Set Expansion is an important NLP task that aims at expanding a small\nset of entities into a larger one with items from a large pool of candidates.\nIn this paper, we propose GausSetExpander, an unsupervised approach based on\noptimal transport techniques. We propose to re-frame the problem as choosing\nthe entity that best completes the seed set. For this, we interpret a set as an\nelliptical distribution with a centroid which represents the mean and a spread\nthat is represented by the scale parameter. The best entity is the one that\nincreases the spread of the set the least. We demonstrate the validity of our\napproach by comparing to state-of-the art approaches.\n","authors":["Aïssatou Diallo","Johannes Fürnkranz"],"pdf_url":"https://arxiv.org/pdf/2202.13649v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2206.08657v4","updated":"2023-02-02T16:22:23Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v4.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2211.14829v3","updated":"2023-02-02T15:38:00Z","published":"2022-11-27T13:49:19Z","title":"ESIE-BERT: Enriching Sub-words Information Explicitly with BERT for\n  Joint Intent Classification and SlotFilling","summary":"  Natural language understanding (NLU) has two core tasks: intent\nclassification and slot filling. The success of pre-training language models\nresulted in a significant breakthrough in the two tasks. One of the promising\nsolutions called BERT can jointly optimize the two tasks. We note that\nBERT-based models convert each complex token into multiple sub-tokens by\nwordpiece algorithm, which generates a mismatch between the lengths of the\ntokens and the labels. This leads to BERT-based models do not do well in label\nprediction which limits model performance improvement. Many existing models can\nbe compatible with this issue but some hidden semantic information is discarded\nin the fine-tuning process. We address the problem by introducing a novel joint\nmethod on top of BERT which explicitly models the multiple sub-tokens features\nafter wordpiece tokenization, thereby contributing to the two tasks. Our method\ncan well extract the contextual features from complex tokens by the proposed\nsub-words attention adapter (SAA), which preserves overall utterance\ninformation. Additionally, we propose an intent attention adapter (IAA) to\nobtain the full sentence features to aid users to predict intent. Experimental\nresults confirm that our proposed model is significantly improved on two public\nbenchmark datasets. In particular, the slot filling F1 score is improved from\n96.1 to 98.2 (2.1% absolute) on the Airline Travel Information Systems (ATIS)\ndataset.\n","authors":["Yu Guo","Zhilong Xie","Xingyan Chen","Huangen Chen","Leilei Wang","Huaming Du","Shaopeng Wei","Yu Zhao","Qing Li","Gang Wu"],"pdf_url":"https://arxiv.org/pdf/2211.14829v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01148v1","updated":"2023-02-02T15:08:25Z","published":"2023-02-02T15:08:25Z","title":"Combining Deep Neural Reranking and Unsupervised Extraction for\n  Multi-Query Focused Summarization","summary":"  The CrisisFACTS Track aims to tackle challenges such as multi-stream\nfact-finding in the domain of event tracking; participants' systems extract\nimportant facts from several disaster-related events while incorporating the\ntemporal order. We propose a combination of retrieval, reranking, and the\nwell-known Integer Linear Programming (ILP) and Maximal Marginal Relevance\n(MMR) frameworks. In the former two modules, we explore various methods\nincluding an entity-based baseline, pre-trained and fine-tuned Question\nAnswering systems, and ColBERT. We then use the latter module as an extractive\nsummarization component by taking diversity and novelty criteria into account.\nThe automatic scoring runs show strong results across the evaluation setups but\nalso reveal shortcomings and challenges.\n","authors":["Philipp Seeberger","Korbinian Riedhammer"],"pdf_url":"https://arxiv.org/pdf/2302.01148v1.pdf","comment":"CrisisFACTS (TREC 2022)"},{"id":"http://arxiv.org/abs/2302.01097v1","updated":"2023-02-02T13:37:48Z","published":"2023-02-02T13:37:48Z","title":"New Linear-time Algorithm for SubTree Kernel Computation based on\n  Root-Weighted Tree Automata","summary":"  Tree kernels have been proposed to be used in many areas as the automatic\nlearning of natural language applications. In this paper, we propose a new\nlinear time algorithm based on the concept of weighted tree automata for\nSubTree kernel computation. First, we introduce a new class of weighted tree\nautomata, called Root-Weighted Tree Automata, and their associated formal tree\nseries. Then we define, from this class, the SubTree automata that represent\ncompact computational models for finite tree languages. This allows us to\ndesign a theoretically guaranteed linear-time algorithm for computing the\nSubTree Kernel based on weighted tree automata intersection. The key idea\nbehind the proposed algorithm is to replace DAG reduction and nodes sorting\nsteps used in previous approaches by states equivalence classes computation\nallowed in the weighted tree automata approach. Our approach has three major\nadvantages: it is output-sensitive, it is free sensitive from the tree types\n(ordered trees versus unordered trees), and it is well adapted to any\nincremental tree kernel based learning methods. Finally, we conduct a variety\nof comparative experiments on a wide range of synthetic tree languages datasets\nadapted for a deep algorithm analysis. The obtained results show that the\nproposed algorithm outperforms state-of-the-art methods.\n","authors":["Ludovic Mignot","Faissal Ouardi","Djelloul Ziadi"],"pdf_url":"https://arxiv.org/pdf/2302.01097v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.08063v3","updated":"2023-02-02T12:17:25Z","published":"2022-02-16T13:44:00Z","title":"Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective","summary":"  Knowledge Extraction (KE), aiming to extract structural information from\nunstructured texts, often suffers from data scarcity and emerging unseen types,\ni.e., low-resource scenarios. Many neural approaches to low-resource KE have\nbeen widely investigated and achieved impressive performance. In this paper, we\npresent a literature review towards KE in low-resource scenarios, and\nsystematically categorize existing works into three paradigms: (1) exploiting\nhigher-resource data, (2) exploiting stronger models, and (3) exploiting data\nand models together. In addition, we highlight promising applications and\noutline some potential directions for future research. We hope that our survey\ncan help both the academic and industrial communities to better understand this\nfield, inspire more ideas, and boost broader applications.\n","authors":["Shumin Deng","Ningyu Zhang","Feiyu Xiong","Jeff Z. Pan","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2202.08063v3.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2302.01025v1","updated":"2023-02-02T11:40:16Z","published":"2023-02-02T11:40:16Z","title":"Semantic Coherence Markers for the Early Diagnosis of the Alzheimer\n  Disease","summary":"  In this work we explore how language models can be employed to analyze\nlanguage and discriminate between mentally impaired and healthy subjects\nthrough the perplexity metric. Perplexity was originally conceived as an\ninformation-theoretic measure to assess how much a given language model is\nsuited to predict a text sequence or, equivalently, how much a word sequence\nfits into a specific language model. We carried out an extensive\nexperimentation with the publicly available data, and employed language models\nas diverse as N-grams, from 2-grams to 5-grams, and GPT-2, a transformer-based\nlanguage model. We investigated whether perplexity scores may be used to\ndiscriminate between the transcripts of healthy subjects and subjects suffering\nfrom Alzheimer Disease (AD). Our best performing models achieved full accuracy\nand F-score (1.00 in both precision/specificity and recall/sensitivity) in\ncategorizing subjects from both the AD class and control subjects. These\nresults suggest that perplexity can be a valuable analytical metrics with\npotential application to supporting early diagnosis of symptoms of mental\ndisorders.\n","authors":["Davide Colla","Matteo Delsanto","Marco Agosto","Benedetto Vitiello","Daniele Paolo Radicioni"],"pdf_url":"https://arxiv.org/pdf/2302.01025v1.pdf","comment":"This paper is the (significantly) abridged version of the article\n  \"Semantic coherence markers: The contribution of perplexity metrics\"\n  (https://doi.org/10.1016/j.artmed.2022.102393), which also contains\n  references to employed data and to the implementation of the described work"},{"id":"http://arxiv.org/abs/2302.01005v1","updated":"2023-02-02T10:49:06Z","published":"2023-02-02T10:49:06Z","title":"Predefined domain specific embeddings of food concepts and recipes: A\n  case study on heterogeneous recipe datasets","summary":"  Although recipe data are very easy to come by nowadays, it is really hard to\nfind a complete recipe dataset - with a list of ingredients, nutrient values\nper ingredient, and per recipe, allergens, etc. Recipe datasets are usually\ncollected from social media websites where users post and publish recipes.\nUsually written with little to no structure, using both standardized and\nnon-standardized units of measurement. We collect six different recipe\ndatasets, publicly available, in different formats, and some including data in\ndifferent languages. Bringing all of these datasets to the needed format for\napplying a machine learning (ML) pipeline for nutrient prediction [1], [2],\nincludes data normalization using dictionary-based named entity recognition\n(NER), rule-based NER, as well as conversions using external domain-specific\nresources. From the list of ingredients, domain-specific embeddings are created\nusing the same embedding space for all recipes - one ingredient dataset is\ngenerated. The result from this normalization process is two corpora - one with\npredefined ingredient embeddings and one with predefined recipe embeddings. On\nall six recipe datasets, the ML pipeline is evaluated. The results from this\nuse case also confirm that the embeddings merged using the domain heuristic\nyield better results than the baselines.\n","authors":["Gordana Ispirova","Tome Eftimov","Barbara Koroušić Seljak"],"pdf_url":"https://arxiv.org/pdf/2302.01005v1.pdf","comment":"10 pages, 7 tables"},{"id":"http://arxiv.org/abs/2302.00954v1","updated":"2023-02-02T08:48:26Z","published":"2023-02-02T08:48:26Z","title":"Curriculum-guided Abstractive Summarization for Mental Health Online\n  Posts","summary":"  Automatically generating short summaries from users' online mental health\nposts could save counselors' reading time and reduce their fatigue so that they\ncan provide timely responses to those seeking help for improving their mental\nstate. Recent Transformers-based summarization models have presented a\npromising approach to abstractive summarization. They go beyond sentence\nselection and extractive strategies to deal with more complicated tasks such as\nnovel word generation and sentence paraphrasing. Nonetheless, these models have\na prominent shortcoming; their training strategy is not quite efficient, which\nrestricts the model's performance. In this paper, we include a curriculum\nlearning approach to reweigh the training samples, bringing about an efficient\nlearning procedure. We apply our model on extreme summarization dataset of\nMentSum posts -- a dataset of mental health related posts from Reddit social\nmedia. Compared to the state-of-the-art model, our proposed method makes\nsubstantial gains in terms of Rouge and Bertscore evaluation metrics, yielding\n3.5% (Rouge-1), 10.4% (Rouge-2), and 4.7% (Rouge-L), 1.5% (Bertscore) relative\nimprovements.\n","authors":["Sajad Sotudeh","Nazli Goharian","Hanieh Deilamsalehy","Franck Dernoncourt"],"pdf_url":"https://arxiv.org/pdf/2302.00954v1.pdf","comment":"4 pages, short paper, accepted to The 13th International Workshop on\n  Health Text Mining and Information Analysis (LOUHI 2022)"},{"id":"http://arxiv.org/abs/2302.00944v1","updated":"2023-02-02T08:35:34Z","published":"2023-02-02T08:35:34Z","title":"TransFool: An Adversarial Attack against Neural Machine Translation\n  Models","summary":"  Deep neural networks have been shown to be vulnerable to small perturbations\nof their inputs, known as adversarial attacks. In this paper, we investigate\nthe vulnerability of Neural Machine Translation (NMT) models to adversarial\nattacks and propose a new attack algorithm called TransFool. To fool NMT\nmodels, TransFool builds on a multi-term optimization problem and a gradient\nprojection step. By integrating the embedding representation of a language\nmodel, we generate fluent adversarial examples in the source language that\nmaintain a high level of semantic similarity with the clean samples.\nExperimental results demonstrate that, for different translation tasks and NMT\narchitectures, our white-box attack can severely degrade the translation\nquality while the semantic similarity between the original and the adversarial\nsentences stays high. Moreover, we show that TransFool is transferable to\nunknown target models. Finally, based on automatic and human evaluations,\nTransFool leads to improvement in terms of success rate, semantic similarity,\nand fluency compared to the existing attacks both in white-box and black-box\nsettings. Thus, TransFool permits us to better characterize the vulnerability\nof NMT models and outlines the necessity to design strong defense mechanisms\nand more robust NMT systems for real-life applications.\n","authors":["Sahar Sadrizadeh","Ljiljana Dolamic","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2302.00944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00937v1","updated":"2023-02-02T08:25:48Z","published":"2023-02-02T08:25:48Z","title":"The Fewer Splits are Better: Deconstructing Readability in Sentence\n  Splitting","summary":"  In this work, we focus on sentence splitting, a subfield of text\nsimplification, motivated largely by an unproven idea that if you divide a\nsentence in pieces, it should become easier to understand. Our primary goal in\nthis paper is to find out whether this is true. In particular, we ask, does it\nmatter whether we break a sentence into two or three? We report on our findings\nbased on Amazon Mechanical Turk.\n  More specifically, we introduce a Bayesian modeling framework to further\ninvestigate to what degree a particular way of splitting the complex sentence\naffects readability, along with a number of other parameters adopted from\ndiverse perspectives, including clinical linguistics, and cognitive\nlinguistics. The Bayesian modeling experiment provides clear evidence that\nbisecting the sentence leads to enhanced readability to a degree greater than\nwhat we create by trisection.\n","authors":["Tadashi Nomoto"],"pdf_url":"https://arxiv.org/pdf/2302.00937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00923v1","updated":"2023-02-02T07:51:19Z","published":"2023-02-02T07:51:19Z","title":"Multimodal Chain-of-Thought Reasoning in Language Models","summary":"  Large language models (LLMs) have shown impressive performance on complex\nreasoning by leveraging chain-of-thought (CoT) prompting to generate\nintermediate reasoning chains as the rationale to infer the answer. However,\nexisting CoT studies are mostly isolated in the language modality with LLMs,\nwhere LLMs are hard to deploy. To elicit CoT reasoning in multimodality, a\npossible solution is to fine-tune small language models by fusing the vision\nand language features to perform CoT reasoning. The key challenge is that those\nlanguage models tend to generate hallucinated reasoning chains that mislead the\nanswer inference. To mitigate the effect of such mistakes, we propose\nMultimodal-CoT that incorporates vision features in a decoupled training\nframework. The framework separates the rationale generation and answer\ninference into two stages. By incorporating the vision features in both stages,\nthe model is able to generate effective rationales that contribute to answer\ninference. With Multimodal-CoT, our model under 1 billion parameters\noutperforms the previous state-of-the-art LLM (GPT-3.5) by 16% (75.17%->91.68%)\non the ScienceQA benchmark and even surpasses human performance. Code is\npublicly available at https://github.com/amazon-science/mm-cot.\n","authors":["Zhuosheng Zhang","Aston Zhang","Mu Li","Hai Zhao","George Karypis","Alex Smola"],"pdf_url":"https://arxiv.org/pdf/2302.00923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00907v1","updated":"2023-02-02T06:54:33Z","published":"2023-02-02T06:54:33Z","title":"History-Aware Hierarchical Transformer for Multi-session Open-domain\n  Dialogue System","summary":"  With the evolution of pre-trained language models, current open-domain\ndialogue systems have achieved great progress in conducting one-session\nconversations. In contrast, Multi-Session Conversation (MSC), which consists of\nmultiple sessions over a long term with the same user, is under-investigated.\nIn this paper, we propose History-Aware Hierarchical Transformer (HAHT) for\nmulti-session open-domain dialogue. HAHT maintains a long-term memory of\nhistory conversations and utilizes history information to understand current\nconversation context and generate well-informed and context-relevant responses.\nSpecifically, HAHT first encodes history conversation sessions hierarchically\ninto a history memory. Then, HAHT leverages historical information to\nfacilitate the understanding of the current conversation context by encoding\nthe history memory together with the current context with attention-based\nmechanisms. Finally, to explicitly utilize historical information, HAHT uses a\nhistory-aware response generator that switches between a generic vocabulary and\na history-aware vocabulary. Experimental results on a large-scale MSC dataset\nsuggest that the proposed HAHT model consistently outperforms baseline models.\nHuman evaluation results support that HAHT generates more human-like,\ncontext-relevant and history-relevant responses than baseline models.\n","authors":["Tong Zhang","Yong Liu","Boyang Li","Zhiwei Zeng","Pengwei Wang","Yuan You","Chunyan Miao","Lizhen Cui"],"pdf_url":"https://arxiv.org/pdf/2302.00907v1.pdf","comment":"EMNLP 2022(Findings)"},{"id":"http://arxiv.org/abs/2302.00902v1","updated":"2023-02-02T06:38:44Z","published":"2023-02-02T06:38:44Z","title":"Language Quantized AutoEncoders: Towards Unsupervised Text-Image\n  Alignment","summary":"  Recent progress in scaling up large language models has shown impressive\ncapabilities in performing few-shot learning across a wide range of text-based\ntasks. However, a key limitation is that these language models fundamentally\nlack visual perception - a crucial attribute needed to extend these models to\nbe able to interact with the real world and solve vision tasks, such as in\nvisual-question answering and robotics. Prior works have largely connected\nimage to text through pretraining and/or fine-tuning on curated image-text\ndatasets, which can be a costly and expensive process. In order to resolve this\nlimitation, we propose a simple yet effective approach called\nLanguage-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to\nalign text-image data in an unsupervised manner by leveraging pretrained\nlanguage models (e.g., BERT, RoBERTa). Our main idea is to encode image as\nsequences of text tokens by directly quantizing image embeddings using a\npretrained language codebook. We then apply random masking followed by a BERT\nmodel, and have the decoder reconstruct the original image from BERT predicted\ntext token embeddings. By doing so, LQAE learns to represent similar images\nwith similar clusters of text tokens, thereby aligning these two modalities\nwithout the use of aligned text-image pairs. This enables few-shot image\nclassification with large language models (e.g., GPT-3) as well as linear\nclassification of images based on BERT text features. To the best of our\nknowledge, our work is the first work that uses unaligned images for multimodal\ntasks by leveraging the power of pretrained language models.\n","authors":["Hao Liu","Wilson Yan","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.00902v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2106.13884 by other authors"},{"id":"http://arxiv.org/abs/2302.00894v1","updated":"2023-02-02T06:01:50Z","published":"2023-02-02T06:01:50Z","title":"How to choose \"Good\" Samples for Text Data Augmentation","summary":"  Deep learning-based text classification models need abundant labeled data to\nobtain competitive performance. Unfortunately, annotating large-size corpus is\ntime-consuming and laborious. To tackle this, multiple researches try to use\ndata augmentation to expand the corpus size. However, data augmentation may\npotentially produce some noisy augmented samples. There are currently no works\nexploring sample selection for augmented samples in nature language processing\nfield. In this paper, we propose a novel self-training selection framework with\ntwo selectors to select the high-quality samples from data augmentation.\nSpecifically, we firstly use an entropy-based strategy and the model prediction\nto select augmented samples. Considering some samples with high quality at the\nabove step may be wrongly filtered, we propose to recall them from two\nperspectives of word overlap and semantic similarity. Experimental results show\nthe effectiveness and simplicity of our framework.\n","authors":["Xiaotian Lin","Nankai Lin","Yingwen Fu","Ziyu Yang","Shengyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.00894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01621v3","updated":"2023-02-02T05:22:04Z","published":"2023-01-04T13:49:14Z","title":"Grammar construction methods for extended deterministic expressions","summary":"  Extended regular expressions with counting and interleaving are widely used\nin practice. However the related theoretical studies for this kind of\nexpressions currently cannot meet the need of practical work. This paper\ndevelops syntax definitions for extended deterministic expressions and their\nsubclasses, hope to completely solve the long-standing problem that there are\nno syntax definitions for this kind of expressions, which has become an\nimportant reason for restricting the use of extended expressions.\n","authors":["Xiaoying Mou","Haiming Chen"],"pdf_url":"https://arxiv.org/pdf/2301.01621v3.pdf","comment":"in Chinese language"},{"id":"http://arxiv.org/abs/2207.09068v5","updated":"2023-02-02T05:19:44Z","published":"2022-07-19T04:45:41Z","title":"PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic\n  Search","summary":"  While contextualized word embeddings have been a de-facto standard, learning\ncontextualized phrase embeddings is less explored and being hindered by the\nlack of a human-annotated benchmark that tests machine understanding of phrase\nsemantics given a context sentence or paragraph (instead of phrases alone). To\nfill this gap, we propose PiC -- a dataset of ~28K of noun phrases accompanied\nby their contextual Wikipedia pages and a suite of three tasks for training and\nevaluating phrase embeddings. Training on PiC improves ranking models' accuracy\nand remarkably pushes span-selection (SS) models (i.e., predicting the start\nand end index of the target phrase) near-human accuracy, which is 95% Exact\nMatch (EM) on semantic search given a query phrase and a passage.\nInterestingly, we find evidence that such impressive performance is because the\nSS models learn to better capture the common meaning of a phrase regardless of\nits actual context. SotA models perform poorly in distinguishing two senses of\nthe same phrase in two contexts (~60% EM) and in estimating the similarity\nbetween two different phrases in the same context (~70% EM).\n","authors":["Thang M. Pham","Seunghyun Yoon","Trung Bui","Anh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2207.09068v5.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.00871v1","updated":"2023-02-02T04:46:03Z","published":"2023-02-02T04:46:03Z","title":"Using In-Context Learning to Improve Dialogue Safety","summary":"  While large neural-based conversational models have become increasingly\nproficient as dialogue agents, recent work has highlighted safety issues with\nthese systems. For example, these systems can be goaded into generating toxic\ncontent, which often perpetuates social biases or stereotypes. We investigate a\nretrieval-based framework for reducing bias and toxicity in responses generated\nfrom neural-based chatbots. It uses in-context learning to steer a model\ntowards safer generations. Concretely, to generate a response to an unsafe\ndialogue context, we retrieve demonstrations of safe model responses to similar\ndialogue contexts. We find our proposed approach performs competitively with\nstrong baselines which use fine-tuning. For instance, using automatic\nevaluation, we find our best fine-tuned baseline only generates safe responses\nto unsafe dialogue contexts from DiaSafety 2.92% more than our approach.\nFinally, we also propose a straightforward re-ranking procedure which can\nfurther improve response safeness.\n","authors":["Nicholas Meade","Spandana Gella","Devamanyu Hazarika","Prakhar Gupta","Di Jin","Siva Reddy","Yang Liu","Dilek Hakkani-Tür"],"pdf_url":"https://arxiv.org/pdf/2302.00871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00856v1","updated":"2023-02-02T03:56:16Z","published":"2023-02-02T03:56:16Z","title":"idT5: Indonesian Version of Multilingual T5 Transformer","summary":"  Indonesian language is spoken by almost 200 million people and is the 10th\nmost spoken language in the world, but it is under-represented in NLP (Natural\nLanguage Processing) research. A sparsity of language resources has hampered\nprevious work on Indonesian. The Transformer is a new architecture rapidly\nbecoming dominant for NLP, surpassing alternatives like convolutional and\nrecurrent neural networks. T5 (Text-to-Text Transfer Transformer) is a\nTransformer model that converts all text-based language problems to\ntext-to-text format for English. The multilingual variant is mT5 (multilingual\nT5) which has shown promising results on many NLP tasks across languages.\nHowever, the size of this multilingual model is a drawback for its application\nin real production applications, which sometimes require only one language. In\nthis study, the mT5 model was adapted for only one language, Indonesian,\nresulting in a pre-trained T5 model that was specific only for Indonesian with\na smaller size. For performance comparison, we fine-tuned this model and the\nmT5 model to the Sentiment Analysis (SA), Question Generation (QG), and\nQuestion Answering (QA) tasks with the exact mechanism and dataset. Fine-tuned\nmodel based on our model achieved 77.18% accuracy on SA, 8% higher than the\nmT5-based model, and obtained nearly the same score as the mT5-based model on\nQG and QA. The results confirm that it is possible to produce a smaller\npre-trained model that maintains comparable yields while reducing the model\nsize by up to 58%. In addition, the resulting model requires less memory, loads\nfaster, and inference times faster.\n","authors":["Mukhlish Fuadi","Adhi Dharma Wibawa","Surya Sumpeno"],"pdf_url":"https://arxiv.org/pdf/2302.00856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00836v1","updated":"2023-02-02T02:46:32Z","published":"2023-02-02T02:46:32Z","title":"Improving Rare Words Recognition through Homophone Extension and Unified\n  Writing for Low-resource Cantonese Speech Recognition","summary":"  Homophone characters are common in tonal syllable-based languages, such as\nMandarin and Cantonese. The data-intensive end-to-end Automatic Speech\nRecognition (ASR) systems are more likely to mis-recognize homophone characters\nand rare words under low-resource settings. For the problem of lowresource\nCantonese speech recognition, this paper presents a novel homophone extension\nmethod to integrate human knowledge of the homophone lexicon into the beam\nsearch decoding process with language model re-scoring. Besides, we propose an\nautomatic unified writing method to merge the variants of Cantonese characters\nand standardize speech annotation guidelines, which enables more efficient\nutilization of labeled utterances by providing more samples for the merged\ncharacters. We empirically show that both homophone extension and unified\nwriting improve the recognition performance significantly on both in-domain and\nout-of-domain test sets, with an absolute Character Error Rate (CER) decrease\nof around 5% and 18%.\n","authors":["HoLam Chung","Junan Li","Pengfei Liu1","Wai-Kim Leung","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2302.00836v1.pdf","comment":"The 13th International Symposium on Chinese Spoken Language\n  Processing (ISCSLP 2022)"},{"id":"http://arxiv.org/abs/2212.13465v2","updated":"2023-02-02T02:44:58Z","published":"2022-12-27T12:34:57Z","title":"A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and\n  Future Directions","summary":"  Table-and-text hybrid question answering (HybridQA) is a widely used and\nchallenging NLP task commonly applied in the financial and scientific domain.\nThe early research focuses on migrating other QA task methods to HybridQA,\nwhile with further research, more and more HybridQA-specific methods have been\npresent. With the rapid development of HybridQA, the systematic survey is still\nunder-explored to summarize the main techniques and advance further research.\nSo we present this work to summarize the current HybridQA benchmarks and\nmethods, then analyze the challenges and future directions of this task. The\ncontributions of this paper can be summarized in three folds: (1) first survey,\nto our best knowledge, including benchmarks, methods and challenges for\nHybridQA; (2) systematic investigation with the reasonable comparison of the\nexisting systems to articulate their advantages and shortcomings; (3) detailed\nanalysis of challenges in four important dimensions to shed light on future\ndirections.\n","authors":["Dingzirui Wang","Longxu Dou","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2212.13465v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2209.10492v2","updated":"2023-02-02T02:08:52Z","published":"2022-09-21T16:50:22Z","title":"Summarization Programs: Interpretable Abstractive Summarization with\n  Neural Modular Trees","summary":"  Current abstractive summarization models either suffer from a lack of clear\ninterpretability or provide incomplete rationales by only highlighting parts of\nthe source document. To this end, we propose the Summarization Program (SP), an\ninterpretable modular framework consisting of an (ordered) list of binary\ntrees, each encoding the step-by-step generative process of an abstractive\nsummary sentence from the source document. A Summarization Program contains one\nroot node per summary sentence, and a distinct tree connects each summary\nsentence (root node) to the document sentences (leaf nodes) from which it is\nderived, with the connecting nodes containing intermediate generated sentences.\nEdges represent different modular operations involved in summarization such as\nsentence fusion, compression, and paraphrasing. We first propose an efficient\nbest-first search method over neural modules, SP-Search that identifies SPs for\nhuman summaries by directly optimizing for ROUGE scores. Next, using these\nprograms as automatic supervision, we propose seq2seq models that generate\nSummarization Programs, which are then executed to obtain final summaries. We\ndemonstrate that SP-Search effectively represents the generative process behind\nhuman summaries using modules that are typically faithful to their intended\nbehavior. We also conduct a simulation study to show that Summarization\nPrograms improve the interpretability of summarization models by allowing\nhumans to better simulate model reasoning. Summarization Programs constitute a\npromising step toward interpretable and modular abstractive summarization, a\ncomplex task previously addressed primarily through blackbox end-to-end neural\nsystems. Supporting code available at\nhttps://github.com/swarnaHub/SummarizationPrograms\n","authors":["Swarnadeep Saha","Shiyue Zhang","Peter Hase","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2209.10492v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01451v1","updated":"2023-02-02T22:38:23Z","published":"2023-02-02T22:38:23Z","title":"CTE: A Dataset for Contextualized Table Extraction","summary":"  Relevant information in documents is often summarized in tables, helping the\nreader to identify useful facts. Most benchmark datasets support either\ndocument layout analysis or table understanding, but lack in providing data to\napply both tasks in a unified way. We define the task of Contextualized Table\nExtraction (CTE), which aims to extract and define the structure of tables\nconsidering the textual context of the document. The dataset comprises 75k\nfully annotated pages of scientific papers, including more than 35k tables.\nData are gathered from PubMed Central, merging the information provided by\nannotations in the PubTables-1M and PubLayNet datasets. The dataset can support\nCTE and adds new classes to the original ones. The generated annotations can be\nused to develop end-to-end pipelines for various tasks, including document\nlayout analysis, table detection, structure recognition, and functional\nanalysis. We formally define CTE and evaluation metrics, showing which subtasks\ncan be tackled, describing advantages, limitations, and future works of this\ncollection of data. Annotations and code will be accessible a\nhttps://github.com/AILab-UniFI/cte-dataset.\n","authors":["Andrea Gemelli","Emanuele Vivoli","Simone Marinai"],"pdf_url":"https://arxiv.org/pdf/2302.01451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01441v1","updated":"2023-02-02T22:04:07Z","published":"2023-02-02T22:04:07Z","title":"Commonsense-Aware Prompting for Controllable Empathetic Dialogue\n  Generation","summary":"  Improving the emotional awareness of pre-trained language models is an\nemerging important problem for dialogue generation tasks. Although prior\nstudies have introduced methods to improve empathetic dialogue generation, few\nhave discussed how to incorporate commonsense knowledge into pre-trained\nlanguage models for controllable dialogue generation. In this study, we propose\na novel framework that improves empathetic dialogue generation using\npre-trained language models by 1) incorporating commonsense knowledge through\nprompt verbalization, and 2) controlling dialogue generation using a\nstrategy-driven future discriminator. We conducted experiments to reveal that\nboth the incorporation of social commonsense knowledge and enforcement of\ncontrol over generation help to improve generation performance. Finally, we\ndiscuss the implications of our study for future research.\n","authors":["Yiren Liu","Halil Kilicoglu"],"pdf_url":"https://arxiv.org/pdf/2302.01441v1.pdf","comment":"Accepted to Workshop on Knowledge Augmented Methods for Natural\n  Language Processing, in conjunction with AAAI 2023"},{"id":"http://arxiv.org/abs/2302.01398v1","updated":"2023-02-02T20:19:46Z","published":"2023-02-02T20:19:46Z","title":"The unreasonable effectiveness of few-shot learning for machine\n  translation","summary":"  We demonstrate the potential of few-shot translation systems, trained with\nunpaired language data, for both high and low-resource language pairs. We show\nthat with only 5 examples of high-quality translation data shown at inference,\na transformer decoder-only model trained solely with self-supervised learning,\nis able to match specialized supervised state-of-the-art models as well as more\ngeneral commercial translation systems. In particular, we outperform the best\nperforming system on the WMT'21 English - Chinese news translation task by only\nusing five examples of English - Chinese parallel data at inference. Moreover,\nour approach in building these models does not necessitate joint multilingual\ntraining or back-translation, is conceptually simple and shows the potential to\nextend to the multilingual setting. Furthermore, the resulting models are two\norders of magnitude smaller than state-of-the-art language models. We then\nanalyze the factors which impact the performance of few-shot translation\nsystems, and highlight that the quality of the few-shot demonstrations heavily\ndetermines the quality of the translations generated by our models. Finally, we\nshow that the few-shot paradigm also provides a way to control certain\nattributes of the translation -- we show that we are able to control for\nregional varieties and formality using only a five examples at inference,\npaving the way towards controllable machine translation systems.\n","authors":["Xavier Garcia","Yamini Bansal","Colin Cherry","George Foster","Maxim Krikun","Fangxiaoyu Feng","Melvin Johnson","Orhan Firat"],"pdf_url":"https://arxiv.org/pdf/2302.01398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01342v1","updated":"2023-02-02T11:09:37Z","published":"2023-02-02T11:09:37Z","title":"Curriculum-Guided Abstractive Summarization","summary":"  Recent Transformer-based summarization models have provided a promising\napproach to abstractive summarization. They go beyond sentence selection and\nextractive strategies to deal with more complicated tasks such as novel word\ngeneration and sentence paraphrasing. Nonetheless, these models have two\nshortcomings: (1) they often perform poorly in content selection, and (2) their\ntraining strategy is not quite efficient, which restricts model performance. In\nthis paper, we explore two orthogonal ways to compensate for these pitfalls.\nFirst, we augment the Transformer network with a sentence cross-attention\nmodule in the decoder, encouraging more abstraction of salient content. Second,\nwe include a curriculum learning approach to reweight the training samples,\nbringing about an efficient learning procedure. Our second approach to enhance\nthe training strategy of Transformers networks makes stronger gains as compared\nto the first approach. We apply our model on extreme summarization dataset of\nReddit TIFU posts. We further look into three cross-domain summarization\ndatasets (Webis-TLDR-17, CNN/DM, and XSum), measuring the efficacy of\ncurriculum learning when applied in summarization. Moreover, a human evaluation\nis conducted to show the efficacy of the proposed method in terms of\nqualitative criteria, namely, fluency, informativeness, and overall quality.\n","authors":["Sajad Sotudeh","Hanieh Deilamsalehy","Franck Dernoncourt","Nazli Goharian"],"pdf_url":"https://arxiv.org/pdf/2302.01342v1.pdf","comment":"8 pages, Long paper. arXiv admin note: text overlap with\n  arXiv:2302.00954"},{"id":"http://arxiv.org/abs/2302.01339v1","updated":"2023-02-02T01:10:26Z","published":"2023-02-02T01:10:26Z","title":"Creating a Large Language Model of a Philosopher","summary":"  Can large language models be trained to produce philosophical texts that are\ndifficult to distinguish from texts produced by human philosophers? To address\nthis question, we fine-tuned OpenAI's GPT-3 with the works of philosopher\nDaniel C. Dennett as additional training data. To explore the Dennett model, we\nasked the real Dennett ten philosophical questions and then posed the same\nquestions to the language model, collecting four responses for each question\nwithout cherry-picking. We recruited 425 participants to distinguish Dennett's\nanswer from the four machine-generated answers. Experts on Dennett's work (N =\n25) succeeded 51% of the time, above the chance rate of 20% but short of our\nhypothesized rate of 80% correct. For two of the ten questions, the language\nmodel produced at least one answer that experts selected more frequently than\nDennett's own answer. Philosophy blog readers (N = 302) performed similarly to\nthe experts, while ordinary research participants (N = 98) were near chance\ndistinguishing GPT-3's responses from those of an \"actual human philosopher\".\n","authors":["Eric Schwitzgebel","David Schwitzgebel","Anna Strasser"],"pdf_url":"https://arxiv.org/pdf/2302.01339v1.pdf","comment":"Earlier version (Nov 2, 2022) available at\n  http://www.faculty.ucr.edu/~eschwitz/SchwitzPapers/GPT-3-Dennett-221102.pdf;\n  stable URL for updated versions\n  http://faculty.ucr.edu/~eschwitz/SchwitzAbs/GPT3Dennett.htm"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.01334v1","updated":"2023-02-02T18:59:47Z","published":"2023-02-02T18:59:47Z","title":"STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth\n  Estimation","summary":"  Self-supervised depth estimation draws a lot of attention recently as it can\npromote the 3D sensing capabilities of self-driving vehicles. However, it\nintrinsically relies upon the photometric consistency assumption, which hardly\nholds during nighttime. Although various supervised nighttime image enhancement\nmethods have been proposed, their generalization performance in challenging\ndriving scenarios is not satisfactory. To this end, we propose the first method\nthat jointly learns a nighttime image enhancer and a depth estimator, without\nusing ground truth for either task. Our method tightly entangles two\nself-supervised tasks using a newly proposed uncertain pixel masking strategy.\nThis strategy originates from the observation that nighttime images not only\nsuffer from underexposed regions but also from overexposed regions. By fitting\na bridge-shaped curve to the illumination map distribution, both regions are\nsuppressed and two tasks are bridged naturally. We benchmark the method on two\nestablished datasets: nuScenes and RobotCar and demonstrate state-of-the-art\nperformance on both of them. Detailed ablations also reveal the mechanism of\nour proposal. Last but not least, to mitigate the problem of sparse ground\ntruth of existing datasets, we provide a new photo-realistically enhanced\nnighttime dataset based upon CARLA. It brings meaningful new challenges to the\ncommunity. Codes, data, and models are available at\nhttps://github.com/ucaszyp/STEPS.\n","authors":["Yupeng Zheng","Chengliang Zhong","Pengfei Li","Huan-ang Gao","Yuhang Zheng","Bu Jin","Ling Wang","Hao Zhao","Guyue Zhou","Qichao Zhang","Dongbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.01334v1.pdf","comment":"Accepted by ICRA 2023, Code: https://github.com/ucaszyp/STEPS"},{"id":"http://arxiv.org/abs/2302.01332v1","updated":"2023-02-02T18:59:23Z","published":"2023-02-02T18:59:23Z","title":"Bayesian Metric Learning for Uncertainty Quantification in Image\n  Retrieval","summary":"  We propose the first Bayesian encoder for metric learning. Rather than\nrelying on neural amortization as done in prior works, we learn a distribution\nover the network weights with the Laplace Approximation. We actualize this by\nfirst proving that the contrastive loss is a valid log-posterior. We then\npropose three methods that ensure a positive definite Hessian. Lastly, we\npresent a novel decomposition of the Generalized Gauss-Newton approximation.\nEmpirically, we show that our Laplacian Metric Learner (LAM) estimates\nwell-calibrated uncertainties, reliably detects out-of-distribution examples,\nand yields state-of-the-art predictive performance.\n","authors":["Frederik Warburg","Marco Miani","Silas Brack","Soren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2302.01332v1.pdf","comment":"Code: https://github.com/FrederikWarburg/bayesian-metric-learning"},{"id":"http://arxiv.org/abs/2302.01330v1","updated":"2023-02-02T18:59:16Z","published":"2023-02-02T18:59:16Z","title":"SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections","summary":"  In this work, we present SceneDreamer, an unconditional generative model for\nunbounded 3D scenes, which synthesizes large-scale 3D landscapes from random\nnoises. Our framework is learned from in-the-wild 2D image collections only,\nwithout any 3D annotations. At the core of SceneDreamer is a principled\nlearning paradigm comprising 1) an efficient yet expressive 3D scene\nrepresentation, 2) a generative scene parameterization, and 3) an effective\nrenderer that can leverage the knowledge from 2D images. Our framework starts\nfrom an efficient bird's-eye-view (BEV) representation generated from simplex\nnoise, which consists of a height field and a semantic field. The height field\nrepresents the surface elevation of 3D scenes, while the semantic field\nprovides detailed scene semantics. This BEV scene representation enables 1)\nrepresenting a 3D scene with quadratic complexity, 2) disentangled geometry and\nsemantics, and 3) efficient training. Furthermore, we propose a novel\ngenerative neural hash grid to parameterize the latent space given 3D positions\nand the scene semantics, which aims to encode generalizable features across\nscenes. Lastly, a neural volumetric renderer, learned from 2D image collections\nthrough adversarial training, is employed to produce photorealistic images.\nExtensive experiments demonstrate the effectiveness of SceneDreamer and\nsuperiority over state-of-the-art methods in generating vivid yet diverse\nunbounded 3D worlds.\n","authors":["Zhaoxi Chen","Guangcong Wang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2302.01330v1.pdf","comment":"Project Page https://scene-dreamer.github.io/"},{"id":"http://arxiv.org/abs/2302.01329v1","updated":"2023-02-02T18:58:58Z","published":"2023-02-02T18:58:58Z","title":"Dreamix: Video Diffusion Models are General Video Editors","summary":"  Text-driven image and video diffusion models have recently achieved\nunprecedented generation realism. While diffusion models have been successfully\napplied for image editing, very few works have done so for video editing. We\npresent the first diffusion-based method that is able to perform text-based\nmotion and appearance editing of general videos. Our approach uses a video\ndiffusion model to combine, at inference time, the low-resolution\nspatio-temporal information from the original video with new, high resolution\ninformation that it synthesized to align with the guiding text prompt. As\nobtaining high-fidelity to the original video requires retaining some of its\nhigh-resolution information, we add a preliminary stage of finetuning the model\non the original video, significantly boosting fidelity. We propose to improve\nmotion editability by a new, mixed objective that jointly finetunes with full\ntemporal attention and with temporal attention masking. We further introduce a\nnew framework for image animation. We first transform the image into a coarse\nvideo by simple image processing operations such as replication and perspective\ngeometric projections, and then use our general video editor to animate it. As\na further application, we can use our method for subject-driven video\ngeneration. Extensive qualitative and numerical experiments showcase the\nremarkable editing ability of our method and establish its superior performance\ncompared to baseline methods.\n","authors":["Eyal Molad","Eliahu Horwitz","Dani Valevski","Alex Rav Acha","Yossi Matias","Yael Pritch","Yaniv Leviathan","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2302.01329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01328v1","updated":"2023-02-02T18:58:05Z","published":"2023-02-02T18:58:05Z","title":"$IC^3$: Image Captioning by Committee Consensus","summary":"  If you ask a human to describe an image, they might do so in a thousand\ndifferent ways. Traditionally, image captioning models are trained to\napproximate the reference distribution of image captions, however, doing so\nencourages captions that are viewpoint-impoverished. Such captions often focus\non only a subset of the possible details, while ignoring potentially useful\ninformation in the scene. In this work, we introduce a simple, yet novel,\nmethod: \"Image Captioning by Committee Consensus\" ($IC^3$), designed to\ngenerate a single caption that captures high-level details from several\nviewpoints. Notably, humans rate captions produced by $IC^3$ at least as\nhelpful as baseline SOTA models more than two thirds of the time, and $IC^3$\ncaptions can improve the performance of SOTA automated recall systems by up to\n84%, indicating significant material improvements over existing SOTA approaches\nfor visual description. Our code is publicly available at\nhttps://github.com/DavidMChan/caption-by-committee\n","authors":["David M. Chan","Austin Myers","Sudheendra Vijayanarasimhan","David A. Ross","John Canny"],"pdf_url":"https://arxiv.org/pdf/2302.01328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01327v1","updated":"2023-02-02T18:56:25Z","published":"2023-02-02T18:56:25Z","title":"Dual PatchNorm","summary":"  We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms),\nbefore and after the patch embedding layer in Vision Transformers. We\ndemonstrate that Dual PatchNorm outperforms the result of exhaustive search for\nalternative LayerNorm placement strategies in the Transformer block itself. In\nour experiments, incorporating this trivial modification, often leads to\nimproved accuracy over well-tuned Vision Transformers and never hurts.\n","authors":["Manoj Kumar","Mostafa Dehghani","Neil Houlsby"],"pdf_url":"https://arxiv.org/pdf/2302.01327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01316v1","updated":"2023-02-02T18:43:16Z","published":"2023-02-02T18:43:16Z","title":"Are Diffusion Models Vulnerable to Membership Inference Attacks?","summary":"  Diffusion-based generative models have shown great potential for image\nsynthesis, but there is a lack of research on the security and privacy risks\nthey may pose. In this paper, we investigate the vulnerability of diffusion\nmodels to Membership Inference Attacks (MIAs), a common privacy concern. Our\nresults indicate that existing MIAs designed for GANs or VAE are largely\nineffective on diffusion models, either due to inapplicable scenarios (e.g.,\nrequiring the discriminator of GANs) or inappropriate assumptions (e.g., closer\ndistances between synthetic images and member images). To address this gap, we\npropose Step-wise Error Comparing Membership Inference (SecMI), a black-box MIA\nthat infers memberships by assessing the matching of forward process posterior\nestimation at each timestep. SecMI follows the common overfitting assumption in\nMIA where member samples normally have smaller estimation errors, compared with\nhold-out samples. We consider both the standard diffusion models, e.g., DDPM,\nand the text-to-image diffusion models, e.g., Stable Diffusion. Experimental\nresults demonstrate that our methods precisely infer the membership with high\nconfidence on both of the two scenarios across six different datasets\n","authors":["Jinhao Duan","Fei Kong","Shiqi Wang","Xiaoshuang Shi","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2302.01316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12058v2","updated":"2023-02-02T18:36:49Z","published":"2023-01-28T02:25:30Z","title":"Aerial Image Object Detection With Vision Transformer Detector (ViTDet)","summary":"  The past few years have seen an increased interest in aerial image object\ndetection due to its critical value to large-scale geo-scientific research like\nenvironmental studies, urban planning, and intelligence monitoring. However,\nthe task is very challenging due to the birds-eye view perspective, complex\nbackgrounds, large and various image sizes, different appearances of objects,\nand the scarcity of well-annotated datasets. Recent advances in computer vision\nhave shown promise tackling the challenge. Specifically, Vision Transformer\nDetector (ViTDet) was proposed to extract multi-scale features for object\ndetection. The empirical study shows that ViTDet's simple design achieves good\nperformance on natural scene images and can be easily embedded into any\ndetector architecture. To date, ViTDet's potential benefit to challenging\naerial image object detection has not been explored. Therefore, in our study,\n25 experiments were carried out to evaluate the effectiveness of ViTDet for\naerial image object detection on three well-known datasets: Airbus Aircraft,\nRarePlanes, and Dataset of Object DeTection in Aerial images (DOTA). Our\nresults show that ViTDet can consistently outperform its convolutional neural\nnetwork counterparts on horizontal bounding box (HBB) object detection by a\nlarge margin (up to 17% on average precision) and that it achieves the\ncompetitive performance for oriented bounding box (OBB) object detection. Our\nresults also establish a baseline for future research.\n","authors":["Liya Wang","Alex Tien"],"pdf_url":"https://arxiv.org/pdf/2301.12058v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01295v1","updated":"2023-02-02T18:22:00Z","published":"2023-02-02T18:22:00Z","title":"Ditto in the House: Building Articulation Models of Indoor Scenes\n  through Interactive Perception","summary":"  Virtualizing the physical world into virtual models has been a critical\ntechnique for robot navigation and planning in the real world. To foster\nmanipulation with articulated objects in everyday life, this work explores\nbuilding articulation models of indoor scenes through a robot's purposeful\ninteractions in these scenes. Prior work on articulation reasoning primarily\nfocuses on siloed objects of limited categories. To extend to room-scale\nenvironments, the robot has to efficiently and effectively explore a\nlarge-scale 3D space, locate articulated objects, and infer their\narticulations. We introduce an interactive perception approach to this task.\nOur approach, named Ditto in the House, discovers possible articulated objects\nthrough affordance prediction, interacts with these objects to produce\narticulated motions, and infers the articulation properties from the visual\nobservations before and after each interaction. It tightly couples affordance\nprediction and articulation inference to improve both tasks. We demonstrate the\neffectiveness of our approach in both simulation and real-world scenes. Code\nand additional results are available at\nhttps://ut-austin-rpl.github.io/HouseDitto/\n","authors":["Cheng-Chun Hsu","Zhenyu Jiang","Yuke Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.01295v1.pdf","comment":"ICRA 2023. Code and additional results are available at\n  https://ut-austin-rpl.github.io/HouseDitto/"},{"id":"http://arxiv.org/abs/2301.12246v2","updated":"2023-02-02T18:19:37Z","published":"2023-01-28T16:42:05Z","title":"A Closer Look at Few-shot Classification Again","summary":"  Few-shot classification consists of a training phase where a model is learned\non a relatively large dataset and an adaptation phase where the learned model\nis adapted to previously-unseen tasks with limited labeled samples. In this\npaper, we empirically prove that the training algorithm and the adaptation\nalgorithm can be completely disentangled, which allows algorithm analysis and\ndesign to be done individually for each phase. Our meta-analysis for each phase\nreveals several interesting insights that may help better understand key\naspects of few-shot classification and connections with other fields such as\nvisual representation learning and transfer learning. We hope the insights and\nresearch challenges revealed in this paper can inspire future work in related\ndirections.\n","authors":["Xu Luo","Hao Wu","Ji Zhang","Lianli Gao","Jing Xu","Jingkuan Song"],"pdf_url":"https://arxiv.org/pdf/2301.12246v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01287v1","updated":"2023-02-02T18:19:01Z","published":"2023-02-02T18:19:01Z","title":"Multi-scale Feature Alignment for Continual Learning of Unlabeled\n  Domains","summary":"  Methods for unsupervised domain adaptation (UDA) help to improve the\nperformance of deep neural networks on unseen domains without any labeled data.\nEspecially in medical disciplines such as histopathology, this is crucial since\nlarge datasets with detailed annotations are scarce. While the majority of\nexisting UDA methods focus on the adaptation from a labeled source to a single\nunlabeled target domain, many real-world applications with a long life cycle\ninvolve more than one target domain. Thus, the ability to sequentially adapt to\nmultiple target domains becomes essential. In settings where the data from\npreviously seen domains cannot be stored, e.g., due to data protection\nregulations, the above becomes a challenging continual learning problem. To\nthis end, we propose to use generative feature-driven image replay in\nconjunction with a dual-purpose discriminator that not only enables the\ngeneration of images with realistic features for replay, but also promotes\nfeature alignment during domain adaptation. We evaluate our approach\nextensively on a sequence of three histopathological datasets for tissue-type\nclassification, achieving state-of-the-art results. We present detailed\nablation experiments studying our proposed method components and demonstrate a\npossible use-case of our continual UDA method for an unsupervised patch-based\nsegmentation task given high-resolution tissue images.\n","authors":["Kevin Thandiackal","Luigi Piccinelli","Pushpak Pati","Orcun Goksel"],"pdf_url":"https://arxiv.org/pdf/2302.01287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01243v1","updated":"2023-02-02T17:25:29Z","published":"2023-02-02T17:25:29Z","title":"Human not in the loop: objective sample difficulty measures for\n  Curriculum Learning","summary":"  Curriculum learning is a learning method that trains models in a meaningful\norder from easier to harder samples. A key here is to devise automatic and\nobjective difficulty measures of samples. In the medical domain, previous work\napplied domain knowledge from human experts to qualitatively assess\nclassification difficulty of medical images to guide curriculum learning, which\nrequires extra annotation efforts, relies on subjective human experience, and\nmay introduce bias. In this work, we propose a new automated curriculum\nlearning technique using the variance of gradients (VoG) to compute an\nobjective difficulty measure of samples and evaluated its effects on elbow\nfracture classification from X-ray images. Specifically, we used VoG as a\nmetric to rank each sample in terms of the classification difficulty, where\nhigh VoG scores indicate more difficult cases for classification, to guide the\ncurriculum training process We compared the proposed technique to a baseline\n(without curriculum learning), a previous method that used human annotations on\nclassification difficulty, and anti-curriculum learning. Our experiment results\nshowed comparable and higher performance for the binary and multi-class bone\nfracture classification tasks.\n","authors":["Zhengbo Zhou","Jun Luo","Gene Kitamura","Shandong Wu"],"pdf_url":"https://arxiv.org/pdf/2302.01243v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2302.01226v1","updated":"2023-02-02T17:06:50Z","published":"2023-02-02T17:06:50Z","title":"Factor Fields: A Unified Framework for Neural Fields and Beyond","summary":"  We present Factor Fields, a novel framework for modeling and representing\nsignals. Factor Fields decomposes a signal into a product of factors, each of\nwhich is represented by a neural or regular field representation operating on a\ncoordinate transformed input signal. We show that this decomposition yields a\nunified framework that generalizes several recent signal representations\nincluding NeRF, PlenOxels, EG3D, Instant-NGP, and TensoRF. Moreover, the\nframework allows for the creation of powerful new signal representations, such\nas the Coefficient-Basis Factorization (CoBaFa) which we propose in this paper.\nAs evidenced by our experiments, CoBaFa leads to improvements over previous\nfast reconstruction methods in terms of the three critical goals in neural\nsignal representation: approximation quality, compactness and efficiency.\nExperimentally, we demonstrate that our representation achieves better image\napproximation quality on 2D image regression tasks, higher geometric quality\nwhen reconstructing 3D signed distance fields and higher compactness for\nradiance field reconstruction tasks compared to previous fast reconstruction\nmethods. Besides, our CoBaFa representation enables generalization by sharing\nthe basis across signals during training, enabling generalization tasks such as\nimage regression with sparse observations and few-shot radiance field\nreconstruction.\n","authors":["Anpei Chen","Zexiang Xu","Xinyue Wei","Siyu Tang","Hao Su","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2302.01226v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2209.12358v2","updated":"2023-02-02T16:31:39Z","published":"2022-09-26T01:08:36Z","title":"UDepth: Fast Monocular Depth Estimation for Visually-guided Underwater\n  Robots","summary":"  In this paper, we present a fast monocular depth estimation method for\nenabling 3D perception capabilities of low-cost underwater robots. We formulate\na novel end-to-end deep visual learning pipeline named UDepth, which\nincorporates domain knowledge of image formation characteristics of natural\nunderwater scenes. First, we adapt a new input space from raw RGB image space\nby exploiting underwater light attenuation prior, and then devise a\nleast-squared formulation for coarse pixel-wise depth prediction. Subsequently,\nwe extend this into a domain projection loss that guides the end-to-end\nlearning of UDepth on over 9K RGB-D training samples. UDepth is designed with a\ncomputationally light MobileNetV2 backbone and a Transformer-based optimizer\nfor ensuring fast inference rates on embedded systems. By domain-aware design\nchoices and through comprehensive experimental analyses, we demonstrate that it\nis possible to achieve state-of-the-art depth estimation performance while\nensuring a small computational footprint. Specifically, with 70%-80% less\nnetwork parameters than existing benchmarks, UDepth achieves comparable and\noften better depth estimation performance. While the full model offers over 66\nFPS (13 FPS) inference rates on a single GPU (CPU core), our domain projection\nfor coarse depth prediction runs at 51.5 FPS rates on single-board NVIDIA\nJetson TX2s. The inference pipelines are available at\nhttps://github.com/uf-robopi/UDepth.\n","authors":["Boxiao Yu","Jiayi Wu","Md Jahidul Islam"],"pdf_url":"https://arxiv.org/pdf/2209.12358v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2206.08657v4","updated":"2023-02-02T16:22:23Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v4.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2302.01171v1","updated":"2023-02-02T15:49:03Z","published":"2023-02-02T15:49:03Z","title":"Boosting Low-Data Instance Segmentation by Unsupervised Pre-training\n  with Saliency Prompt","summary":"  Recently, inspired by DETR variants, query-based end-to-end instance\nsegmentation (QEIS) methods have outperformed CNN-based models on large-scale\ndatasets. Yet they would lose efficacy when only a small amount of training\ndata is available since it's hard for the crucial queries/kernels to learn\nlocalization and shape priors. To this end, this work offers a novel\nunsupervised pre-training solution for low-data regimes. Inspired by the recent\nsuccess of the Prompting technique, we introduce a new pre-training method that\nboosts QEIS models by giving Saliency Prompt for queries/kernels. Our method\ncontains three parts: 1) Saliency Masks Proposal is responsible for generating\npseudo masks from unlabeled images based on the saliency mechanism. 2)\nPrompt-Kernel Matching transfers pseudo masks into prompts and injects the\ncorresponding localization and shape priors to the best-matched kernels. 3)\nKernel Supervision is applied to supply supervision at the kernel level for\nrobust learning. From a practical perspective, our pre-training method helps\nQEIS models achieve a similar convergence speed and comparable performance with\nCNN-based models in low-data regimes. Experimental results show that our method\nsignificantly boosts several QEIS models on three datasets. Code will be made\navailable.\n","authors":["Hao Li","Dingwen Zhang","Nian Liu","Lechao Cheng","Yalun Dai","Chao Zhang","Xinggang Wang","Junwei Han"],"pdf_url":"https://arxiv.org/pdf/2302.01171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01162v1","updated":"2023-02-02T15:37:46Z","published":"2023-02-02T15:37:46Z","title":"Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using\n  Pixel-aligned Reconstruction Priors","summary":"  Fast generation of high-quality 3D digital humans is important to a vast\nnumber of applications ranging from entertainment to professional concerns.\nRecent advances in differentiable rendering have enabled the training of 3D\ngenerative models without requiring 3D ground truths. However, the quality of\nthe generated 3D humans still has much room to improve in terms of both\nfidelity and diversity. In this paper, we present Get3DHuman, a novel 3D human\nframework that can significantly boost the realism and diversity of the\ngenerated outcomes by only using a limited budget of 3D ground-truth data. Our\nkey observation is that the 3D generator can profit from human-related priors\nlearned through 2D human generators and 3D reconstructors. Specifically, we\nbridge the latent space of Get3DHuman with that of StyleGAN-Human via a\nspecially-designed prior network, where the input latent code is mapped to the\nshape and texture feature volumes spanned by the pixel-aligned 3D\nreconstructor. The outcomes of the prior network are then leveraged as the\nsupervisory signals for the main generator network. To ensure effective\ntraining, we further propose three tailored losses applied to the generated\nfeature volumes and the intermediate feature maps. Extensive experiments\ndemonstrate that Get3DHuman greatly outperforms the other state-of-the-art\napproaches and can support a wide range of applications including shape\ninterpolation, shape re-texturing, and single-view reconstruction through\nlatent inversion.\n","authors":["Zhangyang Xiong","Di Kang","Derong Jin","Weikai Chen","Linchao Bao","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2302.01162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07399v2","updated":"2023-02-02T15:23:33Z","published":"2022-09-15T16:00:04Z","title":"A Light Recipe to Train Robust Vision Transformers","summary":"  In this paper, we ask whether Vision Transformers (ViTs) can serve as an\nunderlying architecture for improving the adversarial robustness of machine\nlearning models against evasion attacks. While earlier works have focused on\nimproving Convolutional Neural Networks, we show that also ViTs are highly\nsuitable for adversarial training to achieve competitive performance. We\nachieve this objective using a custom adversarial training recipe, discovered\nusing rigorous ablation studies on a subset of the ImageNet dataset. The\ncanonical training recipe for ViTs recommends strong data augmentation, in part\nto compensate for the lack of vision inductive bias of attention modules, when\ncompared to convolutions. We show that this recipe achieves suboptimal\nperformance when used for adversarial training. In contrast, we find that\nomitting all heavy data augmentation, and adding some additional bag-of-tricks\n($\\varepsilon$-warmup and larger weight decay), significantly boosts the\nperformance of robust ViTs. We show that our recipe generalizes to different\nclasses of ViT architectures and large-scale models on full ImageNet-1k.\nAdditionally, investigating the reasons for the robustness of our models, we\nshow that it is easier to generate strong attacks during training when using\nour recipe and that this leads to better robustness at test time. Finally, we\nfurther study one consequence of adversarial training by proposing a way to\nquantify the semantic nature of adversarial perturbations and highlight its\ncorrelation with the robustness of the model. Overall, we recommend that the\ncommunity should avoid translating the canonical training recipes in ViTs to\nrobust training and rethink common training choices in the context of\nadversarial training.\n","authors":["Edoardo Debenedetti","Vikash Sehwag","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2209.07399v2.pdf","comment":"Camera-ready version for SaTML 2023, code available at\n  https://github.com/dedeswim/vits-robustness-torch"},{"id":"http://arxiv.org/abs/2202.07993v3","updated":"2023-02-02T15:14:47Z","published":"2022-02-16T11:13:37Z","title":"Planckian Jitter: countering the color-crippling effects of color jitter\n  on self-supervised training","summary":"  Several recent works on self-supervised learning are trained by mapping\ndifferent augmentations of the same image to the same feature representation.\nThe data augmentations used are of crucial importance to the quality of learned\nfeature representations. In this paper, we analyze how the color jitter\ntraditionally used in data augmentation negatively impacts the quality of the\ncolor features in learned feature representations. To address this problem, we\npropose a more realistic, physics-based color data augmentation - which we call\nPlanckian Jitter - that creates realistic variations in chromaticity and\nproduces a model robust to illumination changes that can be commonly observed\nin real life, while maintaining the ability to discriminate image content based\non color information. Experiments confirm that such a representation is\ncomplementary to the representations learned with the currently-used color\njitter augmentation and that a simple concatenation leads to significant\nperformance gains on a wide range of downstream datasets. In addition, we\npresent a color sensitivity analysis that documents the impact of different\ntraining methods on model neurons and shows that the performance of the learned\nfeatures is robust with respect to illuminant variations.\n","authors":["Simone Zini","Alex Gomez-Villa","Marco Buzzelli","Bartłomiej Twardowski","Andrew D. Bagdanov","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2202.07993v3.pdf","comment":"Accepted at Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2302.01144v1","updated":"2023-02-02T15:00:03Z","published":"2023-02-02T15:00:03Z","title":"UW-CVGAN: UnderWater Image Enhancement with Capsules Vectors\n  Quantization","summary":"  The degradation in the underwater images is due to wavelength-dependent light\nattenuation, scattering, and to the diversity of the water types in which they\nare captured. Deep neural networks take a step in this field, providing\nautonomous models able to achieve the enhancement of underwater images. We\nintroduce Underwater Capsules Vectors GAN UWCVGAN based on the discrete\nfeatures quantization paradigm from VQGAN for this task. The proposed UWCVGAN\ncombines an encoding network, which compresses the image into its latent\nrepresentation, with a decoding network, able to reconstruct the enhancement of\nthe image from the only latent representation. In contrast with VQGAN, UWCVGAN\nachieves feature quantization by exploiting the clusterization ability of\ncapsule layer, making the model completely trainable and easier to manage. The\nmodel obtains enhanced underwater images with high quality and fine details.\nMoreover, the trained encoder is independent of the decoder giving the\npossibility to be embedded onto the collector as compressing algorithm to\nreduce the memory space required for the images, of factor $3\\times$.\n\\myUWCVGAN{ }is validated with quantitative and qualitative analysis on\nbenchmark datasets, and we present metrics results compared with the state of\nthe art.\n","authors":["Rita Pucci","Christian Micheloni","Niki Martinel"],"pdf_url":"https://arxiv.org/pdf/2302.01144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01133v1","updated":"2023-02-02T14:47:19Z","published":"2023-02-02T14:47:19Z","title":"SceneScape: Text-Driven Consistent Scene Generation","summary":"  We propose a method for text-driven perpetual view generation -- synthesizing\nlong videos of arbitrary scenes solely from an input text describing the scene\nand camera poses. We introduce a novel framework that generates such videos in\nan online fashion by combining the generative power of a pre-trained\ntext-to-image model with the geometric priors learned by a pre-trained\nmonocular depth prediction model. To achieve 3D consistency, i.e., generating\nvideos that depict geometrically-plausible scenes, we deploy an online\ntest-time training to encourage the predicted depth map of the current frame to\nbe geometrically consistent with the synthesized scene; the depth maps are used\nto construct a unified mesh representation of the scene, which is updated\nthroughout the generation and is used for rendering. In contrast to previous\nworks, which are applicable only for limited domains (e.g., landscapes), our\nframework generates diverse scenes, such as walkthroughs in spaceships, caves,\nor ice castles. Project page: https://scenescape.github.io/\n","authors":["Rafail Fridman","Amit Abecasis","Yoni Kasten","Tali Dekel"],"pdf_url":"https://arxiv.org/pdf/2302.01133v1.pdf","comment":"Project page: https://scenescape.github.io/"},{"id":"http://arxiv.org/abs/2302.01110v1","updated":"2023-02-02T14:08:49Z","published":"2023-02-02T14:08:49Z","title":"A Simple Baseline for Direct 2D Multi-Person Head Pose Estimation with\n  Full-range Angles","summary":"  Existing head pose estimation (HPE) mainly focuses on single person with\npre-detected frontal heads, which limits their applications in real complex\nscenarios with multi-persons. We argue that these single HPE methods are\nfragile and inefficient for Multi-Person Head Pose Estimation (MPHPE) since\nthey rely on the separately trained face detector that cannot generalize well\nto full viewpoints, especially for heads with invisible face areas. In this\npaper, we focus on the full-range MPHPE problem, and propose a direct\nend-to-end simple baseline named DirectMHP. Due to the lack of datasets\napplicable to the full-range MPHPE, we firstly construct two benchmarks by\nextracting ground-truth labels for head detection and head orientation from\npublic datasets AGORA and CMU Panoptic. They are rather challenging for having\nmany truncated, occluded, tiny and unevenly illuminated human heads. Then, we\ndesign a novel end-to-end trainable one-stage network architecture by joint\nregressing locations and orientations of multi-head to address the MPHPE\nproblem. Specifically, we regard pose as an auxiliary attribute of the head,\nand append it after the traditional object prediction. Arbitrary pose\nrepresentation such as Euler angles is acceptable by this flexible design.\nThen, we jointly optimize these two tasks by sharing features and utilizing\nappropriate multiple losses. In this way, our method can implicitly benefit\nfrom more surroundings to improve HPE accuracy while maintaining head detection\nperformance. We present comprehensive comparisons with state-of-the-art single\nHPE methods on public benchmarks, as well as superior baseline results on our\nconstructed MPHPE datasets. Datasets and code are released in\nhttps://github.com/hnuzhy/DirectMHP.\n","authors":["Huayi Zhou","Fei Jiang","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2302.01110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01109v1","updated":"2023-02-02T14:06:46Z","published":"2023-02-02T14:06:46Z","title":"GraphReg: Dynamical Point Cloud Registration with Geometry-aware Graph\n  Signal Processing","summary":"  This study presents a high-accuracy, efficient, and physically induced method\nfor 3D point cloud registration, which is the core of many important 3D vision\nproblems. In contrast to existing physics-based methods that merely consider\nspatial point information and ignore surface geometry, we explore geometry\naware rigid-body dynamics to regulate the particle (point) motion, which\nresults in more precise and robust registration. Our proposed method consists\nof four major modules. First, we leverage the graph signal processing (GSP)\nframework to define a new signature, (i.e., point response intensity for each\npoint), by which we succeed in describing the local surface variation,\nresampling keypoints, and distinguishing different particles. Then, to address\nthe shortcomings of current physics-based approaches that are sensitive to\noutliers, we accommodate the defined point response intensity to median\nabsolute deviation (MAD) in robust statistics and adopt the X84 principle for\nadaptive outlier depression, ensuring a robust and stable registration.\nSubsequently, we propose a novel geometric invariant under rigid\ntransformations to incorporate higher-order features of point clouds, which is\nfurther embedded for force modeling to guide the correspondence between\npairwise scans credibly. Finally, we introduce an adaptive simulated annealing\n(ASA) method to search for the global optimum and substantially accelerate the\nregistration process. We perform comprehensive experiments to evaluate the\nproposed method on various datasets captured from range scanners to LiDAR.\nResults demonstrate that our proposed method outperforms representative\nstate-of-the-art approaches in terms of accuracy and is more suitable for\nregistering large-scale point clouds. Furthermore, it is considerably faster\nand more robust than most competitors.\n","authors":["Zhao Mingyang","Ma Lei","Jia Xiaohong","Yan Dong-Ming","Huang Tiejun"],"pdf_url":"https://arxiv.org/pdf/2302.01109v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01107v1","updated":"2023-02-02T13:58:18Z","published":"2023-02-02T13:58:18Z","title":"A Survey on Efficient Training of Transformers","summary":"  Recent advances in Transformers have come with a huge requirement on\ncomputing resources, highlighting the importance of developing efficient\ntraining techniques to make Transformer training faster, at lower cost, and to\nhigher accuracy by the efficient use of computation and memory resources. This\nsurvey provides the first systematic overview of the efficient training of\nTransformers, covering the recent progress in acceleration arithmetic and\nhardware, with a focus on the former. We analyze and compare methods that save\ncomputation and memory costs for intermediate tensors during training, together\nwith techniques on hardware/algorithm co-design. We finally discuss challenges\nand promising areas for future research.\n","authors":["Bohan Zhuang","Jing Liu","Zizheng Pan","Haoyu He","Yuetian Weng","Chunhua Shen"],"pdf_url":"https://arxiv.org/pdf/2302.01107v1.pdf","comment":"A brief review"},{"id":"http://arxiv.org/abs/2302.01104v1","updated":"2023-02-02T13:52:54Z","published":"2023-02-02T13:52:54Z","title":"LesionAid: Vision Transformers-based Skin Lesion Generation and\n  Classification","summary":"  Skin cancer is one of the most prevalent forms of human cancer. It is\nrecognized mainly visually, beginning with clinical screening and continuing\nwith the dermoscopic examination, histological assessment, and specimen\ncollection. Deep convolutional neural networks (CNNs) perform highly segregated\nand potentially universal tasks against a classified finegrained object. This\nresearch proposes a novel multi-class prediction framework that classifies skin\nlesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative\nAdversarial Networks) are utilized to tackle the class imbalance. The framework\nconsists of four main phases: ViTGANs, Image processing, and explainable AI.\nPhase 1 consists of generating synthetic images to balance all the classes in\nthe dataset. Phase 2 consists of applying different data augmentation\ntechniques and morphological operations to increase the size of the data.\nPhases 3 & 4 involve developing a ViT model for edge computing systems that can\nidentify patterns and categorize skin lesions from the user's skin visible in\nthe image. In phase 3, after classifying the lesions into the desired class\nwith ViT, we will use explainable AI (XAI) that leads to more explainable\nresults (using activation maps, etc.) while ensuring high predictive accuracy.\nReal-time images of skin diseases can capture by a doctor or a patient using\nthe camera of a mobile application to perform an early examination and\ndetermine the cause of the skin lesion. The whole framework is compared with\nthe existing frameworks for skin lesion detection.\n","authors":["Ghanta Sai Krishna","Kundrapu Supriya","Mallikharjuna Rao K","Meetiksha Sorgile"],"pdf_url":"https://arxiv.org/pdf/2302.01104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01089v1","updated":"2023-02-02T13:22:18Z","published":"2023-02-02T13:22:18Z","title":"Curriculum Learning for ab initio Deep Learned Refractive Optics","summary":"  Deep lens optimization has recently emerged as a new paradigm for designing\ncomputational imaging systems, however it has been limited to either simple\noptical systems consisting of a single DOE or metalens, or the fine-tuning of\ncompound lenses from good initial designs. Here we present a deep lens design\nmethod based on curriculum learning, which is able to learn optical designs of\ncompound lenses ab initio from randomly initialized surfaces, therefore\novercoming the need for a good initial design. We demonstrate this approach\nwith the fully-automatic design of an extended depth-of-field computational\ncamera in a cellphone-style form factor, highly aspherical surfaces, and a\nshort back focal length.\n","authors":["Xinge Yang","Qiang Fu","Wolfgang Heidrich"],"pdf_url":"https://arxiv.org/pdf/2302.01089v1.pdf","comment":"Automatically design computational lenses from scratch with\n  differentiable ray tracing"},{"id":"http://arxiv.org/abs/2302.00675v1","updated":"2023-02-02T13:21:03Z","published":"2023-02-02T13:21:03Z","title":"NDJIR: Neural Direct and Joint Inverse Rendering for Geometry, Lights,\n  and Materials of Real Object","summary":"  The goal of inverse rendering is to decompose geometry, lights, and materials\ngiven pose multi-view images. To achieve this goal, we propose neural direct\nand joint inverse rendering, NDJIR. Different from prior works which relies on\nsome approximations of the rendering equation, NDJIR directly addresses the\nintegrals in the rendering equation and jointly decomposes geometry: signed\ndistance function, lights: environment and implicit lights, materials: base\ncolor, roughness, specular reflectance using the powerful and flexible volume\nrendering framework, voxel grid feature, and Bayesian prior. Our method\ndirectly uses the physically-based rendering, so we can seamlessly export an\nextracted mesh with materials to DCC tools and show material conversion\nexamples. We perform intensive experiments to show that our proposed method can\ndecompose semantically well for real object in photogrammetric setting and what\nfactors contribute towards accurate inverse rendering.\n","authors":["Kazuki Yoshiyama","Takuya Narihira"],"pdf_url":"https://arxiv.org/pdf/2302.00675v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2301.10047v2","updated":"2023-02-02T12:56:21Z","published":"2023-01-24T14:44:03Z","title":"DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion\n  Model","summary":"  Speech-driven gesture synthesis is a field of growing interest in virtual\nhuman creation. However, a critical challenge is the inherent intricate\none-to-many mapping between speech and gestures. Previous studies have explored\nand achieved significant progress with generative models. Notwithstanding, most\nsynthetic gestures are still vastly less natural. This paper presents\nDiffMotion, a novel speech-driven gesture synthesis architecture based on\ndiffusion models. The model comprises an autoregressive temporal encoder and a\ndenoising diffusion probability Module. The encoder extracts the temporal\ncontext of the speech input and historical gestures. The diffusion module\nlearns a parameterized Markov chain to gradually convert a simple distribution\ninto a complex distribution and generates the gestures according to the\naccompanied speech. Compared with baselines, objective and subjective\nevaluations confirm that our approach can produce natural and diverse\ngesticulation and demonstrate the benefits of diffusion-based models on\nspeech-driven gesture synthesis.\n","authors":["Fan Zhang","Naye Ji","Fuxing Gao","Yongping Li"],"pdf_url":"https://arxiv.org/pdf/2301.10047v2.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.01060v1","updated":"2023-02-02T12:45:30Z","published":"2023-02-02T12:45:30Z","title":"Physics Constrained Motion Prediction with Uncertainty Quantification","summary":"  Predicting the motion of dynamic agents is a critical task for guaranteeing\nthe safety of autonomous systems. A particular challenge is that motion\nprediction algorithms should obey dynamics constraints and quantify prediction\nuncertainty as a measure of confidence. We present a physics-constrained\napproach for motion prediction which uses a surrogate dynamical model to ensure\nthat predicted trajectories are dynamically feasible. We propose a two-step\nintegration consisting of intent and trajectory prediction subject to dynamics\nconstraints. We also construct prediction regions that quantify uncertainty and\nare tailored for autonomous driving by using conformal prediction, a popular\nstatistical tool. Physics Constrained Motion Prediction achieves a 41% better\nADE, 56% better FDE, and 19% better IoU over a baseline in experiments using an\nautonomous racing dataset.\n","authors":["Renukanandan Tumu","Lars Lindemann","Truong Nghiem","Rahul Mangharam"],"pdf_url":"https://arxiv.org/pdf/2302.01060v1.pdf","comment":"Submitted to IV 2023"},{"id":"http://arxiv.org/abs/2302.01058v1","updated":"2023-02-02T12:43:29Z","published":"2023-02-02T12:43:29Z","title":"IKOL: Inverse kinematics optimization layer for 3D human pose and shape\n  estimation via Gauss-Newton differentiation","summary":"  This paper presents an inverse kinematic optimization layer (IKOL) for 3D\nhuman pose and shape estimation that leverages the strength of both\noptimization- and regression-based methods within an end-to-end framework. IKOL\ninvolves a nonconvex optimization that establishes an implicit mapping from an\nimage's 3D keypoints and body shapes to the relative body-part rotations. The\n3D keypoints and the body shapes are the inputs and the relative body-part\nrotations are the solutions. However, this procedure is implicit and hard to\nmake differentiable. So, to overcome this issue, we designed a Gauss-Newton\ndifferentiation (GN-Diff) procedure to differentiate IKOL. GN-Diff iteratively\nlinearizes the nonconvex objective function to obtain Gauss-Newton directions\nwith closed form solutions. Then, an automatic differentiation procedure is\ndirectly applied to generate a Jacobian matrix for end-to-end training.\nNotably, the GN-Diff procedure works fast because it does not rely on a\ntime-consuming implicit differentiation procedure. The twist rotation and shape\nparameters are learned from the neural networks and, as a result, IKOL has a\nmuch lower computational overhead than most existing optimization-based\nmethods. Additionally, compared to existing regression-based methods, IKOL\nprovides a more accurate mesh-image correspondence. This is because it\niteratively reduces the distance between the keypoints and also enhances the\nreliability of the pose structures. Extensive experiments demonstrate the\nsuperiority of our proposed framework over a wide range of 3D human pose and\nshape estimation methods.\n","authors":["Juze Zhang","Ye Shi","Ye Shi","Lan Xu","Jingyi Yu","Jingya Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01058v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2206.00471v2","updated":"2023-02-02T12:40:25Z","published":"2022-06-01T13:03:58Z","title":"Augmentation Component Analysis: Modeling Similarity via the\n  Augmentation Overlaps","summary":"  Self-supervised learning aims to learn a embedding space where semantically\nsimilar samples are close. Contrastive learning methods pull views of samples\ntogether and push different samples away, which utilizes semantic invariance of\naugmentation but ignores the relationship between samples. To better exploit\nthe power of augmentation, we observe that semantically similar samples are\nmore likely to have similar augmented views. Therefore, we can take the\naugmented views as a special description of a sample. In this paper, we model\nsuch a description as the augmentation distribution and we call it augmentation\nfeature. The similarity in augmentation feature reflects how much the views of\ntwo samples overlap and is related to their semantical similarity. Without\ncomputational burdens to explicitly estimate values of the augmentation\nfeature, we propose Augmentation Component Analysis (ACA) with a\ncontrastive-like loss to learn principal components and an on-the-fly\nprojection loss to embed data. ACA equals an efficient dimension reduction by\nPCA and extracts low-dimensional embeddings, theoretically preserving the\nsimilarity of augmentation distribution between samples. Empirical results show\nour method can achieve competitive results against various traditional\ncontrastive learning methods on different benchmarks.\n","authors":["Lu Han","Han-Jia Ye","De-Chuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2206.00471v2.pdf","comment":"Accept to ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01056v1","updated":"2023-02-02T12:37:24Z","published":"2023-02-02T12:37:24Z","title":"Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial\n  Defense","summary":"  Masked Image Modeling (MIM) has been a prevailing framework for\nself-supervised visual representation learning. Within the\npretraining-finetuning paradigm, the MIM framework trains an encoder by\nreconstructing masked image patches with the help of a decoder which would be\nabandoned when the encoder is used for finetuning. Despite its state-of-the-art\nperformance on clean images, MIM models are vulnerable to adversarial attacks,\nlimiting its real-world application, and few studies have focused on this\nissue. In this paper, we have discovered that noisy image modeling (NIM), a\nvariant of MIM that uses denoising as the pre-text task, provides not only good\npretrained visual features, but also effective adversarial defense for\ndownstream models. To achieve a better accuracy-robustness trade-off, we\nfurther propose to sample the hyperparameter that controls the reconstruction\ndifficulty from random distributions instead of setting it globally, and\nfine-tune downstream networks with denoised images. Experimental results\ndemonstrate that our pre-trained denoising autoencoders are effective against\ndifferent white-box, gray-box, and black-box attacks without being trained with\nadversarial images, while not harming the clean accuracy of fine-tuned models.\nSource code and models will be made available.\n","authors":["Zunzhi You","Daochang Liu","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2302.01056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01049v1","updated":"2023-02-02T12:24:14Z","published":"2023-02-02T12:24:14Z","title":"Paced-Curriculum Distillation with Prediction and Label Uncertainty for\n  Image Segmentation","summary":"  Purpose: In curriculum learning, the idea is to train on easier samples first\nand gradually increase the difficulty, while in self-paced learning, a pacing\nfunction defines the speed to adapt the training progress. While both methods\nheavily rely on the ability to score the difficulty of data samples, an optimal\nscoring function is still under exploration. Methodology: Distillation is a\nknowledge transfer approach where a teacher network guides a student network by\nfeeding a sequence of random samples. We argue that guiding student networks\nwith an efficient curriculum strategy can improve model generalization and\nrobustness. For this purpose, we design an uncertainty-based paced curriculum\nlearning in self distillation for medical image segmentation. We fuse the\nprediction uncertainty and annotation boundary uncertainty to develop a novel\npaced-curriculum distillation (PCD). We utilize the teacher model to obtain\nprediction uncertainty and spatially varying label smoothing with Gaussian\nkernel to generate segmentation boundary uncertainty from the annotation. We\nalso investigate the robustness of our method by applying various types and\nseverity of image perturbation and corruption. Results: The proposed technique\nis validated on two medical datasets of breast ultrasound image segmentation\nand robotassisted surgical scene segmentation and achieved significantly better\nperformance in terms of segmentation and robustness. Conclusion: P-CD improves\nthe performance and obtains better generalization and robustness over the\ndataset shift. While curriculum learning requires extensive tuning of\nhyper-parameters for pacing function, the level of performance improvement\nsuppresses this limitation.\n","authors":["Mobarakol Islam","Lalithkumar Seenivasan","S. P. Sharan","V. K. Viekash","Bhavesh Gupta","Ben Glocker","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2302.01049v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2302.01047v1","updated":"2023-02-02T12:21:10Z","published":"2023-02-02T12:21:10Z","title":"Real-Time Evaluation in Online Continual Learning: A New Paradigm","summary":"  Current evaluations of Continual Learning (CL) methods typically assume that\nthere is no constraint on training time and computation. This is an unrealistic\nassumption for any real-world setting, which motivates us to propose: a\npractical real-time evaluation of continual learning, in which the stream does\nnot wait for the model to complete training before revealing the next data for\npredictions. To do this, we evaluate current CL methods with respect to their\ncomputational costs. We hypothesize that under this new evaluation paradigm,\ncomputationally demanding CL approaches may perform poorly on streams with a\nvarying distribution. We conduct extensive experiments on CLOC, a large-scale\ndataset containing 39 million time-stamped images with geolocation labels. We\nshow that a simple baseline outperforms state-of-the-art CL methods under this\nevaluation, questioning the applicability of existing methods in realistic\nsettings. In addition, we explore various CL components commonly used in the\nliterature, including memory sampling strategies and regularization approaches.\nWe find that all considered methods fail to be competitive against our simple\nbaseline. This surprisingly suggests that the majority of existing CL\nliterature is tailored to a specific class of streams that is not practical. We\nhope that the evaluation we provide will be the first step towards a paradigm\nshift to consider the computational cost in the development of online continual\nlearning methods.\n","authors":["Yasir Ghunaim","Adel Bibi","Kumail Alhamoud","Motasem Alfarra","Hasan Abed Al Kader Hammoud","Ameya Prabhu","Philip H. S. Torr","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2302.01047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01034v1","updated":"2023-02-02T11:57:41Z","published":"2023-02-02T11:57:41Z","title":"An Efficient Convex Hull-Based Vehicle Pose Estimation Method for 3D\n  LiDAR","summary":"  Vehicle pose estimation is essential in the perception technology of\nautonomous driving. However, due to the different density distributions of the\nLiDAR point cloud, it is challenging to achieve accurate direction extraction\nbased on 3D LiDAR by using the existing pose estimation methods. In this paper,\nwe proposed a novel convex hull-based vehicle pose estimation method. The\nextracted 3D cluster is reduced to the convex hull, reducing the computation\nburden. Then a novel criterion based on the minimum occlusion area is developed\nfor the search-based algorithm, which can achieve accurate pose estimation. The\nproposed algorithm is validated on the KITTI dataset and a manually labeled\ndataset acquired at an industrial park. The results show that our proposed\nmethod can achieve better accuracy than the three mainstream algorithms while\nmaintaining real-time speed.\n","authors":["Ningning Ding"],"pdf_url":"https://arxiv.org/pdf/2302.01034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12232v3","updated":"2023-02-02T11:47:13Z","published":"2022-08-25T17:31:15Z","title":"A survey, review, and future trends of skin lesion segmentation and\n  classification","summary":"  The Computer-aided Diagnosis or Detection (CAD) approach for skin lesion\nanalysis is an emerging field of research that has the potential to alleviate\nthe burden and cost of skin cancer screening. Researchers have recently\nindicated increasing interest in developing such CAD systems, with the\nintention of providing a user-friendly tool to dermatologists to reduce the\nchallenges encountered or associated with manual inspection. This article aims\nto provide a comprehensive literature survey and review of a total of 594\npublications (356 for skin lesion segmentation and 238 for skin lesion\nclassification) published between 2011 and 2022. These articles are analyzed\nand summarized in a number of different ways to contribute vital information\nregarding the methods for the development of CAD systems. These ways include\nrelevant and essential definitions and theories, input data (dataset\nutilization, preprocessing, augmentations, and fixing imbalance problems),\nmethod configuration (techniques, architectures, module frameworks, and\nlosses), training tactics (hyperparameter settings), and evaluation criteria.\nWe intend to investigate a variety of performance-enhancing approaches,\nincluding ensemble and post-processing. We also discuss these dimensions to\nreveal their current trends based on utilization frequencies. In addition, we\nhighlight the primary difficulties associated with evaluating skin lesion\nsegmentation and classification systems using minimal datasets, as well as the\npotential solutions to these difficulties. Findings, recommendations, and\ntrends are disclosed to inform future research on developing an automated and\nrobust CAD system for skin lesion analysis.\n","authors":["Md. Kamrul Hasan","Md. Asif Ahamad","Choon Hwai Yap","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2208.12232v3.pdf","comment":"This manuscript has been accepted to be published in Computers in\n  Biology and Medicine and has a total of 106 pages (single column and double\n  spacing), 13 figures, and 11 tables"},{"id":"http://arxiv.org/abs/2302.01027v1","updated":"2023-02-02T11:42:26Z","published":"2023-02-02T11:42:26Z","title":"FCB-SwinV2 Transformer for Polyp Segmentation","summary":"  Polyp segmentation within colonoscopy video frames using deep learning models\nhas the potential to automate the workflow of clinicians. This could help\nimprove the early detection rate and characterization of polyps which could\nprogress to colorectal cancer. Recent state-of-the-art deep learning polyp\nsegmentation models have combined the outputs of Fully Convolutional Network\narchitectures and Transformer Network architectures which work in parallel. In\nthis paper we propose modifications to the current state-of-the-art polyp\nsegmentation model FCBFormer. The transformer architecture of the FCBFormer is\nreplaced with a SwinV2 Transformer-UNET and minor changes to the Fully\nConvolutional Network architecture are made to create the FCB-SwinV2\nTransformer. The performance of the FCB-SwinV2 Transformer is evaluated on the\npopular colonoscopy segmentation bench-marking datasets Kvasir-SEG and\nCVC-ClinicDB. Generalizability tests are also conducted. The FCB-SwinV2\nTransformer is able to consistently achieve higher mDice scores across all\ntests conducted and therefore represents new state-of-the-art performance.\nIssues found with how colonoscopy segmentation model performance is evaluated\nwithin literature are also re-ported and discussed. One of the most important\nissues identified is that when evaluating performance on the CVC-ClinicDB\ndataset it would be preferable to ensure no data leakage from video sequences\noccurs during the training/validation/test data partition.\n","authors":["Kerr Fitzgerald","Bogdan Matuszewski"],"pdf_url":"https://arxiv.org/pdf/2302.01027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.07208v2","updated":"2023-02-02T11:12:00Z","published":"2020-12-14T01:51:59Z","title":"INSPIRE: Intensity and spatial information-based deformable image\n  registration","summary":"  We present INSPIRE, a top-performing general-purpose method for deformable\nimage registration. INSPIRE brings distance measures which combine intensity\nand spatial information into an elastic B-splines-based transformation model\nand incorporates an inverse inconsistency penalization supporting symmetric\nregistration performance. We introduce several theoretical and algorithmic\nsolutions which provide high computational efficiency and thereby applicability\nof the proposed framework in a wide range of real scenarios. We show that\nINSPIRE delivers highly accurate, as well as stable and robust registration\nresults. We evaluate the method on a 2D dataset created from retinal images,\ncharacterized by presence of networks of thin structures. Here INSPIRE exhibits\nexcellent performance, substantially outperforming the widely used reference\nmethods. {We also evaluate INSPIRE on the Fundus Image Registration Dataset\n(FIRE), which consists of 134 pairs of separately acquired retinal images.\nINSPIRE exhibits excellent performance on the FIRE dataset, substantially\noutperforming several domain-specific methods.} We also evaluate the method on\nfour benchmark datasets of 3D magnetic resonance images of brains, for a total\nof 2088 pairwise registrations. A comparison with 17 other state-of-the-art\nmethods reveals that INSPIRE provides the best overall performance. Code is\navailable at http://github.com/MIDA-group/inspire\n","authors":["Johan Öfverstedt","Joakim Lindblad","Nataša Sladoje"],"pdf_url":"https://arxiv.org/pdf/2012.07208v2.pdf","comment":"24 pages, 7 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.00995v1","updated":"2023-02-02T10:29:23Z","published":"2023-02-02T10:29:23Z","title":"Open-Set Multi-Source Multi-Target Domain Adaptation","summary":"  Single-Source Single-Target Domain Adaptation (1S1T) aims to bridge the gap\nbetween a labelled source domain and an unlabelled target domain. Despite 1S1T\nbeing a well-researched topic, they are typically not deployed to the real\nworld. Methods like Multi-Source Domain Adaptation and Multi-Target Domain\nAdaptation have evolved to model real-world problems but still do not\ngeneralise well. The fact that most of these methods assume a common label-set\nbetween source and target is very restrictive. Recent Open-Set Domain\nAdaptation methods handle unknown target labels but fail to generalise in\nmultiple domains. To overcome these difficulties, first, we propose a novel\ngeneric domain adaptation (DA) setting named Open-Set Multi-Source Multi-Target\nDomain Adaptation (OS-nSmT), with n and m being number of source and target\ndomains respectively. Next, we propose a graph attention based framework named\nDEGAA which can capture information from multiple source and target domains\nwithout knowing the exact label-set of the target. We argue that our method,\nthough offered for multiple sources and multiple targets, can also be agnostic\nto various other DA settings. To check the robustness and versatility of DEGAA,\nwe put forward ample experiments and ablation studies.\n","authors":["Rohit Lal","Arihant Gaur","Aadhithya Iyer","Muhammed Abdullah Shaikh","Ritik Agrawal"],"pdf_url":"https://arxiv.org/pdf/2302.00995v1.pdf","comment":"Submitted in NeurIPS 2021 Workshop on Pre-registration in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2302.00988v1","updated":"2023-02-02T10:13:04Z","published":"2023-02-02T10:13:04Z","title":"Hand Pose Estimation via Multiview Collaborative Self-Supervised\n  Learning","summary":"  3D hand pose estimation has made significant progress in recent years.\nHowever, the improvement is highly dependent on the emergence of large-scale\nannotated datasets. To alleviate the label-hungry limitation, we propose a\nmulti-view collaborative self-supervised learning framework, HaMuCo, that\nestimates hand pose only with pseudo labels for training. We use a two-stage\nstrategy to tackle the noisy label challenge and the multi-view ``groupthink''\nproblem. In the first stage, we estimate the 3D hand poses for each view\nindependently. In the second stage, we employ a cross-view interaction network\nto capture the cross-view correlated features and use multi-view consistency\nloss to achieve collaborative learning among views. To further enhance the\ncollaboration between single-view and multi-view, we fuse the results of all\nviews to supervise the single-view network. To summarize, we introduce\ncollaborative learning in two folds, the cross-view level and the multi- to\nsingle-view level. Extensive experiments show that our method can achieve\nstate-of-the-art performance on multi-view self-supervised hand pose\nestimation. Moreover, ablation studies verify the effectiveness of each\ncomponent. Results on multiple datasets further demonstrate the generalization\nability of our network.\n","authors":["Xiaozheng Zheng","Chao Wen","Zhou Xue","Jingyu Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00980v1","updated":"2023-02-02T09:59:55Z","published":"2023-02-02T09:59:55Z","title":"Domain Generalization Emerges from Dreaming","summary":"  Recent studies have proven that DNNs, unlike human vision, tend to exploit\ntexture information rather than shape. Such texture bias is one of the factors\nfor the poor generalization performance of DNNs. We observe that the texture\nbias negatively affects not only in-domain generalization but also\nout-of-distribution generalization, i.e., Domain Generalization. Motivated by\nthe observation, we propose a new framework to reduce the texture bias of a\nmodel by a novel optimization-based data augmentation, dubbed Stylized Dream.\nOur framework utilizes adaptive instance normalization (AdaIN) to augment the\nstyle of an original image yet preserve the content. We then adopt a\nregularization loss to predict consistent outputs between Stylized Dream and\noriginal images, which encourages the model to learn shape-based\nrepresentations. Extensive experiments show that the proposed method achieves\nstate-of-the-art performance in out-of-distribution settings on public\nbenchmark datasets: PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet.\n","authors":["Hwan Heo","Youngjin Oh","Jaewon Lee","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2302.00980v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2106.07916v2","updated":"2023-02-02T09:40:29Z","published":"2021-06-15T07:04:39Z","title":"Encouraging Intra-Class Diversity Through a Reverse Contrastive Loss for\n  Better Single-Source Domain Generalization","summary":"  Traditional deep learning algorithms often fail to generalize when they are\ntested outside of the domain of the training data. The issue can be mitigated\nby using unlabeled data from the target domain at training time, but because\ndata distributions can change dynamically in real-life applications once a\nlearned model is deployed, it is critical to create networks robust to unknown\nand unforeseen domain shifts. In this paper we focus on one of the reasons\nbehind the inability of neural networks to be so: deep networks focus only on\nthe most obvious, potentially spurious, clues to make their predictions and are\nblind to useful but slightly less efficient or more complex patterns. This\nbehaviour has been identified and several methods partially addressed the\nissue. To investigate their effectiveness and limits, we first design a\npublicly available MNIST-based benchmark to precisely measure the ability of an\nalgorithm to find the ''hidden'' patterns. Then, we evaluate state-of-the-art\nalgorithms through our benchmark and show that the issue is largely unsolved.\nFinally, we propose a partially reversed contrastive loss to encourage\nintra-class diversity and find less strongly correlated patterns, whose\nefficiency is demonstrated by our experiments.\n","authors":["Thomas Duboudin","Emmanuel Dellandréa","Corentin Abgrall","Gilles Hénaff","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2106.07916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05301v2","updated":"2023-02-02T09:30:00Z","published":"2022-12-10T14:01:54Z","title":"Leveraging Modality-specific Representations for Audio-visual Speech\n  Recognition via Reinforcement Learning","summary":"  Audio-visual speech recognition (AVSR) has gained remarkable success for\nameliorating the noise-robustness of speech recognition. Mainstream methods\nfocus on fusing audio and visual inputs to obtain modality-invariant\nrepresentations. However, such representations are prone to over-reliance on\naudio modality as it is much easier to recognize than video modality in clean\nconditions. As a result, the AVSR model underestimates the importance of visual\nstream in face of noise corruption. To this end, we leverage visual\nmodality-specific representations to provide stable complementary information\nfor the AVSR task. Specifically, we propose a reinforcement learning (RL) based\nframework called MSRL, where the agent dynamically harmonizes\nmodality-invariant and modality-specific representations in the auto-regressive\ndecoding process. We customize a reward function directly related to\ntask-specific metrics (i.e., word error rate), which encourages the MSRL to\neffectively explore the optimal integration strategy. Experimental results on\nthe LRS3 dataset show that the proposed method achieves state-of-the-art in\nboth clean and various noisy conditions. Furthermore, we demonstrate the better\ngenerality of MSRL system than other baselines when test set contains unseen\nnoises.\n","authors":["Chen Chen","Yuchen Hu","Qiang Zhang","Heqing Zou","Beier Zhu","Eng Siong Chng"],"pdf_url":"https://arxiv.org/pdf/2212.05301v2.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2112.05755v4","updated":"2023-02-02T09:15:48Z","published":"2021-12-10T05:32:23Z","title":"Information Prebuilt Recurrent Reconstruction Network for Video\n  Super-Resolution","summary":"  The video super-resolution (VSR) method based on the recurrent convolutional\nnetwork has strong temporal modeling capability for video sequences. However,\nthe temporal receptive field of different recurrent units in the unidirectional\nrecurrent network is unbalanced. Earlier reconstruction frames receive less\nspatio-temporal information, resulting in fuzziness or artifacts. Although the\nbidirectional recurrent network can alleviate this problem, it requires more\nmemory space and fails to perform many tasks with low latency requirements. To\nsolve the above problems, we propose an end-to-end information prebuilt\nrecurrent reconstruction network (IPRRN), consisting of an information prebuilt\nnetwork (IPNet) and a recurrent reconstruction network (RRNet). By integrating\nsufficient information from the front of the video to build the hidden state\nneeded for the initially recurrent unit to help restore the earlier frames, the\ninformation prebuilt network balances the input information difference at\ndifferent time steps. In addition, we demonstrate an efficient recurrent\nreconstruction network, which outperforms the existing unidirectional recurrent\nschemes in all aspects. Many experiments have verified the effectiveness of the\nnetwork we propose, which can effectively achieve better quantitative and\nqualitative evaluation performance compared to the existing state-of-the-art\nmethods.\n","authors":["Shuyun Wang","Ming Yu","Cuihong Xue","Yingchun Guo","Gang Yan"],"pdf_url":"https://arxiv.org/pdf/2112.05755v4.pdf","comment":"12 pages,9 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2211.10155v3","updated":"2023-02-02T09:07:43Z","published":"2022-11-17T09:03:25Z","title":"Structured Pruning Adapters","summary":"  Adapters are a parameter-efficient alternative to fine-tuning, which augment\na frozen base network to learn new tasks. Yet, the inference of the adapted\nmodel is often slower than the corresponding fine-tuned model. To improve on\nthis, we propose Structured Pruning Adapters (SPAs), a family of compressing,\ntask-switching network adapters, that accelerate and specialize networks using\ntiny parameter sets and structured pruning. Specifically, we propose a\nchannel-based SPA and evaluate it with a suite of pruning methods on multiple\ncomputer vision benchmarks. Compared to regular structured pruning with\nfine-tuning, our channel-SPAs improve accuracy by 6.9% on average while using\nhalf the parameters at 90% pruned weights. Alternatively, they can learn\nadaptations with 17x fewer parameters at 70% pruning with 1.6% lower accuracy.\nSimilarly, our block-SPA requires far fewer parameters than pruning with\nfine-tuning. Our experimental code and Python library of adapters are available\nat github.com/lukashedegaard/structured-pruning-adapters.\n","authors":["Lukas Hedegaard","Aman Alok","Juby Jose","Alexandros Iosifidis"],"pdf_url":"https://arxiv.org/pdf/2211.10155v3.pdf","comment":"11 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.00353v2","updated":"2023-02-02T08:57:01Z","published":"2023-02-01T10:24:55Z","title":"Towards Label-Efficient Incremental Learning: A Survey","summary":"  The current dominant paradigm when building a machine learning model is to\niterate over a dataset over and over until convergence. Such an approach is\nnon-incremental, as it assumes access to all images of all categories at once.\nHowever, for many applications, non-incremental learning is unrealistic. To\nthat end, researchers study incremental learning, where a learner is required\nto adapt to an incoming stream of data with a varying distribution while\npreventing forgetting of past knowledge. Significant progress has been made,\nhowever, the vast majority of works focus on the fully supervised setting,\nmaking these algorithms label-hungry thus limiting their real-life deployment.\nTo that end, in this paper, we make the first attempt to survey recently\ngrowing interest in label-efficient incremental learning. We identify three\nsubdivisions, namely semi-, few-shot- and self-supervised learning to reduce\nlabeling efforts. Finally, we identify novel directions that can further\nenhance label-efficiency and improve incremental learning scalability. Project\nwebsite: https://github.com/kilickaya/label-efficient-il.\n","authors":["Mert Kilickaya","Joost van de Weijer","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2302.00353v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11417v2","updated":"2023-02-02T08:54:56Z","published":"2023-01-26T21:07:12Z","title":"Are Labels Needed for Incremental Instance Learning?","summary":"  In this paper, we learn to classify visual object instances, incrementally\nand via self-supervision (self-incremental). Our learner observes a single\ninstance at a time, which is then discarded from the dataset. Incremental\ninstance learning is challenging, since longer learning sessions exacerbate\nforgetfulness, and labeling instances is cumbersome. We overcome these\nchallenges via three contributions: i. We propose VINIL, a self-incremental\nlearner that can learn object instances sequentially, ii. We equip VINIL with\nself-supervision to by-pass the need for instance labelling, iii. We compare\nVINIL to label-supervised variants on two large-scale benchmarks and show that\nVINIL significantly improves accuracy while reducing forgetfulness.\n","authors":["Mert Kilickaya","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2301.11417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13418v2","updated":"2023-02-02T08:50:36Z","published":"2023-01-31T05:14:49Z","title":"BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete\n  Annotations","summary":"  Methods to detect malignant lesions from screening mammograms are usually\ntrained with fully annotated datasets, where images are labelled with the\nlocalisation and classification of cancerous lesions. However, real-world\nscreening mammogram datasets commonly have a subset that is fully annotated and\nanother subset that is weakly annotated with just the global classification\n(i.e., without lesion localisation). Given the large size of such datasets,\nresearchers usually face a dilemma with the weakly annotated subset: to not use\nit or to fully annotate it. The first option will reduce detection accuracy\nbecause it does not use the whole dataset, and the second option is too\nexpensive given that the annotation needs to be done by expert radiologists. In\nthis paper, we propose a middle-ground solution for the dilemma, which is to\nformulate the training as a weakly- and semi-supervised learning problem that\nwe refer to as malignant breast lesion detection with incomplete annotations.\nTo address this problem, our new method comprises two stages, namely: 1)\npre-training a multi-view mammogram classifier with weak supervision from the\nwhole dataset, and 2) extending the trained classifier to become a multi-view\ndetector that is trained with semi-supervised student-teacher learning, where\nthe training set contains fully and weakly-annotated mammograms. We provide\nextensive detection results on two real-world screening mammogram datasets\ncontaining incomplete annotations, and show that our proposed approach achieves\nstate-of-the-art results in the detection of malignant breast lesions with\nincomplete annotations.\n","authors":["Yuanhong Chen","Yuyuan Liu","Chong Wang","Michael Elliott","Chun Fung Kwok","Carlos Pena-Solorzano","Yu Tian","Fengbei Liu","Helen Frazer","Davis J. McCarthy","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2301.13418v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2302.00953v1","updated":"2023-02-02T08:45:17Z","published":"2023-02-02T08:45:17Z","title":"Deep-Learning Tool for Early Identifying Non-Traumatic Intracranial\n  Hemorrhage Etiology based on CT Scan","summary":"  Background: To develop an artificial intelligence system that can accurately\nidentify acute non-traumatic intracranial hemorrhage (ICH) etiology based on\nnon-contrast CT (NCCT) scans and investigate whether clinicians can benefit\nfrom it in a diagnostic setting. Materials and Methods: The deep learning model\nwas developed with 1868 eligible NCCT scans with non-traumatic ICH collected\nbetween January 2011 and April 2018. We tested the model on two independent\ndatasets (TT200 and SD 98) collected after April 2018. The model's diagnostic\nperformance was compared with clinicians's performance. We further designed a\nsimulated study to compare the clinicians's performance with and without the\ndeep learning system augmentation. Results: The proposed deep learning system\nachieved area under the receiver operating curve of 0.986 (95% CI 0.967-1.000)\non aneurysms, 0.952 (0.917-0.987) on hypertensive hemorrhage, 0.950\n(0.860-1.000) on arteriovenous malformation (AVM), 0.749 (0.586-0.912) on\nMoyamoya disease (MMD), 0.837 (0.704-0.969) on cavernous malformation (CM), and\n0.839 (0.722-0.959) on other causes in TT200 dataset. Given a 90% specificity\nlevel, the sensitivities of our model were 97.1% and 90.9% for aneurysm and AVM\ndiagnosis, respectively. The model also shows an impressive generalizability in\nan independent dataset SD98. The clinicians achieve significant improvements in\nthe sensitivity, specificity, and accuracy of diagnoses of certain hemorrhage\netiologies with proposed system augmentation. Conclusions: The proposed deep\nlearning algorithms can be an effective tool for early identification of\nhemorrhage etiologies based on NCCT scans. It may also provide more information\nfor clinicians for triage and further imaging examination selection.\n","authors":["Meng Zhao","Yifan Hu","Ruixuan Jiang","Yuanli Zhao","Dong Zhang","Yan Zhang","Rong Wang","Yong Cao","Qian Zhang","Yonggang Ma","Jiaxi Li","Shaochen Yu","Wenjie Li","Ran Zhang","Yefeng Zheng","Shuo Wang","Jizong Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.00953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00952v1","updated":"2023-02-02T08:44:12Z","published":"2023-02-02T08:44:12Z","title":"QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time\n  Reasoning","summary":"  Daily images may convey abstract meanings that require us to memorize and\ninfer profound information from them. To encourage such human-like reasoning,\nin this work, we teach machines to predict where and when it was taken rather\nthan performing basic tasks like traditional segmentation or classification.\nInspired by Horn's QR theory, we designed a novel QR-CLIP model consisting of\ntwo components: 1) the Quantity module first retrospects more open-world\nknowledge as the candidate language inputs; 2) the Relevance module carefully\nestimates vision and language cues and infers the location and time.\nExperiments show our QR-CLIP's effectiveness, and it outperforms the previous\nSOTA on each task by an average of about 10% and 130% relative lift in terms of\nlocation and time reasoning. This study lays a technical foundation for\nlocation and time reasoning and suggests that effectively introducing\nopen-world knowledge is one of the panaceas for the tasks.\n","authors":["Weimin Shi","Mingchen Zhuge","Zhong Zhou","Dehong Gao","Deng-Ping Fan"],"pdf_url":"https://arxiv.org/pdf/2302.00952v1.pdf","comment":"On-Processing Work"},{"id":"http://arxiv.org/abs/2302.00939v1","updated":"2023-02-02T08:29:10Z","published":"2023-02-02T08:29:10Z","title":"An optimization method for out-of-distribution anomaly detection models","summary":"  Frequent false alarms impede the promotion of unsupervised anomaly detection\nalgorithms in industrial applications. Potential characteristics of false\nalarms depending on the trained detector are revealed by investigating density\nprobability distributions of prediction scores in the out-of-distribution\nanomaly detection tasks. An SVM-based classifier is exploited as a\npost-processing module to identify false alarms from the anomaly map at the\nobject level. Besides, a sample synthesis strategy is devised to incorporate\nfuzzy prior knowledge on the specific application in the anomaly-free training\ndataset. Experimental results illustrate that the proposed method\ncomprehensively improves the performances of two segmentation models at both\nimage and pixel levels on two industrial applications.\n","authors":["Ji Qiu","Hongmei Shi","Yu Hen Hu","Zujun Yu"],"pdf_url":"https://arxiv.org/pdf/2302.00939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00930v1","updated":"2023-02-02T08:06:02Z","published":"2023-02-02T08:06:02Z","title":"Adaptive Siamese Tracking with a Compact Latent Network","summary":"  In this paper, we provide an intuitive viewing to simplify the Siamese-based\ntrackers by converting the tracking task to a classification. Under this\nviewing, we perform an in-depth analysis for them through visual simulations\nand real tracking examples, and find that the failure cases in some challenging\nsituations can be regarded as the issue of missing decisive samples in offline\ntraining. Since the samples in the initial (first) frame contain rich\nsequence-specific information, we can regard them as the decisive samples to\nrepresent the whole sequence. To quickly adapt the base model to new scenes, a\ncompact latent network is presented via fully using these decisive samples.\nSpecifically, we present a statistics-based compact latent feature for fast\nadjustment by efficiently extracting the sequence-specific information.\nFurthermore, a new diverse sample mining strategy is designed for training to\nfurther improve the discrimination ability of the proposed compact latent\nnetwork. Finally, a conditional updating strategy is proposed to efficiently\nupdate the basic models to handle scene variation during the tracking phase. To\nevaluate the generalization ability and effectiveness and of our method, we\napply it to adjust three classical Siamese-based trackers, namely SiamRPN++,\nSiamFC, and SiamBAN. Extensive experimental results on six recent datasets\ndemonstrate that all three adjusted trackers obtain the superior performance in\nterms of the accuracy, while having high running speed.\n","authors":["Xingping Dong","Jianbing Shen","Fatih Porikli","Jiebo Luo","Ling Shao"],"pdf_url":"https://arxiv.org/pdf/2302.00930v1.pdf","comment":"Extended version of the paper \"CLNet: A Compact Latent Network for\n  Fast Adjusting Siamese Trackers\" presented at ECCV 2020. Accepted at TPAMI"},{"id":"http://arxiv.org/abs/2302.00923v1","updated":"2023-02-02T07:51:19Z","published":"2023-02-02T07:51:19Z","title":"Multimodal Chain-of-Thought Reasoning in Language Models","summary":"  Large language models (LLMs) have shown impressive performance on complex\nreasoning by leveraging chain-of-thought (CoT) prompting to generate\nintermediate reasoning chains as the rationale to infer the answer. However,\nexisting CoT studies are mostly isolated in the language modality with LLMs,\nwhere LLMs are hard to deploy. To elicit CoT reasoning in multimodality, a\npossible solution is to fine-tune small language models by fusing the vision\nand language features to perform CoT reasoning. The key challenge is that those\nlanguage models tend to generate hallucinated reasoning chains that mislead the\nanswer inference. To mitigate the effect of such mistakes, we propose\nMultimodal-CoT that incorporates vision features in a decoupled training\nframework. The framework separates the rationale generation and answer\ninference into two stages. By incorporating the vision features in both stages,\nthe model is able to generate effective rationales that contribute to answer\ninference. With Multimodal-CoT, our model under 1 billion parameters\noutperforms the previous state-of-the-art LLM (GPT-3.5) by 16% (75.17%->91.68%)\non the ScienceQA benchmark and even surpasses human performance. Code is\npublicly available at https://github.com/amazon-science/mm-cot.\n","authors":["Zhuosheng Zhang","Aston Zhang","Mu Li","Hai Zhao","George Karypis","Alex Smola"],"pdf_url":"https://arxiv.org/pdf/2302.00923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00918v1","updated":"2023-02-02T07:34:27Z","published":"2023-02-02T07:34:27Z","title":"Visual Realism Assessment for Face-swap Videos","summary":"  Deep-learning based face-swap videos, also known as deep fakes, are becoming\nmore and more realistic and deceiving. The malicious usage of these face-swap\nvideos has caused wide concerns. The research community has been focusing on\nthe automatic detection of these fake videos, but the as sessment of their\nvisual realism, as perceived by human eyes, is still an unexplored dimension.\nVisual realism assessment, or VRA, is essential for assessing the potential\nimpact that may be brought by a specific face-swap video, and it is also\nimportant as a quality assessment metric to compare different face-swap\nmethods. In this paper, we make a small step to wards this new VRA direction by\nbuilding a benchmark for evaluating the effectiveness of different automatic\nVRA models, which range from using traditional hand-crafted features to\ndifferent kinds of deep-learning features. The evaluations are based on a\nrecent competition dataset named as DFGC 2022, which contains 1400 diverse\nface-swap videos that are annotated with Mean Opinion Scores (MOS) on visual\nrealism. Comprehensive experiment results using 11 models and 3 protocols are\nshown and discussed. We demonstrate the feasibility of devising effective VRA\nmodels for assessing face-swap videos and methods. The particular usefulness of\nexisting deepfake detection features for VRA is also noted. The code and\nbenchmark will be made publicly available.\n","authors":["Xianyun Sun","Beibei Dong","Caiyong Wang","Bo Peng","Jing Dong"],"pdf_url":"https://arxiv.org/pdf/2302.00918v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00916v1","updated":"2023-02-02T07:32:13Z","published":"2023-02-02T07:32:13Z","title":"Cooperative Saliency-based Obstacle Detection and AR Rendering for\n  Increased Situational Awareness","summary":"  Autonomous vehicles are expected to operate safely in real-life road\nconditions in the next years. Nevertheless, unanticipated events such as the\nexistence of unexpected objects in the range of the road, can put safety at\nrisk. The advancement of sensing and communication technologies and Internet of\nThings may facilitate the recognition of hazardous situations and information\nexchange in a cooperative driving scheme, providing new opportunities for the\nincrease of collaborative situational awareness. Safe and unobtrusive\nvisualization of the obtained information may nowadays be enabled through the\nadoption of novel Augmented Reality (AR) interfaces in the form of windshields.\nMotivated by these technological opportunities, we propose in this work a\nsaliency-based distributed, cooperative obstacle detection and rendering scheme\nfor increasing the driver's situational awareness through (i) automated\nobstacle detection, (ii) AR visualization and (iii) information sharing\n(upcoming potential dangers) with other connected vehicles or road\ninfrastructure. An extensive evaluation study using a variety of real datasets\nfor pothole detection showed that the proposed method provides favorable\nresults and features compared to other recent and relevant approaches.\n","authors":["Gerasimos Arvanitis","Nikolaos Stagakis","Evangelia I. Zacharaki","Konstantinos Moustakas"],"pdf_url":"https://arxiv.org/pdf/2302.00916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08320v2","updated":"2023-02-02T07:26:26Z","published":"2022-12-16T07:46:53Z","title":"Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image\n  Transformers Help 3D Representation Learning?","summary":"  The success of deep learning heavily relies on large-scale data with\ncomprehensive labels, which is more expensive and time-consuming to fetch in 3D\ncompared to 2D images or natural languages. This promotes the potential of\nutilizing models pretrained with data more than 3D as teachers for cross-modal\nknowledge transferring. In this paper, we revisit masked modeling in a unified\nfashion of knowledge distillation, and we show that foundational Transformers\npretrained with 2D images or natural languages can help self-supervised 3D\nrepresentation learning through training Autoencoders as Cross-Modal Teachers\n(ACT). The pretrained Transformers are transferred as cross-modal 3D teachers\nusing discrete variational autoencoding self-supervision, during which the\nTransformers are frozen with prompt tuning for better knowledge inheritance.\nThe latent features encoded by the 3D teachers are used as the target of masked\npoint modeling, wherein the dark knowledge is distilled to the 3D Transformer\nstudents as foundational geometry understanding. Our ACT pretrained 3D learner\nachieves state-of-the-art generalization capacity across various downstream\nbenchmarks, e.g., 88.21% overall accuracy on ScanObjectNN. Codes have been\nreleased at https://github.com/RunpeiDong/ACT.\n","authors":["Runpei Dong","Zekun Qi","Linfeng Zhang","Junbo Zhang","Jianjian Sun","Zheng Ge","Li Yi","Kaisheng Ma"],"pdf_url":"https://arxiv.org/pdf/2212.08320v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2204.07414v2","updated":"2023-02-02T07:22:36Z","published":"2022-04-15T10:31:12Z","title":"SOTVerse: A User-defined Task Space of Single Object Tracking","summary":"  Single object tracking (SOT) research falls into a cycle -- trackers perform\nwell on most benchmarks but quickly fail in challenging scenarios, causing\nresearchers to doubt the insufficient data content and take more effort to\nconstruct larger datasets with more challenging situations. However,\ninefficient data utilization and limited evaluation methods more seriously\nhinder SOT research. The former causes existing datasets can not be exploited\ncomprehensively, while the latter neglects challenging factors in the\nevaluation process. In this article, we systematize the representative\nbenchmarks and form a Single Object Tracking metaverse (SOTVerse) -- a\nuser-defined SOT task space to break through the bottleneck. We first propose a\n3E Paradigm to describe tasks by three components (i.e., environment,\nevaluation, and executor). Then, we summarize task characteristics, clarify the\norganization standards, and construct SOTVerse with 12.56 million frames.\nSpecifically, SOTVerse automatically labels challenging factors per frame,\nallowing users to generate user-defined spaces efficiently via construction\nrules. Besides, SOTVerse provides two mechanisms with new indicators and\nsuccessfully evaluates trackers under various subtasks. Consequently, SOTVerse\nfirst provides a strategy to improve resource utilization in the computer\nvision area, making research more standardized and scientific. The SOTVerse,\ntoolkit, evaluation server, and results are available at\nhttp://metaverse.aitestunion.com.\n","authors":["Shiyu Hu","Xin Zhao","Kaiqi Huang"],"pdf_url":"https://arxiv.org/pdf/2204.07414v2.pdf","comment":"This paper is submitted to an international journal"},{"id":"http://arxiv.org/abs/2302.00912v1","updated":"2023-02-02T07:07:35Z","published":"2023-02-02T07:07:35Z","title":"Advances and Challenges in Multimodal Remote Sensing Image Registration","summary":"  Over the past few decades, with the rapid development of global aerospace and\naerial remote sensing technology, the types of sensors have evolved from the\ntraditional monomodal sensors (e.g., optical sensors) to the new generation of\nmultimodal sensors [e.g., multispectral, hyperspectral, light detection and\nranging (LiDAR) and synthetic aperture radar (SAR) sensors]. These advanced\ndevices can dynamically provide various and abundant multimodal remote sensing\nimages with different spatial, temporal, and spectral resolutions according to\ndifferent application requirements. Since then, it is of great scientific\nsignificance to carry out the research of multimodal remote sensing image\nregistration, which is a crucial step for integrating the complementary\ninformation among multimodal data and making comprehensive observations and\nanalysis of the Earths surface. In this work, we will present our own\ncontributions to the field of multimodal image registration, summarize the\nadvantages and limitations of existing multimodal image registration methods,\nand then discuss the remaining challenges and make a forward-looking prospect\nfor the future development of the field.\n","authors":["Bai Zhu","Liang Zhou","Simiao Pu","Jianwei Fan","Yuanxin Ye"],"pdf_url":"https://arxiv.org/pdf/2302.00912v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.00908v1","updated":"2023-02-02T06:55:40Z","published":"2023-02-02T06:55:40Z","title":"GANalyzer: Analysis and Manipulation of GANs Latent Space for\n  Controllable Face Synthesis","summary":"  Generative Adversarial Networks (GANs) are capable of synthesizing\nhigh-quality facial images. Despite their success, GANs do not provide any\ninformation about the relationship between the input vectors and the generated\nimages. Currently, facial GANs are trained on imbalanced datasets, which\ngenerate less diverse images. For example, more than 77% of 100K images that we\nrandomly synthesized using the StyleGAN3 are classified as Happy, and only\naround 3% are Angry. The problem even becomes worse when a mixture of facial\nattributes is desired: less than 1% of the generated samples are Angry Woman,\nand only around 2% are Happy Black. To address these problems, this paper\nproposes a framework, called GANalyzer, for the analysis, and manipulation of\nthe latent space of well-trained GANs. GANalyzer consists of a set of\ntransformation functions designed to manipulate latent vectors for a specific\nfacial attribute such as facial Expression, Age, Gender, and Race. We analyze\nfacial attribute entanglement in the latent space of GANs and apply the\nproposed transformation for editing the disentangled facial attributes. Our\nexperimental results demonstrate the strength of GANalyzer in editing facial\nattributes and generating any desired faces. We also create and release a\nbalanced photo-realistic human face dataset. Our code is publicly available on\nGitHub.\n","authors":["Ali Pourramezan Fard","Mohammad H. Mahoor","Sarah Ariel Lamer","Timothy Sweeny"],"pdf_url":"https://arxiv.org/pdf/2302.00908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02277v3","updated":"2023-02-02T06:46:04Z","published":"2022-12-05T13:55:02Z","title":"R2FD2: Fast and Robust Matching of Multimodal Remote Sensing Image via\n  Repeatable Feature Detector and Rotation-invariant Feature Descriptor","summary":"  Automatically identifying feature correspondences between multimodal images\nis facing enormous challenges because of the significant differences both in\nradiation and geometry. To address these problems, we propose a novel feature\nmatching method (named R2FD2) that is robust to radiation and rotation\ndifferences. Our R2FD2 is conducted in two critical contributions, consisting\nof a repeatable feature detector and a rotation-invariant feature descriptor.\nIn the first stage, a repeatable feature detector called the Multi-channel\nAuto-correlation of the Log-Gabor (MALG) is presented for feature detection,\nwhich combines the multi-channel auto-correlation strategy with the Log-Gabor\nwavelets to detect interest points (IPs) with high repeatability and uniform\ndistribution. In the second stage, a rotation-invariant feature descriptor is\nconstructed, named the Rotation-invariant Maximum index map of the Log-Gabor\n(RMLG), which consists of two components: fast assignment of dominant\norientation and construction of feature representation. In the process of fast\nassignment of dominant orientation, a Rotation-invariant Maximum Index Map\n(RMIM) is built to address rotation deformations. Then, the proposed RMLG\nincorporates the rotation-invariant RMIM with the spatial configuration of\nDAISY to depict a more discriminative feature representation, which improves\nRMLG's resistance to radiation and rotation variances.Experimental results show\nthat the proposed R2FD2 outperforms five state-of-the-art feature matching\nmethods, and has superior advantages in adaptability and universality.\nMoreover, our R2FD2 achieves the accuracy of matching within two pixels and has\na great advantage in matching efficiency over other state-of-the-art methods.\n","authors":["Bai Zhu","Chao Yang","Jinkun Dai","Jianwei Fan","Yuanxin Ye"],"pdf_url":"https://arxiv.org/pdf/2212.02277v3.pdf","comment":"33 pages, 15 figures"},{"id":"http://arxiv.org/abs/2302.00903v1","updated":"2023-02-02T06:41:02Z","published":"2023-02-02T06:41:02Z","title":"No One Left Behind: Real-World Federated Class-Incremental Learning","summary":"  Federated learning (FL) is a hot collaborative training framework via\naggregating model parameters of decentralized local clients. However, most\nexisting models unreasonably assume that data categories of FL framework are\nknown and fxed in advance. It renders the global model to signifcantly degrade\nrecognition performance on old categories (i.e., catastrophic forgetting), when\nlocal clients receive new categories consecutively under limited memory of\nstoring old categories. Moreover, some new local clients that collect novel\ncategories unseen by other clients may be introduced to the FL training\nirregularly, which further exacerbates the catastrophic forgetting on old\ncategories. To tackle the above issues, we propose a novel Local-Global\nAnti-forgetting (LGA) model to address local and global catastrophic forgetting\non old categories, which is a pioneering work to explore a global\nclass-incremental model in the FL feld. Specifcally, considering tackling class\nimbalance of local client to surmount local forgetting, we develop a\ncategory-balanced gradient-adaptive compensation loss and a category\ngradient-induced semantic distillation loss. They can balance heterogeneous\nforgetting speeds of hard-to-forget and easy-to-forget old categories, while\nensure intrinsic class relations consistency within different incremental\ntasks. Moreover, a proxy server is designed to tackle global forgetting caused\nby Non-IID class imbalance between different clients. It collects perturbed\nprototype images of new categories from local clients via prototype gradient\ncommunication under privacy preservation, and augments them via self-supervised\nprototype augmentation to choose the best old global model and improve local\ndistillation gain. Experiments on representative datasets verify superior\nperformance of our model against other comparison methods.\n","authors":["Jiahua Dong","Yang Cong","Gan Sun","Yulun Zhang","Bernt Schiele","Dengxin Dai"],"pdf_url":"https://arxiv.org/pdf/2302.00903v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.00902v1","updated":"2023-02-02T06:38:44Z","published":"2023-02-02T06:38:44Z","title":"Language Quantized AutoEncoders: Towards Unsupervised Text-Image\n  Alignment","summary":"  Recent progress in scaling up large language models has shown impressive\ncapabilities in performing few-shot learning across a wide range of text-based\ntasks. However, a key limitation is that these language models fundamentally\nlack visual perception - a crucial attribute needed to extend these models to\nbe able to interact with the real world and solve vision tasks, such as in\nvisual-question answering and robotics. Prior works have largely connected\nimage to text through pretraining and/or fine-tuning on curated image-text\ndatasets, which can be a costly and expensive process. In order to resolve this\nlimitation, we propose a simple yet effective approach called\nLanguage-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to\nalign text-image data in an unsupervised manner by leveraging pretrained\nlanguage models (e.g., BERT, RoBERTa). Our main idea is to encode image as\nsequences of text tokens by directly quantizing image embeddings using a\npretrained language codebook. We then apply random masking followed by a BERT\nmodel, and have the decoder reconstruct the original image from BERT predicted\ntext token embeddings. By doing so, LQAE learns to represent similar images\nwith similar clusters of text tokens, thereby aligning these two modalities\nwithout the use of aligned text-image pairs. This enables few-shot image\nclassification with large language models (e.g., GPT-3) as well as linear\nclassification of images based on BERT text features. To the best of our\nknowledge, our work is the first work that uses unaligned images for multimodal\ntasks by leveraging the power of pretrained language models.\n","authors":["Hao Liu","Wilson Yan","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.00902v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2106.13884 by other authors"},{"id":"http://arxiv.org/abs/2302.00901v1","updated":"2023-02-02T06:38:00Z","published":"2023-02-02T06:38:00Z","title":"Longformer: Longitudinal Transformer for Alzheimer's Disease\n  Classification with Structural MRIs","summary":"  Structural magnetic resonance imaging (sMRI) is widely used for brain\nneurological disease diagnosis; while longitudinal MRIs are often collected to\nmonitor and capture disease progression, as clinically used in diagnosing\nAlzheimer's disease (AD). However, most current methods neglect AD's\nprogressive nature and only take a single sMRI for recognizing AD. In this\npaper, we consider the problem of leveraging the longitudinal MRIs of a subject\nfor AD identification. To capture longitudinal changes in sMRIs, we propose a\nnovel model Longformer, a spatiotemporal transformer network that performs\nattention mechanisms spatially on sMRIs at each time point and integrates brain\nregion features over time to obtain longitudinal embeddings for classification.\nOur Longformer achieves state-of-the-art performance on two binary\nclassification tasks of separating different stages of AD using the ADNI\ndataset. Our source code is available at https://github.com/Qybc/LongFormer.\n","authors":["Qiuhui Chen","Yi Hong"],"pdf_url":"https://arxiv.org/pdf/2302.00901v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.00899v1","updated":"2023-02-02T06:14:21Z","published":"2023-02-02T06:14:21Z","title":"KST-Mixer: Kinematic Spatio-Temporal Data Mixer For Colon Shape\n  Estimation","summary":"  We propose a spatio-temporal mixing kinematic data estimation method to\nestimate the shape of the colon with deformations caused by colonoscope\ninsertion. Endoscope tracking or a navigation system that navigates physicians\nto target positions is needed to reduce such complications as organ\nperforations. Although many previous methods focused to track bronchoscopes and\nsurgical endoscopes, few number of colonoscope tracking methods were proposed.\nThis is because the colon largely deforms during colonoscope insertion. The\ndeformation causes significant tracking errors. Colon deformation should be\ntaken into account in the tracking process. We propose a colon shape estimation\nmethod using a Kinematic Spatio-Temporal data Mixer (KST-Mixer) that can be\nused during colonoscope insertions to the colon. Kinematic data of a\ncolonoscope and the colon, including positions and directions of their\ncenterlines, are obtained using electromagnetic and depth sensors. The proposed\nmethod separates the data into sub-groups along the spatial and temporal axes.\nThe KST-Mixer extracts kinematic features and mix them along the spatial and\ntemporal axes multiple times. We evaluated colon shape estimation accuracies in\nphantom studies. The proposed method achieved 11.92 mm mean Euclidean distance\nerror, the smallest of the previous methods. Statistical analysis indicated\nthat the proposed method significantly reduced the error compared to the\nprevious methods.\n","authors":["Masahiro Oda","Kazuhiro Furukawa","Nassir Navab","Kensaku Mori"],"pdf_url":"https://arxiv.org/pdf/2302.00899v1.pdf","comment":"Accepted paper as an oral presentation at Joint MICCAI workshop 2022,\n  AE-CAI/CARE/OR2.0. Received the Outstanding Paper Award"},{"id":"http://arxiv.org/abs/2302.00885v1","updated":"2023-02-02T05:31:53Z","published":"2023-02-02T05:31:53Z","title":"AOP-Net: All-in-One Perception Network for Joint LiDAR-based 3D Object\n  Detection and Panoptic Segmentation","summary":"  LiDAR-based 3D object detection and panoptic segmentation are two crucial\ntasks in the perception systems of autonomous vehicles and robots. In this\npaper, we propose All-in-One Perception Network (AOP-Net), a LiDAR-based\nmulti-task framework that combines 3D object detection and panoptic\nsegmentation. In this method, a dual-task 3D backbone is developed to extract\nboth panoptic- and detection-level features from the input LiDAR point cloud.\nAlso, a new 2D backbone that intertwines Multi-Layer Perceptron (MLP) and\nconvolution layers is designed to further improve the detection task\nperformance. Finally, a novel module is proposed to guide the detection head by\nrecovering useful features discarded during down-sampling operations in the 3D\nbackbone. This module leverages estimated instance segmentation masks to\nrecover detailed information from each candidate object. The AOP-Net achieves\nstate-of-the-art performance for published works on the nuScenes benchmark for\nboth 3D object detection and panoptic segmentation tasks. Also, experiments\nshow that our method easily adapts to and significantly improves the\nperformance of any BEV-based 3D object detection method.\n","authors":["Yixuan Xu","Hamidreza Fazlali","Yuan Ren","Bingbing Liu"],"pdf_url":"https://arxiv.org/pdf/2302.00885v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.00884v1","updated":"2023-02-02T05:24:50Z","published":"2023-02-02T05:24:50Z","title":"Exploring Invariant Representation for Visible-Infrared Person\n  Re-Identification","summary":"  Cross-spectral person re-identification, which aims to associate identities\nto pedestrians across different spectra, faces a main challenge of the modality\ndiscrepancy. In this paper, we address the problem from both image-level and\nfeature-level in an end-to-end hybrid learning framework named robust feature\nmining network (RFM). In particular, we observe that the reflective intensity\nof the same surface in photos shot in different wavelengths could be\ntransformed using a linear model. Besides, we show the variable linear factor\nacross the different surfaces is the main culprit which initiates the modality\ndiscrepancy. We integrate such a reflection observation into an image-level\ndata augmentation by proposing the linear transformation generator (LTG).\nMoreover, at the feature level, we introduce a cross-center loss to explore a\nmore compact intra-class distribution and modality-aware spatial attention to\ntake advantage of textured regions more efficiently. Experiment results on two\nstandard cross-spectral person re-identification datasets, i.e., RegDB and\nSYSU-MM01, have demonstrated state-of-the-art performance.\n","authors":["Lei Tan","Yukang Zhang","Shengmei Shen","Yan Wang","Pingyang Dai","Xianming Lin","Yongjian Wu","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2302.00884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12558v5","updated":"2023-02-02T05:06:25Z","published":"2022-01-29T10:54:57Z","title":"The KFIoU Loss for Rotated Object Detection","summary":"  Differing from the well-developed horizontal object detection area whereby\nthe computing-friendly IoU based loss is readily adopted and well fits with the\ndetection metrics. In contrast, rotation detectors often involve a more\ncomplicated loss based on SkewIoU which is unfriendly to gradient-based\ntraining. In this paper, we propose an effective approximate SkewIoU loss based\non Gaussian modeing and Kalman filter, which mainly consists of two items. The\nfirst term is a scale-insensitive center point loss, which is used to quickly\nget the center points between bounding boxes closer to assist the second term.\nIn the distance-independent second term, Kalman filter is adopted to inherently\nmimic the mechanism of SkewIoU by its definition, and show its alignment with\nthe SkewIoU loss at trend-level within a certain distance (i.e. within 9\npixels). This is in contrast to recent Gaussian modeling based rotation\ndetectors e.g. GWD loss and KLD loss that involve a human-specified\ndistribution distance metric which require additional hyperparameter tuning\nthat vary across datasets and detectors. The resulting new loss called KFIoU\nloss is easier to implement and works better compared with exact SkewIoU loss,\nthanks to its full differentiability and ability to handle the non-overlapping\ncases. We further extend our technique to the 3-D case which also suffers from\nthe same issues as 2-D detection. Extensive results on various public datasets\n(2-D/3-D, aerial/text/face images) with different base detectors show the\neffectiveness of our approach.\n","authors":["Xue Yang","Yue Zhou","Gefan Zhang","Jirui Yang","Wentao Wang","Junchi Yan","Xiaopeng Zhang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2201.12558v5.pdf","comment":"17 pages, 6 figures, 7 tables, accepted by ICLR 2023, TensorFlow\n  code: https://github.com/yangxue0827/RotationDetection, PyTorch code:\n  https://github.com/open-mmlab/mmrotate, Jittor code:\n  https://github.com/Jittor/JDet"},{"id":"http://arxiv.org/abs/2210.06742v3","updated":"2023-02-02T05:02:05Z","published":"2022-10-13T05:12:45Z","title":"H2RBox: Horizontal Box Annotation is All You Need for Oriented Object\n  Detection","summary":"  Oriented object detection emerges in many applications from aerial images to\nautonomous driving, while many existing detection benchmarks are annotated with\nhorizontal bounding box only which is also less costive than fine-grained\nrotated box, leading to a gap between the readily available training corpus and\nthe rising demand for oriented object detection. This paper proposes a simple\nyet effective oriented object detection approach called H2RBox merely using\nhorizontal box annotation for weakly-supervised training, which closes the\nabove gap and shows competitive performance even against those trained with\nrotated boxes. The cores of our method are weakly- and self-supervised\nlearning, which predicts the angle of the object by learning the consistency of\ntwo different views. To our best knowledge, H2RBox is the first horizontal box\nannotation-based oriented object detector. Compared to an alternative i.e.\nhorizontal box-supervised instance segmentation with our post adaption to\noriented object detection, our approach is not susceptible to the prediction\nquality of mask and can perform more robustly in complex scenes containing a\nlarge number of dense objects and outliers. Experimental results show that\nH2RBox has significant performance and speed advantages over horizontal\nbox-supervised instance segmentation methods, as well as lower memory\nrequirements. While compared to rotated box-supervised oriented object\ndetectors, our method shows very close performance and speed. The source code\nis available at https://github.com/yangxue0827/h2rbox-mmrotate and\nhttps://github.com/yangxue0827/h2rbox-jittor.\n","authors":["Xue Yang","Gefan Zhang","Wentong Li","Xuehui Wang","Yue Zhou","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2210.06742v3.pdf","comment":"15 pages, 6 figures, 7 tables, accepted by ICLR 2023, the source code\n  is available at https://github.com/yangxue0827/h2rbox-mmrotate and\n  https://github.com/yangxue0827/h2rbox-jittor"},{"id":"http://arxiv.org/abs/2302.00875v1","updated":"2023-02-02T04:52:08Z","published":"2023-02-02T04:52:08Z","title":"Vision Transformer-based Feature Extraction for Generalized Zero-Shot\n  Learning","summary":"  Generalized zero-shot learning (GZSL) is a technique to train a deep learning\nmodel to identify unseen classes using the image attribute. In this paper, we\nput forth a new GZSL approach exploiting Vision Transformer (ViT) to maximize\nthe attribute-related information contained in the image feature. In ViT, the\nentire image region is processed without the degradation of the image\nresolution and the local image information is preserved in patch features. To\nfully enjoy these benefits of ViT, we exploit patch features as well as the CLS\nfeature in extracting the attribute-related image feature. In particular, we\npropose a novel attention-based module, called attribute attention module\n(AAM), to aggregate the attribute-related information in patch features. In\nAAM, the correlation between each patch feature and the synthetic image\nattribute is used as the importance weight for each patch. From extensive\nexperiments on benchmark datasets, we demonstrate that the proposed technique\noutperforms the state-of-the-art GZSL approaches by a large margin.\n","authors":["Jiseob Kim","Kyuhong Shim","Junhan Kim","Byonghyo Shim"],"pdf_url":"https://arxiv.org/pdf/2302.00875v1.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2302.00869v1","updated":"2023-02-02T04:37:29Z","published":"2023-02-02T04:37:29Z","title":"Disentanglement of Latent Representations via Sparse Causal\n  Interventions","summary":"  The process of generating data such as images is controlled by independent\nand unknown factors of variation. The retrieval of these variables has been\nstudied extensively in the disentanglement, causal representation learning, and\nindependent component analysis fields. Recently, approaches merging these\ndomains together have shown great success. Instead of directly representing the\nfactors of variation, the problem of disentanglement can be seen as finding the\ninterventions on one image that yield a change to a single factor. Following\nthis assumption, we introduce a new method for disentanglement inspired by\ncausal dynamics that combines causality theory with vector-quantized\nvariational autoencoders. Our model considers the quantized vectors as causal\nvariables and links them in a causal graph. It performs causal interventions on\nthe graph and generates atomic transitions affecting a unique factor of\nvariation in the image. We also introduce a new task of action retrieval that\nconsists of finding the action responsible for the transition between two\nimages. We test our method on standard synthetic and real-world disentanglement\ndatasets. We show that it can effectively disentangle the factors of variation\nand perform precise interventions on high-level semantic attributes of an image\nwithout affecting its quality, even with imbalanced data distributions.\n","authors":["Gaël Gendron","Michael Witbrock","Gillian Dobbie"],"pdf_url":"https://arxiv.org/pdf/2302.00869v1.pdf","comment":"16 pages, 10 pages for the main paper and 6 pages for the supplement,\n  14 figures, submitted to IJCAI 2023"},{"id":"http://arxiv.org/abs/2302.00864v1","updated":"2023-02-02T04:27:54Z","published":"2023-02-02T04:27:54Z","title":"CLIPood: Generalizing CLIP to Out-of-Distributions","summary":"  Out-of-distribution (OOD) generalization, where the model needs to handle\ndistribution shifts from training, is a major challenge of machine learning.\nRecently, contrastive language-image pre-training (CLIP) models have shown\nimpressive zero-shot ability, revealing a promising path toward OOD\ngeneralization. However, to boost upon zero-shot performance, further\nadaptation of CLIP on downstream tasks is indispensable but undesirably\ndegrades OOD generalization ability. In this paper, we aim at generalizing CLIP\nto out-of-distribution test data on downstream tasks. Beyond the two canonical\nOOD situations, domain shift and open class, we tackle a more general but\ndifficult in-the-wild setting where both OOD situations may occur on the unseen\ntest data. We propose CLIPood, a simple fine-tuning method that can adapt CLIP\nmodels to all OOD situations. To exploit semantic relations between classes\nfrom the text modality, CLIPood introduces a new training objective, margin\nmetric softmax (MMS), with class adaptive margins for fine-tuning. Moreover, to\nincorporate both the pre-trained zero-shot model and the fine-tuned\ntask-adaptive model, CLIPood proposes a new Beta moving average (BMA) to\nmaintain a temporal ensemble according to Beta distribution. Experiments on\ndiverse datasets with different OOD scenarios show that CLIPood consistently\noutperforms existing generalization techniques.\n","authors":["Yang Shu","Xingzhuo Guo","Jialong Wu","Ximei Wang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2302.00864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00858v1","updated":"2023-02-02T04:03:38Z","published":"2023-02-02T04:03:38Z","title":"Online Continual Learning via the Knowledge Invariant and Spread-out\n  Properties","summary":"  The goal of continual learning is to provide intelligent agents that are\ncapable of learning continually a sequence of tasks using the knowledge\nobtained from previous tasks while performing well on prior tasks. However, a\nkey challenge in this continual learning paradigm is catastrophic forgetting,\nnamely adapting a model to new tasks often leads to severe performance\ndegradation on prior tasks. Current memory-based approaches show their success\nin alleviating the catastrophic forgetting problem by replaying examples from\npast tasks when new tasks are learned. However, these methods are infeasible to\ntransfer the structural knowledge from previous tasks i.e., similarities or\ndissimilarities between different instances. Furthermore, the learning bias\nbetween the current and prior tasks is also an urgent problem that should be\nsolved. In this work, we propose a new method, named Online Continual Learning\nvia the Knowledge Invariant and Spread-out Properties (OCLKISP), in which we\nconstrain the evolution of the embedding features via Knowledge Invariant and\nSpread-out Properties (KISP). Thus, we can further transfer the inter-instance\nstructural knowledge of previous tasks while alleviating the forgetting due to\nthe learning bias. We empirically evaluate our proposed method on four popular\nbenchmarks for continual learning: Split CIFAR 100, Split SVHN, Split CUB200\nand Split Tiny-Image-Net. The experimental results show the efficacy of our\nproposed method compared to the state-of-the-art continual learning algorithms.\n","authors":["Ya-nan Han","Jian-wei Liu"],"pdf_url":"https://arxiv.org/pdf/2302.00858v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2208.10967v3","updated":"2023-02-02T03:31:21Z","published":"2022-08-23T13:41:01Z","title":"The Value of Out-of-Distribution Data","summary":"  We expect the generalization error to improve with more samples from a\nsimilar task, and to deteriorate with more samples from an out-of-distribution\n(OOD) task. In this work, we show a counter-intuitive phenomenon: the\ngeneralization error of a task can be a non-monotonic function of the number of\nOOD samples. As the number of OOD samples increases, the generalization error\non the target task improves before deteriorating beyond a threshold. In other\nwords, there is value in training on small amounts of OOD data. We use Fisher's\nLinear Discriminant on synthetic datasets and deep networks on computer vision\nbenchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet to demonstrate\nand analyze this phenomenon. In the idealistic setting where we know which\nsamples are OOD, we show that these non-monotonic trends can be exploited using\nan appropriately weighted objective of the target and OOD empirical risk. While\nits practical utility is limited, this does suggest that if we can detect OOD\nsamples, then there may be ways to benefit from them. When we do not know which\nsamples are OOD, we show how a number of go-to strategies such as\ndata-augmentation, hyper-parameter optimization, and pre-training are not\nenough to ensure that the target generalization error does not deteriorate with\nthe number of OOD samples in the dataset.\n","authors":["Ashwin De Silva","Rahul Ramesh","Carey E. Priebe","Pratik Chaudhari","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2208.10967v3.pdf","comment":"Previous versions of this work have been presented at the\n  Out-of-Distribution Generalization in Computer Vision (OOD-CV) Workshop (ECCV\n  2022) and the Workshop on Distribution Shifts (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2009.00902v2","updated":"2023-02-02T02:52:04Z","published":"2020-09-02T08:52:15Z","title":"Adversarially Robust Neural Architectures","summary":"  Deep Neural Networks (DNNs) are vulnerable to adversarial attacks. Existing\nmethods are devoted to developing various robust training strategies or\nregularizations to update the weights of the neural network. But beyond the\nweights, the overall structure and information flow in the network are\nexplicitly determined by the neural architecture, which remains unexplored.\nThis paper thus aims to improve the adversarial robustness of the network from\nthe architecture perspective. We explore the relationship among adversarial\nrobustness, Lipschitz constant, and architecture parameters and show that an\nappropriate constraint on architecture parameters could reduce the Lipschitz\nconstant to further improve the robustness. The importance of architecture\nparameters could vary from operation to operation or connection to connection.\nWe approximate the Lipschitz constant of the entire network through a\nunivariate log-normal distribution, whose mean and variance are related to\narchitecture parameters. The confidence can be fulfilled through formulating a\nconstraint on the distribution parameters based on the cumulative function.\nCompared with adversarially trained neural architectures searched by various\nNAS algorithms as well as efficient human-designed models, our algorithm\nempirically achieves the best performance among all the models under various\nattacks on different datasets.\n","authors":["Minjing Dong","Yanxi Li","Yunhe Wang","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2009.00902v2.pdf","comment":"13 pages, 5 figures, 8 tables"},{"id":"http://arxiv.org/abs/2302.00837v1","updated":"2023-02-02T02:46:52Z","published":"2023-02-02T02:46:52Z","title":"SHINE: Deep Learning-Based Accessible Parking Management System","summary":"  The enhancement of science and technology has helped expand urban cities like\nnever before. Due to the undeniable benefits of owning a private vehicle, the\nnumber of cars has rocketed in many parts of the world, including South Korea.\nHowever, these gradual increments in the number of vehicles lead to\nparking-related problems, including the abuse of disabled parking spaces\n(referred to as accessible parking spaces hereafter). Due to the high frame\nrate of surveillance cameras, traditional license plate recognition (LPR)\nsystems are ineffective in real-time. On the other hand, natural and artificial\nnoise and differences in lighting and weather conditions make detection and\nrecognition difficult for these systems. With the growing concept of parking\n4.0, many sensors, IoT and deep learning-based approaches have been applied to\nautomatic LPR and parking management systems. However, the studies show a need\nfor a robust and efficient model for managing accessible parking spaces in\nSouth Korea. We have proposed a novel system called 'SHINE', which uses the\ndeep learning-based object detection algorithm for detecting the vehicle,\nlicense plate, and disability badges (referred to as cards, badges, or access\nbadges hereafter) and then authenticates the rights to use the accessible\nparking spaces by coordinating with the central server. This model, achieving\n92.16% mean average precision, is believed to solve the problem of accessible\nparking space abuse.\n","authors":["Dhiraj Neupane","Aashish Bhattarai","Sunil Aryal","Mohamed Reda Bouadjenek","Uk-Min Seok","Jongwon Seok"],"pdf_url":"https://arxiv.org/pdf/2302.00837v1.pdf","comment":"14 papges main manuscript, 6 pages Appendix, 8 figures"},{"id":"http://arxiv.org/abs/2302.00833v1","updated":"2023-02-02T02:45:23Z","published":"2023-02-02T02:45:23Z","title":"RobustNeRF: Ignoring Distractors with Robust Losses","summary":"  Neural radiance fields (NeRF) excel at synthesizing new views given\nmulti-view, calibrated images of a static scene. When scenes include\ndistractors, which are not persistent during image capture (moving objects,\nlighting variations, shadows), artifacts appear as view-dependent effects or\n'floaters'. To cope with distractors, we advocate a form of robust estimation\nfor NeRF training, modeling distractors in training data as outliers of an\noptimization problem. Our method successfully removes outliers from a scene and\nimproves upon our baselines, on synthetic and real-world scenes. Our technique\nis simple to incorporate in modern NeRF frameworks, with few hyper-parameters.\nIt does not assume a priori knowledge of the types of distractors, and is\ninstead focused on the optimization problem rather than pre-processing or\nmodeling transient objects. More results on our page\nhttps://robustnerf.github.io/public.\n","authors":["Sara Sabour","Suhani Vora","Daniel Duckworth","Ivan Krasin","David J. Fleet","Andrea Tagliasacchi"],"pdf_url":"https://arxiv.org/pdf/2302.00833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09060v2","updated":"2023-02-02T02:31:40Z","published":"2023-01-22T05:26:08Z","title":"3D Reconstruction of Non-cooperative Resident Space Objects using\n  Instant NGP-accelerated NeRF and D-NeRF","summary":"  The proliferation of non-cooperative resident space objects (RSOs) in orbit\nhas spurred the demand for active space debris removal, on-orbit servicing\n(OOS), classification, and functionality identification of these RSOs. Recent\nadvances in computer vision have enabled high-definition 3D modeling of objects\nbased on a set of 2D images captured from different viewing angles. This work\nadapts Instant NeRF and D-NeRF, variations of the neural radiance field (NeRF)\nalgorithm to the problem of mapping RSOs in orbit for the purposes of\nfunctionality identification and assisting with OOS. The algorithms are\nevaluated for 3D reconstruction quality and hardware requirements using\ndatasets of images of a spacecraft mock-up taken under two different lighting\nand motion conditions at the Orbital Robotic Interaction, On-Orbit Servicing\nand Navigation (ORION) Laboratory at Florida Institute of Technology. Instant\nNeRF is shown to learn high-fidelity 3D models with a computational cost that\ncould feasibly be trained on on-board computers.\n","authors":["Trupti Mahendrakar","Basilio Caruso","Van Minh Nguyen","Ryan T. White","Todd Steffen"],"pdf_url":"https://arxiv.org/pdf/2301.09060v2.pdf","comment":"Presented at AAS/AIAA Spaceflight Mechanics Conference 2023, 14\n  pages, 10 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.00824v1","updated":"2023-02-02T02:11:39Z","published":"2023-02-02T02:11:39Z","title":"SpaceYOLO: A Human-Inspired Model for Real-time, On-board Spacecraft\n  Feature Detection","summary":"  The rapid proliferation of non-cooperative spacecraft and space debris in\norbit has precipitated a surging demand for on-orbit servicing and space debris\nremoval at a scale that only autonomous missions can address, but the\nprerequisite autonomous navigation and flightpath planning to safely capture an\nunknown, non-cooperative, tumbling space object is an open problem. This\nrequires algorithms for real-time, automated spacecraft feature recognition to\npinpoint the locations of collision hazards (e.g. solar panels or antennas) and\nsafe docking features (e.g. satellite bodies or thrusters) so safe, effective\nflightpaths can be planned. Prior work in this area reveals the performance of\ncomputer vision models are highly dependent on the training dataset and its\ncoverage of scenarios visually similar to the real scenarios that occur in\ndeployment. Hence, the algorithm may have degraded performance under certain\nlighting conditions even when the rendezvous maneuver conditions of the chaser\nto the target spacecraft are the same. This work delves into how humans perform\nthese tasks through a survey of how aerospace engineering students experienced\nwith spacecraft shapes and components recognize features of the three\nspacecraft: Landsat, Envisat, Anik, and the orbiter Mir. The survey reveals\nthat the most common patterns in the human detection process were to consider\nthe shape and texture of the features: antennas, solar panels, thrusters, and\nsatellite bodies. This work introduces a novel algorithm SpaceYOLO, which fuses\na state-of-the-art object detector YOLOv5 with a separate neural network based\non these human-inspired decision processes exploiting shape and texture.\nPerformance in autonomous spacecraft detection of SpaceYOLO is compared to\nordinary YOLOv5 in hardware-in-the-loop experiments under different lighting\nand chaser maneuver conditions at the ORION Laboratory at Florida Tech.\n","authors":["Trupti Mahendrakar","Ryan T. White","Markus Wilde","Madhur Tiwari"],"pdf_url":"https://arxiv.org/pdf/2302.00824v1.pdf","comment":"Accepted at IEEE Aerospace Conference 2023, 11 pages, 21 figures"},{"id":"http://arxiv.org/abs/2302.00816v1","updated":"2023-02-02T01:37:43Z","published":"2023-02-02T01:37:43Z","title":"Dynamic Atomic Column Detection in Transmission Electron Microscopy\n  Videos via Ridge Estimation","summary":"  Ridge detection is a classical tool to extract curvilinear features in image\nprocessing. As such, it has great promise in applications to material science\nproblems; specifically, for trend filtering relatively stable atom-shaped\nobjects in image sequences, such as Transmission Electron Microscopy (TEM)\nvideos. Standard analysis of TEM videos is limited to frame-by-frame object\nrecognition. We instead harness temporal correlation across frames through\nsimultaneous analysis of long image sequences, specified as a spatio-temporal\nimage tensor. We define new ridge detection algorithms to non-parametrically\nestimate explicit trajectories of atomic-level object locations as a continuous\nfunction of time. Our approach is specially tailored to handle temporal\nanalysis of objects that seemingly stochastically disappear and subsequently\nreappear throughout a sequence. We demonstrate that the proposed method is\nhighly effective and efficient in simulation scenarios, and delivers notable\nperformance improvements in TEM experiments compared to other material science\nbenchmarks.\n","authors":["Yuchen Xu","Andrew M. Thomas","Peter A. Crozier","David S. Matteson"],"pdf_url":"https://arxiv.org/pdf/2302.00816v1.pdf","comment":"27 pages, 11 figures"},{"id":"http://arxiv.org/abs/2301.09422v2","updated":"2023-02-02T01:31:37Z","published":"2023-01-20T01:57:34Z","title":"HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural\n  Networks","summary":"  Low-rank compression is an important model compression strategy for obtaining\ncompact neural network models. In general, because the rank values directly\ndetermine the model complexity and model accuracy, proper selection of\nlayer-wise rank is very critical and desired. To date, though many low-rank\ncompression approaches, either selecting the ranks in a manual or automatic\nway, have been proposed, they suffer from costly manual trials or unsatisfied\ncompression performance. In addition, all of the existing works are not\ndesigned in a hardware-aware way, limiting the practical performance of the\ncompressed models on real-world hardware platforms.\n  To address these challenges, in this paper we propose HALOC, a hardware-aware\nautomatic low-rank compression framework. By interpreting automatic rank\nselection from an architecture search perspective, we develop an end-to-end\nsolution to determine the suitable layer-wise ranks in a differentiable and\nhardware-aware way. We further propose design principles and mitigation\nstrategy to efficiently explore the rank space and reduce the potential\ninterference problem.\n  Experimental results on different datasets and hardware platforms demonstrate\nthe effectiveness of our proposed approach. On CIFAR-10 dataset, HALOC enables\n0.07% and 0.38% accuracy increase over the uncompressed ResNet-20 and VGG-16\nmodels with 72.20% and 86.44% fewer FLOPs, respectively. On ImageNet dataset,\nHALOC achieves 0.9% higher top-1 accuracy than the original ResNet-18 model\nwith 66.16% fewer FLOPs. HALOC also shows 0.66% higher top-1 accuracy increase\nthan the state-of-the-art automatic low-rank compression solution with fewer\ncomputational and memory costs. In addition, HALOC demonstrates the practical\nspeedups on different hardware platforms, verified by the measurement results\non desktop GPU, embedded GPU and ASIC accelerator.\n","authors":["Jinqi Xiao","Chengming Zhang","Yu Gong","Miao Yin","Yang Sui","Lizhi Xiang","Dingwen Tao","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.09422v2.pdf","comment":"AAAI-23"},{"id":"http://arxiv.org/abs/2211.15646v2","updated":"2023-02-02T23:23:21Z","published":"2022-11-28T18:52:33Z","title":"Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions\n  with \"Spurious\" Correlations","summary":"  Spurious correlations, or correlations that change across domains where a\nmodel can be deployed, present significant challenges to real-world\napplications of machine learning models. However, such correlations are not\nalways \"spurious\"; often, they provide valuable prior information for a\nprediction. Here, we present a test-time adaptation method that exploits the\nspurious correlation phenomenon, in contrast to recent approaches that attempt\nto eliminate spurious correlations through invariance. We consider situations\nwhere the prior distribution $p(y, z)$, which models the dependence between the\nclass label $y$ and the \"nuisance\" factors $z$, may change across domains, but\nthe generative model for features $p(\\mathbf{x}|y, z)$ is constant. We note\nthat this corresponds to an expanded version of the label shift assumption,\nwhere the labels now also include the nuisance factors $z$. Based on this\nobservation, we train a classifier to predict $p(y, z|\\mathbf{x})$ on the\nsource distribution, and propose a test-time label shift correction that adapts\nto changes in the marginal distribution $p(y, z)$ using unlabeled samples from\nthe target domain. We evaluate our method, which we call \"Test-Time Label-Shift\nAdaptation\" (TTLSA), on two different image datasets -- the CheXpert chest\nX-ray dataset and the Colored MNIST dataset -- and show a significant\nimprovement over baseline methods. Code reproducing experiments is available at\nhttps://github.com/nalzok/test-time-label-shift .\n","authors":["Qingyao Sun","Kevin Murphy","Sayna Ebrahimi","Alexander D'Amour"],"pdf_url":"https://arxiv.org/pdf/2211.15646v2.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.01459v1","updated":"2023-02-02T23:03:51Z","published":"2023-02-02T23:03:51Z","title":"A sliced-Wasserstein distance-based approach for\n  out-of-class-distribution detection","summary":"  There exist growing interests in intelligent systems for numerous medical\nimaging, image processing, and computer vision applications, such as face\nrecognition, medical diagnosis, character recognition, and self-driving cars,\namong others. These applications usually require solving complex classification\nproblems involving complex images with unknown data generative processes. In\naddition to recent successes of the current classification approaches relying\non feature engineering and deep learning, several shortcomings of them, such as\nthe lack of robustness, generalizability, and interpretability, have also been\nobserved. These methods often require extensive training data, are\ncomputationally expensive, and are vulnerable to out-of-distribution samples,\ne.g., adversarial attacks. Recently, an accurate, data-efficient,\ncomputationally efficient, and robust transport-based classification approach\nhas been proposed, which describes a generative model-based problem formulation\nand closed-form solution for a specific category of classification problems.\nHowever, all these approaches lack mechanisms to detect test samples outside\nthe class distributions used during training. In real-world settings, where the\ncollected training samples are unable to exhaust or cover all classes, the\ntraditional classification schemes are unable to handle the unseen classes\neffectively, which is especially an important issue for safety-critical\nsystems, such as self-driving and medical imaging diagnosis. In this work, we\npropose a method for detecting out-of-class distributions based on the\ndistribution of sliced-Wasserstein distance from the Radon Cumulative\nDistribution Transform (R-CDT) subspace. We tested our method on the MNIST and\ntwo medical image datasets and reported better accuracy than the\nstate-of-the-art methods without an out-of-class distribution detection\nprocedure.\n","authors":["Mohammad Shifat E Rabbi","Abu Hasnat Mohammad Rubaiyat","Yan Zhuang","Gustavo K Rohde"],"pdf_url":"https://arxiv.org/pdf/2302.01459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01451v1","updated":"2023-02-02T22:38:23Z","published":"2023-02-02T22:38:23Z","title":"CTE: A Dataset for Contextualized Table Extraction","summary":"  Relevant information in documents is often summarized in tables, helping the\nreader to identify useful facts. Most benchmark datasets support either\ndocument layout analysis or table understanding, but lack in providing data to\napply both tasks in a unified way. We define the task of Contextualized Table\nExtraction (CTE), which aims to extract and define the structure of tables\nconsidering the textual context of the document. The dataset comprises 75k\nfully annotated pages of scientific papers, including more than 35k tables.\nData are gathered from PubMed Central, merging the information provided by\nannotations in the PubTables-1M and PubLayNet datasets. The dataset can support\nCTE and adds new classes to the original ones. The generated annotations can be\nused to develop end-to-end pipelines for various tasks, including document\nlayout analysis, table detection, structure recognition, and functional\nanalysis. We formally define CTE and evaluation metrics, showing which subtasks\ncan be tackled, describing advantages, limitations, and future works of this\ncollection of data. Annotations and code will be accessible a\nhttps://github.com/AILab-UniFI/cte-dataset.\n","authors":["Andrea Gemelli","Emanuele Vivoli","Simone Marinai"],"pdf_url":"https://arxiv.org/pdf/2302.01451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01427v1","updated":"2023-02-02T21:37:42Z","published":"2023-02-02T21:37:42Z","title":"Benchmarking Probabilistic Deep Learning Methods for License Plate\n  Recognition","summary":"  Learning-based algorithms for automated license plate recognition implicitly\nassume that the training and test data are well aligned. However, this may not\nbe the case under extreme environmental conditions, or in forensic applications\nwhere the system cannot be trained for a specific acquisition device.\nPredictions on such out-of-distribution images have an increased chance of\nfailing. But this failure case is oftentimes hard to recognize for a human\noperator or an automated system. Hence, in this work we propose to model the\nprediction uncertainty for license plate recognition explicitly. Such an\nuncertainty measure allows to detect false predictions, indicating an analyst\nwhen not to trust the result of the automated license plate recognition. In\nthis paper, we compare three methods for uncertainty quantification on two\narchitectures. The experiments on synthetic noisy or blurred low-resolution\nimages show that the predictive uncertainty reliably finds wrong predictions.\nWe also show that a multi-task combination of classification and\nsuper-resolution improves the recognition performance by 109\\% and the\ndetection of wrong predictions by 29 %.\n","authors":["Franziska Schirrmacher","Benedikt Lorch","Anatol Maier","Christian Riess"],"pdf_url":"https://arxiv.org/pdf/2302.01427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01417v1","updated":"2023-02-02T21:10:31Z","published":"2023-02-02T21:10:31Z","title":"A Convolutional-based Model for Early Prediction of Alzheimer's based on\n  the Dementia Stage in the MRI Brain Images","summary":"  Alzheimer's disease is a degenerative brain disease. Being the primary cause\nof Dementia in adults and progressively destroys brain memory. Though\nAlzheimer's disease does not have a cure currently, diagnosing it at an earlier\nstage will help reduce the severity of the disease. Thus, early diagnosis of\nAlzheimer's could help to reduce or stop the disease from progressing. In this\npaper, we proposed a deep convolutional neural network-based model for learning\nmodel using to determine the stage of Dementia in adults based on the Magnetic\nResonance Imaging (MRI) images to detect the early onset of Alzheimer's.\n","authors":["Shrish Pellakur","Nelly Elsayed","Zag ElSayed","Murat Ozer"],"pdf_url":"https://arxiv.org/pdf/2302.01417v1.pdf","comment":"Short paper, Under Review in FLAIRS-36"},{"id":"http://arxiv.org/abs/2302.01409v1","updated":"2023-02-02T20:47:45Z","published":"2023-02-02T20:47:45Z","title":"Hyperbolic Contrastive Learning","summary":"  Learning good image representations that are beneficial to downstream tasks\nis a challenging task in computer vision. As such, a wide variety of\nself-supervised learning approaches have been proposed. Among them, contrastive\nlearning has shown competitive performance on several benchmark datasets. The\nembeddings of contrastive learning are arranged on a hypersphere that results\nin using the inner (dot) product as a distance measurement in Euclidean space.\nHowever, the underlying structure of many scientific fields like social\nnetworks, brain imaging, and computer graphics data exhibit highly\nnon-Euclidean latent geometry. We propose a novel contrastive learning\nframework to learn semantic relationships in the hyperbolic space. Hyperbolic\nspace is a continuous version of trees that naturally owns the ability to model\nhierarchical structures and is thus beneficial for efficient contrastive\nrepresentation learning. We also extend the proposed Hyperbolic Contrastive\nLearning (HCL) to the supervised domain and studied the adversarial robustness\nof HCL. The comprehensive experiments show that our proposed method achieves\nbetter results on self-supervised pretraining, supervised classification, and\nhigher robust accuracy than baseline methods.\n","authors":["Yun Yue","Fangzhou Lin","Kazunori D Yamada","Ziming Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01403v1","updated":"2023-02-02T20:34:13Z","published":"2023-02-02T20:34:13Z","title":"Self-Supervised Relation Alignment for Scene Graph Generation","summary":"  The goal of scene graph generation is to predict a graph from an input image,\nwhere nodes correspond to identified and localized objects and edges to their\ncorresponding interaction predicates. Existing methods are trained in a fully\nsupervised manner and focus on message passing mechanisms, loss functions,\nand/or bias mitigation. In this work we introduce a simple-yet-effective\nself-supervised relational alignment regularization designed to improve the\nscene graph generation performance. The proposed alignment is general and can\nbe combined with any existing scene graph generation framework, where it is\ntrained alongside the original model's objective. The alignment is achieved\nthrough distillation, where an auxiliary relation prediction branch, that\nmirrors and shares parameters with the supervised counterpart, is designed. In\nthe auxiliary branch, relational input features are partially masked prior to\nmessage passing and predicate prediction. The predictions for masked relations\nare then aligned with the supervised counterparts after the message passing. We\nillustrate the effectiveness of this self-supervised relational alignment in\nconjunction with two scene graph generation architectures, SGTR and Neural\nMotifs, and show that in both cases we achieve significantly improved\nperformance.\n","authors":["Bicheng Xu","Renjie Liao","Leonid Sigal"],"pdf_url":"https://arxiv.org/pdf/2302.01403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10351v2","updated":"2023-02-02T20:26:39Z","published":"2023-01-24T23:40:01Z","title":"Few-Shot Learning Enables Population-Scale Analysis of Leaf Traits in\n  Populus trichocarpa","summary":"  Plant phenotyping is typically a time-consuming and expensive endeavor,\nrequiring large groups of researchers to meticulously measure biologically\nrelevant plant traits, and is the main bottleneck in understanding plant\nadaptation and the genetic architecture underlying complex traits at population\nscale. In this work, we address these challenges by leveraging few-shot\nlearning with convolutional neural networks (CNNs) to segment the leaf body and\nvisible venation of 2,906 P. trichocarpa leaf images obtained in the field. In\ncontrast to previous methods, our approach (i) does not require experimental or\nimage pre-processing, (ii) uses the raw RGB images at full resolution, and\n(iii) requires very few samples for training (e.g., just eight images for vein\nsegmentation). Traits relating to leaf morphology and vein topology are\nextracted from the resulting segmentations using traditional open-source\nimage-processing tools, validated using real-world physical measurements, and\nused to conduct a genome-wide association study to identify genes controlling\nthe traits. In this way, the current work is designed to provide the plant\nphenotyping community with (i) methods for fast and accurate image-based\nfeature extraction that require minimal training data, and (ii) a new\npopulation-scale data set, including 68 different leaf phenotypes, for domain\nscientists and machine learning researchers. All of the few-shot learning code,\ndata, and results are made publicly available.\n","authors":["John Lagergren","Mirko Pavicic","Hari B. Chhetri","Larry M. York","P. Doug Hyatt","David Kainer","Erica M. Rutter","Kevin Flores","Jack Bailey-Bale","Marie Klein","Gail Taylor","Daniel Jacobson","Jared Streich"],"pdf_url":"https://arxiv.org/pdf/2301.10351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08671v2","updated":"2023-02-02T20:22:18Z","published":"2022-06-17T10:17:20Z","title":"FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and\n  Federated Image Classification","summary":"  Modern deep learning systems are increasingly deployed in situations such as\npersonalization and federated learning where it is necessary to support i)\nlearning on small amounts of data, and ii) communication efficient distributed\ntraining protocols. In this work, we develop FiLM Transfer (FiT) which fulfills\nthese requirements in the image classification setting by combining ideas from\ntransfer learning (fixed pretrained backbones and fine-tuned FiLM adapter\nlayers) and meta-learning (automatically configured Naive Bayes classifiers and\nepisodic training) to yield parameter efficient models with superior\nclassification accuracy at low-shot. The resulting parameter efficiency is key\nfor enabling few-shot learning, inexpensive model updates for personalization,\nand communication efficient federated learning. We experiment with FiT on a\nwide range of downstream datasets and show that it achieves better\nclassification accuracy than the leading Big Transfer (BiT) algorithm at\nlow-shot and achieves state-of-the art accuracy on the challenging VTAB-1k\nbenchmark, with fewer than 1% of the updateable parameters. Finally, we\ndemonstrate the parameter efficiency and superior accuracy of FiT in\ndistributed low-shot applications including model personalization and federated\nlearning where model update size is an important performance metric.\n","authors":["Aliaksandra Shysheya","John Bronskill","Massimiliano Patacchiola","Sebastian Nowozin","Richard E Turner"],"pdf_url":"https://arxiv.org/pdf/2206.08671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01392v1","updated":"2023-02-02T20:06:58Z","published":"2023-02-02T20:06:58Z","title":"MoE-Fusion: Instance Embedded Mixture-of-Experts for Infrared and\n  Visible Image Fusion","summary":"  Infrared and visible image fusion can compensate for the incompleteness of\nsingle-modality imaging and provide a more comprehensive scene description\nbased on cross-modal complementarity. Most works focus on learning the overall\ncross-modal features by high- and low-frequency constraints at the image level\nalone, ignoring the fact that cross-modal instance-level features often contain\nmore valuable information. To fill this gap, we model cross-modal\ninstance-level features by embedding instance information into a set of\nMixture-of-Experts (MoEs) for the first time, prompting image fusion networks\nto specifically learn instance-level information. We propose a novel framework\nwith instance embedded Mixture-of-Experts for infrared and visible image\nfusion, termed MoE-Fusion, which contains an instance embedded MoE group\n(IE-MoE), an MoE-Decoder, two encoders, and two auxiliary detection networks.\nBy embedding the instance-level information learned in the auxiliary network,\nIE-MoE achieves specialized learning of cross-modal foreground and background\nfeatures. MoE-Decoder can adaptively select suitable experts for cross-modal\nfeature decoding and obtain fusion results dynamically. Extensive experiments\nshow that our MoE-Fusion outperforms state-of-the-art methods in preserving\ncontrast and texture details by learning instance-level information in\ncross-modal images.\n","authors":["Yiming Sun","Bing Cao","Pengfei Zhu","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2302.01392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01386v1","updated":"2023-02-02T19:46:39Z","published":"2023-02-02T19:46:39Z","title":"Continual Learning with Scaled Gradient Projection","summary":"  In neural networks, continual learning results in gradient interference among\nsequential tasks, leading to catastrophic forgetting of old tasks while\nlearning new ones. This issue is addressed in recent methods by storing the\nimportant gradient spaces for old tasks and updating the model orthogonally\nduring new tasks. However, such restrictive orthogonal gradient updates hamper\nthe learning capability of the new tasks resulting in sub-optimal performance.\nTo improve new learning while minimizing forgetting, in this paper we propose a\nScaled Gradient Projection (SGP) method, where we combine the orthogonal\ngradient projections with scaled gradient steps along the important gradient\nspaces for the past tasks. The degree of gradient scaling along these spaces\ndepends on the importance of the bases spanning them. We propose an efficient\nmethod for computing and accumulating importance of these bases using the\nsingular value decomposition of the input representations for each task. We\nconduct extensive experiments ranging from continual image classification to\nreinforcement learning tasks and report better performance with less training\noverhead than the state-of-the-art approaches.\n","authors":["Gobinda Saha","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2302.01386v1.pdf","comment":"Accepted at AAAI 2023"},{"id":"http://arxiv.org/abs/2302.01384v1","updated":"2023-02-02T19:41:00Z","published":"2023-02-02T19:41:00Z","title":"Energy-Inspired Self-Supervised Pretraining for Vision Models","summary":"  Motivated by the fact that forward and backward passes of a deep network\nnaturally form symmetric mappings between input and output representations, we\nintroduce a simple yet effective self-supervised vision model pretraining\nframework inspired by energy-based models (EBMs). In the proposed framework, we\nmodel energy estimation and data restoration as the forward and backward passes\nof a single network without any auxiliary components, e.g., an extra decoder.\nFor the forward pass, we fit a network to an energy function that assigns low\nenergy scores to samples that belong to an unlabeled dataset, and high energy\notherwise. For the backward pass, we restore data from corrupted versions\niteratively using gradient-based optimization along the direction of energy\nminimization. In this way, we naturally fold the encoder-decoder architecture\nwidely used in masked image modeling into the forward and backward passes of a\nsingle vision model. Thus, our framework now accepts a wide range of pretext\ntasks with different data corruption methods, and permits models to be\npretrained from masked image modeling, patch sorting, and image restoration,\nincluding super-resolution, denoising, and colorization. We support our\nfindings with extensive experiments, and show the proposed method delivers\ncomparable and even better performance with remarkably fewer epochs of training\ncompared to the state-of-the-art self-supervised vision model pretraining\nmethods. Our findings shed light on further exploring self-supervised vision\nmodel pretraining and pretext tasks beyond masked image modeling.\n","authors":["Ze Wang","Jiang Wang","Zicheng Liu","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.01384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01381v1","updated":"2023-02-02T19:28:41Z","published":"2023-02-02T19:28:41Z","title":"Effective Robustness against Natural Distribution Shifts for Models with\n  Different Training Data","summary":"  ``Effective robustness'' measures the extra out-of-distribution (OOD)\nrobustness beyond what can be predicted from the in-distribution (ID)\nperformance. Existing effective robustness evaluations typically use a single\ntest set such as ImageNet to evaluate ID accuracy. This becomes problematic\nwhen evaluating models trained on different data distributions, e.g., comparing\nmodels trained on ImageNet vs. zero-shot language-image pre-trained models\ntrained on LAION. In this paper, we propose a new effective robustness\nevaluation metric to compare the effective robustness of models trained on\ndifferent data distributions. To do this we control for the accuracy on\nmultiple ID test sets that cover the training distributions for all the\nevaluated models. Our new evaluation metric provides a better estimate of the\neffectiveness robustness and explains the surprising effective robustness gains\nof zero-shot CLIP-like models exhibited when considering only one ID dataset,\nwhile the gains diminish under our evaluation.\n","authors":["Zhouxing Shi","Nicholas Carlini","Ananth Balashankar","Ludwig Schmidt","Cho-Jui Hsieh","Alex Beutel","Yao Qin"],"pdf_url":"https://arxiv.org/pdf/2302.01381v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.01223v1","updated":"2023-02-02T17:03:40Z","published":"2023-02-02T17:03:40Z","title":"Practical Bandits: An Industry Perspective","summary":"  The bandit paradigm provides a unified modeling framework for problems that\nrequire decision-making under uncertainty. Because many business metrics can be\nviewed as rewards (a.k.a. utilities) that result from actions, bandit\nalgorithms have seen a large and growing interest from industrial applications,\nsuch as search, recommendation and advertising. Indeed, with the bandit lens\ncomes the promise of direct optimisation for the metrics we care about.\n  Nevertheless, the road to successfully applying bandits in production is not\nan easy one. Even when the action space and rewards are well-defined,\npractitioners still need to make decisions regarding multi-arm or contextual\napproaches, on- or off-policy setups, delayed or immediate feedback, myopic or\nlong-term optimisation, etc. To make matters worse, industrial platforms\ntypically give rise to large action spaces in which existing approaches tend to\nbreak down. The research literature on these topics is broad and vast, but this\ncan overwhelm practitioners, whose primary aim is to solve practical problems,\nand therefore need to decide on a specific instantiation or approach for each\nproject. This tutorial will take a step towards filling that gap between the\ntheory and practice of bandits. Our goal is to present a unified overview of\nthe field and its existing terminology, concepts and algorithms -- with a focus\non problems relevant to industry. We hope our industrial perspective will help\nfuture practitioners who wish to leverage the bandit paradigm for their\napplication.\n","authors":["Bram van den Akker","Olivier Jeunen","Ying Li","Ben London","Zahra Nazari","Devesh Parekh"],"pdf_url":"https://arxiv.org/pdf/2302.01223v1.pdf","comment":"Tutorial held at The Web Conference 2023 (formerly known as WWW) in\n  Austin, Texas (USA), on April 30 - May 4, 2023"},{"id":"http://arxiv.org/abs/2202.12183v5","updated":"2023-02-02T16:37:48Z","published":"2022-02-24T16:37:07Z","title":"Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning\n  with Provable Convergence","summary":"  NDCG, namely Normalized Discounted Cumulative Gain, is a widely used ranking\nmetric in information retrieval and machine learning. However, efficient and\nprovable stochastic methods for maximizing NDCG are still lacking, especially\nfor deep models. In this paper, we propose a principled approach to optimize\nNDCG and its top-$K$ variant. First, we formulate a novel compositional\noptimization problem for optimizing the NDCG surrogate, and a novel bilevel\ncompositional optimization problem for optimizing the top-$K$ NDCG surrogate.\nThen, we develop efficient stochastic algorithms with provable convergence\nguarantees for the non-convex objectives. Different from existing NDCG\noptimization methods, the per-iteration complexity of our algorithms scales\nwith the mini-batch size instead of the number of total items. To improve the\neffectiveness for deep learning, we further propose practical strategies by\nusing initial warm-up and stop gradient operator. Experimental results on\nmultiple datasets demonstrate that our methods outperform prior ranking\napproaches in terms of NDCG. To the best of our knowledge, this is the first\ntime that stochastic algorithms are proposed to optimize NDCG with a provable\nconvergence guarantee. Our proposed methods are implemented in the LibAUC\nlibrary at https://libauc.org/.\n","authors":["Zi-Hao Qiu","Quanqi Hu","Yongjian Zhong","Lijun Zhang","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2202.12183v5.pdf","comment":"32 pages, 12 figures; Accepted by ICML2022"},{"id":"http://arxiv.org/abs/2302.01115v1","updated":"2023-02-02T14:15:36Z","published":"2023-02-02T14:15:36Z","title":"PEPNet: Parameter and Embedding Personalized Network for Infusing with\n  Personalized Prior Information","summary":"  With the increase of pages and buttons in real-world applications,\nindustrial-scale recommender systems face multi-domain and multi-task\nchallenges. On the one hand, users and items in multiple domains suffer\ninconsistent distributions. On the other hand, multiple tasks have distinctive\nsparsity and interdependence. Personalization modeling is the core of\nrecommender systems. Accurate personalization estimation helps to capture the\ndegree of user preference for items in different situations, especially in the\ncase of multiple domains and multiple tasks. In multi-task and multi-domain\nrecommendation, how to introduce personalized priors into the model in the\nright place and in the right way is crucial. In this paper, we propose a\nplug-and-play Parameter and Embedding Personalized Network (PEPNet) for\nmulti-task recommendation in the multi-domain setting. PEPNet takes features\nwith strong bias as input and dynamically acts on the bottom-layer embeddings\nor the top-layer DNN hidden units in the model through the gate mechanism. By\nmapping significant priors to scaling weights ranging from 0 to 2, PEPNet\nintroduces both parameter personalization and embedding personalization.\nEmbedding Personalized Network (EPNet) selects and aligns embeddings with\ndifferent semantics under multiple domains. Parameter Personalized Network\n(PPNet) influences DNN parameters to balance interdependent targets in multiple\ntasks. To further adapt to the characteristics of the model, we have made\ncorresponding engineering optimizations on the Embedding and DNN parameter\nupdate strategies. We have deployed the model in Kuaishou and Kuaishou Express\napps, serving over 300 million daily users. Both online and offline experiments\nhave demonstrated substantial improvements in multiple metrics. In particular,\nwe have seen a more than 1\\% online increase in three major domains.\n","authors":["Jianxin Chang","Chenbin Zhang","Yiqun Hui","Dewei Leng","Yanan Niu","Yang Song"],"pdf_url":"https://arxiv.org/pdf/2302.01115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01090v1","updated":"2023-02-02T13:23:54Z","published":"2023-02-02T13:23:54Z","title":"Goniometers are a Powerful Acoustic Feature for Music Information\n  Retrieval Tasks","summary":"  Goniometers, also known as Phase Scopes or Vector Scopes, are audio metering\ntools that help music producers and mixing engineers monitor spatial aspects of\na music mix, such as the stereo panorama, the width of single sources, the\namount and diffuseness of reverberation as well as phase cancellations that may\noccur on the sweet-spot and in a mono-mixdown. In addition, they implicitly\ninform about the dynamics of the sound. Self-organizing maps trained with a\ngoniometer, are consulted to explore the usefulness of this acoustic feature\nfor music information retrieval tasks. One can see that goniometers are able to\nclassify different genres and cluster a single album. The advantage of\ngoniometers is the causality: Music producers and mixing engineers consciously\nconsult goniometers to reach their desired sound, which is not the case for\nother acoustic features, from Zero-Crossing Rate to Mel-Frequency Cepstral\nCoefficients.\n","authors":["Tim Ziemer"],"pdf_url":"https://arxiv.org/pdf/2302.01090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11080v3","updated":"2023-02-02T12:56:15Z","published":"2022-12-21T15:27:52Z","title":"Is it worth it? Comparing six deep and classical methods for\n  unsupervised anomaly detection in time series","summary":"  Detecting anomalies in time series data is important in a variety of fields,\nincluding system monitoring, healthcare, and cybersecurity. While the abundance\nof available methods makes it difficult to choose the most appropriate method\nfor a given application, each method has its strengths in detecting certain\ntypes of anomalies. In this study, we compare six unsupervised anomaly\ndetection methods of varying complexity to determine whether more complex\nmethods generally perform better and if certain methods are better suited to\ncertain types of anomalies. We evaluated the methods using the UCR anomaly\narchive, a recent benchmark dataset for anomaly detection. We analyzed the\nresults on a dataset and anomaly type level after adjusting the necessary\nhyperparameters for each method. Additionally, we assessed the ability of each\nmethod to incorporate prior knowledge about anomalies and examined the\ndifferences between point-wise and sequence-wise features. Our experiments show\nthat classical machine learning methods generally outperform deep learning\nmethods across a range of anomaly types.\n","authors":["Ferdinand Rewicki","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2212.11080v3.pdf","comment":"17 Pages, The repository to reproduce the results is available at\n  https://gitlab.com/dlr-dw/is-it-worth-it-benchmark"},{"id":"http://arxiv.org/abs/2202.08063v3","updated":"2023-02-02T12:17:25Z","published":"2022-02-16T13:44:00Z","title":"Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective","summary":"  Knowledge Extraction (KE), aiming to extract structural information from\nunstructured texts, often suffers from data scarcity and emerging unseen types,\ni.e., low-resource scenarios. Many neural approaches to low-resource KE have\nbeen widely investigated and achieved impressive performance. In this paper, we\npresent a literature review towards KE in low-resource scenarios, and\nsystematically categorize existing works into three paradigms: (1) exploiting\nhigher-resource data, (2) exploiting stronger models, and (3) exploiting data\nand models together. In addition, we highlight promising applications and\noutline some potential directions for future research. We hope that our survey\ncan help both the academic and industrial communities to better understand this\nfield, inspire more ideas, and boost broader applications.\n","authors":["Shumin Deng","Ningyu Zhang","Feiyu Xiong","Jeff Z. Pan","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2202.08063v3.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2302.03497v1","updated":"2023-02-02T02:59:00Z","published":"2023-02-02T02:59:00Z","title":"MMRec: Simplifying Multimodal Recommendation","summary":"  This paper presents an open-source toolbox, MMRec for multimodal\nrecommendation. MMRec simplifies and canonicalizes the process of implementing\nand comparing multimodal recommendation models. The objective of MMRec is to\nprovide a unified and configurable arena that can minimize the effort in\nimplementing and testing multimodal recommendation models. It enables\nmultimodal models, ranging from traditional matrix factorization to modern\ngraph-based algorithms, capable of fusing information from multiple modalities\nsimultaneously. Our documentation, examples, and source code are available at\n\\url{https://github.com/enoche/MMRec}.\n","authors":["Xin Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.03497v1.pdf","comment":"3 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.01333v1","updated":"2023-02-02T18:59:30Z","published":"2023-02-02T18:59:30Z","title":"Lower Bounds for Learning in Revealing POMDPs","summary":"  This paper studies the fundamental limits of reinforcement learning (RL) in\nthe challenging \\emph{partially observable} setting. While it is\nwell-established that learning in Partially Observable Markov Decision\nProcesses (POMDPs) requires exponentially many samples in the worst case, a\nsurge of recent work shows that polynomial sample complexities are achievable\nunder the \\emph{revealing condition} -- A natural condition that requires the\nobservables to reveal some information about the unobserved latent states.\nHowever, the fundamental limits for learning in revealing POMDPs are much less\nunderstood, with existing lower bounds being rather preliminary and having\nsubstantial gaps from the current best upper bounds.\n  We establish strong PAC and regret lower bounds for learning in revealing\nPOMDPs. Our lower bounds scale polynomially in all relevant problem parameters\nin a multiplicative fashion, and achieve significantly smaller gaps against the\ncurrent best upper bounds, providing a solid starting point for future studies.\nIn particular, for \\emph{multi-step} revealing POMDPs, we show that (1) the\nlatent state-space dependence is at least $\\Omega(S^{1.5})$ in the PAC sample\ncomplexity, which is notably harder than the $\\widetilde{\\Theta}(S)$ scaling\nfor fully-observable MDPs; (2) Any polynomial sublinear regret is at least\n$\\Omega(T^{2/3})$, suggesting its fundamental difference from the\n\\emph{single-step} case where $\\widetilde{O}(\\sqrt{T})$ regret is achievable.\nTechnically, our hard instance construction adapts techniques in\n\\emph{distribution testing}, which is new to the RL literature and may be of\nindependent interest.\n","authors":["Fan Chen","Huan Wang","Caiming Xiong","Song Mei","Yu Bai"],"pdf_url":"https://arxiv.org/pdf/2302.01333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01332v1","updated":"2023-02-02T18:59:23Z","published":"2023-02-02T18:59:23Z","title":"Bayesian Metric Learning for Uncertainty Quantification in Image\n  Retrieval","summary":"  We propose the first Bayesian encoder for metric learning. Rather than\nrelying on neural amortization as done in prior works, we learn a distribution\nover the network weights with the Laplace Approximation. We actualize this by\nfirst proving that the contrastive loss is a valid log-posterior. We then\npropose three methods that ensure a positive definite Hessian. Lastly, we\npresent a novel decomposition of the Generalized Gauss-Newton approximation.\nEmpirically, we show that our Laplacian Metric Learner (LAM) estimates\nwell-calibrated uncertainties, reliably detects out-of-distribution examples,\nand yields state-of-the-art predictive performance.\n","authors":["Frederik Warburg","Marco Miani","Silas Brack","Soren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2302.01332v1.pdf","comment":"Code: https://github.com/FrederikWarburg/bayesian-metric-learning"},{"id":"http://arxiv.org/abs/2302.01328v1","updated":"2023-02-02T18:58:05Z","published":"2023-02-02T18:58:05Z","title":"$IC^3$: Image Captioning by Committee Consensus","summary":"  If you ask a human to describe an image, they might do so in a thousand\ndifferent ways. Traditionally, image captioning models are trained to\napproximate the reference distribution of image captions, however, doing so\nencourages captions that are viewpoint-impoverished. Such captions often focus\non only a subset of the possible details, while ignoring potentially useful\ninformation in the scene. In this work, we introduce a simple, yet novel,\nmethod: \"Image Captioning by Committee Consensus\" ($IC^3$), designed to\ngenerate a single caption that captures high-level details from several\nviewpoints. Notably, humans rate captions produced by $IC^3$ at least as\nhelpful as baseline SOTA models more than two thirds of the time, and $IC^3$\ncaptions can improve the performance of SOTA automated recall systems by up to\n84%, indicating significant material improvements over existing SOTA approaches\nfor visual description. Our code is publicly available at\nhttps://github.com/DavidMChan/caption-by-committee\n","authors":["David M. Chan","Austin Myers","Sudheendra Vijayanarasimhan","David A. Ross","John Canny"],"pdf_url":"https://arxiv.org/pdf/2302.01328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01327v1","updated":"2023-02-02T18:56:25Z","published":"2023-02-02T18:56:25Z","title":"Dual PatchNorm","summary":"  We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms),\nbefore and after the patch embedding layer in Vision Transformers. We\ndemonstrate that Dual PatchNorm outperforms the result of exhaustive search for\nalternative LayerNorm placement strategies in the Transformer block itself. In\nour experiments, incorporating this trivial modification, often leads to\nimproved accuracy over well-tuned Vision Transformers and never hurts.\n","authors":["Manoj Kumar","Mostafa Dehghani","Neil Houlsby"],"pdf_url":"https://arxiv.org/pdf/2302.01327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01326v1","updated":"2023-02-02T18:56:24Z","published":"2023-02-02T18:56:24Z","title":"Federated Analytics: A survey","summary":"  Federated analytics (FA) is a privacy-preserving framework for computing data\nanalytics over multiple remote parties (e.g., mobile devices) or silo-ed\ninstitutional entities (e.g., hospitals, banks) without sharing the data among\nparties. Motivated by the practical use cases of federated analytics, we follow\na systematic discussion on federated analytics in this article. In particular,\nwe discuss the unique characteristics of federated analytics and how it differs\nfrom federated learning. We also explore a wide range of FA queries and discuss\nvarious existing solutions and potential use case applications for different FA\nqueries.\n","authors":["Ahmed Roushdy Elkordy","Yahya H. Ezzeldin","Shanshan Han","Shantanu Sharma","Chaoyang He","Sharad Mehrotra","Salman Avestimehr"],"pdf_url":"https://arxiv.org/pdf/2302.01326v1.pdf","comment":"To appear in APSIPA Transactions on Signal and Information\n  Processing, Volume 12, Issue 1"},{"id":"http://arxiv.org/abs/2302.01324v1","updated":"2023-02-02T18:52:14Z","published":"2023-02-02T18:52:14Z","title":"Randomized Greedy Learning for Non-monotone Stochastic Submodular\n  Maximization Under Full-bandit Feedback","summary":"  We investigate the problem of unconstrained combinatorial multi-armed bandits\nwith full-bandit feedback and stochastic rewards for submodular maximization.\nPrevious works investigate the same problem assuming a submodular and monotone\nreward function. In this work, we study a more general problem, i.e., when the\nreward function is not necessarily monotone, and the submodularity is assumed\nonly in expectation. We propose Randomized Greedy Learning (RGL) algorithm and\ntheoretically prove that it achieves a $\\frac{1}{2}$-regret upper bound of\n$\\tilde{\\mathcal{O}}(n T^{\\frac{2}{3}})$ for horizon $T$ and number of arms\n$n$. We also show in experiments that RGL empirically outperforms other\nfull-bandit variants in submodular and non-submodular settings.\n","authors":["Fares Fourati","Vaneet Aggarwal","Christopher John Quinn","Mohamed-Slim Alouini"],"pdf_url":"https://arxiv.org/pdf/2302.01324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01316v1","updated":"2023-02-02T18:43:16Z","published":"2023-02-02T18:43:16Z","title":"Are Diffusion Models Vulnerable to Membership Inference Attacks?","summary":"  Diffusion-based generative models have shown great potential for image\nsynthesis, but there is a lack of research on the security and privacy risks\nthey may pose. In this paper, we investigate the vulnerability of diffusion\nmodels to Membership Inference Attacks (MIAs), a common privacy concern. Our\nresults indicate that existing MIAs designed for GANs or VAE are largely\nineffective on diffusion models, either due to inapplicable scenarios (e.g.,\nrequiring the discriminator of GANs) or inappropriate assumptions (e.g., closer\ndistances between synthetic images and member images). To address this gap, we\npropose Step-wise Error Comparing Membership Inference (SecMI), a black-box MIA\nthat infers memberships by assessing the matching of forward process posterior\nestimation at each timestep. SecMI follows the common overfitting assumption in\nMIA where member samples normally have smaller estimation errors, compared with\nhold-out samples. We consider both the standard diffusion models, e.g., DDPM,\nand the text-to-image diffusion models, e.g., Stable Diffusion. Experimental\nresults demonstrate that our methods precisely infer the membership with high\nconfidence on both of the two scenarios across six different datasets\n","authors":["Jinhao Duan","Fei Kong","Shiqi Wang","Xiaoshuang Shi","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2302.01316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01313v1","updated":"2023-02-02T18:39:30Z","published":"2023-02-02T18:39:30Z","title":"Double Permutation Equivariance for Knowledge Graph Completion","summary":"  This work provides a formalization of Knowledge Graphs (KGs) as a new class\nof graphs that we denote doubly exchangeable attributed graphs, where node and\npairwise (joint 2-node) representations must be equivariant to permutations of\nboth node ids and edge (& node) attributes (relations & node features).\nDouble-permutation equivariant KG representations open a new research direction\nin KGs. We show that this equivariance imposes a structural representation of\nrelations that allows neural networks to perform complex logical reasoning\ntasks in KGs. Finally, we introduce a general blueprint for such equivariant\nrepresentations and test a simple GNN-based double-permutation equivariant\nneural architecture that achieve 100% Hits@10 test accuracy in both the\nWN18RRv1 and NELL995v1 inductive KG completion tasks, and can accurately\nperform logical reasoning tasks that no existing methods can perform, to the\nbest of our knowledge.\n","authors":["Jianfei Gao","Yangze Zhou","Bruno Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2302.01313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10769v2","updated":"2023-02-02T18:38:42Z","published":"2022-10-19T17:58:09Z","title":"\"Why did the Model Fail?\": Attributing Model Performance Changes to\n  Distribution Shifts","summary":"  Performance of machine learning models may differ between training and\ndeployment for many reasons. For instance, model performance can change between\nenvironments due to changes in data quality, observing a different population\nthan the one in training, or changes in the relationship between labels and\nfeatures. These changes result in distribution shifts across environments.\nAttributing model performance changes to specific shifts is critical for\nidentifying sources of model failures, and for taking mitigating actions that\nensure robust models. In this work, we introduce the problem of attributing\nperformance differences between environments to distribution shifts in the\nunderlying data generating mechanisms. We formulate the problem as a\ncooperative game where the players are distributions. We define the value of a\nset of distributions to be the change in model performance when only this set\nof distributions has changed between environments, and derive an importance\nweighting method for computing the value of an arbitrary set of distributions.\nThe contribution of each distribution to the total performance change is then\nquantified as its Shapley value. We demonstrate the correctness and utility of\nour method on synthetic, semi-synthetic, and real-world case studies, showing\nits effectiveness in attributing performance changes to a wide range of\ndistribution shifts.\n","authors":["Haoran Zhang","Harvineet Singh","Marzyeh Ghassemi","Shalmali Joshi"],"pdf_url":"https://arxiv.org/pdf/2210.10769v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01312v1","updated":"2023-02-02T18:38:35Z","published":"2023-02-02T18:38:35Z","title":"Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty\n  Modeling","summary":"  In this work, we demonstrate how to reliably estimate epistemic uncertainty\nwhile maintaining the flexibility needed to capture complicated aleatoric\ndistributions. To this end, we propose an ensemble of Normalizing Flows (NF),\nwhich are state-of-the-art in modeling aleatoric uncertainty. The ensembles are\ncreated via sets of fixed dropout masks, making them less expensive than\ncreating separate NF models. We demonstrate how to leverage the unique\nstructure of NFs, base distributions, to estimate aleatoric uncertainty without\nrelying on samples, provide a comprehensive set of baselines, and derive\nunbiased estimates for differential entropy. The methods were applied to a\nvariety of experiments, commonly used to benchmark aleatoric and epistemic\nuncertainty estimation: 1D sinusoidal data, 2D windy grid-world ($\\it{Wet\nChicken}$), $\\it{Pendulum}$, and $\\it{Hopper}$. In these experiments, we setup\nan active learning framework and evaluate each model's capability at measuring\naleatoric and epistemic uncertainty. The results show the advantages of using\nNF ensembles in capturing complicated aleatoric while maintaining accurate\nepistemic uncertainty estimates.\n","authors":["Lucas Berry","David Meger"],"pdf_url":"https://arxiv.org/pdf/2302.01312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01310v1","updated":"2023-02-02T18:33:34Z","published":"2023-02-02T18:33:34Z","title":"Bayesian Optimization of Multiple Objectives with Different Latencies","summary":"  Multi-objective Bayesian optimization aims to find the Pareto front of\noptimal trade-offs between a set of expensive objectives while collecting as\nfew samples as possible. In some cases, it is possible to evaluate the\nobjectives separately, and a different latency or evaluation cost can be\nassociated with each objective. This presents an opportunity to learn the\nPareto front faster by evaluating the cheaper objectives more frequently. We\npropose a scalarization based knowledge gradient acquisition function which\naccounts for the different evaluation costs of the objectives. We prove\nconsistency of the algorithm and show empirically that it significantly\noutperforms a benchmark algorithm which always evaluates both objectives.\n","authors":["Jack M. Buckingham","Sebastian Rojas Gonzalez","Juergen Branke"],"pdf_url":"https://arxiv.org/pdf/2302.01310v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2302.01308v1","updated":"2023-02-02T18:32:46Z","published":"2023-02-02T18:32:46Z","title":"What Language Reveals about Perception: Distilling Psychophysical\n  Knowledge from Large Language Models","summary":"  Understanding the extent to which the perceptual world can be recovered from\nlanguage is a fundamental problem in cognitive science. We reformulate this\nproblem as that of distilling psychophysical information from text and show how\nthis can be done by combining large language models (LLMs) with a classic\npsychophysical method based on similarity judgments. Specifically, we use the\nprompt auto-completion functionality of GPT3, a state-of-the-art LLM, to elicit\nsimilarity scores between stimuli and then apply multidimensional scaling to\nuncover their underlying psychological space. We test our approach on six\nperceptual domains and show that the elicited judgments strongly correlate with\nhuman data and successfully recover well-known psychophysical structures such\nas the color wheel and pitch spiral. We also explore meaningful divergences\nbetween LLM and human representations. Our work showcases how combining\nstate-of-the-art machine models with well-known cognitive paradigms can shed\nnew light on fundamental questions in perception and language research.\n","authors":["Raja Marjieh","Ilia Sucholutsky","Pol van Rijn","Nori Jacoby","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2302.01308v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.01302v1","updated":"2023-02-02T18:27:31Z","published":"2023-02-02T18:27:31Z","title":"Bayesian Inference on Binary Spiking Networks Leveraging Nanoscale\n  Device Stochasticity","summary":"  Bayesian Neural Networks (BNNs) can overcome the problem of overconfidence\nthat plagues traditional frequentist deep neural networks, and are hence\nconsidered to be a key enabler for reliable AI systems. However, conventional\nhardware realizations of BNNs are resource intensive, requiring the\nimplementation of random number generators for synaptic sampling. Owing to\ntheir inherent stochasticity during programming and read operations, nanoscale\nmemristive devices can be directly leveraged for sampling, without the need for\nadditional hardware resources. In this paper, we introduce a novel Phase Change\nMemory (PCM)-based hardware implementation for BNNs with binary synapses. The\nproposed architecture consists of separate weight and noise planes, in which\nPCM cells are configured and operated to represent the nominal values of\nweights and to generate the required noise for sampling, respectively. Using\nexperimentally observed PCM noise characteristics, for the exemplary Breast\nCancer Dataset classification problem, we obtain hardware accuracy and expected\ncalibration error matching that of an 8-bit fixed-point (FxP8) implementation,\nwith projected savings of over 9$\\times$ in terms of core area transistor\ncount.\n","authors":["Prabodh Katti","Nicolas Skatchkovsky","Osvaldo Simeone","Bipin Rajendran","Bashir M. Al-Hashimi"],"pdf_url":"https://arxiv.org/pdf/2302.01302v1.pdf","comment":"Submitted and Accepted in ISCAS 2023"},{"id":"http://arxiv.org/abs/2302.01301v1","updated":"2023-02-02T18:27:20Z","published":"2023-02-02T18:27:20Z","title":"MARLIN: Soft Actor-Critic based Reinforcement Learning for Congestion\n  Control in Real Networks","summary":"  Fast and efficient transport protocols are the foundation of an increasingly\ndistributed world. The burden of continuously delivering improved communication\nperformance to support next-generation applications and services, combined with\nthe increasing heterogeneity of systems and network technologies, has promoted\nthe design of Congestion Control (CC) algorithms that perform well under\nspecific environments. The challenge of designing a generic CC algorithm that\ncan adapt to a broad range of scenarios is still an open research question. To\ntackle this challenge, we propose to apply a novel Reinforcement Learning (RL)\napproach. Our solution, MARLIN, uses the Soft Actor-Critic algorithm to\nmaximize both entropy and return and models the learning process as an\ninfinite-horizon task. We trained MARLIN on a real network with varying\nbackground traffic patterns to overcome the sim-to-real mismatch that\nresearchers have encountered when applying RL to CC. We evaluated our solution\non the task of file transfer and compared it to TCP Cubic. While further\nresearch is required, results have shown that MARLIN can achieve comparable\nresults to TCP with little hyperparameter tuning, in a task significantly\ndifferent from its training setting. Therefore, we believe that our work\nrepresents a promising first step toward building CC algorithms based on the\nmaximum entropy RL framework.\n","authors":["Raffaele Galliera","Alessandro Morelli","Roberto Fronteddu","Niranjan Suri"],"pdf_url":"https://arxiv.org/pdf/2302.01301v1.pdf","comment":"10 pages, 5 figures, AAAI 2023 workshop \"Reinforcement Learning Ready\n  for Production\", accepted at NOMS 2023 - IEEE/IFIP Network Operations and\n  Management Symposium"},{"id":"http://arxiv.org/abs/2003.13438v3","updated":"2023-02-02T18:22:54Z","published":"2020-03-30T13:03:28Z","title":"Analysis of Knowledge Transfer in Kernel Regime","summary":"  Knowledge transfer is shown to be a very successful technique for training\nneural classifiers: together with the ground truth data, it uses the\n\"privileged information\" (PI) obtained by a \"teacher\" network to train a\n\"student\" network. It has been observed that classifiers learn much faster and\nmore reliably via knowledge transfer. However, there has been little or no\ntheoretical analysis of this phenomenon. To bridge this gap, we propose to\napproach the problem of knowledge transfer by regularizing the fit between the\nteacher and the student with PI provided by the teacher. Using tools from\ndynamical systems theory, we show that when the student is an extremely wide\ntwo layer network, we can analyze it in the kernel regime and show that it is\nable to interpolate between PI and the given data. This characterization sheds\nnew light on the relation between the training error and capacity of the\nstudent relative to the teacher. Another contribution of the paper is a\nquantitative statement on the convergence of student network. We prove that the\nteacher reduces the number of required iterations for a student to learn, and\nconsequently improves the generalization power of the student. We give\ncorresponding experimental analysis that validates the theoretical results and\nyield additional insights.\n","authors":["Arman Rahbar","Ashkan Panahi","Chiranjib Bhattacharyya","Devdatt Dubhashi","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2003.13438v3.pdf","comment":"The work is published by CIKM 2022"},{"id":"http://arxiv.org/abs/2301.11962v2","updated":"2023-02-02T18:21:48Z","published":"2023-01-27T19:32:27Z","title":"On the Feasibility of Machine Learning Augmented Magnetic Resonance for\n  Point-of-Care Identification of Disease","summary":"  Early detection of many life-threatening diseases (e.g., prostate and breast\ncancer) within at-risk population can improve clinical outcomes and reduce cost\nof care. While numerous disease-specific \"screening\" tests that are closer to\nPoint-of-Care (POC) are in use for this task, their low specificity results in\nunnecessary biopsies, leading to avoidable patient trauma and wasteful\nhealthcare spending. On the other hand, despite the high accuracy of Magnetic\nResonance (MR) imaging in disease diagnosis, it is not used as a POC disease\nidentification tool because of poor accessibility. The root cause of poor\naccessibility of MR stems from the requirement to reconstruct high-fidelity\nimages, as it necessitates a lengthy and complex process of acquiring large\nquantities of high-quality k-space measurements. In this study we explore the\nfeasibility of an ML-augmented MR pipeline that directly infers the disease\nsidestepping the image reconstruction process. We hypothesise that the disease\nclassification task can be solved using a very small tailored subset of k-space\ndata, compared to image reconstruction. Towards that end, we propose a method\nthat performs two tasks: 1) identifies a subset of the k-space that maximizes\ndisease identification accuracy, and 2) infers the disease directly using the\nidentified k-space subset, bypassing the image reconstruction step. We validate\nour hypothesis by measuring the performance of the proposed system across\nmultiple diseases and anatomies. We show that comparable performance to\nimage-based classifiers, trained on images reconstructed with full k-space\ndata, can be achieved using small quantities of data: 8% of the data for\ndetecting multiple abnormalities in prostate and brain scans, and 5% of the\ndata for knee abnormalities. To better understand the proposed approach and\ninstigate future research, we provide an extensive analysis and release code.\n","authors":["Raghav Singhal","Mukund Sudarshan","Anish Mahishi","Sri Kaushik","Luke Ginocchio","Angela Tong","Hersh Chandarana","Daniel K. Sodickson","Rajesh Ranganath","Sumit Chopra"],"pdf_url":"https://arxiv.org/pdf/2301.11962v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12246v2","updated":"2023-02-02T18:19:37Z","published":"2023-01-28T16:42:05Z","title":"A Closer Look at Few-shot Classification Again","summary":"  Few-shot classification consists of a training phase where a model is learned\non a relatively large dataset and an adaptation phase where the learned model\nis adapted to previously-unseen tasks with limited labeled samples. In this\npaper, we empirically prove that the training algorithm and the adaptation\nalgorithm can be completely disentangled, which allows algorithm analysis and\ndesign to be done individually for each phase. Our meta-analysis for each phase\nreveals several interesting insights that may help better understand key\naspects of few-shot classification and connections with other fields such as\nvisual representation learning and transfer learning. We hope the insights and\nresearch challenges revealed in this paper can inspire future work in related\ndirections.\n","authors":["Xu Luo","Hao Wu","Ji Zhang","Lianli Gao","Jing Xu","Jingkuan Song"],"pdf_url":"https://arxiv.org/pdf/2301.12246v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11118v2","updated":"2023-02-02T18:15:52Z","published":"2023-01-26T14:13:37Z","title":"Box$^2$EL: Concept and Role Box Embeddings for the Description Logic\n  EL++","summary":"  Representation learning in the form of semantic embeddings has been\nsuccessfully applied to a variety of tasks in natural language processing and\nknowledge graphs. Recently, there has been growing interest in developing\nsimilar methods for learning embeddings of entire ontologies. We propose\nBox$^2$EL, a novel method for representation learning of ontologies in the\nDescription Logic EL++, which represents both concepts and roles as boxes (i.e.\naxis-aligned hyperrectangles), such that the logical structure of the ontology\nis preserved. We theoretically prove the soundness of our model and conduct an\nextensive empirical evaluation, in which we achieve state-of-the-art results in\nsubsumption prediction, link prediction, and deductive reasoning. As part of\nour evaluation, we introduce a novel benchmark for evaluating EL++ embedding\nmodels on predicting subsumptions involving both atomic and complex concepts.\n","authors":["Mathias Jackermeier","Jiaoyan Chen","Ian Horrocks"],"pdf_url":"https://arxiv.org/pdf/2301.11118v2.pdf","comment":"Corrected the GitHub URL and updated baselines"},{"id":"http://arxiv.org/abs/2302.01278v1","updated":"2023-02-02T18:12:08Z","published":"2023-02-02T18:12:08Z","title":"Convolutional Autoencoders, Clustering and POD for Low-dimensional\n  Parametrization of Navier-Stokes Equations","summary":"  Simulations of large-scale dynamical systems require expensive computations.\nLow-dimensional parametrization of high-dimensional states such as Proper\nOrthogonal Decomposition (POD) can be a solution to lessen the burdens by\nproviding a certain compromise between accuracy and model complexity. However,\nfor really low-dimensional parametrizations (for example for controller design)\nlinear methods like the POD come to their natural limits so that nonlinear\napproaches will be the methods of choice. In this work we propose a\nconvolutional autoencoder (CAE) consisting of a nonlinear encoder and an affine\nlinear decoder and consider combinations with k-means clustering for improved\nencoding performance. The proposed set of methods is compared to the standard\nPOD approach in two cylinder-wake scenarios modeled by the incompressible\nNavier-Stokes equations.\n","authors":["Yongho Kim","Jan Heiland"],"pdf_url":"https://arxiv.org/pdf/2302.01278v1.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2212.14468v2","updated":"2023-02-02T18:08:26Z","published":"2022-12-29T22:06:51Z","title":"An Instrumental Variable Approach to Confounded Off-Policy Evaluation","summary":"  Off-policy evaluation (OPE) is a method for estimating the return of a target\npolicy using some pre-collected observational data generated by a potentially\ndifferent behavior policy. In some cases, there may be unmeasured variables\nthat can confound the action-reward or action-next-state relationships,\nrendering many existing OPE approaches ineffective. This paper develops an\ninstrumental variable (IV)-based method for consistent OPE in confounded Markov\ndecision processes (MDPs). Similar to single-stage decision making, we show\nthat IV enables us to correctly identify the target policy's value in infinite\nhorizon settings as well. Furthermore, we propose an efficient and robust value\nestimator and illustrate its effectiveness through extensive simulations and\nanalysis of real data from a world-leading short-video platform.\n","authors":["Yang Xu","Jin Zhu","Chengchun Shi","Shikai Luo","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2212.14468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01275v1","updated":"2023-02-02T18:05:27Z","published":"2023-02-02T18:05:27Z","title":"ReLOAD: Reinforcement Learning with Optimistic Ascent-Descent for\n  Last-Iterate Convergence in Constrained MDPs","summary":"  In recent years, Reinforcement Learning (RL) has been applied to real-world\nproblems with increasing success. Such applications often require to put\nconstraints on the agent's behavior. Existing algorithms for constrained RL\n(CRL) rely on gradient descent-ascent, but this approach comes with a caveat.\nWhile these algorithms are guaranteed to converge on average, they do not\nguarantee last-iterate convergence, i.e., the current policy of the agent may\nnever converge to the optimal solution. In practice, it is often observed that\nthe policy alternates between satisfying the constraints and maximizing the\nreward, rarely accomplishing both objectives simultaneously. Here, we address\nthis problem by introducing Reinforcement Learning with Optimistic\nAscent-Descent (ReLOAD), a principled CRL method with guaranteed last-iterate\nconvergence. We demonstrate its empirical effectiveness on a wide variety of\nCRL problems including discrete MDPs and continuous control. In the process we\nestablish a benchmark of challenging CRL problems.\n","authors":["Ted Moskovitz","Brendan O'Donoghue","Vivek Veeriah","Sebastian Flennerhag","Satinder Singh","Tom Zahavy"],"pdf_url":"https://arxiv.org/pdf/2302.01275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12141v2","updated":"2023-02-02T18:02:58Z","published":"2022-07-25T12:45:58Z","title":"Live in the Moment: Learning Dynamics Model Adapted to Evolving Policy","summary":"  Model-based reinforcement learning (RL) often achieves higher sample\nefficiency in practice than model-free RL by learning a dynamics model to\ngenerate samples for policy learning. Previous works learn a dynamics model\nthat fits under the empirical state-action visitation distribution for all\nhistorical policies, i.e., the sample replay buffer. However, in this paper, we\nobserve that fitting the dynamics model under the distribution for \\emph{all\nhistorical policies} does not necessarily benefit model prediction for the\n\\emph{current policy} since the policy in use is constantly evolving over time.\nThe evolving policy during training will cause state-action visitation\ndistribution shifts. We theoretically analyze how this distribution shift over\nhistorical policies affects the model learning and model rollouts. We then\npropose a novel dynamics model learning method, named \\textit{Policy-adapted\nDynamics Model Learning (PDML)}. PDML dynamically adjusts the historical policy\nmixture distribution to ensure the learned model can continually adapt to the\nstate-action visitation distribution of the evolving policy. Experiments on a\nrange of continuous control environments in MuJoCo show that PDML achieves\nsignificant improvement in sample efficiency and higher asymptotic performance\ncombined with the state-of-the-art model-based RL methods.\n","authors":["Xiyao Wang","Wichayaporn Wongkamjan","Ruonan Jia","Furong Huang"],"pdf_url":"https://arxiv.org/pdf/2207.12141v2.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.01259v1","updated":"2023-02-02T17:45:02Z","published":"2023-02-02T17:45:02Z","title":"Geometric Deep Learning for Autonomous Driving: Unlocking the Power of\n  Graph Neural Networks With CommonRoad-Geometric","summary":"  Heterogeneous graphs offer powerful data representations for traffic, given\ntheir ability to model the complex interaction effects among a varying number\nof traffic participants and the underlying road infrastructure. With the recent\nadvent of graph neural networks (GNNs) as the accompanying deep learning\nframework, the graph structure can be efficiently leveraged for various machine\nlearning applications such as trajectory prediction. As a first of its kind,\nour proposed Python framework offers an easy-to-use and fully customizable data\nprocessing pipeline to extract standardized graph datasets from traffic\nscenarios. Providing a platform for GNN-based autonomous driving research, it\nimproves comparability between approaches and allows researchers to focus on\nmodel implementation instead of dataset curation.\n","authors":["Eivind Meyer","Maurice Brenner","Bowen Zhang","Max Schickert","Bilal Musani","Matthias Althoff"],"pdf_url":"https://arxiv.org/pdf/2302.01259v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01255v1","updated":"2023-02-02T17:39:10Z","published":"2023-02-02T17:39:10Z","title":"adSformers: Personalization from Short-Term Sequences and Diversity of\n  Representations in Etsy Ads","summary":"  In this article, we present our approach to personalizing Etsy Ads through\nencoding and learning from short-term (one-hour) sequences of user actions and\ndiverse representations. To this end we introduce a three-component adSformer\ndiversifiable personalization module (ADPM) and illustrate how we use this\nmodule to derive a short-term dynamic user representation and personalize the\nClick-Through Rate (CTR) and Post-Click Conversion Rate (PCCVR) models used in\nsponsored search (ad) ranking. The first component of the ADPM is a custom\ntransformer encoder that learns the inherent structure from the sequence of\nactions. ADPM's second component enriches the signal through visual, multimodal\nand textual pretrained representations. Lastly, the third ADPM component\nincludes a \"learned\" on the fly average pooled representation. The\nADPM-personalized CTR and PCCVR models, henceforth referred to as adSformer CTR\nand adSformer PCCVR, outperform the CTR and PCCVR production baselines by\n$+6.65\\%$ and $+12.70\\%$, respectively, in offline Precision-Recall Area Under\nthe Curve (PR AUC). At the time of this writing, following the online gains in\nA/B tests, such as $+5.34\\%$ in return on ad spend, a seller success metric, we\nare ramping up the adSformers to $100\\%$ traffic in Etsy Ads.\n","authors":["Alaa Awad","Denisa Roberts","Eden Dolev","Andrea Heyman","Zahra Ebrahimzadeh","Zoe Weil","Marcin Mejran","Vaibhav Malpani","Mahir Yavuz"],"pdf_url":"https://arxiv.org/pdf/2302.01255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01248v1","updated":"2023-02-02T17:29:10Z","published":"2023-02-02T17:29:10Z","title":"Avoiding Model Estimation in Robust Markov Decision Processes with a\n  Generative Model","summary":"  Robust Markov Decision Processes (MDPs) are getting more attention for\nlearning a robust policy which is less sensitive to environment changes. There\nare an increasing number of works analyzing sample-efficiency of robust MDPs.\nHowever, most works study robust MDPs in a model-based regime, where the\ntransition probability needs to be estimated and requires\n$\\mathcal{O}(|\\mathcal{S}|^2|\\mathcal{A}|)$ storage in memory. A common way to\nsolve robust MDPs is to formulate them as a distributionally robust\noptimization (DRO) problem. However, solving a DRO problem is non-trivial, so\nprior works typically assume a strong oracle to obtain the optimal solution of\nthe DRO problem easily. To remove the need for an oracle, we first transform\nthe original robust MDPs into an alternative form, as the alternative form\nallows us to use stochastic gradient methods to solve the robust MDPs.\nMoreover, we prove the alternative form still preserves the role of robustness.\nWith this new formulation, we devise a sample-efficient algorithm to solve the\nrobust MDPs in a model-free regime, from which we benefit lower memory space\n$\\mathcal{O}(|\\mathcal{S}||\\mathcal{A}|)$ without using the oracle. Finally, we\nvalidate our theoretical findings via numerical experiments and show the\nefficiency to solve the alternative form of robust MDPs.\n","authors":["Wenhao Yang","Han Wang","Tadashi Kozuno","Scott M. Jordan","Zhihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01244v1","updated":"2023-02-02T17:27:16Z","published":"2023-02-02T17:27:16Z","title":"Is Model Ensemble Necessary? Model-based RL via a Single Model with\n  Lipschitz Regularized Value Function","summary":"  Probabilistic dynamics model ensemble is widely used in existing model-based\nreinforcement learning methods as it outperforms a single dynamics model in\nboth asymptotic performance and sample efficiency. In this paper, we provide\nboth practical and theoretical insights on the empirical success of the\nprobabilistic dynamics model ensemble through the lens of Lipschitz continuity.\nWe find that, for a value function, the stronger the Lipschitz condition is,\nthe smaller the gap between the true dynamics- and learned dynamics-induced\nBellman operators is, thus enabling the converged value function to be closer\nto the optimal value function. Hence, we hypothesize that the key functionality\nof the probabilistic dynamics model ensemble is to regularize the Lipschitz\ncondition of the value function using generated samples. To test this\nhypothesis, we devise two practical robust training mechanisms through\ncomputing the adversarial noise and regularizing the value network's spectral\nnorm to directly regularize the Lipschitz condition of the value functions.\nEmpirical results show that combined with our mechanisms, model-based RL\nalgorithms with a single dynamics model outperform those with an ensemble of\nprobabilistic dynamics models. These findings not only support the theoretical\ninsight, but also provide a practical solution for developing computationally\nefficient model-based RL algorithms.\n","authors":["Ruijie Zheng","Xiyao Wang","Huazhe Xu","Furong Huang"],"pdf_url":"https://arxiv.org/pdf/2302.01244v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01243v1","updated":"2023-02-02T17:25:29Z","published":"2023-02-02T17:25:29Z","title":"Human not in the loop: objective sample difficulty measures for\n  Curriculum Learning","summary":"  Curriculum learning is a learning method that trains models in a meaningful\norder from easier to harder samples. A key here is to devise automatic and\nobjective difficulty measures of samples. In the medical domain, previous work\napplied domain knowledge from human experts to qualitatively assess\nclassification difficulty of medical images to guide curriculum learning, which\nrequires extra annotation efforts, relies on subjective human experience, and\nmay introduce bias. In this work, we propose a new automated curriculum\nlearning technique using the variance of gradients (VoG) to compute an\nobjective difficulty measure of samples and evaluated its effects on elbow\nfracture classification from X-ray images. Specifically, we used VoG as a\nmetric to rank each sample in terms of the classification difficulty, where\nhigh VoG scores indicate more difficult cases for classification, to guide the\ncurriculum training process We compared the proposed technique to a baseline\n(without curriculum learning), a previous method that used human annotations on\nclassification difficulty, and anti-curriculum learning. Our experiment results\nshowed comparable and higher performance for the binary and multi-class bone\nfracture classification tasks.\n","authors":["Zhengbo Zhou","Jun Luo","Gene Kitamura","Shandong Wu"],"pdf_url":"https://arxiv.org/pdf/2302.01243v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2302.01242v1","updated":"2023-02-02T17:24:43Z","published":"2023-02-02T17:24:43Z","title":"Neuro Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and\n  Concept Rehearsal","summary":"  We introduce Neuro-Symbolic Continual Learning, where a model has to solve a\nsequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to\nhigh-level concepts and compute predictions by reasoning consistently with\nprior knowledge. Our key observation is that neuro-symbolic tasks, although\ndifferent, often share concepts whose semantics remains stable over time.\nTraditional approaches fall short: existing continual strategies ignore\nknowledge altogether, while stock neuro-symbolic architectures suffer from\ncatastrophic forgetting. We show that leveraging prior knowledge by combining\nneuro-symbolic architectures with continual strategies does help avoid\ncatastrophic forgetting, but also that doing so can yield models affected by\nreasoning shortcuts. These undermine the semantics of the acquired concepts,\neven when detailed prior knowledge is provided upfront and inference is exact,\nand in turn continual performance. To overcome these issues, we introduce COOL,\na COncept-level cOntinual Learning strategy tailored for neuro-symbolic\ncontinual problems that acquires high-quality concepts and remembers them over\ntime. Our experiments on three novel benchmarks highlights how COOL attains\nsustained high performance on neuro-symbolic continual learning tasks in which\nother strategies fail.\n","authors":["Emanuele Marconato","Gianpaolo Bontempo","Elisa Ficarra","Simone Calderara","Andrea Passerini","Stefano Teso"],"pdf_url":"https://arxiv.org/pdf/2302.01242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01241v1","updated":"2023-02-02T17:23:28Z","published":"2023-02-02T17:23:28Z","title":"Diagrammatization: Rationalizing with diagrammatic AI explanations for\n  abductive reasoning on hypotheses","summary":"  Many visualizations have been developed for explainable AI (XAI), but they\noften require further reasoning by users to interpret. We argue that XAI should\nsupport abductive reasoning - inference to the best explanation - with\ndiagrammatic reasoning to convey hypothesis generation and evaluation. Inspired\nby Peircean diagrammatic reasoning and the 5-step abduction process, we propose\nDiagrammatization, an approach to provide diagrammatic, abductive explanations\nbased on domain hypotheses. We implemented DiagramNet for a clinical\napplication to predict diagnoses from heart auscultation, and explain with\nshape-based murmur diagrams. In modeling studies, we found that DiagramNet not\nonly provides faithful murmur shape explanations, but also has better\nprediction performance than baseline models. We further demonstrate the\nusefulness of diagrammatic explanations in a qualitative user study with\nmedical students, showing that clinically-relevant, diagrammatic explanations\nare preferred over technical saliency map explanations. This work contributes\ninsights into providing domain-conventional abductive explanations for\nuser-centric XAI.\n","authors":["Brian Y. Lim","Joseph P. Cahaly","Chester Y. F. Sng","Adam Chew"],"pdf_url":"https://arxiv.org/pdf/2302.01241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01237v1","updated":"2023-02-02T17:20:25Z","published":"2023-02-02T17:20:25Z","title":"Robust Estimation under the Wasserstein Distance","summary":"  We study the problem of robust distribution estimation under the Wasserstein\nmetric, a popular discrepancy measure between probability distributions rooted\nin optimal transport (OT) theory. We introduce a new outlier-robust Wasserstein\ndistance $\\mathsf{W}_p^\\varepsilon$ which allows for $\\varepsilon$ outlier mass\nto be removed from its input distributions, and show that minimum distance\nestimation under $\\mathsf{W}_p^\\varepsilon$ achieves minimax optimal robust\nestimation risk. Our analysis is rooted in several new results for partial OT,\nincluding an approximate triangle inequality, which may be of independent\ninterest. To address computational tractability, we derive a dual formulation\nfor $\\mathsf{W}_p^\\varepsilon$ that adds a simple penalty term to the classic\nKantorovich dual objective. As such, $\\mathsf{W}_p^\\varepsilon$ can be\nimplemented via an elementary modification to standard, duality-based OT\nsolvers. Our results are extended to sliced OT, where distributions are\nprojected onto low-dimensional subspaces, and applications to homogeneity and\nindependence testing are explored. We illustrate the virtues of our framework\nvia applications to generative modeling with contaminated datasets.\n","authors":["Sloan Nietert","Rachel Cummings","Ziv Goldfeld"],"pdf_url":"https://arxiv.org/pdf/2302.01237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09633v2","updated":"2023-02-02T17:13:48Z","published":"2023-01-23T18:59:28Z","title":"Prediction-Powered Inference","summary":"  We introduce prediction-powered inference $\\unicode{x2013}$ a framework for\nperforming valid statistical inference when an experimental data set is\nsupplemented with predictions from a machine-learning system. Our framework\nyields provably valid conclusions without making any assumptions on the\nmachine-learning algorithm that supplies the predictions. Higher accuracy of\nthe predictions translates to smaller confidence intervals, permitting more\npowerful inference. Prediction-powered inference yields simple algorithms for\ncomputing valid confidence intervals for statistical objects such as means,\nquantiles, and linear and logistic regression coefficients. We demonstrate the\nbenefits of prediction-powered inference with data sets from proteomics,\ngenomics, electronic voting, remote sensing, census analysis, and ecology.\n","authors":["Anastasios N. Angelopoulos","Stephen Bates","Clara Fannjiang","Michael I. Jordan","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2301.09633v2.pdf","comment":"Code is available at\n  https://github.com/aangelopoulos/prediction-powered-inference"},{"id":"http://arxiv.org/abs/2302.01228v1","updated":"2023-02-02T17:07:36Z","published":"2023-02-02T17:07:36Z","title":"Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic\n  Neurons","summary":"  Activity difference based learning algorithms-such as contrastive Hebbian\nlearning and equilibrium propagation-have been proposed as biologically\nplausible alternatives to error back-propagation. However, on traditional\ndigital chips these algorithms suffer from having to solve a costly inference\nproblem twice, making these approaches more than two orders of magnitude slower\nthan back-propagation. In the analog realm equilibrium propagation may be\npromising for fast and energy efficient learning, but states still need to be\ninferred and stored twice. Inspired by lifted neural networks and compartmental\nneuron models we propose a simple energy based compartmental neuron model,\ntermed dual propagation, in which each neuron is a dyad with two intrinsic\nstates. At inference time these intrinsic states encode the error/activity\nduality through their difference and their mean respectively. The advantage of\nthis method is that only a single inference phase is needed and that inference\ncan be solved in layerwise closed-form. Experimentally we show on common\ncomputer vision datasets, including Imagenet32x32, that dual propagation\nperforms equivalently to back-propagation both in terms of accuracy and\nruntime.\n","authors":["Rasmus Høier","D. Staudt","Christopher Zach"],"pdf_url":"https://arxiv.org/pdf/2302.01228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01226v1","updated":"2023-02-02T17:06:50Z","published":"2023-02-02T17:06:50Z","title":"Factor Fields: A Unified Framework for Neural Fields and Beyond","summary":"  We present Factor Fields, a novel framework for modeling and representing\nsignals. Factor Fields decomposes a signal into a product of factors, each of\nwhich is represented by a neural or regular field representation operating on a\ncoordinate transformed input signal. We show that this decomposition yields a\nunified framework that generalizes several recent signal representations\nincluding NeRF, PlenOxels, EG3D, Instant-NGP, and TensoRF. Moreover, the\nframework allows for the creation of powerful new signal representations, such\nas the Coefficient-Basis Factorization (CoBaFa) which we propose in this paper.\nAs evidenced by our experiments, CoBaFa leads to improvements over previous\nfast reconstruction methods in terms of the three critical goals in neural\nsignal representation: approximation quality, compactness and efficiency.\nExperimentally, we demonstrate that our representation achieves better image\napproximation quality on 2D image regression tasks, higher geometric quality\nwhen reconstructing 3D signed distance fields and higher compactness for\nradiance field reconstruction tasks compared to previous fast reconstruction\nmethods. Besides, our CoBaFa representation enables generalization by sharing\nthe basis across signals during training, enabling generalization tasks such as\nimage regression with sparse observations and few-shot radiance field\nreconstruction.\n","authors":["Anpei Chen","Zexiang Xu","Xinyue Wei","Siyu Tang","Hao Su","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2302.01226v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.01223v1","updated":"2023-02-02T17:03:40Z","published":"2023-02-02T17:03:40Z","title":"Practical Bandits: An Industry Perspective","summary":"  The bandit paradigm provides a unified modeling framework for problems that\nrequire decision-making under uncertainty. Because many business metrics can be\nviewed as rewards (a.k.a. utilities) that result from actions, bandit\nalgorithms have seen a large and growing interest from industrial applications,\nsuch as search, recommendation and advertising. Indeed, with the bandit lens\ncomes the promise of direct optimisation for the metrics we care about.\n  Nevertheless, the road to successfully applying bandits in production is not\nan easy one. Even when the action space and rewards are well-defined,\npractitioners still need to make decisions regarding multi-arm or contextual\napproaches, on- or off-policy setups, delayed or immediate feedback, myopic or\nlong-term optimisation, etc. To make matters worse, industrial platforms\ntypically give rise to large action spaces in which existing approaches tend to\nbreak down. The research literature on these topics is broad and vast, but this\ncan overwhelm practitioners, whose primary aim is to solve practical problems,\nand therefore need to decide on a specific instantiation or approach for each\nproject. This tutorial will take a step towards filling that gap between the\ntheory and practice of bandits. Our goal is to present a unified overview of\nthe field and its existing terminology, concepts and algorithms -- with a focus\non problems relevant to industry. We hope our industrial perspective will help\nfuture practitioners who wish to leverage the bandit paradigm for their\napplication.\n","authors":["Bram van den Akker","Olivier Jeunen","Ying Li","Ben London","Zahra Nazari","Devesh Parekh"],"pdf_url":"https://arxiv.org/pdf/2302.01223v1.pdf","comment":"Tutorial held at The Web Conference 2023 (formerly known as WWW) in\n  Austin, Texas (USA), on April 30 - May 4, 2023"},{"id":"http://arxiv.org/abs/2302.01222v1","updated":"2023-02-02T17:03:08Z","published":"2023-02-02T17:03:08Z","title":"Temporal fusion transformer using variational mode decomposition for\n  wind power forecasting","summary":"  The power output of a wind turbine depends on a variety of factors, including\nwind speed at different heights, wind direction, temperature and turbine\nproperties. Wind speed and direction, in particular, have complex cycles and\nfluctuate dramatically, leading to large uncertainties in wind power output.\nThis study uses variational mode decomposition (VMD) to decompose the wind\npower series and Temporal fusion transformer (TFT) to forecast wind power for\nthe next 1h, 3h and 6h. The experimental results show that VMD outperforms\nother decomposition algorithms and the TFT model outperforms other\ndecomposition models.\n","authors":["Meiyu Jiang","Xuetao Jiang","Qingguo Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.01222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00753v1","updated":"2023-02-02T16:55:12Z","published":"2023-02-02T16:55:12Z","title":"High-precision regressors for particle physics","summary":"  Monte Carlo simulations of physics processes at particle colliders like the\nLarge Hadron Collider at CERN take up a major fraction of the computational\nbudget. For some simulations, a single data point takes seconds, minutes, or\neven hours to compute from first principles. Since the necessary number of data\npoints per simulation is on the order of $10^9$ - $10^{12}$, machine learning\nregressors can be used in place of physics simulators to significantly reduce\nthis computational burden. However, this task requires high-precision\nregressors that can deliver data with relative errors of less than $1\\%$ or\neven $0.1\\%$ over the entire domain of the function. In this paper, we develop\noptimal training strategies and tune various machine learning regressors to\nsatisfy the high-precision requirement. We leverage symmetry arguments from\nparticle physics to optimize the performance of the regressors. Inspired by\nResNets, we design a Deep Neural Network with skip connections that outperform\nfully connected Deep Neural Networks. We find that at lower dimensions, boosted\ndecision trees far outperform neural networks while at higher dimensions neural\nnetworks perform significantly better. We show that these regressors can speed\nup simulations by a factor of $10^3$ - $10^6$ over the first-principles\ncomputations currently used in Monte Carlo simulations. Additionally, using\nsymmetry arguments derived from particle physics, we reduce the number of\nregressors necessary for each simulation by an order of magnitude. Our work can\nsignificantly reduce the training and storage burden of Monte Carlo simulations\nat current and future collider experiments.\n","authors":["Fady Bishara","Ayan Paul","Jennifer Dy"],"pdf_url":"https://arxiv.org/pdf/2302.00753v1.pdf","comment":"15 pages, 7 figure and 2 tables"},{"id":"http://arxiv.org/abs/2302.01217v1","updated":"2023-02-02T16:55:03Z","published":"2023-02-02T16:55:03Z","title":"A Theoretical Justification for Image Inpainting using Denoising\n  Diffusion Probabilistic Models","summary":"  We provide a theoretical justification for sample recovery using diffusion\nbased image inpainting in a linear model setting. While most inpainting\nalgorithms require retraining with each new mask, we prove that diffusion based\ninpainting generalizes well to unseen masks without retraining. We analyze a\nrecently proposed popular diffusion based inpainting algorithm called RePaint\n(Lugmayr et al., 2022), and show that it has a bias due to misalignment that\nhampers sample recovery even in a two-state diffusion process. Motivated by our\nanalysis, we propose a modified RePaint algorithm we call RePaint$^+$ that\nprovably recovers the underlying true sample and enjoys a linear rate of\nconvergence. It achieves this by rectifying the misalignment error present in\ndrift and dispersion of the reverse process. To the best of our knowledge, this\nis the first linear convergence result for a diffusion based image inpainting\nalgorithm.\n","authors":["Litu Rout","Advait Parulekar","Constantine Caramanis","Sanjay Shakkottai"],"pdf_url":"https://arxiv.org/pdf/2302.01217v1.pdf","comment":"30 pages, 5 figures, 1 Table"},{"id":"http://arxiv.org/abs/2302.00628v2","updated":"2023-02-02T16:46:03Z","published":"2023-02-01T17:46:47Z","title":"Training Normalizing Flows with the Precision-Recall Divergence","summary":"  Generative models can have distinct mode of failures like mode dropping and\nlow quality samples, which cannot be captured by a single scalar metric. To\naddress this, recent works propose evaluating generative models using precision\nand recall, where precision measures quality of samples and recall measures the\ncoverage of the target distribution. Although a variety of discrepancy measures\nbetween the target and estimated distribution are used to train generative\nmodels, it is unclear what precision-recall trade-offs are achieved by various\nchoices of the discrepancy measures. In this paper, we show that achieving a\nspecified precision-recall trade-off corresponds to minimising -divergences\nfrom a family we call the {\\em PR-divergences }. Conversely, any -divergence\ncan be written as a linear combination of PR-divergences and therefore\ncorrespond to minimising a weighted precision-recall trade-off. Further, we\npropose a novel generative model that is able to train a normalizing flow to\nminimise any -divergence, and in particular, achieve a given precision-recall\ntrade-off.\n","authors":["Alexandre Verine","Benjamin Negrevergne","Muni Sreenivas Pydi","Yann Chevaleyre"],"pdf_url":"https://arxiv.org/pdf/2302.00628v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.12183v5","updated":"2023-02-02T16:37:48Z","published":"2022-02-24T16:37:07Z","title":"Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning\n  with Provable Convergence","summary":"  NDCG, namely Normalized Discounted Cumulative Gain, is a widely used ranking\nmetric in information retrieval and machine learning. However, efficient and\nprovable stochastic methods for maximizing NDCG are still lacking, especially\nfor deep models. In this paper, we propose a principled approach to optimize\nNDCG and its top-$K$ variant. First, we formulate a novel compositional\noptimization problem for optimizing the NDCG surrogate, and a novel bilevel\ncompositional optimization problem for optimizing the top-$K$ NDCG surrogate.\nThen, we develop efficient stochastic algorithms with provable convergence\nguarantees for the non-convex objectives. Different from existing NDCG\noptimization methods, the per-iteration complexity of our algorithms scales\nwith the mini-batch size instead of the number of total items. To improve the\neffectiveness for deep learning, we further propose practical strategies by\nusing initial warm-up and stop gradient operator. Experimental results on\nmultiple datasets demonstrate that our methods outperform prior ranking\napproaches in terms of NDCG. To the best of our knowledge, this is the first\ntime that stochastic algorithms are proposed to optimize NDCG with a provable\nconvergence guarantee. Our proposed methods are implemented in the LibAUC\nlibrary at https://libauc.org/.\n","authors":["Zi-Hao Qiu","Quanqi Hu","Yongjian Zhong","Lijun Zhang","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2202.12183v5.pdf","comment":"32 pages, 12 figures; Accepted by ICML2022"},{"id":"http://arxiv.org/abs/2301.12254v3","updated":"2023-02-02T16:36:36Z","published":"2023-01-28T17:09:50Z","title":"Combinatorial Inference on the Optimal Assortment in Multinomial Logit\n  Models","summary":"  Assortment optimization has received active explorations in the past few\ndecades due to its practical importance. Despite the extensive literature\ndealing with optimization algorithms and latent score estimation, uncertainty\nquantification for the optimal assortment still needs to be explored and is of\ngreat practical significance. Instead of estimating and recovering the complete\noptimal offer set, decision-makers may only be interested in testing whether a\ngiven property holds true for the optimal assortment, such as whether they\nshould include several products of interest in the optimal set, or how many\ncategories of products the optimal set should include. This paper proposes a\nnovel inferential framework for testing such properties. We consider the widely\nadopted multinomial logit (MNL) model, where we assume that each customer will\npurchase an item within the offered products with a probability proportional to\nthe underlying preference score associated with the product. We reduce\ninferring a general optimal assortment property to quantifying the uncertainty\nassociated with the sign change point detection of the marginal revenue gaps.\nWe show the asymptotic normality of the marginal revenue gap estimator, and\nconstruct a maximum statistic via the gap estimators to detect the sign change\npoint. By approximating the distribution of the maximum statistic with\nmultiplier bootstrap techniques, we propose a valid testing procedure. We also\nconduct numerical experiments to assess the performance of our method.\n","authors":["Shuting Shen","Xi Chen","Ethan X. Fang","Junwei Lu"],"pdf_url":"https://arxiv.org/pdf/2301.12254v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01204v1","updated":"2023-02-02T16:30:43Z","published":"2023-02-02T16:30:43Z","title":"Laplacian Change Point Detection for Single and Multi-view Dynamic\n  Graphs","summary":"  Dynamic graphs are rich data structures that are used to model complex\nrelationships between entities over time. In particular, anomaly detection in\ntemporal graphs is crucial for many real world applications such as intrusion\nidentification in network systems, detection of ecosystem disturbances and\ndetection of epidemic outbreaks. In this paper, we focus on change point\ndetection in dynamic graphs and address three main challenges associated with\nthis problem: i). how to compare graph snapshots across time, ii). how to\ncapture temporal dependencies, and iii). how to combine different views of a\ntemporal graph. To solve the above challenges, we first propose Laplacian\nAnomaly Detection (LAD) which uses the spectrum of graph Laplacian as the low\ndimensional embedding of the graph structure at each snapshot. LAD explicitly\nmodels short term and long term dependencies by applying two sliding windows.\nNext, we propose MultiLAD, a simple and effective generalization of LAD to\nmulti-view graphs. MultiLAD provides the first change point detection method\nfor multi-view dynamic graphs. It aggregates the singular values of the\nnormalized graph Laplacian from different views through the scalar power mean\noperation. Through extensive synthetic experiments, we show that i). LAD and\nMultiLAD are accurate and outperforms state-of-the-art baselines and their\nmulti-view extensions by a large margin, ii). MultiLAD's advantage over\ncontenders significantly increases when additional views are available, and\niii). MultiLAD is highly robust to noise from individual views. In five real\nworld dynamic graphs, we demonstrate that LAD and MultiLAD identify significant\nevents as top anomalies such as the implementation of government COVID-19\ninterventions which impacted the population mobility in multi-view traffic\nnetworks.\n","authors":["Shenyang Huang","Samy Coulombe","Yasmeen Hitti","Reihaneh Rabbany","Guillaume Rabusseau"],"pdf_url":"https://arxiv.org/pdf/2302.01204v1.pdf","comment":"30 pages, 15 figures, extended version of previous paper \"Laplacian\n  Change Point Detection for Dynamic Graphs\" with novel material. arXiv admin\n  note: substantial text overlap with arXiv:2007.01229"},{"id":"http://arxiv.org/abs/2302.01203v1","updated":"2023-02-02T16:30:33Z","published":"2023-02-02T16:30:33Z","title":"Online Bidding in Repeated Non-Truthful Auctions under Budget and ROI\n  Constraints","summary":"  Online advertising platforms typically use auction mechanisms to allocate ad\nplacements. Advertisers participate in a series of repeated auctions, and must\nselect bids that will maximize their overall rewards while adhering to certain\nconstraints. We focus on the scenario in which the advertiser has budget and\nreturn-on-investment (ROI) constraints. We investigate the problem of budget-\nand ROI-constrained bidding in repeated non-truthful auctions, such as\nfirst-price auctions, and present a best-of-both-worlds framework with\nno-regret guarantees under both stochastic and adversarial inputs. By utilizing\nthe notion of interval regret, we demonstrate that our framework does not\nrequire knowledge of specific parameters of the problem which could be\ndifficult to determine in practice. Our proof techniques can be applied to both\nthe adversarial and stochastic cases with minimal modifications, thereby\nproviding a unified perspective on the two problems. In the adversarial\nsetting, we also show that it is possible to loosen the traditional requirement\nof having a strictly feasible solution to the offline optimization problem at\neach round.\n","authors":["Matteo Castiglioni","Andrea Celli","Christian Kroer"],"pdf_url":"https://arxiv.org/pdf/2302.01203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01198v1","updated":"2023-02-02T16:25:16Z","published":"2023-02-02T16:25:16Z","title":"Causal Lifting and Link Prediction","summary":"  Current state-of-the-art causal models for link prediction assume an\nunderlying set of inherent node factors -- an innate characteristic defined at\nthe node's birth -- that governs the causal evolution of links in the graph. In\nsome causal tasks, however, link formation is path-dependent, i.e., the outcome\nof link interventions depends on existing links. For instance, in the\ncustomer-product graph of an online retailer, the effect of an 85-inch TV ad\n(treatment) likely depends on whether the costumer already has an 85-inch TV.\nUnfortunately, existing causal methods are impractical in these scenarios. The\ncascading functional dependencies between links (due to path dependence) are\neither unidentifiable or require an impractical number of control variables. In\norder to remedy this shortcoming, this work develops the first causal model\ncapable of dealing with path dependencies in link prediction. It introduces the\nconcept of causal lifting, an invariance in causal models that, when satisfied,\nallows the identification of causal link prediction queries using limited\ninterventional data. On the estimation side, we show how structural pairwise\nembeddings -- a type of symmetry-based joint representation of node pairs in a\ngraph -- exhibit lower bias and correctly represent the causal structure of the\ntask, as opposed to existing node embedding methods, e.g., GNNs and matrix\nfactorization. Finally, we validate our theoretical findings on four datasets\nunder three different scenarios for causal link prediction tasks: knowledge\nbase completion, covariance matrix estimation and consumer-product\nrecommendations.\n","authors":["Leonardo Cotta","Beatrice Bevilacqua","Nesreen Ahmed","Bruno Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2302.01198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08657v4","updated":"2023-02-02T16:22:23Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v4.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2302.01193v1","updated":"2023-02-02T16:19:13Z","published":"2023-02-02T16:19:13Z","title":"Imitating careful experts to avoid catastrophic events","summary":"  RL is increasingly being used to control robotic systems that interact\nclosely with humans. This interaction raises the problem of safe RL: how to\nensure that a RL-controlled robotic system never, for instance, injures a\nhuman. This problem is especially challenging in rich, realistic settings where\nit is not even possible to clearly write down a reward function which\nincorporates these outcomes. In these circumstances, perhaps the only viable\napproach is based on IRL, which infers rewards from human demonstrations.\nHowever, IRL is massively underdetermined as many different rewards can lead to\nthe same optimal policies; we show that this makes it difficult to distinguish\ncatastrophic outcomes (such as injuring a human) from merely undesirable\noutcomes. Our key insight is that humans do display different behaviour when\ncatastrophic outcomes are possible: they become much more careful. We\nincorporate carefulness signals into IRL, and find that they do indeed allow\nIRL to disambiguate undesirable from catastrophic outcomes, which is critical\nto ensuring safety in future real-world human-robot interactions.\n","authors":["Jack R. P. Hanslope","Laurence Aitchison"],"pdf_url":"https://arxiv.org/pdf/2302.01193v1.pdf","comment":"9 pages, 8 figures, accepted to NeurIPS 2022 Workshop on Robot\n  Learning: Trustworthy Robotics"},{"id":"http://arxiv.org/abs/2302.01190v1","updated":"2023-02-02T16:16:25Z","published":"2023-02-02T16:16:25Z","title":"On the Efficacy of Differentially Private Few-shot Image Classification","summary":"  There has been significant recent progress in training differentially private\n(DP) models which achieve accuracy that approaches the best non-private models.\nThese DP models are typically pretrained on large public datasets and then\nfine-tuned on downstream datasets that are (i) relatively large, and (ii)\nsimilar in distribution to the pretraining data. However, in many applications\nincluding personalization, it is crucial to perform well in the few-shot\nsetting, as obtaining large amounts of labeled data may be problematic; and on\nimages from a wide variety of domains for use in various specialist settings.\nTo understand under which conditions few-shot DP can be effective, we perform\nan exhaustive set of experiments that reveals how the accuracy and\nvulnerability to attack of few-shot DP image classification models are affected\nas the number of shots per class, privacy level, model architecture, dataset,\nand subset of learnable parameters in the model vary. We show that to achieve\nDP accuracy on par with non-private models, the shots per class must be\nincreased as the privacy level increases by as much as 32$\\times$ for CIFAR-100\nat $\\epsilon=1$. We also find that few-shot non-private models are highly\nsusceptible to membership inference attacks. DP provides clear mitigation\nagainst the attacks, but a small $\\epsilon$ is required to effectively prevent\nthem. Finally, we evaluate DP federated learning systems and establish\nstate-of-the-art performance on the challenging FLAIR federated learning\nbenchmark.\n","authors":["Marlon Tobaben","Aliaksandra Shysheya","John Bronskill","Andrew Paverd","Shruti Tople","Santiago Zanella-Beguelin","Richard E Turner","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2302.01190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01188v1","updated":"2023-02-02T16:14:19Z","published":"2023-02-02T16:14:19Z","title":"Best Possible Q-Learning","summary":"  Fully decentralized learning, where the global information, i.e., the actions\nof other agents, is inaccessible, is a fundamental challenge in cooperative\nmulti-agent reinforcement learning. However, the convergence and optimality of\nmost decentralized algorithms are not theoretically guaranteed, since the\ntransition probabilities are non-stationary as all agents are updating policies\nsimultaneously. To tackle this challenge, we propose best possible operator, a\nnovel decentralized operator, and prove that the policies of agents will\nconverge to the optimal joint policy if each agent independently updates its\nindividual state-action value by the operator. Further, to make the update more\nefficient and practical, we simplify the operator and prove that the\nconvergence and optimality still hold with the simplified one. By instantiating\nthe simplified operator, the derived fully decentralized algorithm, best\npossible Q-learning (BQL), does not suffer from non-stationarity. Empirically,\nwe show that BQL achieves remarkable improvement over baselines in a variety of\ncooperative multi-agent tasks.\n","authors":["Jiechuan Jiang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2302.01188v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2302.01186v1","updated":"2023-02-02T16:13:27Z","published":"2023-02-02T16:13:27Z","title":"The Power of Preconditioning in Overparameterized Low-Rank Matrix\n  Sensing","summary":"  We propose $\\textsf{ScaledGD($\\lambda$)}$, a preconditioned gradient descent\nmethod to tackle the low-rank matrix sensing problem when the true rank is\nunknown, and when the matrix is possibly ill-conditioned. Using\noverparametrized factor representations, $\\textsf{ScaledGD($\\lambda$)}$ starts\nfrom a small random initialization, and proceeds by gradient descent with a\nspecific form of damped preconditioning to combat bad curvatures induced by\noverparameterization and ill-conditioning. At the expense of light\ncomputational overhead incurred by preconditioners,\n$\\textsf{ScaledGD($\\lambda$)}$ is remarkably robust to ill-conditioning\ncompared to vanilla gradient descent ($\\textsf{GD}$) even with\noverprameterization. Specifically, we show that, under the Gaussian design,\n$\\textsf{ScaledGD($\\lambda$)}$ converges to the true low-rank matrix at a\nconstant linear rate after a small number of iterations that scales only\nlogarithmically with respect to the condition number and the problem dimension.\nThis significantly improves over the convergence rate of vanilla $\\textsf{GD}$\nwhich suffers from a polynomial dependency on the condition number. Our work\nprovides evidence on the power of preconditioning in accelerating the\nconvergence without hurting generalization in overparameterized learning.\n","authors":["Xingyu Xu","Yandi Shen","Yuejie Chi","Cong Ma"],"pdf_url":"https://arxiv.org/pdf/2302.01186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01178v1","updated":"2023-02-02T15:54:45Z","published":"2023-02-02T15:54:45Z","title":"Convolutional Neural Operators","summary":"  Although very successfully used in machine learning, convolution based neural\nnetwork architectures -- believed to be inconsistent in function space -- have\nbeen largely ignored in the context of learning solution operators of PDEs.\nHere, we adapt convolutional neural networks to demonstrate that they are\nindeed able to process functions as inputs and outputs. The resulting\narchitecture, termed as convolutional neural operators (CNOs), is shown to\nsignificantly outperform competing models on benchmark experiments, paving the\nway for the design of an alternative robust and accurate framework for learning\noperators.\n","authors":["Bogdan Raonić","Roberto Molinaro","Tobias Rohner","Siddhartha Mishra","Emmanuel de Bezenac"],"pdf_url":"https://arxiv.org/pdf/2302.01178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.08924v7","updated":"2023-02-02T15:53:20Z","published":"2021-07-19T14:37:57Z","title":"Epistemic Neural Networks","summary":"  Intelligence relies on an agent's knowledge of what it does not know. This\ncapability can be assessed based on the quality of joint predictions of labels\nacross multiple inputs. In principle, ensemble-based approaches produce\neffective joint predictions, but the computational costs of training large\nensembles can become prohibitive. We introduce the epinet: an architecture that\ncan supplement any conventional neural network, including large pretrained\nmodels, and can be trained with modest incremental computation to estimate\nuncertainty. With an epinet, conventional neural networks outperform very large\nensembles, consisting of hundreds or more particles, with orders of magnitude\nless computation. The epinet does not fit the traditional framework of Bayesian\nneural networks. To accommodate development of approaches beyond BNNs, such as\nthe epinet, we introduce the epistemic neural network (ENN) as an interface for\nmodels that produce joint predictions.\n","authors":["Ian Osband","Zheng Wen","Seyed Mohammad Asghari","Vikranth Dwaracherla","Morteza Ibrahimi","Xiuyuan Lu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2107.08924v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01172v1","updated":"2023-02-02T15:49:03Z","published":"2023-02-02T15:49:03Z","title":"STEP: Learning N:M Structured Sparsity Masks from Scratch with\n  Precondition","summary":"  Recent innovations on hardware (e.g. Nvidia A100) have motivated learning N:M\nstructured sparsity masks from scratch for fast model inference. However,\nstate-of-the-art learning recipes in this regime (e.g. SR-STE) are proposed for\nnon-adaptive optimizers like momentum SGD, while incurring non-trivial accuracy\ndrop for Adam-trained models like attention-based LLMs. In this paper, we first\ndemonstrate such gap origins from poorly estimated second moment (i.e.\nvariance) in Adam states given by the masked weights. We conjecture that\nlearning N:M masks with Adam should take the critical regime of variance\nestimation into account. In light of this, we propose STEP, an Adam-aware\nrecipe that learns N:M masks with two phases: first, STEP calculates a reliable\nvariance estimate (precondition phase) and subsequently, the variance remains\nfixed and is used as a precondition to learn N:M masks (mask-learning phase).\nSTEP automatically identifies the switching point of two phases by dynamically\nsampling variance changes over the training trajectory and testing the sample\nconcentration. Empirically, we evaluate STEP and other baselines such as ASP\nand SR-STE on multiple tasks including CIFAR classification, machine\ntranslation and LLM fine-tuning (BERT-Base, GPT-2). We show STEP mitigates the\naccuracy drop of baseline recipes and is robust to aggressive structured\nsparsity ratios.\n","authors":["Yucheng Lu","Shivani Agrawal","Suvinay Subramanian","Oleg Rybakov","Christopher De Sa","Amir Yazdanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2302.01172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01170v1","updated":"2023-02-02T15:48:39Z","published":"2023-02-02T15:48:39Z","title":"Timewarp: Transferable Acceleration of Molecular Dynamics by Learning\n  Time-Coarsened Dynamics","summary":"  Molecular dynamics (MD) simulation is a widely used technique to simulate\nmolecular systems, most commonly at the all-atom resolution where the equations\nof motion are integrated with timesteps on the order of femtoseconds\n($1\\textrm{fs}=10^{-15}\\textrm{s}$). MD is often used to compute equilibrium\nproperties, which requires sampling from an equilibrium distribution such as\nthe Boltzmann distribution. However, many important processes, such as binding\nand folding, occur over timescales of milliseconds or beyond, and cannot be\nefficiently sampled with conventional MD. Furthermore, new MD simulations need\nto be performed from scratch for each molecular system studied. We present\nTimewarp, an enhanced sampling method which uses a normalising flow as a\nproposal distribution in a Markov chain Monte Carlo method targeting the\nBoltzmann distribution. The flow is trained offline on MD trajectories and\nlearns to make large steps in time, simulating the molecular dynamics of\n$10^{5} - 10^{6}\\:\\textrm{fs}$. Crucially, Timewarp is transferable between\nmolecular systems: once trained, we show that it generalises to unseen small\npeptides (2-4 amino acids), exploring their metastable states and providing\nwall-clock acceleration when sampling compared to standard MD. Our method\nconstitutes an important step towards developing general, transferable\nalgorithms for accelerating MD.\n","authors":["Leon Klein","Andrew Y. K. Foong","Tor Erlend Fjelde","Bruno Mlodozeniec","Marc Brockschmidt","Sebastian Nowozin","Frank Noé","Ryota Tomioka"],"pdf_url":"https://arxiv.org/pdf/2302.01170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.13669v3","updated":"2023-02-02T15:33:31Z","published":"2021-04-28T09:47:21Z","title":"Optimal Stopping via Randomized Neural Networks","summary":"  This paper presents new machine learning approaches to approximate the\nsolutions of optimal stopping problems. The key idea of these methods is to use\nneural networks, where the parameters of the hidden layers are generated\nrandomly and only the last layer is trained, in order to approximate the\ncontinuation value. Our approaches are applicable to high dimensional problems\nwhere the existing approaches become increasingly impractical. In addition,\nsince our approaches can be optimized using simple linear regression, they are\neasy to implement and theoretical guarantees are provided. Our randomized\nreinforcement learning approach and randomized recurrent neural network\napproach outperform the state-of-the-art and other relevant machine learning\napproaches in Markovian and non-Markovian examples, respectively. In\nparticular, we test our approaches on Black-Scholes, Heston, rough Heston and\nfractional Brownian motion. Moreover, we show that they can also be used to\nefficiently compute Greeks of American options.\n","authors":["Calypso Herrera","Florian Krach","Pierre Ruyssen","Josef Teichmann"],"pdf_url":"https://arxiv.org/pdf/2104.13669v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01161v1","updated":"2023-02-02T15:32:25Z","published":"2023-02-02T15:32:25Z","title":"Vectorized Scenario Description and Motion Prediction for Scenario-Based\n  Testing","summary":"  Automated vehicles (AVs) are tested in diverse scenarios, typically specified\nby parameters such as velocities, distances, or curve radii. To describe\nscenarios uniformly independent of such parameters, this paper proposes a\nvectorized scenario description defined by the road geometry and vehicles'\ntrajectories. Data of this form are generated for three scenarios, merged, and\nused to train the motion prediction model VectorNet, allowing to predict an\nAV's trajectory for unseen scenarios. Predicting scenario evaluation metrics,\nVectorNet partially achieves lower errors than regression models that\nseparately process the three scenarios' data. However, for comprehensive\ngeneralization, sufficient variance in the training data must be ensured. Thus,\ncontrary to existing methods, our proposed method can merge diverse scenarios'\ndata and exploit spatial and temporal nuances in the vectorized scenario\ndescription. As a result, data from specified test scenarios and real-world\nscenarios can be compared and combined for (predictive) analyses and scenario\nselection.\n","authors":["Max Winkelmann","Constantin Vasconi","Steffen Müller"],"pdf_url":"https://arxiv.org/pdf/2302.01161v1.pdf","comment":"6 pages, 7 figures, 3 tables, submitted to IEEE IV 2023"},{"id":"http://arxiv.org/abs/1905.05095v3","updated":"2023-02-02T15:32:06Z","published":"2019-05-13T15:38:38Z","title":"Do Kernel and Neural Embeddings Help in Training and Generalization?","summary":"  Recent results on optimization and generalization properties of neural\nnetworks showed that in a simple two-layer network, the alignment of the labels\nto the eigenvectors of the corresponding Gram matrix determines the convergence\nof the optimization during training. Such analyses also provide upper bounds on\nthe generalization error. We experimentally investigate the implications of\nthese results to deeper networks via embeddings. We regard the layers preceding\nthe final hidden layer as producing different representations of the input data\nwhich are then fed to the two-layer model. We show that these representations\nimprove both optimization and generalization. In particular, we investigate\nthree kernel representations when fed to the final hidden layer: the Gaussian\nkernel and its approximation by random Fourier features, kernels designed to\nimitate representations produced by neural networks and finally an optimal\nkernel designed to align the data with target labels. The approximated\nrepresentations induced by these kernels are fed to the neural network and the\noptimization and generalization properties of the final model are evaluated and\ncompared.\n","authors":["Arman Rahbar","Emilio Jorge","Devdatt Dubhashi","Morteza Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/1905.05095v3.pdf","comment":"This work is published by Neural Processing Letters"},{"id":"http://arxiv.org/abs/2205.09072v2","updated":"2023-02-02T15:29:41Z","published":"2022-05-18T16:57:10Z","title":"On the Effective Number of Linear Regions in Shallow Univariate ReLU\n  Networks: Convergence Guarantees and Implicit Bias","summary":"  We study the dynamics and implicit bias of gradient flow (GF) on univariate\nReLU neural networks with a single hidden layer in a binary classification\nsetting. We show that when the labels are determined by the sign of a target\nnetwork with $r$ neurons, with high probability over the initialization of the\nnetwork and the sampling of the dataset, GF converges in direction (suitably\ndefined) to a network achieving perfect training accuracy and having at most\n$\\mathcal{O}(r)$ linear regions, implying a generalization bound. Unlike many\nother results in the literature, under an additional assumption on the\ndistribution of the data, our result holds even for mild over-parameterization,\nwhere the width is $\\tilde{\\mathcal{O}}(r)$ and independent of the sample size.\n","authors":["Itay Safran","Gal Vardi","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2205.09072v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05849v2","updated":"2023-02-02T15:27:48Z","published":"2023-01-14T08:08:29Z","title":"Survey of Knowledge Distillation in Federated Edge Learning","summary":"  The increasing demand for intelligent services and privacy protection of\nmobile and Internet of Things (IoT) devices motivates the wide application of\nFederated Edge Learning (FEL), in which devices collaboratively train on-device\nMachine Learning (ML) models without sharing their private data. Limited by\ndevice hardware, diverse user behaviors and network infrastructure, the\nalgorithm design of FEL faces challenges related to resources, personalization\nand network environments. Fortunately, Knowledge Distillation (KD) has been\nleveraged as an important technique to tackle the above challenges in FEL. In\nthis paper, we investigate the works that KD applies to FEL, discuss the\nlimitations and open problems of existing KD-based FEL approaches, and provide\nguidance for their real deployment.\n","authors":["Zhiyuan Wu","Sheng Sun","Yuwei Wang","Min Liu","Xuefeng Jiang","Runhan Li","Bo Gao"],"pdf_url":"https://arxiv.org/pdf/2301.05849v2.pdf","comment":"13 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2209.07399v2","updated":"2023-02-02T15:23:33Z","published":"2022-09-15T16:00:04Z","title":"A Light Recipe to Train Robust Vision Transformers","summary":"  In this paper, we ask whether Vision Transformers (ViTs) can serve as an\nunderlying architecture for improving the adversarial robustness of machine\nlearning models against evasion attacks. While earlier works have focused on\nimproving Convolutional Neural Networks, we show that also ViTs are highly\nsuitable for adversarial training to achieve competitive performance. We\nachieve this objective using a custom adversarial training recipe, discovered\nusing rigorous ablation studies on a subset of the ImageNet dataset. The\ncanonical training recipe for ViTs recommends strong data augmentation, in part\nto compensate for the lack of vision inductive bias of attention modules, when\ncompared to convolutions. We show that this recipe achieves suboptimal\nperformance when used for adversarial training. In contrast, we find that\nomitting all heavy data augmentation, and adding some additional bag-of-tricks\n($\\varepsilon$-warmup and larger weight decay), significantly boosts the\nperformance of robust ViTs. We show that our recipe generalizes to different\nclasses of ViT architectures and large-scale models on full ImageNet-1k.\nAdditionally, investigating the reasons for the robustness of our models, we\nshow that it is easier to generate strong attacks during training when using\nour recipe and that this leads to better robustness at test time. Finally, we\nfurther study one consequence of adversarial training by proposing a way to\nquantify the semantic nature of adversarial perturbations and highlight its\ncorrelation with the robustness of the model. Overall, we recommend that the\ncommunity should avoid translating the canonical training recipes in ViTs to\nrobust training and rethink common training choices in the context of\nadversarial training.\n","authors":["Edoardo Debenedetti","Vikash Sehwag","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2209.07399v2.pdf","comment":"Camera-ready version for SaTML 2023, code available at\n  https://github.com/dedeswim/vits-robustness-torch"},{"id":"http://arxiv.org/abs/2302.01155v1","updated":"2023-02-02T15:16:13Z","published":"2023-02-02T15:16:13Z","title":"Deep COVID-19 Forecasting for Multiple States with Data Augmentation","summary":"  In this work, we propose a deep learning approach to forecasting state-level\nCOVID-19 trends of weekly cumulative death in the United States (US) and\nincident cases in Germany. This approach includes a transformer model, an\nensemble method, and a data augmentation technique for time series. We arrange\nthe inputs of the transformer in such a way that predictions for different\nstates can attend to the trends of the others. To overcome the issue of\nscarcity of training data for this COVID-19 pandemic, we have developed a novel\ndata augmentation technique to generate useful data for training. More\nimportantly, the generated data can also be used for model validation. As such,\nit has a two-fold advantage: 1) more actual observations can be used for\ntraining, and 2) the model can be validated on data which has distribution\ncloser to the expected situation. Our model has achieved some of the best\nstate-level results on the COVID-19 Forecast Hub for the US and for Germany.\n","authors":["Chung Yan Fong","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2302.01155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.02393v3","updated":"2023-02-02T15:16:05Z","published":"2021-12-04T18:07:47Z","title":"Optimization-Based Separations for Neural Networks","summary":"  Depth separation results propose a possible theoretical explanation for the\nbenefits of deep neural networks over shallower architectures, establishing\nthat the former possess superior approximation capabilities. However, there are\nno known results in which the deeper architecture leverages this advantage into\na provable optimization guarantee. We prove that when the data are generated by\na distribution with radial symmetry which satisfies some mild assumptions,\ngradient descent can efficiently learn ball indicator functions using a depth 2\nneural network with two layers of sigmoidal activations, and where the hidden\nlayer is held fixed throughout training. By building on and refining existing\ntechniques for approximation lower bounds of neural networks with a single\nlayer of non-linearities, we show that there are $d$-dimensional radial\ndistributions on the data such that ball indicators cannot be learned\nefficiently by any algorithm to accuracy better than $\\Omega(d^{-4})$, nor by a\nstandard gradient descent implementation to accuracy better than a constant.\nThese results establish what is to the best of our knowledge, the first\noptimization-based separations where the approximation benefits of the stronger\narchitecture provably manifest in practice. Our proof technique introduces new\ntools and ideas that may be of independent interest in the theoretical study of\nboth the approximation and optimization of neural networks.\n","authors":["Itay Safran","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2112.02393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07993v3","updated":"2023-02-02T15:14:47Z","published":"2022-02-16T11:13:37Z","title":"Planckian Jitter: countering the color-crippling effects of color jitter\n  on self-supervised training","summary":"  Several recent works on self-supervised learning are trained by mapping\ndifferent augmentations of the same image to the same feature representation.\nThe data augmentations used are of crucial importance to the quality of learned\nfeature representations. In this paper, we analyze how the color jitter\ntraditionally used in data augmentation negatively impacts the quality of the\ncolor features in learned feature representations. To address this problem, we\npropose a more realistic, physics-based color data augmentation - which we call\nPlanckian Jitter - that creates realistic variations in chromaticity and\nproduces a model robust to illumination changes that can be commonly observed\nin real life, while maintaining the ability to discriminate image content based\non color information. Experiments confirm that such a representation is\ncomplementary to the representations learned with the currently-used color\njitter augmentation and that a simple concatenation leads to significant\nperformance gains on a wide range of downstream datasets. In addition, we\npresent a color sensitivity analysis that documents the impact of different\ntraining methods on model neurons and shows that the performance of the learned\nfeatures is robust with respect to illuminant variations.\n","authors":["Simone Zini","Alex Gomez-Villa","Marco Buzzelli","Bartłomiej Twardowski","Andrew D. Bagdanov","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2202.07993v3.pdf","comment":"Accepted at Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2302.01152v1","updated":"2023-02-02T15:14:27Z","published":"2023-02-02T15:14:27Z","title":"A comparative study of statistical and machine learning models on\n  near-real-time daily emissions prediction","summary":"  The rapid ascent in carbon dioxide emissions is a major cause of global\nwarming and climate change, which pose a huge threat to human survival and\nimpose far-reaching influence on the global ecosystem. Therefore, it is very\nnecessary to effectively control carbon dioxide emissions by accurately\npredicting and analyzing the change trend timely, so as to provide a reference\nfor carbon dioxide emissions mitigation measures. This paper is aiming to\nselect a suitable model to predict the near-real-time daily emissions based on\nunivariate daily time-series data from January 1st, 2020 to September 30st,\n2022 of all sectors (Power, Industry, Ground Transport, Residential, Domestic\nAviation, International Aviation) in China. We proposed six prediction models,\nwhich including three statistical models: Grey prediction (GM(1,1)),\nautoregressive integrated moving average (ARIMA) and seasonal autoregressive\nintegrated moving average with exogenous factors (SARIMAX); three machine\nlearning models: artificial neural network (ANN), random forest (RF) and long\nshort term memory (LSTM). To evaluate the performance of these models, five\ncriteria: Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean\nAbsolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Coefficient of\nDetermination () are imported and discussed in detail. In the results, three\nmachine learning models perform better than that three statistical models, in\nwhich LSTM model performs the best on five criteria values for daily emissions\nprediction with the 3.5179e-04 MSE value, 0.0187 RMSE value, 0.0140 MAE value,\n14.8291% MAPE value and 0.9844 value.\n","authors":["Xiangqian Li"],"pdf_url":"https://arxiv.org/pdf/2302.01152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01144v1","updated":"2023-02-02T15:00:03Z","published":"2023-02-02T15:00:03Z","title":"UW-CVGAN: UnderWater Image Enhancement with Capsules Vectors\n  Quantization","summary":"  The degradation in the underwater images is due to wavelength-dependent light\nattenuation, scattering, and to the diversity of the water types in which they\nare captured. Deep neural networks take a step in this field, providing\nautonomous models able to achieve the enhancement of underwater images. We\nintroduce Underwater Capsules Vectors GAN UWCVGAN based on the discrete\nfeatures quantization paradigm from VQGAN for this task. The proposed UWCVGAN\ncombines an encoding network, which compresses the image into its latent\nrepresentation, with a decoding network, able to reconstruct the enhancement of\nthe image from the only latent representation. In contrast with VQGAN, UWCVGAN\nachieves feature quantization by exploiting the clusterization ability of\ncapsule layer, making the model completely trainable and easier to manage. The\nmodel obtains enhanced underwater images with high quality and fine details.\nMoreover, the trained encoder is independent of the decoder giving the\npossibility to be embedded onto the collector as compressing algorithm to\nreduce the memory space required for the images, of factor $3\\times$.\n\\myUWCVGAN{ }is validated with quantitative and qualitative analysis on\nbenchmark datasets, and we present metrics results compared with the state of\nthe art.\n","authors":["Rita Pucci","Christian Micheloni","Niki Martinel"],"pdf_url":"https://arxiv.org/pdf/2302.01144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09756v3","updated":"2023-02-02T14:53:12Z","published":"2022-11-17T18:32:26Z","title":"An Advantage Using Feature Selection with a Quantum Annealer","summary":"  Feature selection is a technique in statistical prediction modeling that\nidentifies features in a record with a strong statistical connection to the\ntarget variable. Excluding features with a weak statistical connection to the\ntarget variable in training not only drops the dimension of the data, which\ndecreases the time complexity of the algorithm, it also decreases noise within\nthe data which assists in avoiding overfitting. In all, feature selection\nassists in training a robust statistical model that performs well and is\nstable. Given the lack of scalability in classical computation, current\ntechniques only consider the predictive power of the feature and not redundancy\nbetween the features themselves. Recent advancements in feature selection that\nleverages quantum annealing (QA) gives a scalable technique that aims to\nmaximize the predictive power of the features while minimizing redundancy. As a\nconsequence, it is expected that this algorithm would assist in the\nbias/variance trade-off yielding better features for training a statistical\nmodel. This paper tests this intuition against classical methods by utilizing\nopen-source data sets and evaluate the efficacy of each trained statistical\nmodel well-known prediction algorithms. The numerical results display an\nadvantage utilizing the features selected from the algorithm that leveraged QA.\n","authors":["Andrew Vlasic","Hunter Grant","Salvatore Certo"],"pdf_url":"https://arxiv.org/pdf/2211.09756v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01129v1","updated":"2023-02-02T14:40:47Z","published":"2023-02-02T14:40:47Z","title":"De Novo Molecular Generation via Connection-aware Motif Mining","summary":"  De novo molecular generation is an essential task for science discovery.\nRecently, fragment-based deep generative models have attracted much research\nattention due to their flexibility in generating novel molecules based on\nexisting molecule fragments. However, the motif vocabulary, i.e., the\ncollection of frequent fragments, is usually built upon heuristic rules, which\nbrings difficulties to capturing common substructures from large amounts of\nmolecules. In this work, we propose a new method, MiCaM, to generate molecules\nbased on mined connection-aware motifs. Specifically, it leverages a\ndata-driven algorithm to automatically discover motifs from a molecule library\nby iteratively merging subgraphs based on their frequency. The obtained motif\nvocabulary consists of not only molecular motifs (i.e., the frequent\nfragments), but also their connection information, indicating how the motifs\nare connected with each other. Based on the mined connection-aware motifs,\nMiCaM builds a connection-aware generator, which simultaneously picks up motifs\nand determines how they are connected. We test our method on\ndistribution-learning benchmarks (i.e., generating novel molecules to resemble\nthe distribution of a given training set) and goal-directed benchmarks (i.e.,\ngenerating molecules with target properties), and achieve significant\nimprovements over previous fragment-based baselines. Furthermore, we\ndemonstrate that our method can effectively mine domain-specific motifs for\ndifferent tasks.\n","authors":["Zijie Geng","Shufang Xie","Yingce Xia","Lijun Wu","Tao Qin","Jie Wang","Yongdong Zhang","Feng Wu","Tie-Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2302.01129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01128v1","updated":"2023-02-02T14:40:28Z","published":"2023-02-02T14:40:28Z","title":"Mnemosyne: Learning to Train Transformers with Transformers","summary":"  Training complex machine learning (ML) architectures requires a compute and\ntime consuming process of selecting the right optimizer and tuning its\nhyper-parameters. A new paradigm of learning optimizers from data has emerged\nas a better alternative to hand-designed ML optimizers. We propose Mnemosyne\noptimizer, that uses Performers: implicit low-rank attention Transformers. It\ncan learn to train entire neural network architectures including other\nTransformers without any task-specific optimizer tuning. We show that\nMnemosyne: (a) generalizes better than popular LSTM optimizer, (b) in\nparticular can successfully train Vision Transformers (ViTs) while\nmeta--trained on standard MLPs and (c) can initialize optimizers for faster\nconvergence in Robotics applications. We believe that these results open the\npossibility of using Transformers to build foundational optimization models\nthat can address the challenges of regular Transformer training. We complement\nour results with an extensive theoretical analysis of the compact associative\nmemory used by Mnemosyne.\n","authors":["Deepali Jain","Krzysztof Marcin Choromanski","Sumeet Singh","Vikas Sindhwani","Tingnan Zhang","Jie Tan","Avinava Dubey"],"pdf_url":"https://arxiv.org/pdf/2302.01128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12805v2","updated":"2023-02-02T14:18:54Z","published":"2022-07-26T10:59:52Z","title":"Neural Design for Genetic Perturbation Experiments","summary":"  The problem of how to genetically modify cells in order to maximize a certain\ncellular phenotype has taken center stage in drug development over the last few\nyears (with, for example, genetically edited CAR-T, CAR-NK, and CAR-NKT cells\nentering cancer clinical trials). Exhausting the search space for all possible\ngenetic edits (perturbations) or combinations thereof is infeasible due to cost\nand experimental limitations. This work provides a theoretically sound\nframework for iteratively exploring the space of perturbations in pooled\nbatches in order to maximize a target phenotype under an experimental budget.\nInspired by this application domain, we study the problem of batch query bandit\noptimization and introduce the Optimistic Arm Elimination ($\\mathrm{OAE}$)\nprinciple designed to find an almost optimal arm under different functional\nrelationships between the queries (arms) and the outputs (rewards). We analyze\nthe convergence properties of $\\mathrm{OAE}$ by relating it to the Eluder\ndimension of the algorithm's function class and validate that $\\mathrm{OAE}$\noutperforms other strategies in finding optimal actions in experiments on\nsimulated problems, public datasets well-studied in bandit contexts, and in\ngenetic perturbation datasets when the regression model is a deep neural\nnetwork. OAE also outperforms the benchmark algorithms in 3 of 4 datasets in\nthe GeneDisco experimental planning challenge.\n","authors":["Aldo Pacchiano","Drausin Wulsin","Robert A. Barton","Luis Voloch"],"pdf_url":"https://arxiv.org/pdf/2207.12805v2.pdf","comment":"22 pages main, 15 pages appendix"},{"id":"http://arxiv.org/abs/2211.13019v2","updated":"2023-02-02T14:12:35Z","published":"2022-11-21T16:44:04Z","title":"Safe Optimization of an Industrial Refrigeration Process Using an\n  Adaptive and Explorative Framework","summary":"  Many industrial applications rely on real-time optimization to improve key\nperformance indicators. In the case of unknown process characteristics,\nreal-time optimization becomes challenging, particularly for the satisfaction\nof safety constraints. In this paper, we demonstrate the application of an\nadaptive and explorative real-time optimization framework to an industrial\nrefrigeration process, where we learn the process characteristics through\nchanges in process control targets and through exploration to satisfy safety\nconstraints. We quantify the uncertainty in unknown compressor characteristics\nof the refrigeration plant by using Gaussian processes and incorporate this\nuncertainty into the objective function of the real-time optimization problem\nas a weighted cost term. We adaptively control the weight of this term to drive\nexploration. The results of our simulation experiments indicate the proposed\napproach can help to increase the energy efficiency of the considered\nrefrigeration process, closely approximating the performance of a solution that\nhas complete information about the compressor performance characteristics.\n","authors":["Buse Sibel Korkmaz","Marta Zagórowska","Mehmet Mercangöz"],"pdf_url":"https://arxiv.org/pdf/2211.13019v2.pdf","comment":"Under review for IFAC WC 2023. arXiv admin note: substantial text\n  overlap with arXiv:2211.05495"},{"id":"http://arxiv.org/abs/2302.01107v1","updated":"2023-02-02T13:58:18Z","published":"2023-02-02T13:58:18Z","title":"A Survey on Efficient Training of Transformers","summary":"  Recent advances in Transformers have come with a huge requirement on\ncomputing resources, highlighting the importance of developing efficient\ntraining techniques to make Transformer training faster, at lower cost, and to\nhigher accuracy by the efficient use of computation and memory resources. This\nsurvey provides the first systematic overview of the efficient training of\nTransformers, covering the recent progress in acceleration arithmetic and\nhardware, with a focus on the former. We analyze and compare methods that save\ncomputation and memory costs for intermediate tensors during training, together\nwith techniques on hardware/algorithm co-design. We finally discuss challenges\nand promising areas for future research.\n","authors":["Bohan Zhuang","Jing Liu","Zizheng Pan","Haoyu He","Yuetian Weng","Chunhua Shen"],"pdf_url":"https://arxiv.org/pdf/2302.01107v1.pdf","comment":"A brief review"},{"id":"http://arxiv.org/abs/2302.01098v1","updated":"2023-02-02T13:40:12Z","published":"2023-02-02T13:40:12Z","title":"A general Markov decision process formalism for action-state\n  entropy-regularized reward maximization","summary":"  Previous work has separately addressed different forms of action, state and\naction-state entropy regularization, pure exploration and space occupation.\nThese problems have become extremely relevant for regularization,\ngeneralization, speeding up learning and providing robust solutions at\nunprecedented levels. However, solutions of those problems are hectic, ranging\nfrom convex and non-convex optimization, and unconstrained optimization to\nconstrained optimization. Here we provide a general dual function formalism\nthat transforms the constrained optimization problem into an unconstrained\nconvex one for any mixture of action and state entropies. The cases with pure\naction entropy and pure state entropy are understood as limits of the mixture.\n","authors":["Dmytro Grytskyy","Jorge Ramírez-Ruiz","Rubén Moreno-Bote"],"pdf_url":"https://arxiv.org/pdf/2302.01098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05520v2","updated":"2023-02-02T13:35:28Z","published":"2022-11-10T12:29:30Z","title":"Unravelling the Performance of Physics-informed Graph Neural Networks\n  for Dynamical Systems","summary":"  Recently, graph neural networks have been gaining a lot of attention to\nsimulate dynamical systems due to their inductive nature leading to zero-shot\ngeneralizability. Similarly, physics-informed inductive biases in deep-learning\nframeworks have been shown to give superior performance in learning the\ndynamics of physical systems. There is a growing volume of literature that\nattempts to combine these two approaches. Here, we evaluate the performance of\nthirteen different graph neural networks, namely, Hamiltonian and Lagrangian\ngraph neural networks, graph neural ODE, and their variants with explicit\nconstraints and different architectures. We briefly explain the theoretical\nformulation highlighting the similarities and differences in the inductive\nbiases and graph architecture of these systems. We evaluate these models on\nspring, pendulum, gravitational, and 3D deformable solid systems to compare the\nperformance in terms of rollout error, conserved quantities such as energy and\nmomentum, and generalizability to unseen system sizes. Our study demonstrates\nthat GNNs with additional inductive biases, such as explicit constraints and\ndecoupling of kinetic and potential energies, exhibit significantly enhanced\nperformance. Further, all the physics-informed GNNs exhibit zero-shot\ngeneralizability to system sizes an order of magnitude larger than the training\nsystem, thus providing a promising route to simulate large-scale realistic\nsystems.\n","authors":["Abishek Thangamuthu","Gunjan Kumar","Suresh Bishnoi","Ravinder Bhattoo","N M Anoop Krishnan","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2211.05520v2.pdf","comment":"Accepted at 36th Conference on Neural Information Processing Systems\n  (NeurIPS 2022)"},{"id":"http://arxiv.org/abs/2302.01094v1","updated":"2023-02-02T13:30:48Z","published":"2023-02-02T13:30:48Z","title":"Confidence and Dispersity Speak: Characterising Prediction Matrix for\n  Unsupervised Accuracy Estimation","summary":"  This work aims to assess how well a model performs under distribution shifts\nwithout using labels. While recent methods study prediction confidence, this\nwork reports prediction dispersity is another informative cue. Confidence\nreflects whether the individual prediction is certain; dispersity indicates how\nthe overall predictions are distributed across all categories. Our key insight\nis that a well-performing model should give predictions with high confidence\nand high dispersity. That is, we need to consider both properties so as to make\nmore accurate estimates. To this end, we use the nuclear norm that has been\nshown to be effective in characterizing both properties. Extensive experiments\nvalidate the effectiveness of nuclear norm for various models (e.g., ViT and\nConvNeXt), different datasets (e.g., ImageNet and CUB-200), and diverse types\nof distribution shifts (e.g., style shift and reproduction shift). We show that\nthe nuclear norm is more accurate and robust in accuracy estimation than\nexisting methods. Furthermore, we validate the feasibility of other\nmeasurements (e.g., mutual information maximization) for characterizing\ndispersity and confidence. Lastly, we investigate the limitation of the nuclear\nnorm, study its improved variant under severe class imbalance, and discuss\npotential directions.\n","authors":["Weijian Deng","Yumin Suh","Stephen Gould","Liang Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.01094v1.pdf","comment":"This version is not fully edited and will be updated soon"},{"id":"http://arxiv.org/abs/2302.01089v1","updated":"2023-02-02T13:22:18Z","published":"2023-02-02T13:22:18Z","title":"Curriculum Learning for ab initio Deep Learned Refractive Optics","summary":"  Deep lens optimization has recently emerged as a new paradigm for designing\ncomputational imaging systems, however it has been limited to either simple\noptical systems consisting of a single DOE or metalens, or the fine-tuning of\ncompound lenses from good initial designs. Here we present a deep lens design\nmethod based on curriculum learning, which is able to learn optical designs of\ncompound lenses ab initio from randomly initialized surfaces, therefore\novercoming the need for a good initial design. We demonstrate this approach\nwith the fully-automatic design of an extended depth-of-field computational\ncamera in a cellphone-style form factor, highly aspherical surfaces, and a\nshort back focal length.\n","authors":["Xinge Yang","Qiang Fu","Wolfgang Heidrich"],"pdf_url":"https://arxiv.org/pdf/2302.01089v1.pdf","comment":"Automatically design computational lenses from scratch with\n  differentiable ray tracing"},{"id":"http://arxiv.org/abs/2208.08881v2","updated":"2023-02-02T13:19:48Z","published":"2022-08-17T12:03:23Z","title":"Modelling the long-term fairness dynamics of data-driven targeted help\n  on job seekers","summary":"  The use of data-driven decision support by public agencies is becoming more\nwidespread and already influences the allocation of public resources. This\nraises ethical concerns, as it has adversely affected minorities and\nhistorically discriminated groups. In this paper, we use an approach that\ncombines statistics and data-driven approaches with dynamical modeling to\nassess long-term fairness effects of labor market interventions. Specifically,\nwe develop and use a model to investigate the impact of decisions caused by a\npublic employment authority that selectively supports job-seekers through\ntargeted help. The selection of who receives what help is based on a\ndata-driven intervention model that estimates an individual's chances of\nfinding a job in a timely manner and rests upon data that describes a\npopulation in which skills relevant to the labor market are unevenly\ndistributed between two groups (e.g., males and females). The intervention\nmodel has incomplete access to the individual's actual skills and can augment\nthis with knowledge of the individual's group affiliation, thus using a\nprotected attribute to increase predictive accuracy. We assess this\nintervention model's dynamics -- especially fairness-related issues and\ntrade-offs between different fairness goals -- over time and compare it to an\nintervention model that does not use group affiliation as a predictive feature.\nWe conclude that in order to quantify the trade-off correctly and to assess the\nlong-term fairness effects of such a system in the real-world, careful modeling\nof the surrounding labor market is indispensable.\n","authors":["Sebastian Scher","Simone Kopeinik","Andreas Trügler","Dominik Kowald"],"pdf_url":"https://arxiv.org/pdf/2208.08881v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11964v2","updated":"2023-02-02T13:14:11Z","published":"2023-01-27T19:40:03Z","title":"Adversarial Networks and Machine Learning for File Classification","summary":"  Correctly identifying the type of file under examination is a critical part\nof a forensic investigation. The file type alone suggests the embedded content,\nsuch as a picture, video, manuscript, spreadsheet, etc. In cases where a system\nowner might desire to keep their files inaccessible or file type concealed, we\npropose using an adversarially-trained machine learning neural network to\ndetermine a file's true type even if the extension or file header is obfuscated\nto complicate its discovery. Our semi-supervised generative adversarial network\n(SGAN) achieved 97.6% accuracy in classifying files across 11 different types.\nWe also compared our network against a traditional standalone neural network\nand three other machine learning algorithms. The adversarially-trained network\nproved to be the most precise file classifier especially in scenarios with few\nsupervised samples available. Our implementation of a file classifier using an\nSGAN is implemented on GitHub (https://ksaintg.github.io/SGAN-File-Classier).\n","authors":["Ken St. Germain","Josh Angichiodo"],"pdf_url":"https://arxiv.org/pdf/2301.11964v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.08459v2","updated":"2023-02-02T13:11:47Z","published":"2022-05-17T16:00:17Z","title":"Dynamic Recognition of Speakers for Consent Management by Contrastive\n  Embedding Replay","summary":"  Voice assistants overhear conversations and a consent management mechanism is\nrequired. Consent management can be implemented using speaker recognition.\nUsers that do not give consent enrol their voice and all their further\nrecordings are discarded. Building speaker recognition-based consent management\nis challenging as dynamic registration, removal, and re-registration of\nspeakers must be efficiently handled. This work proposes a consent management\nsystem addressing the aforementioned challenges. A contrastive based training\nis applied to learn the underlying speaker equivariance inductive bias. The\ncontrastive features for buckets of speakers are trained a few steps into each\niteration and act as replay buffers. These features are progressively selected\nusing a multi-strided random sampler for classification. Moreover, new methods\nfor dynamic registration using a portion of old utterances, removal, and\nre-registration of speakers are proposed. The results verify memory efficiency\nand dynamic capabilities of the proposed methods and outperform the existing\napproach from the literature.\n","authors":["Arash Shahmansoori","Utz Roedig"],"pdf_url":"https://arxiv.org/pdf/2205.08459v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. The current version includes 36 pages, 8 figures, and 3\n  tables"},{"id":"http://arxiv.org/abs/2302.01079v1","updated":"2023-02-02T13:10:31Z","published":"2023-02-02T13:10:31Z","title":"Uncertainty in Fairness Assessment: Maintaining Stable Conclusions\n  Despite Fluctuations","summary":"  Several recent works encourage the use of a Bayesian framework when assessing\nperformance and fairness metrics of a classification algorithm in a supervised\nsetting. We propose the Uncertainty Matters (UM) framework that generalizes a\nBeta-Binomial approach to derive the posterior distribution of any criteria\ncombination, allowing stable performance assessment in a bias-aware setting.We\nsuggest modeling the confusion matrix of each demographic group using a\nMultinomial distribution updated through a Bayesian procedure. We extend UM to\nbe applicable under the popular K-fold cross-validation procedure. Experiments\nhighlight the benefits of UM over classical evaluation frameworks regarding\ninformativeness and stability.\n","authors":["Ainhize Barrainkua","Paula Gordaliza","Jose A. Lozano","Novi Quadrianto"],"pdf_url":"https://arxiv.org/pdf/2302.01079v1.pdf","comment":"25 pages (including references and appendix), 10 figures. Submitted\n  to ICML 2023"},{"id":"http://arxiv.org/abs/2302.01075v1","updated":"2023-02-02T13:05:27Z","published":"2023-02-02T13:05:27Z","title":"MonoFlow: Rethinking Divergence GANs via the Perspective of Differential\n  Equations","summary":"  The conventional understanding of adversarial training in generative\nadversarial networks (GANs) is that the discriminator is trained to estimate a\ndivergence, and the generator learns to minimize this divergence. We argue that\ndespite the fact that many variants of GANs were developed following this\nparadigm, the current theoretical understanding of GANs and their practical\nalgorithms are inconsistent. In this paper, we leverage Wasserstein gradient\nflows which characterize the evolution of particles in the sample space, to\ngain theoretical insights and algorithmic inspiration of GANs. We introduce a\nunified generative modeling framework - MonoFlow: the particle evolution is\nrescaled via a monotonically increasing mapping of the log density ratio. Under\nour framework, adversarial training can be viewed as a procedure first\nobtaining MonoFlow's vector field via training the discriminator and the\ngenerator learns to draw the particle flow defined by the corresponding vector\nfield. We also reveal the fundamental difference between variational divergence\nminimization and adversarial training. This analysis helps us to identify what\ntypes of generator loss functions can lead to the successful training of GANs\nand suggest that GANs may have more loss designs beyond the literature (e.g.,\nnon-saturated loss), as long as they realize MonoFlow. Consistent empirical\nstudies are included to validate the effectiveness of our framework.\n","authors":["Mingxuan Yi","Zhanxing Zhu","Song Liu"],"pdf_url":"https://arxiv.org/pdf/2302.01075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01068v1","updated":"2023-02-02T12:56:46Z","published":"2023-02-02T12:56:46Z","title":"Fed-GLOSS-DP: Federated, Global Learning using Synthetic Sets with\n  Record Level Differential Privacy","summary":"  This work proposes Fed-GLOSS-DP, a novel approach to privacy-preserving\nlearning that uses synthetic data to train federated models. In our approach,\nthe server recovers an approximation of the global loss landscape in a local\nneighborhood based on synthetic samples received from the clients. In contrast\nto previous, point-wise, gradient-based, linear approximation (such as FedAvg),\nour formulation enables a type of global optimization that is particularly\nbeneficial in non-IID federated settings. We also present how it rigorously\ncomplements record-level differential privacy. Extensive results show that our\nnovel formulation gives rise to considerable improvements in terms of\nconvergence speed and communication costs. We argue that our new approach to\nfederated learning can provide a potential path toward reconciling privacy and\naccountability by sending differentially private, synthetic data instead of\ngradient updates. The source code will be released upon publication.\n","authors":["Hui-Po Wang","Dingfan Chen","Raouf Kerkouche","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2302.01068v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01067v1","updated":"2023-02-02T12:56:26Z","published":"2023-02-02T12:56:26Z","title":"A Survey on Compositional Generalization in Applications","summary":"  The field of compositional generalization is currently experiencing a\nrenaissance in AI, as novel problem settings and algorithms motivated by\nvarious practical applications are being introduced, building on top of the\nclassical compositional generalization problem. This article aims to provide a\ncomprehensive review of top recent developments in multiple real-life\napplications of the compositional generalization. Specifically, we introduce a\ntaxonomy of common applications and summarize the state-of-the-art for each of\nthose domains. Furthermore, we identify important current trends and provide\nnew perspectives pertaining to the future of this burgeoning field.\n","authors":["Baihan Lin","Djallel Bouneffouf","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2302.01067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11080v3","updated":"2023-02-02T12:56:15Z","published":"2022-12-21T15:27:52Z","title":"Is it worth it? Comparing six deep and classical methods for\n  unsupervised anomaly detection in time series","summary":"  Detecting anomalies in time series data is important in a variety of fields,\nincluding system monitoring, healthcare, and cybersecurity. While the abundance\nof available methods makes it difficult to choose the most appropriate method\nfor a given application, each method has its strengths in detecting certain\ntypes of anomalies. In this study, we compare six unsupervised anomaly\ndetection methods of varying complexity to determine whether more complex\nmethods generally perform better and if certain methods are better suited to\ncertain types of anomalies. We evaluated the methods using the UCR anomaly\narchive, a recent benchmark dataset for anomaly detection. We analyzed the\nresults on a dataset and anomaly type level after adjusting the necessary\nhyperparameters for each method. Additionally, we assessed the ability of each\nmethod to incorporate prior knowledge about anomalies and examined the\ndifferences between point-wise and sequence-wise features. Our experiments show\nthat classical machine learning methods generally outperform deep learning\nmethods across a range of anomaly types.\n","authors":["Ferdinand Rewicki","Joachim Denzler","Julia Niebling"],"pdf_url":"https://arxiv.org/pdf/2212.11080v3.pdf","comment":"17 Pages, The repository to reproduce the results is available at\n  https://gitlab.com/dlr-dw/is-it-worth-it-benchmark"},{"id":"http://arxiv.org/abs/2302.01060v1","updated":"2023-02-02T12:45:30Z","published":"2023-02-02T12:45:30Z","title":"Physics Constrained Motion Prediction with Uncertainty Quantification","summary":"  Predicting the motion of dynamic agents is a critical task for guaranteeing\nthe safety of autonomous systems. A particular challenge is that motion\nprediction algorithms should obey dynamics constraints and quantify prediction\nuncertainty as a measure of confidence. We present a physics-constrained\napproach for motion prediction which uses a surrogate dynamical model to ensure\nthat predicted trajectories are dynamically feasible. We propose a two-step\nintegration consisting of intent and trajectory prediction subject to dynamics\nconstraints. We also construct prediction regions that quantify uncertainty and\nare tailored for autonomous driving by using conformal prediction, a popular\nstatistical tool. Physics Constrained Motion Prediction achieves a 41% better\nADE, 56% better FDE, and 19% better IoU over a baseline in experiments using an\nautonomous racing dataset.\n","authors":["Renukanandan Tumu","Lars Lindemann","Truong Nghiem","Rahul Mangharam"],"pdf_url":"https://arxiv.org/pdf/2302.01060v1.pdf","comment":"Submitted to IV 2023"},{"id":"http://arxiv.org/abs/2206.00471v2","updated":"2023-02-02T12:40:25Z","published":"2022-06-01T13:03:58Z","title":"Augmentation Component Analysis: Modeling Similarity via the\n  Augmentation Overlaps","summary":"  Self-supervised learning aims to learn a embedding space where semantically\nsimilar samples are close. Contrastive learning methods pull views of samples\ntogether and push different samples away, which utilizes semantic invariance of\naugmentation but ignores the relationship between samples. To better exploit\nthe power of augmentation, we observe that semantically similar samples are\nmore likely to have similar augmented views. Therefore, we can take the\naugmented views as a special description of a sample. In this paper, we model\nsuch a description as the augmentation distribution and we call it augmentation\nfeature. The similarity in augmentation feature reflects how much the views of\ntwo samples overlap and is related to their semantical similarity. Without\ncomputational burdens to explicitly estimate values of the augmentation\nfeature, we propose Augmentation Component Analysis (ACA) with a\ncontrastive-like loss to learn principal components and an on-the-fly\nprojection loss to embed data. ACA equals an efficient dimension reduction by\nPCA and extracts low-dimensional embeddings, theoretically preserving the\nsimilarity of augmentation distribution between samples. Empirical results show\nour method can achieve competitive results against various traditional\ncontrastive learning methods on different benchmarks.\n","authors":["Lu Han","Han-Jia Ye","De-Chuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2206.00471v2.pdf","comment":"Accept to ICLR 2023"},{"id":"http://arxiv.org/abs/2205.13134v2","updated":"2023-02-02T12:29:53Z","published":"2022-05-26T03:50:52Z","title":"Symbolic Physics Learner: Discovering governing equations via Monte\n  Carlo tree search","summary":"  Nonlinear dynamics is ubiquitous in nature and commonly seen in various\nscience and engineering disciplines. Distilling analytical expressions that\ngovern nonlinear dynamics from limited data remains vital but challenging. To\ntackle this fundamental issue, we propose a novel Symbolic Physics Learner\n(SPL) machine to discover the mathematical structure of nonlinear dynamics. The\nkey concept is to interpret mathematical operations and system state variables\nby computational rules and symbols, establish symbolic reasoning of\nmathematical formulas via expression trees, and employ a Monte Carlo tree\nsearch (MCTS) agent to explore optimal expression trees based on measurement\ndata. The MCTS agent obtains an optimistic selection policy through the\ntraversal of expression trees, featuring the one that maps to the arithmetic\nexpression of underlying physics. Salient features of the proposed framework\ninclude search flexibility and enforcement of parsimony for discovered\nequations. The efficacy and superiority of the SPL machine are demonstrated by\nnumerical examples, compared with state-of-the-art baselines.\n","authors":["Fangzheng Sun","Yang Liu","Jian-Xun Wang","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2205.13134v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2302.01052v1","updated":"2023-02-02T12:29:38Z","published":"2023-02-02T12:29:38Z","title":"Site-specific Deep Learning Path Loss Models based on the Method of\n  Moments","summary":"  This paper describes deep learning models based on convolutional neural\nnetworks applied to the problem of predicting EM wave propagation over rural\nterrain. A surface integral equation formulation, solved with the method of\nmoments and accelerated using the Fast Far Field approximation, is used to\ngenerate synthetic training data which comprises path loss computed over\nrandomly generated 1D terrain profiles. These are used to train two networks,\none based on fractal profiles and one based on profiles generated using a\nGaussian process. The models show excellent agreement when applied to test\nprofiles generated using the same statistical process used to create the\ntraining data and very good accuracy when applied to real life problems.\n","authors":["Conor Brennan","Kevin McGuinness"],"pdf_url":"https://arxiv.org/pdf/2302.01052v1.pdf","comment":"EuCAP 2023"},{"id":"http://arxiv.org/abs/2302.01051v1","updated":"2023-02-02T12:28:49Z","published":"2023-02-02T12:28:49Z","title":"Randomized prior wavelet neural operator for uncertainty quantification","summary":"  In this paper, we propose a novel data-driven operator learning framework\nreferred to as the \\textit{Randomized Prior Wavelet Neural Operator} (RP-WNO).\nThe proposed RP-WNO is an extension of the recently proposed wavelet neural\noperator, which boasts excellent generalizing capabilities but cannot estimate\nthe uncertainty associated with its predictions. RP-WNO, unlike the vanilla\nWNO, comes with inherent uncertainty quantification module and hence, is\nexpected to be extremely useful for scientists and engineers alike. RP-WNO\nutilizes randomized prior networks, which can account for prior information and\nis easier to implement for large, complex deep-learning architectures than its\nBayesian counterpart. Four examples have been solved to test the proposed\nframework, and the results produced advocate favorably for the efficacy of the\nproposed framework.\n","authors":["Shailesh Garg","Souvik Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2302.01051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01048v1","updated":"2023-02-02T12:22:30Z","published":"2023-02-02T12:22:30Z","title":"Teaching MLOps in Higher Education through Project-Based Learning","summary":"  Building and maintaining production-grade ML-enabled components is a complex\nendeavor that goes beyond the current approach of academic education, focused\non the optimization of ML model performance in the lab. In this paper, we\npresent a project-based learning approach to teaching MLOps, focused on the\ndemonstration and experience with emerging practices and tools to automatize\nthe construction of ML-enabled components. We examine the design of a course\nbased on this approach, including laboratory sessions that cover the end-to-end\nML component life cycle, from model building to production deployment.\nMoreover, we report on preliminary results from the first edition of the\ncourse. During the present year, an updated version of the same course is being\ndelivered in two independent universities; the related learning outcomes will\nbe evaluated to analyze the effectiveness of project-based learning for this\nspecific subject.\n","authors":["Filippo Lanubile","Silverio Martínez-Fernández","Luigi Quaranta"],"pdf_url":"https://arxiv.org/pdf/2302.01048v1.pdf","comment":"Accepted in 2023 IEEE/ACM 45th International Conference on Software\n  Engineering: Software Engineering Education and Training (ICSE-SEET)"},{"id":"http://arxiv.org/abs/2302.01047v1","updated":"2023-02-02T12:21:10Z","published":"2023-02-02T12:21:10Z","title":"Real-Time Evaluation in Online Continual Learning: A New Paradigm","summary":"  Current evaluations of Continual Learning (CL) methods typically assume that\nthere is no constraint on training time and computation. This is an unrealistic\nassumption for any real-world setting, which motivates us to propose: a\npractical real-time evaluation of continual learning, in which the stream does\nnot wait for the model to complete training before revealing the next data for\npredictions. To do this, we evaluate current CL methods with respect to their\ncomputational costs. We hypothesize that under this new evaluation paradigm,\ncomputationally demanding CL approaches may perform poorly on streams with a\nvarying distribution. We conduct extensive experiments on CLOC, a large-scale\ndataset containing 39 million time-stamped images with geolocation labels. We\nshow that a simple baseline outperforms state-of-the-art CL methods under this\nevaluation, questioning the applicability of existing methods in realistic\nsettings. In addition, we explore various CL components commonly used in the\nliterature, including memory sampling strategies and regularization approaches.\nWe find that all considered methods fail to be competitive against our simple\nbaseline. This surprisingly suggests that the majority of existing CL\nliterature is tailored to a specific class of streams that is not practical. We\nhope that the evaluation we provide will be the first step towards a paradigm\nshift to consider the computational cost in the development of online continual\nlearning methods.\n","authors":["Yasir Ghunaim","Adel Bibi","Kumail Alhamoud","Motasem Alfarra","Hasan Abed Al Kader Hammoud","Ameya Prabhu","Philip H. S. Torr","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2302.01047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12232v3","updated":"2023-02-02T11:47:13Z","published":"2022-08-25T17:31:15Z","title":"A survey, review, and future trends of skin lesion segmentation and\n  classification","summary":"  The Computer-aided Diagnosis or Detection (CAD) approach for skin lesion\nanalysis is an emerging field of research that has the potential to alleviate\nthe burden and cost of skin cancer screening. Researchers have recently\nindicated increasing interest in developing such CAD systems, with the\nintention of providing a user-friendly tool to dermatologists to reduce the\nchallenges encountered or associated with manual inspection. This article aims\nto provide a comprehensive literature survey and review of a total of 594\npublications (356 for skin lesion segmentation and 238 for skin lesion\nclassification) published between 2011 and 2022. These articles are analyzed\nand summarized in a number of different ways to contribute vital information\nregarding the methods for the development of CAD systems. These ways include\nrelevant and essential definitions and theories, input data (dataset\nutilization, preprocessing, augmentations, and fixing imbalance problems),\nmethod configuration (techniques, architectures, module frameworks, and\nlosses), training tactics (hyperparameter settings), and evaluation criteria.\nWe intend to investigate a variety of performance-enhancing approaches,\nincluding ensemble and post-processing. We also discuss these dimensions to\nreveal their current trends based on utilization frequencies. In addition, we\nhighlight the primary difficulties associated with evaluating skin lesion\nsegmentation and classification systems using minimal datasets, as well as the\npotential solutions to these difficulties. Findings, recommendations, and\ntrends are disclosed to inform future research on developing an automated and\nrobust CAD system for skin lesion analysis.\n","authors":["Md. Kamrul Hasan","Md. Asif Ahamad","Choon Hwai Yap","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2208.12232v3.pdf","comment":"This manuscript has been accepted to be published in Computers in\n  Biology and Medicine and has a total of 106 pages (single column and double\n  spacing), 13 figures, and 11 tables"},{"id":"http://arxiv.org/abs/2302.01029v1","updated":"2023-02-02T11:46:23Z","published":"2023-02-02T11:46:23Z","title":"On Suppressing Range of Adaptive Stepsizes of Adam to Improve\n  Generalisation Performance","summary":"  A number of recent adaptive optimizers improve the generalisation performance\nof Adam by essentially reducing the variance of adaptive stepsizes to get\ncloser to SGD with momentum. Following the above motivation, we suppress the\nrange of the adaptive stepsizes of Adam by exploiting the layerwise gradient\nstatistics. In particular, at each iteration, we propose to perform three\nconsecutive operations on the second momentum v_t before using it to update a\nDNN model: (1): down-scaling, (2): epsilon-embedding, and (3):\ndown-translating. The resulting algorithm is referred to as SET-Adam, where SET\nis a brief notation of the three operations. The down-scaling operation on v_t\nis performed layerwise by making use of the angles between the layerwise\nsubvectors of v_t and the corresponding all-one subvectors. Extensive\nexperimental results show that SET-Adam outperforms eight adaptive optimizers\nwhen training transformers and LSTMs for NLP, and VGG and ResNet for image\nclassification over CIAF10 and CIFAR100 while matching the best performance of\nthe eight adaptive methods when training WGAN-GP models for image generation\ntasks. Furthermore, SET-Adam produces higher validation accuracies than Adam\nand AdaBelief for training ResNet18 over ImageNet.\n","authors":["Guoqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01029v1.pdf","comment":"12 pages. arXiv admin note: substantial text overlap with\n  arXiv:2203.13273"},{"id":"http://arxiv.org/abs/2302.01027v1","updated":"2023-02-02T11:42:26Z","published":"2023-02-02T11:42:26Z","title":"FCB-SwinV2 Transformer for Polyp Segmentation","summary":"  Polyp segmentation within colonoscopy video frames using deep learning models\nhas the potential to automate the workflow of clinicians. This could help\nimprove the early detection rate and characterization of polyps which could\nprogress to colorectal cancer. Recent state-of-the-art deep learning polyp\nsegmentation models have combined the outputs of Fully Convolutional Network\narchitectures and Transformer Network architectures which work in parallel. In\nthis paper we propose modifications to the current state-of-the-art polyp\nsegmentation model FCBFormer. The transformer architecture of the FCBFormer is\nreplaced with a SwinV2 Transformer-UNET and minor changes to the Fully\nConvolutional Network architecture are made to create the FCB-SwinV2\nTransformer. The performance of the FCB-SwinV2 Transformer is evaluated on the\npopular colonoscopy segmentation bench-marking datasets Kvasir-SEG and\nCVC-ClinicDB. Generalizability tests are also conducted. The FCB-SwinV2\nTransformer is able to consistently achieve higher mDice scores across all\ntests conducted and therefore represents new state-of-the-art performance.\nIssues found with how colonoscopy segmentation model performance is evaluated\nwithin literature are also re-ported and discussed. One of the most important\nissues identified is that when evaluating performance on the CVC-ClinicDB\ndataset it would be preferable to ensure no data leakage from video sequences\noccurs during the training/validation/test data partition.\n","authors":["Kerr Fitzgerald","Bogdan Matuszewski"],"pdf_url":"https://arxiv.org/pdf/2302.01027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01020v1","updated":"2023-02-02T11:15:07Z","published":"2023-02-02T11:15:07Z","title":"Meta Learning in Decentralized Neural Networks: Towards More General AI","summary":"  Meta-learning usually refers to a learning algorithm that learns from other\nlearning algorithms. The problem of uncertainty in the predictions of neural\nnetworks shows that the world is only partially predictable and a learned\nneural network cannot generalize to its ever-changing surrounding environments.\nTherefore, the question is how a predictive model can represent multiple\npredictions simultaneously. We aim to provide a fundamental understanding of\nlearning to learn in the contents of Decentralized Neural Networks\n(Decentralized NNs) and we believe this is one of the most important questions\nand prerequisites to building an autonomous intelligence machine. To this end,\nwe shall demonstrate several pieces of evidence for tackling the problems above\nwith Meta Learning in Decentralized NNs. In particular, we will present three\ndifferent approaches to building such a decentralized learning system: (1)\nlearning from many replica neural networks, (2) building the hierarchy of\nneural networks for different functions, and (3) leveraging different modality\nexperts to learn cross-modal representations.\n","authors":["Yuwei Sun"],"pdf_url":"https://arxiv.org/pdf/2302.01020v1.pdf","comment":"Accepted for AAAI 2023 workshop"},{"id":"http://arxiv.org/abs/2302.01018v1","updated":"2023-02-02T11:12:51Z","published":"2023-02-02T11:12:51Z","title":"Graph Neural Networks for temporal graphs: State of the art, open\n  challenges, and opportunities","summary":"  Graph Neural Networks (GNNs) have become the leading paradigm for learning on\n(static) graph-structured data. However, many real-world systems are dynamic in\nnature, since the graph and node/edge attributes change over time. In recent\nyears, GNN-based models for temporal graphs have emerged as a promising area of\nresearch to extend the capabilities of GNNs. In this work, we provide the first\ncomprehensive overview of the current state-of-the-art of temporal GNN,\nintroducing a rigorous formalization of learning settings and tasks and a novel\ntaxonomy categorizing existing approaches in terms of how the temporal aspect\nis represented and processed. We conclude the survey with a discussion of the\nmost relevant open challenges for the field, from both research and application\nperspectives.\n","authors":["Antonio Longa","Veronica Lachi","Gabriele Santin","Monica Bianchini","Bruno Lepri","Pietro Lio","Franco Scarselli","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2302.01018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13293v2","updated":"2023-02-02T11:06:26Z","published":"2023-01-30T21:11:13Z","title":"An adversarial feature learning strategy for debiasing neural networks","summary":"  Simplicity bias is the concerning tendency of deep networks to over-depend on\nsimple, weakly predictive features, to the exclusion of stronger, more complex\nfeatures. This causes biased, incorrect model predictions in many real-world\napplications, exacerbated by incomplete training data containing spurious\nfeature-label correlations. We propose a direct, interventional method for\naddressing simplicity bias in DNNs, which we call the feature sieve. We aim to\nautomatically identify and suppress easily-computable spurious features in\nlower layers of the network, thereby allowing the higher network levels to\nextract and utilize richer, more meaningful representations. We provide\nconcrete evidence of this differential suppression & enhancement of relevant\nfeatures on both controlled datasets and real-world images, and report\nsubstantial gains on many real-world debiasing benchmarks (11.4% relative gain\non Imagenet-A; 3.2% on BAR, etc). Crucially, we outperform many baselines that\nincorporate knowledge about known spurious or biased attributes, despite our\nmethod not using any such information. We believe that our feature sieve work\nopens up exciting new research directions in automated adversarial feature\nextraction & representation learning for deep networks.\n","authors":["Rishabh Tiwari","Pradeep Shenoy"],"pdf_url":"https://arxiv.org/pdf/2301.13293v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.09346v2","updated":"2023-02-02T10:48:24Z","published":"2022-03-17T14:26:17Z","title":"Error estimates for physics informed neural networks approximating the\n  Navier-Stokes equations","summary":"  We prove rigorous bounds on the errors resulting from the approximation of\nthe incompressible Navier-Stokes equations with (extended) physics informed\nneural networks. We show that the underlying PDE residual can be made\narbitrarily small for tanh neural networks with two hidden layers. Moreover,\nthe total error can be estimated in terms of the training error, network size\nand number of quadrature points. The theory is illustrated with numerical\nexperiments.\n","authors":["Tim De Ryck","Ameya D. Jagtap","Siddhartha Mishra"],"pdf_url":"https://arxiv.org/pdf/2203.09346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01002v1","updated":"2023-02-02T10:40:06Z","published":"2023-02-02T10:40:06Z","title":"Over-parameterised Shallow Neural Networks with Asymmetrical Node\n  Scaling: Global Convergence Guarantees and Feature Learning","summary":"  We consider the optimisation of large and shallow neural networks via\ngradient flow, where the output of each hidden node is scaled by some positive\nparameter. We focus on the case where the node scalings are non-identical,\ndiffering from the classical Neural Tangent Kernel (NTK) parameterisation. We\nprove that, for large neural networks, with high probability, gradient flow\nconverges to a global minimum AND can learn features, unlike in the NTK regime.\nWe also provide experiments on synthetic and real-world datasets illustrating\nour theoretical results and showing the benefit of such scaling in terms of\npruning and transfer learning.\n","authors":["Francois Caron","Fadhel Ayed","Paul Jung","Hoil Lee","Juho Lee","Hongseok Yang"],"pdf_url":"https://arxiv.org/pdf/2302.01002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00999v1","updated":"2023-02-02T10:37:23Z","published":"2023-02-02T10:37:23Z","title":"High-Probability Bounds for Stochastic Optimization and Variational\n  Inequalities: the Case of Unbounded Variance","summary":"  During recent years the interest of optimization and machine learning\ncommunities in high-probability convergence of stochastic optimization methods\nhas been growing. One of the main reasons for this is that high-probability\ncomplexity bounds are more accurate and less studied than in-expectation ones.\nHowever, SOTA high-probability non-asymptotic convergence results are derived\nunder strong assumptions such as the boundedness of the gradient noise variance\nor of the objective's gradient itself. In this paper, we propose several\nalgorithms with high-probability convergence results under less restrictive\nassumptions. In particular, we derive new high-probability convergence results\nunder the assumption that the gradient/operator noise has bounded central\n$\\alpha$-th moment for $\\alpha \\in (1,2]$ in the following setups: (i) smooth\nnon-convex / Polyak-Lojasiewicz / convex / strongly convex / quasi-strongly\nconvex minimization problems, (ii) Lipschitz / star-cocoercive and monotone /\nquasi-strongly monotone variational inequalities. These results justify the\nusage of the considered methods for solving problems that do not fit standard\nfunctional classes studied in stochastic optimization.\n","authors":["Abdurakhmon Sadiev","Marina Danilova","Eduard Gorbunov","Samuel Horváth","Gauthier Gidel","Pavel Dvurechensky","Alexander Gasnikov","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2302.00999v1.pdf","comment":"86 pages"},{"id":"http://arxiv.org/abs/2211.01916v2","updated":"2023-02-02T10:34:04Z","published":"2022-11-03T15:51:00Z","title":"Improved Analysis of Score-based Generative Modeling: User-Friendly\n  Bounds under Minimal Smoothness Assumptions","summary":"  We give an improved theoretical analysis of score-based generative modeling.\nUnder a score estimate with small $L^2$ error (averaged across timesteps), we\nprovide efficient convergence guarantees for any data distribution with\nsecond-order moment, by either employing early stopping or assuming smoothness\ncondition on the score function of the data distribution. Our result does not\nrely on any log-concavity or functional inequality assumption and has a\nlogarithmic dependence on the smoothness. In particular, we show that under\nonly a finite second moment condition, approximating the following in reverse\nKL divergence in $\\epsilon$-accuracy can be done in $\\tilde O\\left(\\frac{d \\log\n(1/\\delta)}{\\epsilon}\\right)$ steps: 1) the variance-$\\delta$ Gaussian\nperturbation of any data distribution; 2) data distributions with\n$1/\\delta$-smooth score functions. Our analysis also provides a quantitative\ncomparison between different discrete approximations and may guide the choice\nof discretization points in practice.\n","authors":["Hongrui Chen","Holden Lee","Jianfeng Lu"],"pdf_url":"https://arxiv.org/pdf/2211.01916v2.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2302.00997v1","updated":"2023-02-02T10:33:09Z","published":"2023-02-02T10:33:09Z","title":"Constrained Online Two-stage Stochastic Optimization: New Algorithms via\n  Adversarial Learning","summary":"  We consider an online two-stage stochastic optimization with long-term\nconstraints over a finite horizon of $T$ periods. At each period, we take the\nfirst-stage action, observe a model parameter realization and then take the\nsecond-stage action from a feasible set that depends both on the first-stage\ndecision and the model parameter. We aim to minimize the cumulative objective\nvalue while guaranteeing that the long-term average second-stage decision\nbelongs to a set. We propose a general algorithmic framework that derives\nonline algorithms for the online two-stage problem from adversarial learning\nalgorithms. Also, the regret bound of our algorithm cam be reduced to the\nregret bound of embedded adversarial learning algorithms. Based on our\nframework, we obtain new results under various settings. When the model\nparameter at each period is drawn from identical distributions, we derive\nstate-of-art regret bound that improves previous bounds under special cases.\nOur algorithm is also robust to adversarial corruptions of model parameter\nrealizations. When the model parameters are drawn from unknown non-stationary\ndistributions and we are given prior estimates of the distributions, we develop\na new algorithm from our framework with a regret $O(W_T+\\sqrt{T})$, where $W_T$\nmeasures the total inaccuracy of the prior estimates.\n","authors":["Jiashuo Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.00997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08609v3","updated":"2023-02-02T10:24:13Z","published":"2022-08-18T03:06:25Z","title":"A Scalable, Interpretable, Verifiable & Differentiable Logic Gate\n  Convolutional Neural Network Architecture From Truth Tables","summary":"  We propose $\\mathcal{T}$ruth $\\mathcal{T}$able net ($\\mathcal{TT}$net), a\nnovel Convolutional Neural Network (CNN) architecture that addresses, by\ndesign, the open challenges of interpretability, formal verification, and logic\ngate conversion. $\\mathcal{TT}$net is built using CNNs' filters that are\nequivalent to tractable truth tables and that we call Learning Truth Table\n(LTT) blocks. The dual form of LTT blocks allows the truth tables to be easily\ntrained with gradient descent and makes these CNNs easy to interpret, verify\nand infer. Specifically, $\\mathcal{TT}$net is a deep CNN model that can be\nautomatically represented, after post-training transformation, as a sum of\nBoolean decision trees, or as a sum of Disjunctive/Conjunctive Normal Form\n(DNF/CNF) formulas, or as a compact Boolean logic circuit. We demonstrate the\neffectiveness and scalability of $\\mathcal{TT}$net on multiple datasets,\nshowing comparable interpretability to decision trees, fast complete/sound\nformal verification, and scalable logic gate representation, all compared to\nstate-of-the-art methods. We believe this work represents a step towards making\nCNNs more transparent and trustworthy for real-world critical applications.\n","authors":["Adrien Benamira","Tristan Guérand","Thomas Peyrin","Trevor Yap","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2208.08609v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00993v1","updated":"2023-02-02T10:21:49Z","published":"2023-02-02T10:21:49Z","title":"Unpaired Multi-Domain Causal Representation Learning","summary":"  The goal of causal representation learning is to find a representation of\ndata that consists of causally related latent variables. We consider a setup\nwhere one has access to data from multiple domains that potentially share a\ncausal representation. Crucially, observations in different domains are assumed\nto be unpaired, that is, we only observe the marginal distribution in each\ndomain but not their joint distribution. In this paper, we give sufficient\nconditions for identifiability of the joint distribution and the shared causal\ngraph in a linear setup. Identifiability holds if we can uniquely recover the\njoint distribution and the shared causal representation from the marginal\ndistributions in each domain. We transform our identifiability results into a\npractical method to recover the shared latent causal graph. Moreover, we study\nhow multiple domains reduce errors in falsely detecting shared causal variables\nin the finite data setting.\n","authors":["Nils Sturma","Chandler Squires","Mathias Drton","Caroline Uhler"],"pdf_url":"https://arxiv.org/pdf/2302.00993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00992v1","updated":"2023-02-02T10:21:00Z","published":"2023-02-02T10:21:00Z","title":"Exposing the CSI: A Systematic Investigation of CSI-based Wi-Fi Sensing\n  Capabilities and Limitations","summary":"  Thanks to the ubiquitous deployment of Wi-Fi hotspots, channel state\ninformation (CSI)-based Wi-Fi sensing can unleash game-changing applications in\nmany fields, such as healthcare, security, and entertainment. However, despite\none decade of active research on Wi-Fi sensing, most existing work only\nconsiders legacy IEEE 802.11n devices, often in particular and\nstrictly-controlled environments. Worse yet, there is a fundamental lack of\nunderstanding of the impact on CSI-based sensing of modern Wi-Fi features, such\nas 160-MHz bandwidth, multiple-input multiple-output (MIMO) transmissions, and\nincreased spectral resolution in IEEE 802.11ax (Wi-Fi 6). This work aims to\nshed light on the impact of Wi-Fi 6 features on the sensing performance and to\ncreate a benchmark for future research on Wi-Fi sensing. To this end, we\nperform an extensive CSI data collection campaign involving 3 individuals, 3\nenvironments, and 12 activities, using Wi-Fi 6 signals. An anonymized ground\ntruth obtained through video recording accompanies our 80-GB dataset, which\ncontains almost two hours of CSI data from three collectors. We leverage our\ndataset to dissect the performance of a state-of-the-art sensing framework\nacross different environments and individuals. Our key findings suggest that\n(i) MIMO transmissions and higher spectral resolution might be more beneficial\nthan larger bandwidth for sensing applications; (ii) there is a pressing need\nto standardize research on Wi-Fi sensing because the path towards a truly\nenvironment-independent framework is still uncertain. To ease the experiments'\nreplicability and address the current lack of Wi-Fi 6 CSI datasets, we release\nour 80-GB dataset to the community.\n","authors":["Marco Cominelli","Francesco Gringoli","Francesco Restuccia"],"pdf_url":"https://arxiv.org/pdf/2302.00992v1.pdf","comment":"10 pages, 13 figures, accepted for publication in Proceedings of IEEE\n  PerCom 2023"},{"id":"http://arxiv.org/abs/2302.00985v1","updated":"2023-02-02T10:09:23Z","published":"2023-02-02T10:09:23Z","title":"Speed-Oblivious Online Scheduling: Knowing (Precise) Speeds is not\n  Necessary","summary":"  We consider online scheduling on unrelated (heterogeneous) machines in a\nspeed-oblivious setting, where an algorithm is unaware of the exact\njob-dependent processing speeds. We show strong impossibility results for\nclairvoyant and non-clairvoyant algorithms and overcome them in models inspired\nby practical settings: (i) we provide competitive learning-augmented\nalgorithms, assuming that (possibly erroneous) predictions on the speeds are\ngiven, and (ii) we provide competitive algorithms for the speed-ordered model,\nwhere a single global order of machines according to their unknown\njob-dependent speeds is known. We prove strong theoretical guarantees and\nevaluate our findings on a representative heterogeneous multi-core processor.\nThese seem to be the first empirical results for algorithms with predictions\nthat are performed in a non-synthetic environment on real hardware.\n","authors":["Alexander Lindermayr","Nicole Megow","Martin Rapp"],"pdf_url":"https://arxiv.org/pdf/2302.00985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00981v1","updated":"2023-02-02T10:00:46Z","published":"2023-02-02T10:00:46Z","title":"Predicting Molecule-Target Interaction by Learning Biomedical Network\n  and Molecule Representations","summary":"  The study of molecule-target interaction is quite important for drug\ndiscovery in terms of target identification, pathway study, drug-drug\ninteraction, etc. Most existing methodologies utilize either biomedical network\ninformation or molecule structural features to predict potential interaction\nlink. However, the biomedical network information based methods usually suffer\nfrom cold start problem, while structure based methods often give limited\nperformance due to the structure/interaction assumption and data quality. To\naddress these issues, we propose a pseudo-siamese Graph Neural Network method,\nnamely MTINet+, which learns both biomedical network topological and molecule\nstructural/chemical information as representations to predict potential\ninteraction of given molecule and target pair. In MTINet+, 1-hop subgraphs of\ngiven molecule and target pair are extracted from known interaction of\nbiomedical network as topological information, meanwhile the molecule\nstructural and chemical attributes are processed as molecule information.\nMTINet+ learns these two types of information as embedding features for\npredicting the pair link. In the experiments of different molecule-target\ninteraction tasks, MTINet+ significantly outperforms over the state-of-the-art\nbaselines. In addition, in our designed network sparsity experiments , MTINet+\nshows strong robustness against different sparse biomedical networks.\n","authors":["Jinjiang Guo","Jie Li"],"pdf_url":"https://arxiv.org/pdf/2302.00981v1.pdf","comment":"9 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:2102.01649"},{"id":"http://arxiv.org/abs/2302.00980v1","updated":"2023-02-02T09:59:55Z","published":"2023-02-02T09:59:55Z","title":"Domain Generalization Emerges from Dreaming","summary":"  Recent studies have proven that DNNs, unlike human vision, tend to exploit\ntexture information rather than shape. Such texture bias is one of the factors\nfor the poor generalization performance of DNNs. We observe that the texture\nbias negatively affects not only in-domain generalization but also\nout-of-distribution generalization, i.e., Domain Generalization. Motivated by\nthe observation, we propose a new framework to reduce the texture bias of a\nmodel by a novel optimization-based data augmentation, dubbed Stylized Dream.\nOur framework utilizes adaptive instance normalization (AdaIN) to augment the\nstyle of an original image yet preserve the content. We then adopt a\nregularization loss to predict consistent outputs between Stylized Dream and\noriginal images, which encourages the model to learn shape-based\nrepresentations. Extensive experiments show that the proposed method achieves\nstate-of-the-art performance in out-of-distribution settings on public\nbenchmark datasets: PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet.\n","authors":["Hwan Heo","Youngjin Oh","Jaewon Lee","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2302.00980v1.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.00973v1","updated":"2023-02-02T09:49:07Z","published":"2023-02-02T09:49:07Z","title":"A Light-weight CNN Model for Efficient Parkinson's Disease Diagnostics","summary":"  In recent years, deep learning methods have achieved great success in various\nfields due to their strong performance in practical applications. In this\npaper, we present a light-weight neural network for Parkinson's disease\ndiagnostics, in which a series of hand-drawn data are collected to distinguish\nParkinson's disease patients from healthy control subjects. The proposed model\nconsists of a convolution neural network (CNN) cascading to long-short-term\nmemory (LSTM) to adapt the characteristics of collected time-series signals. To\nmake full use of their advantages, a multilayered LSTM model is firstly used to\nenrich features which are then concatenated with raw data and fed into a\nshallow one-dimensional (1D) CNN model for efficient classification.\nExperimental results show that the proposed model achieves a high-quality\ndiagnostic result over multiple evaluation metrics with much fewer parameters\nand operations, outperforming conventional methods such as support vector\nmachine (SVM), random forest (RF), lightgbm (LGB) and CNN-based methods.\n","authors":["Xuechao Wang","Junqing Huang","Marianna Chatzakou","Kadri Medijainen","Pille Taba","Aaro Toomela","Sven Nomm","Michael Ruzhansky"],"pdf_url":"https://arxiv.org/pdf/2302.00973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.07916v2","updated":"2023-02-02T09:40:29Z","published":"2021-06-15T07:04:39Z","title":"Encouraging Intra-Class Diversity Through a Reverse Contrastive Loss for\n  Better Single-Source Domain Generalization","summary":"  Traditional deep learning algorithms often fail to generalize when they are\ntested outside of the domain of the training data. The issue can be mitigated\nby using unlabeled data from the target domain at training time, but because\ndata distributions can change dynamically in real-life applications once a\nlearned model is deployed, it is critical to create networks robust to unknown\nand unforeseen domain shifts. In this paper we focus on one of the reasons\nbehind the inability of neural networks to be so: deep networks focus only on\nthe most obvious, potentially spurious, clues to make their predictions and are\nblind to useful but slightly less efficient or more complex patterns. This\nbehaviour has been identified and several methods partially addressed the\nissue. To investigate their effectiveness and limits, we first design a\npublicly available MNIST-based benchmark to precisely measure the ability of an\nalgorithm to find the ''hidden'' patterns. Then, we evaluate state-of-the-art\nalgorithms through our benchmark and show that the issue is largely unsolved.\nFinally, we propose a partially reversed contrastive loss to encourage\nintra-class diversity and find less strongly correlated patterns, whose\nefficiency is demonstrated by our experiments.\n","authors":["Thomas Duboudin","Emmanuel Dellandréa","Corentin Abgrall","Gilles Hénaff","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2106.07916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00967v1","updated":"2023-02-02T09:20:54Z","published":"2023-02-02T09:20:54Z","title":"Energy Efficiency of Training Neural Network Architectures: An Empirical\n  Study","summary":"  The evaluation of Deep Learning models has traditionally focused on criteria\nsuch as accuracy, F1 score, and related measures. The increasing availability\nof high computational power environments allows the creation of deeper and more\ncomplex models. However, the computations needed to train such models entail a\nlarge carbon footprint. In this work, we study the relations between DL model\narchitectures and their environmental impact in terms of energy consumed and\nCO$_2$ emissions produced during training by means of an empirical study using\nDeep Convolutional Neural Networks. Concretely, we study: (i) the impact of the\narchitecture and the location where the computations are hosted on the energy\nconsumption and emissions produced; (ii) the trade-off between accuracy and\nenergy efficiency; and (iii) the difference on the method of measurement of the\nenergy consumed using software-based and hardware-based tools.\n","authors":["Yinlena Xu","Silverio Martínez-Fernández","Matias Martinez","Xavier Franch"],"pdf_url":"https://arxiv.org/pdf/2302.00967v1.pdf","comment":"Accepted in HICSS 2023. For its published version refer to the\n  Proceedings of the 56th Hawaii International Conference on System Sciences;\n  URI https://hdl.handle.net/10125/102727"},{"id":"http://arxiv.org/abs/2208.10833v4","updated":"2023-02-02T09:17:52Z","published":"2022-08-23T09:32:19Z","title":"LogLG: Weakly Supervised Log Anomaly Detection via Log-Event Graph\n  Construction","summary":"  Fully supervised log anomaly detection methods suffer the heavy burden of\nannotating massive unlabeled log data. Recently, many semi-supervised methods\nhave been proposed to reduce annotation costs with the help of parsed\ntemplates. However, these methods consider each keyword independently, which\ndisregards the correlation between keywords and the contextual relationships\namong log sequences. In this paper, we propose a novel weakly supervised log\nanomaly detection framework, named LogLG, to explore the semantic connections\namong keywords from sequences. Specifically, we design an end-to-end iterative\nprocess, where the keywords of unlabeled logs are first extracted to construct\na log-event graph. Then, we build a subgraph annotator to generate pseudo\nlabels for unlabeled log sequences. To ameliorate the annotation quality, we\nadopt a self-supervised task to pre-train a subgraph annotator. After that, a\ndetection model is trained with the generated pseudo labels. Conditioned on the\nclassification results, we re-extract the keywords from the log sequences and\nupdate the log-event graph for the next iteration. Experiments on five\nbenchmarks validate the effectiveness of LogLG for detecting anomalies on\nunlabeled log data and demonstrate that LogLG, as the state-of-the-art weakly\nsupervised method, achieves significant performance improvements compared to\nexisting methods.\n","authors":["Hongcheng Guo","Yuhui Guo","Jian Yang","Jiaheng Liu","Zhoujun Li","Tieqiao Zheng","Weichao Hou","Liangfan Zheng","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2208.10833v4.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2302.00353v2","updated":"2023-02-02T08:57:01Z","published":"2023-02-01T10:24:55Z","title":"Towards Label-Efficient Incremental Learning: A Survey","summary":"  The current dominant paradigm when building a machine learning model is to\niterate over a dataset over and over until convergence. Such an approach is\nnon-incremental, as it assumes access to all images of all categories at once.\nHowever, for many applications, non-incremental learning is unrealistic. To\nthat end, researchers study incremental learning, where a learner is required\nto adapt to an incoming stream of data with a varying distribution while\npreventing forgetting of past knowledge. Significant progress has been made,\nhowever, the vast majority of works focus on the fully supervised setting,\nmaking these algorithms label-hungry thus limiting their real-life deployment.\nTo that end, in this paper, we make the first attempt to survey recently\ngrowing interest in label-efficient incremental learning. We identify three\nsubdivisions, namely semi-, few-shot- and self-supervised learning to reduce\nlabeling efforts. Finally, we identify novel directions that can further\nenhance label-efficiency and improve incremental learning scalability. Project\nwebsite: https://github.com/kilickaya/label-efficient-il.\n","authors":["Mert Kilickaya","Joost van de Weijer","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2302.00353v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00956v1","updated":"2023-02-02T08:51:07Z","published":"2023-02-02T08:51:07Z","title":"Resilient Binary Neural Network","summary":"  Binary neural networks (BNNs) have received ever-increasing popularity for\ntheir great capability of reducing storage burden as well as quickening\ninference time. However, there is a severe performance drop compared with\n{real-valued} networks, due to its intrinsic frequent weight oscillation during\ntraining. In this paper, we introduce a Resilient Binary Neural Network (ReBNN)\nto mitigate the frequent oscillation for better BNNs' training. We identify\nthat the weight oscillation mainly stems from the non-parametric scaling\nfactor. To address this issue, we propose to parameterize the scaling factor\nand introduce a weighted reconstruction loss to build an adaptive training\nobjective. %To the best of our knowledge, it is the first work to solve BNNs\nbased on a dynamically re-weighted loss function. For the first time, we show\nthat the weight oscillation is controlled by the balanced parameter attached to\nthe reconstruction loss, which provides a theoretical foundation to\nparameterize it in back propagation. Based on this, we learn our ReBNN by\n{calculating} the {balanced} parameter {based on} its maximum magnitude, which\ncan effectively mitigate the weight oscillation with a resilient training\nprocess. Extensive experiments are conducted upon various network models, such\nas ResNet and Faster-RCNN for computer vision, as well as BERT for natural\nlanguage processing. The results demonstrate the overwhelming performance of\nour ReBNN over prior arts. For example, our ReBNN achieves 66.9\\% Top-1\naccuracy with ResNet-18 backbone on the ImageNet dataset, surpassing existing\nstate-of-the-arts by a significant margin. Our code is open-sourced at\nhttps://github.com/SteveTsui/ReBNN.\n","authors":["Sheng Xu","Yanjing Li","Teli Ma","Mingbao Lin","Hao Dong","Baochang Zhang","Peng Gao","Jinhu Lv"],"pdf_url":"https://arxiv.org/pdf/2302.00956v1.pdf","comment":"AAAI 2023 Oral"},{"id":"http://arxiv.org/abs/2301.13418v2","updated":"2023-02-02T08:50:36Z","published":"2023-01-31T05:14:49Z","title":"BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete\n  Annotations","summary":"  Methods to detect malignant lesions from screening mammograms are usually\ntrained with fully annotated datasets, where images are labelled with the\nlocalisation and classification of cancerous lesions. However, real-world\nscreening mammogram datasets commonly have a subset that is fully annotated and\nanother subset that is weakly annotated with just the global classification\n(i.e., without lesion localisation). Given the large size of such datasets,\nresearchers usually face a dilemma with the weakly annotated subset: to not use\nit or to fully annotate it. The first option will reduce detection accuracy\nbecause it does not use the whole dataset, and the second option is too\nexpensive given that the annotation needs to be done by expert radiologists. In\nthis paper, we propose a middle-ground solution for the dilemma, which is to\nformulate the training as a weakly- and semi-supervised learning problem that\nwe refer to as malignant breast lesion detection with incomplete annotations.\nTo address this problem, our new method comprises two stages, namely: 1)\npre-training a multi-view mammogram classifier with weak supervision from the\nwhole dataset, and 2) extending the trained classifier to become a multi-view\ndetector that is trained with semi-supervised student-teacher learning, where\nthe training set contains fully and weakly-annotated mammograms. We provide\nextensive detection results on two real-world screening mammogram datasets\ncontaining incomplete annotations, and show that our proposed approach achieves\nstate-of-the-art results in the detection of malignant breast lesions with\nincomplete annotations.\n","authors":["Yuanhong Chen","Yuyuan Liu","Chong Wang","Michael Elliott","Chun Fung Kwok","Carlos Pena-Solorzano","Yu Tian","Fengbei Liu","Helen Frazer","Davis J. McCarthy","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2301.13418v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2210.13277v3","updated":"2023-02-02T08:48:47Z","published":"2022-10-24T14:13:54Z","title":"Provably Doubly Accelerated Federated Learning: The First Theoretically\n  Successful Combination of Local Training and Communication Compression","summary":"  In federated learning, a large number of users are involved in a global\nlearning task, in a collaborative way. They alternate local computations and\ntwo-way communication with a distant orchestrating server. Communication, which\ncan be slow and costly, is the main bottleneck in this setting. To reduce the\ncommunication load and therefore accelerate distributed gradient descent, two\nstrategies are popular: 1) communicate less frequently; that is, perform\nseveral iterations of local computations between the communication rounds; and\n2) communicate compressed information instead of full-dimensional vectors. We\npropose the first algorithm for distributed optimization and federated\nlearning, which harnesses these two strategies jointly and converges linearly\nto an exact solution in the strongly convex setting, with a doubly accelerated\nrate: our algorithm benefits from the two acceleration mechanisms provided by\nlocal training and compression, namely a better dependency on the condition\nnumber of the functions and on the dimension of the model, respectively.\n","authors":["Laurent Condat","Ivan Agarský","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2210.13277v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00953v1","updated":"2023-02-02T08:45:17Z","published":"2023-02-02T08:45:17Z","title":"Deep-Learning Tool for Early Identifying Non-Traumatic Intracranial\n  Hemorrhage Etiology based on CT Scan","summary":"  Background: To develop an artificial intelligence system that can accurately\nidentify acute non-traumatic intracranial hemorrhage (ICH) etiology based on\nnon-contrast CT (NCCT) scans and investigate whether clinicians can benefit\nfrom it in a diagnostic setting. Materials and Methods: The deep learning model\nwas developed with 1868 eligible NCCT scans with non-traumatic ICH collected\nbetween January 2011 and April 2018. We tested the model on two independent\ndatasets (TT200 and SD 98) collected after April 2018. The model's diagnostic\nperformance was compared with clinicians's performance. We further designed a\nsimulated study to compare the clinicians's performance with and without the\ndeep learning system augmentation. Results: The proposed deep learning system\nachieved area under the receiver operating curve of 0.986 (95% CI 0.967-1.000)\non aneurysms, 0.952 (0.917-0.987) on hypertensive hemorrhage, 0.950\n(0.860-1.000) on arteriovenous malformation (AVM), 0.749 (0.586-0.912) on\nMoyamoya disease (MMD), 0.837 (0.704-0.969) on cavernous malformation (CM), and\n0.839 (0.722-0.959) on other causes in TT200 dataset. Given a 90% specificity\nlevel, the sensitivities of our model were 97.1% and 90.9% for aneurysm and AVM\ndiagnosis, respectively. The model also shows an impressive generalizability in\nan independent dataset SD98. The clinicians achieve significant improvements in\nthe sensitivity, specificity, and accuracy of diagnoses of certain hemorrhage\netiologies with proposed system augmentation. Conclusions: The proposed deep\nlearning algorithms can be an effective tool for early identification of\nhemorrhage etiologies based on NCCT scans. It may also provide more information\nfor clinicians for triage and further imaging examination selection.\n","authors":["Meng Zhao","Yifan Hu","Ruixuan Jiang","Yuanli Zhao","Dong Zhang","Yan Zhang","Rong Wang","Yong Cao","Qian Zhang","Yonggang Ma","Jiaxi Li","Shaochen Yu","Wenjie Li","Ran Zhang","Yefeng Zheng","Shuo Wang","Jizong Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.00953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00942v1","updated":"2023-02-02T08:33:36Z","published":"2023-02-02T08:33:36Z","title":"Efficient Graph Field Integrators Meet Point Clouds","summary":"  We present two new classes of algorithms for efficient field integration on\ngraphs encoding point clouds. The first class, SeparatorFactorization(SF),\nleverages the bounded genus of point cloud mesh graphs, while the second class,\nRFDiffusion(RFD), uses popular epsilon-nearest-neighbor graph representations\nfor point clouds. Both can be viewed as providing the functionality of Fast\nMultipole Methods (FMMs), which have had a tremendous impact on efficient\nintegration, but for non-Euclidean spaces. We focus on geometries induced by\ndistributions of walk lengths between points (e.g., shortest-path distance). We\nprovide an extensive theoretical analysis of our algorithms, obtaining new\nresults in structural graph theory as a byproduct. We also perform exhaustive\nempirical evaluation, including on-surface interpolation for rigid and\ndeformable objects (particularly for mesh-dynamics modeling), Wasserstein\ndistance computations for point clouds, and the Gromov-Wasserstein variant.\n","authors":["Krzysztof Choromanski","Arijit Sehanobish","Han Lin","Yunfan Zhao","Eli Berger","Tetiana Parshakova","Alvin Pan","David Watkins","Tianyi Zhang","Valerii Likhosherstov","Somnath Basu Roy Chowdhury","Avinava Dubey","Deepali Jain","Tamas Sarlos","Snigdha Chaturvedi","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2302.00942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00938v1","updated":"2023-02-02T08:28:07Z","published":"2023-02-02T08:28:07Z","title":"An Enhanced V-cycle MgNet Model for Operator Learning in Numerical\n  Partial Differential Equations","summary":"  This study used a multigrid-based convolutional neural network architecture\nknown as MgNet in operator learning to solve numerical partial differential\nequations (PDEs). Given the property of smoothing iterations in multigrid\nmethods where low-frequency errors decay slowly, we introduced a low-frequency\ncorrection structure for residuals to enhance the standard V-cycle MgNet. The\nenhanced MgNet model can capture the low-frequency features of solutions\nconsiderably better than the standard V-cycle MgNet. The numerical results\nobtained using some standard operator learning tasks are better than those\nobtained using many state-of-the-art methods, demonstrating the efficiency of\nour model.Moreover, numerically, our new model is more robust in case of low-\nand high-resolution data during training and testing, respectively.\n","authors":["Jianqing Zhu","Juncai He","Qiumei Huang"],"pdf_url":"https://arxiv.org/pdf/2302.00938v1.pdf","comment":"21 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2302.00932v1","updated":"2023-02-02T08:22:35Z","published":"2023-02-02T08:22:35Z","title":"Dynamic Ensemble of Low-fidelity Experts: Mitigating NAS \"Cold-Start\"","summary":"  Predictor-based Neural Architecture Search (NAS) employs an architecture\nperformance predictor to improve the sample efficiency. However,\npredictor-based NAS suffers from the severe ``cold-start'' problem, since a\nlarge amount of architecture-performance data is required to get a working\npredictor. In this paper, we focus on exploiting information in\ncheaper-to-obtain performance estimations (i.e., low-fidelity information) to\nmitigate the large data requirements of predictor training. Despite the\nintuitiveness of this idea, we observe that using inappropriate low-fidelity\ninformation even damages the prediction ability and different search spaces\nhave different preferences for low-fidelity information types. To solve the\nproblem and better fuse beneficial information provided by different types of\nlow-fidelity information, we propose a novel dynamic ensemble predictor\nframework that comprises two steps. In the first step, we train different\nsub-predictors on different types of available low-fidelity information to\nextract beneficial knowledge as low-fidelity experts. In the second step, we\nlearn a gating network to dynamically output a set of weighting coefficients\nconditioned on each input neural architecture, which will be used to combine\nthe predictions of different low-fidelity experts in a weighted sum. The\noverall predictor is optimized on a small set of actual\narchitecture-performance data to fuse the knowledge from different low-fidelity\nexperts to make the final prediction. We conduct extensive experiments across\nfive search spaces with different architecture encoders under various\nexperimental settings. Our method can easily be incorporated into existing\npredictor-based NAS frameworks to discover better architectures.\n","authors":["Junbo Zhao","Xuefei Ning","Enshu Liu","Binxin Ru","Zixuan Zhou","Tianchen Zhao","Chen Chen","Jiajin Zhang","Qingmin Liao","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00928v1","updated":"2023-02-02T08:00:18Z","published":"2023-02-02T08:00:18Z","title":"Rethinking Warm-Starts with Predictions: Learning Predictions Close to\n  Sets of Optimal Solutions for Faster $\\text{L}$-/$\\text{L}^\\natural$-Convex\n  Function Minimization","summary":"  An emerging line of work has shown that machine-learned predictions are\nuseful to warm-start algorithms for discrete optimization problems, such as\nbipartite matching. Previous studies have shown time complexity bounds\nproportional to some distance between a prediction and an optimal solution,\nwhich we can approximately minimize by learning predictions from past optimal\nsolutions. However, such guarantees may not be meaningful when multiple optimal\nsolutions exist. Indeed, the dual problem of bipartite matching and, more\ngenerally, $\\text{L}$-/$\\text{L}^\\natural$-convex function minimization have\narbitrarily many optimal solutions, making such prediction-dependent bounds\narbitrarily large. To resolve this theoretically critical issue, we present a\nnew warm-start-with-prediction framework for\n$\\text{L}$-/$\\text{L}^\\natural$-convex function minimization. Our framework\noffers time complexity bounds proportional to the distance between a prediction\nand the set of all optimal solutions. The main technical difficulty lies in\nlearning predictions that are provably close to sets of all optimal solutions,\nfor which we present an online-gradient-descent-based method. We thus give the\nfirst polynomial-time learnability of predictions that can provably warm-start\nalgorithms regardless of multiple optimal solutions.\n","authors":["Shinsaku Sakaue","Taihei Oki"],"pdf_url":"https://arxiv.org/pdf/2302.00928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00924v1","updated":"2023-02-02T07:52:34Z","published":"2023-02-02T07:52:34Z","title":"LMC: Fast Training of GNNs via Subgraph Sampling with Provable\n  Convergence","summary":"  The message passing-based graph neural networks (GNNs) have achieved great\nsuccess in many real-world applications. However, training GNNs on large-scale\ngraphs suffers from the well-known neighbor explosion problem, i.e., the\nexponentially increasing dependencies of nodes with the number of message\npassing layers. Subgraph-wise sampling methods -- a promising class of\nmini-batch training techniques -- discard messages outside the mini-batches in\nbackward passes to avoid the neighbor explosion problem at the expense of\ngradient estimation accuracy. This poses significant challenges to their\nconvergence analysis and convergence speeds, which seriously limits their\nreliable real-world applications. To address this challenge, we propose a novel\nsubgraph-wise sampling method with a convergence guarantee, namely Local\nMessage Compensation (LMC). To the best of our knowledge, LMC is the {\\it\nfirst} subgraph-wise sampling method with provable convergence. The key idea of\nLMC is to retrieve the discarded messages in backward passes based on a message\npassing formulation of backward passes. By efficient and effective\ncompensations for the discarded messages in both forward and backward passes,\nLMC computes accurate mini-batch gradients and thus accelerates convergence. We\nfurther show that LMC converges to first-order stationary points of GNNs.\nExperiments on large-scale benchmark tasks demonstrate that LMC significantly\noutperforms state-of-the-art subgraph-wise sampling methods in terms of\nefficiency.\n","authors":["Zhihao Shi","Xize Liang","Jie Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00919v1","updated":"2023-02-02T07:36:58Z","published":"2023-02-02T07:36:58Z","title":"QCM-SGM+: Improved Quantized Compressed Sensing With Score-Based\n  Generative Models for General Sensing Matrices","summary":"  In realistic compressed sensing (CS) scenarios, the obtained measurements\nusually have to be quantized to a finite number of bits before transmission\nand/or storage, thus posing a challenge in recovery, especially for extremely\ncoarse quantization such as 1-bit sign measurements. Recently Meng & Kabashima\nproposed an efficient quantized compressed sensing algorithm called QCS-SGM\nusing the score-based generative models as an implicit prior. Thanks to the\npower of score-based generative models in capturing the rich structure of the\nprior, QCS-SGM achieves remarkably better performances than previous quantized\nCS methods. However, QCS-SGM is restricted to (approximately) row-orthogonal\nsensing matrices since otherwise the likelihood score becomes intractable. To\naddress this challenging problem, in this paper we propose an improved version\nof QCS-SGM, which we call QCS-SGM+, which also works well for general matrices.\nThe key idea is a Bayesian inference perspective of the likelihood score\ncomputation, whereby an expectation propagation algorithm is proposed to\napproximately compute the likelihood score. Experiments on a variety of\nbaseline datasets demonstrate that the proposed QCS-SGM+ outperforms QCS-SGM by\na large margin when sensing matrices are far from row-orthogonal.\n","authors":["Xiangming Meng","Yoshiyuki Kabashima"],"pdf_url":"https://arxiv.org/pdf/2302.00919v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2211.13006"},{"id":"http://arxiv.org/abs/2211.11259v2","updated":"2023-02-02T07:33:42Z","published":"2022-11-21T08:47:51Z","title":"From Traditional Adaptive Data Caching to Adaptive Context Caching: A\n  Survey","summary":"  Context data is in demand more than ever with the rapid increase in the\ndevelopment of many context-aware Internet of Things applications. Research in\ncontext and context-awareness is being conducted to broaden its applicability\nin light of many practical and technical challenges. One of the challenges is\nimproving performance when responding to large number of context queries.\nContext Management Platforms that infer and deliver context to applications\nmeasure this problem using Quality of Service (QoS) parameters. Although\ncaching is a proven way to improve QoS, transiency of context and features such\nas variability, heterogeneity of context queries pose an additional real-time\ncost management problem. This paper presents a critical survey of\nstate-of-the-art in adaptive data caching with the objective of developing a\nbody of knowledge in cost- and performance-efficient adaptive caching\nstrategies. We comprehensively survey a large number of research publications\nand evaluate, compare, and contrast different techniques, policies, approaches,\nand schemes in adaptive caching. Our critical analysis is motivated by the\nfocus on adaptively caching context as a core research problem. A formal\ndefinition for adaptive context caching is then proposed, followed by\nidentified features and requirements of a well-designed, objective optimal\nadaptive context caching strategy.\n","authors":["Shakthi Weerasinghe","Arkady Zaslavsky","Seng W. Loke","Alireza Hassani","Amin Abken","Alexey Medvedev"],"pdf_url":"https://arxiv.org/pdf/2211.11259v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00533v2","updated":"2023-02-02T07:30:13Z","published":"2023-02-01T15:59:57Z","title":"Distillation Policy Optimization","summary":"  On-policy algorithms are supposed to be stable, however, sample-intensive\nyet. Off-policy algorithms utilizing past experiences are deemed to be\nsample-efficient, nevertheless, unstable in general. Can we design an algorithm\nthat can employ the off-policy data, while exploit the stable learning by\nsailing along the course of the on-policy walkway? In this paper, we present an\nactor-critic learning framework that borrows the distributional perspective of\ninterest to evaluate, and cross-breeds two sources of the data for policy\nimprovement, which enables fast learning and can be applied to a wide class of\nalgorithms. In its backbone, the variance reduction mechanisms, such as unified\nadvantage estimator (UAE), that extends generalized advantage estimator (GAE)\nto be applicable on any state-dependent baseline, and a learned baseline, that\nis competent to stabilize the policy gradient, are firstly put forward to not\nmerely be a bridge to the action-value function but also distill the\nadvantageous learning signal. Lastly, it is empirically shown that our method\nimproves sample efficiency and interpolates different levels well. Being of an\norganic whole, its mixture places more inspiration to the algorithm design.\n","authors":["Jianfei Ma"],"pdf_url":"https://arxiv.org/pdf/2302.00533v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.03007v6","updated":"2023-02-02T07:29:07Z","published":"2021-06-06T02:16:45Z","title":"Truthful Self-Play","summary":"  We present a general framework for evolutionary learning to emergent unbiased\nstate representation without any supervision. Evolutionary frameworks such as\nself-play converge to bad local optima in case of multi-agent reinforcement\nlearning in non-cooperative partially observable environments with\ncommunication due to information asymmetry. Our proposed framework is a simple\nmodification of self-play inspired by mechanism design, also known as {\\em\nreverse game theory}, to elicit truthful signals and make the agents\ncooperative. The key idea is to add imaginary rewards using the peer prediction\nmethod, i.e., a mechanism for evaluating the validity of information exchanged\nbetween agents in a decentralized environment. Numerical experiments with\npredator prey, traffic junction and StarCraft tasks demonstrate that the\nstate-of-the-art performance of our framework.\n","authors":["Shohei Ohsawa"],"pdf_url":"https://arxiv.org/pdf/2106.03007v6.pdf","comment":"Accepted for publication at ICLR 2023"},{"id":"http://arxiv.org/abs/2210.01407v4","updated":"2023-02-02T07:07:32Z","published":"2022-10-04T06:32:45Z","title":"Homotopy-based training of NeuralODEs for accurate dynamics discovery","summary":"  Conceptually, Neural Ordinary Differential Equations (NeuralODEs) pose an\nattractive way to extract dynamical laws from time series data, as they are\nnatural extensions of the traditional differential equation-based modeling\nparadigm of the physical sciences. In practice, NeuralODEs display long\ntraining times and suboptimal results, especially for longer duration data\nwhere they may fail to fit the data altogether. While methods have been\nproposed to stabilize NeuralODE training, many of these involve placing a\nstrong constraint on the functional form the trained NeuralODE can take that\nthe actual underlying governing equation does not guarantee satisfaction. In\nthis work, we present a novel NeuralODE training algorithm that leverages tools\nfrom the chaos and mathematical optimization communities - synchronization and\nhomotopy optimization - for a breakthrough in tackling the NeuralODE training\nobstacle. We demonstrate architectural changes are unnecessary for effective\nNeuralODE training. Compared to the conventional training methods, our\nalgorithm achieves drastically lower loss values without any changes to the\nmodel architectures. Experiments on both simulated and real systems with\ncomplex temporal behaviors demonstrate NeuralODEs trained with our algorithm\nare able to accurately capture true long term behaviors and correctly\nextrapolate into the future.\n","authors":["Joon-Hyuk Ko","Hankyul Koh","Nojun Park","Wonho Jhe"],"pdf_url":"https://arxiv.org/pdf/2210.01407v4.pdf","comment":"19 pages, 17 figures, submitted to ICML2023"},{"id":"http://arxiv.org/abs/2302.00911v1","updated":"2023-02-02T06:59:15Z","published":"2023-02-02T06:59:15Z","title":"Conditional expectation for missing data imputation","summary":"  Missing data is common in datasets retrieved in various areas, such as\nmedicine, sports, and finance. In many cases, to enable proper and reliable\nanalyses of such data, the missing values are often imputed, and it is\nnecessary that the method used has a low root mean square error (RMSE) between\nthe imputed and the true values. In addition, for some critical applications,\nit is also often a requirement that the logic behind the imputation is\nexplainable, which is especially difficult for complex methods that are for\nexample, based on deep learning. This motivates us to introduce a conditional\nDistribution based Imputation of Missing Values (DIMV) algorithm. This approach\nworks based on finding the conditional distribution of a feature with missing\nentries based on the fully observed features. As will be illustrated in the\npaper, DIMV (i) gives a low RMSE for the imputed values compared to\nstate-of-the-art methods under comparison; (ii) is explainable; (iii) can\nprovide an approximated confidence region for the missing values in a given\nsample; (iv) works for both small and large scale data; (v) in many scenarios,\ndoes not require a huge number of parameters as deep learning approaches and\ntherefore can be used for mobile devices or web browsers; and (vi) is robust to\nthe normally distributed assumption that its theoretical grounds rely on. In\naddition to DIMV, we also introduce the DPER* algorithm improving the speed of\nDPER for estimating the mean and covariance matrix from the data, and we\nconfirm the speed-up via experiments.\n","authors":["Mai Anh Vu","Thu Nguyen","Tu T. Do","Nhan Phan","Pål Halvorsen","Michael A. Riegler","Binh T. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.00911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00910v1","updated":"2023-02-02T06:57:37Z","published":"2023-02-02T06:57:37Z","title":"Energy Efficient Training of SNN using Local Zeroth Order Method","summary":"  Spiking neural networks are becoming increasingly popular for their low\nenergy requirement in real-world tasks with accuracy comparable to the\ntraditional ANNs. SNN training algorithms face the loss of gradient information\nand non-differentiability due to the Heaviside function in minimizing the model\nloss over model parameters. To circumvent the problem surrogate method uses a\ndifferentiable approximation of the Heaviside in the backward pass, while the\nforward pass uses the Heaviside as the spiking function. We propose to use the\nzeroth order technique at the neuron level to resolve this dichotomy and use it\nwithin the automatic differentiation tool. As a result, we establish a\ntheoretical connection between the proposed local zeroth-order technique and\nthe existing surrogate methods and vice-versa. The proposed method naturally\nlends itself to energy-efficient training of SNNs on GPUs. Experimental results\nwith neuromorphic datasets show that such implementation requires less than 1\npercent neurons to be active in the backward pass, resulting in a 100x speed-up\nin the backward computation time. Our method offers better generalization\ncompared to the state-of-the-art energy-efficient technique while maintaining\nsimilar efficiency.\n","authors":["Bhaskar Mukhoty","Velibor Bojkovic","William de Vazelhes","Huan Xiong","Bin Gu","Giulia De Masi"],"pdf_url":"https://arxiv.org/pdf/2302.00910v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00908v1","updated":"2023-02-02T06:55:40Z","published":"2023-02-02T06:55:40Z","title":"GANalyzer: Analysis and Manipulation of GANs Latent Space for\n  Controllable Face Synthesis","summary":"  Generative Adversarial Networks (GANs) are capable of synthesizing\nhigh-quality facial images. Despite their success, GANs do not provide any\ninformation about the relationship between the input vectors and the generated\nimages. Currently, facial GANs are trained on imbalanced datasets, which\ngenerate less diverse images. For example, more than 77% of 100K images that we\nrandomly synthesized using the StyleGAN3 are classified as Happy, and only\naround 3% are Angry. The problem even becomes worse when a mixture of facial\nattributes is desired: less than 1% of the generated samples are Angry Woman,\nand only around 2% are Happy Black. To address these problems, this paper\nproposes a framework, called GANalyzer, for the analysis, and manipulation of\nthe latent space of well-trained GANs. GANalyzer consists of a set of\ntransformation functions designed to manipulate latent vectors for a specific\nfacial attribute such as facial Expression, Age, Gender, and Race. We analyze\nfacial attribute entanglement in the latent space of GANs and apply the\nproposed transformation for editing the disentangled facial attributes. Our\nexperimental results demonstrate the strength of GANalyzer in editing facial\nattributes and generating any desired faces. We also create and release a\nbalanced photo-realistic human face dataset. Our code is publicly available on\nGitHub.\n","authors":["Ali Pourramezan Fard","Mohammad H. Mahoor","Sarah Ariel Lamer","Timothy Sweeny"],"pdf_url":"https://arxiv.org/pdf/2302.00908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00902v1","updated":"2023-02-02T06:38:44Z","published":"2023-02-02T06:38:44Z","title":"Language Quantized AutoEncoders: Towards Unsupervised Text-Image\n  Alignment","summary":"  Recent progress in scaling up large language models has shown impressive\ncapabilities in performing few-shot learning across a wide range of text-based\ntasks. However, a key limitation is that these language models fundamentally\nlack visual perception - a crucial attribute needed to extend these models to\nbe able to interact with the real world and solve vision tasks, such as in\nvisual-question answering and robotics. Prior works have largely connected\nimage to text through pretraining and/or fine-tuning on curated image-text\ndatasets, which can be a costly and expensive process. In order to resolve this\nlimitation, we propose a simple yet effective approach called\nLanguage-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to\nalign text-image data in an unsupervised manner by leveraging pretrained\nlanguage models (e.g., BERT, RoBERTa). Our main idea is to encode image as\nsequences of text tokens by directly quantizing image embeddings using a\npretrained language codebook. We then apply random masking followed by a BERT\nmodel, and have the decoder reconstruct the original image from BERT predicted\ntext token embeddings. By doing so, LQAE learns to represent similar images\nwith similar clusters of text tokens, thereby aligning these two modalities\nwithout the use of aligned text-image pairs. This enables few-shot image\nclassification with large language models (e.g., GPT-3) as well as linear\nclassification of images based on BERT text features. To the best of our\nknowledge, our work is the first work that uses unaligned images for multimodal\ntasks by leveraging the power of pretrained language models.\n","authors":["Hao Liu","Wilson Yan","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.00902v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2106.13884 by other authors"},{"id":"http://arxiv.org/abs/2204.12723v2","updated":"2023-02-02T06:08:17Z","published":"2022-04-27T06:33:37Z","title":"Information-theoretic limitations of data-based price discrimination","summary":"  This paper studies third-degree price discrimination (3PD) based on a random\nsample of valuation and covariate data, where the covariate is continuous, and\nthe distribution of the data is unknown to the seller. The main results of this\npaper are twofold. The first set of results is pricing strategy independent and\nreveals the fundamental information-theoretic limitation of any data-based\npricing strategy in revenue generation for two cases: 3PD and uniform pricing.\nThe second set of results proposes the $K$-markets empirical revenue\nmaximization (ERM) strategy and shows that the $K$-markets ERM and the uniform\nERM strategies achieve the optimal rate of convergence in revenue to that\ngenerated by their respective true-distribution 3PD and uniform pricing optima.\nOur theoretical and numerical results suggest that the uniform (i.e.,\n$1$-market) ERM strategy generates a larger revenue than the $K$-markets ERM\nstrategy when the sample size is small enough, and vice versa.\n","authors":["Haitian Xie","Ying Zhu","Denis Shishkin"],"pdf_url":"https://arxiv.org/pdf/2204.12723v2.pdf","comment":"In the new version, we have (1) added a simulation and empirical\n  study and (2) fixed some minor issues and improved the clarity"},{"id":"http://arxiv.org/abs/2302.00892v1","updated":"2023-02-02T05:53:31Z","published":"2023-02-02T05:53:31Z","title":"Quantum Graph Learning: Frontiers and Outlook","summary":"  Quantum theory has shown its superiority in enhancing machine learning.\nHowever, facilitating quantum theory to enhance graph learning is in its\ninfancy. This survey investigates the current advances in quantum graph\nlearning (QGL) from three perspectives, i.e., underlying theories, methods, and\nprospects. We first look at QGL and discuss the mutualism of quantum theory and\ngraph learning, the specificity of graph-structured data, and the bottleneck of\ngraph learning, respectively. A new taxonomy of QGL is presented, i.e., quantum\ncomputing on graphs, quantum graph representation, and quantum circuits for\ngraph neural networks. Pitfall traps are then highlighted and explained. This\nsurvey aims to provide a brief but insightful introduction to this emerging\nfield, along with a detailed discussion of frontiers and outlook yet to be\ninvestigated.\n","authors":["Shuo Yu","Ciyuan Peng","Yingbo Wang","Ahsan Shehzad","Feng Xia","Edwin R. Hancock"],"pdf_url":"https://arxiv.org/pdf/2302.00892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00890v1","updated":"2023-02-02T05:45:09Z","published":"2023-02-02T05:45:09Z","title":"Neural Common Neighbor with Completion for Link Prediction","summary":"  Despite its outstanding performance in various graph tasks, vanilla Message\nPassing Neural Network (MPNN) usually fails in link prediction tasks, as it\nonly uses representations of two individual target nodes and ignores the\npairwise relation between them. To capture the pairwise relations, some models\nadd manual features to the input graph and use the output of MPNN to produce\npairwise representations. In contrast, others directly use manual features as\npairwise representations. Though this simplification avoids applying a GNN to\neach link individually and thus improves scalability, these models still have\nmuch room for performance improvement due to the hand-crafted and unlearnable\npairwise features. To upgrade performance while maintaining scalability, we\npropose Neural Common Neighbor (NCN), which uses learnable pairwise\nrepresentations. To further boost NCN, we study the unobserved link problem.\nThe incompleteness of the graph is ubiquitous and leads to distribution shifts\nbetween the training and test set, loss of common neighbor information, and\nperformance degradation of models. Therefore, we propose two intervention\nmethods: common neighbor completion and target link removal. Combining the two\nmethods with NCN, we propose Neural Common Neighbor with Completion (NCNC). NCN\nand NCNC outperform recent strong baselines by large margins. NCNC achieves\nstate-of-the-art performance in link prediction tasks.\n","authors":["Xiyuan Wang","Haotong Yang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13446v4","updated":"2023-02-02T05:38:31Z","published":"2022-09-27T15:09:13Z","title":"Stochastic Optimization for Counterfactual Explanations","summary":"  Explainable AI offers insights into what factors drive a certain prediction\nof a black-box AI system. One popular interpreting approach is through\ncounterfactual explanations, which go beyond why a system arrives at a certain\ndecision to further provide suggestions on what a user can do to alter the\noriginal outcome. A counterfactual example must possess plenty of desiderata.\nThese constraints exist at trade-offs between one and another presenting\nradical challenges to existing works. We here propose a stochastic\nlearning-based framework that effectively balances the counterfactual\ntrade-offs. The framework consists of a generation and a feature selection\nmodule with complementary roles: the former aims to model the distribution of\nvalid counterfactuals whereas the latter serves to enforce additional\nconstraints in a way that allows for differentiable training and amortized\noptimization. We demonstrate the effectiveness of our method in generating\nactionable and plausible counterfactuals that are more diverse than the\nexisting methods and particularly more efficient than closest baselines.\n","authors":["Vy Vo","Trung Le","Van Nguyen","He Zhao","Edwin Bonilla","Gholamreza Haffari","Dinh Phung"],"pdf_url":"https://arxiv.org/pdf/2209.13446v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00293v2","updated":"2023-02-02T05:24:37Z","published":"2023-02-01T07:47:26Z","title":"A Survey of Methods, Challenges and Perspectives in Causality","summary":"  The Causality field aims to find systematic methods for uncovering\ncause-effect relationships. Such methods can find applications in many research\nfields, justifying a great interest in this domain. Machine Learning models\nhave shown success in a large variety of tasks by extracting correlation\npatterns from high-dimensional data but still struggle when generalizing out of\ntheir initial distribution. As causal engines aim to learn mechanisms that are\nindependent from a data distribution, combining Machine Learning with Causality\nhas the potential to bring benefits to the two fields. In our work, we motivate\nthis assumption and provide applications. We first perform an extensive\noverview of the theories and methods for Causality from different perspectives.\nWe then provide a deeper look at the connections between Causality and Machine\nLearning and describe the challenges met by the two domains. We show the early\nattempts to bring the fields together and the possible perspectives for the\nfuture. We finish by providing a large variety of applications for techniques\nfrom Causality.\n","authors":["Gaël Gendron","Michael Witbrock","Gillian Dobbie"],"pdf_url":"https://arxiv.org/pdf/2302.00293v2.pdf","comment":"40 pages, 37 pages for the main paper and 3 pages for the supplement,\n  10 figures, submitted to ACM Computing Surveys; enabled hyperlinks in new\n  version"},{"id":"http://arxiv.org/abs/2302.00883v1","updated":"2023-02-02T05:21:32Z","published":"2023-02-02T05:21:32Z","title":"Synthesizing Physical Character-Scene Interactions","summary":"  Movement is how people interact with and affect their environment. For\nrealistic character animation, it is necessary to synthesize such interactions\nbetween virtual characters and their surroundings. Despite recent progress in\ncharacter animation using machine learning, most systems focus on controlling\nan agent's movements in fairly simple and homogeneous environments, with\nlimited interactions with other objects. Furthermore, many previous approaches\nthat synthesize human-scene interactions require significant manual labeling of\nthe training data. In contrast, we present a system that uses adversarial\nimitation learning and reinforcement learning to train physically-simulated\ncharacters that perform scene interaction tasks in a natural and life-like\nmanner. Our method learns scene interaction behaviors from large unstructured\nmotion datasets, without manual annotation of the motion data. These scene\ninteractions are learned using an adversarial discriminator that evaluates the\nrealism of a motion within the context of a scene. The key novelty involves\nconditioning both the discriminator and the policy networks on scene context.\nWe demonstrate the effectiveness of our approach through three challenging\nscene interaction tasks: carrying, sitting, and lying down, which require\ncoordination of a character's movements in relation to objects in the\nenvironment. Our policies learn to seamlessly transition between different\nbehaviors like idling, walking, and sitting. By randomizing the properties of\nthe objects and their placements during training, our method is able to\ngeneralize beyond the objects and scenarios depicted in the training dataset,\nproducing natural character-scene interactions for a wide variety of object\nshapes and placements. The approach takes physics-based character motion\ngeneration a step closer to broad applicability.\n","authors":["Mohamed Hassan","Yunrong Guo","Tingwu Wang","Michael Black","Sanja Fidler","Xue Bin Peng"],"pdf_url":"https://arxiv.org/pdf/2302.00883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12558v5","updated":"2023-02-02T05:06:25Z","published":"2022-01-29T10:54:57Z","title":"The KFIoU Loss for Rotated Object Detection","summary":"  Differing from the well-developed horizontal object detection area whereby\nthe computing-friendly IoU based loss is readily adopted and well fits with the\ndetection metrics. In contrast, rotation detectors often involve a more\ncomplicated loss based on SkewIoU which is unfriendly to gradient-based\ntraining. In this paper, we propose an effective approximate SkewIoU loss based\non Gaussian modeing and Kalman filter, which mainly consists of two items. The\nfirst term is a scale-insensitive center point loss, which is used to quickly\nget the center points between bounding boxes closer to assist the second term.\nIn the distance-independent second term, Kalman filter is adopted to inherently\nmimic the mechanism of SkewIoU by its definition, and show its alignment with\nthe SkewIoU loss at trend-level within a certain distance (i.e. within 9\npixels). This is in contrast to recent Gaussian modeling based rotation\ndetectors e.g. GWD loss and KLD loss that involve a human-specified\ndistribution distance metric which require additional hyperparameter tuning\nthat vary across datasets and detectors. The resulting new loss called KFIoU\nloss is easier to implement and works better compared with exact SkewIoU loss,\nthanks to its full differentiability and ability to handle the non-overlapping\ncases. We further extend our technique to the 3-D case which also suffers from\nthe same issues as 2-D detection. Extensive results on various public datasets\n(2-D/3-D, aerial/text/face images) with different base detectors show the\neffectiveness of our approach.\n","authors":["Xue Yang","Yue Zhou","Gefan Zhang","Jirui Yang","Wentao Wang","Junchi Yan","Xiaopeng Zhang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2201.12558v5.pdf","comment":"17 pages, 6 figures, 7 tables, accepted by ICLR 2023, TensorFlow\n  code: https://github.com/yangxue0827/RotationDetection, PyTorch code:\n  https://github.com/open-mmlab/mmrotate, Jittor code:\n  https://github.com/Jittor/JDet"},{"id":"http://arxiv.org/abs/2302.00880v1","updated":"2023-02-02T05:03:21Z","published":"2023-02-02T05:03:21Z","title":"Empirical Analysis of the AdaBoost's Error Bound","summary":"  Understanding the accuracy limits of machine learning algorithms is essential\nfor data scientists to properly measure performance so they can continually\nimprove their models' predictive capabilities. This study empirically verified\nthe error bound of the AdaBoost algorithm for both synthetic and real-world\ndata. The results show that the error bound holds up in practice, demonstrating\nits efficiency and importance to a variety of applications. The corresponding\nsource code is available at\nhttps://github.com/armanbolatov/adaboost_error_bound.\n","authors":["Arman Bolatov","Kaisar Dauletbek"],"pdf_url":"https://arxiv.org/pdf/2302.00880v1.pdf","comment":"4 pages, 4 figures"},{"id":"http://arxiv.org/abs/2301.02747v3","updated":"2023-02-02T05:03:15Z","published":"2023-01-06T23:32:07Z","title":"Sample-efficient Surrogate Model for Frequency Response of Linear PDEs\n  using Self-Attentive Complex Polynomials","summary":"  Linear Partial Differential Equations (PDEs) govern the spatial-temporal\ndynamics of physical systems that are essential to building modern technology.\nWhen working with linear PDEs, designing a physical system for a specific\noutcome is difficult and costly due to slow and expensive explicit simulation\nof PDEs and the highly nonlinear relationship between a system's configuration\nand its behavior. In this work, we prove a parametric form that certain\nphysical quantities in the Fourier domain must obey in linear PDEs, named the\nCZP (Constant-Zeros-Poles) framework. Applying CZP to antenna design, an\nindustrial application using linear PDEs (i.e., Maxwell's equations), we derive\na sample-efficient parametric surrogate model that directly predicts its\nscattering coefficients without explicit numerical PDE simulation. Combined\nwith a novel image-based antenna representation and an attention-based neural\nnetwork architecture, CZP outperforms baselines by 10% to 25% in terms of test\nloss and also is able to find 2D antenna designs verifiable by commercial\nsoftware with $33\\%$ greater success than baselines, when coupled with\nsequential search techniques like reinforcement learning.\n","authors":["Andrew Cohen","Weiping Dou","Jiang Zhu","Slawomir Koziel","Peter Renner","Jan-Ove Mattsson","Xiaomeng Yang","Beidi Chen","Kevin Stone","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2301.02747v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00878v1","updated":"2023-02-02T05:00:29Z","published":"2023-02-02T05:00:29Z","title":"The Contextual Lasso: Sparse Linear Models via Deep Neural Networks","summary":"  Sparse linear models are a gold standard tool for interpretable machine\nlearning, a field of emerging importance as predictive models permeate\ndecision-making in many domains. Unfortunately, sparse linear models are far\nless flexible as functions of their input features than black-box models like\ndeep neural networks. With this capability gap in mind, we study a not-uncommon\nsituation where the input features dichotomize into two groups: explanatory\nfeatures, which we wish to explain the model's predictions, and contextual\nfeatures, which we wish to determine the model's explanations. This dichotomy\nleads us to propose the contextual lasso, a new statistical estimator that fits\na sparse linear model whose sparsity pattern and coefficients can vary with the\ncontextual features. The fitting process involves learning a nonparametric map,\nrealized via a deep neural network, from contextual feature vector to sparse\ncoefficient vector. To attain sparse coefficients, we train the network with a\nnovel lasso regularizer in the form of a projection layer that maps the\nnetwork's output onto the space of $\\ell_1$-constrained linear models.\nExtensive experiments on real and synthetic data suggest that the learned\nmodels, which remain highly transparent, can be sparser than the regular lasso\nwithout sacrificing the predictive power of a standard deep neural network.\n","authors":["Ryan Thompson","Amir Dezfouli","Robert Kohn"],"pdf_url":"https://arxiv.org/pdf/2302.00878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02001v3","updated":"2023-02-02T04:53:44Z","published":"2022-06-04T14:54:05Z","title":"Surprising Instabilities in Training Deep Networks and a Theoretical\n  Analysis","summary":"  We discover restrained numerical instabilities in current training practices\nof deep networks with stochastic gradient descent (SGD). We show numerical\nerror (on the order of the smallest floating point bit) induced from floating\npoint arithmetic in training deep nets can be amplified significantly and\nresult in significant test accuracy variance, comparable to the test accuracy\nvariance due to stochasticity in SGD. We show how this is likely traced to\ninstabilities of the optimization dynamics that are restrained, i.e., localized\nover iterations and regions of the weight tensor space. We do this by\npresenting a theoretical framework using numerical analysis of partial\ndifferential equations (PDE), and analyzing the gradient descent PDE of\nconvolutional neural networks (CNNs). We show that it is stable only under\ncertain conditions on the learning rate and weight decay. We show that rather\nthan blowing up when the conditions are violated, the instability can be\nrestrained. We show this is a consequence of the non-linear PDE associated with\nthe gradient descent of the CNN, whose local linearization changes when\nover-driving the step size of the discretization, resulting in a stabilizing\neffect. We link restrained instabilities to the recently discovered Edge of\nStability (EoS) phenomena, in which the stable step size predicted by classical\ntheory is exceeded while continuing to optimize the loss and still converging.\nBecause restrained instabilities occur at the EoS, our theory provides new\npredictions about the EoS, in particular, the role of regularization and the\ndependence on the network complexity.\n","authors":["Yuxin Sun","Dong Lao","Ganesh Sundaramoorthi","Anthony Yezzi"],"pdf_url":"https://arxiv.org/pdf/2206.02001v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00873v1","updated":"2023-02-02T04:46:21Z","published":"2023-02-02T04:46:21Z","title":"Predicting the Silent Majority on Graphs: Knowledge Transferable Graph\n  Neural Network","summary":"  Graphs consisting of vocal nodes (\"the vocal minority\") and silent nodes\n(\"the silent majority\"), namely VS-Graph, are ubiquitous in the real world. The\nvocal nodes tend to have abundant features and labels. In contrast, silent\nnodes only have incomplete features and rare labels, e.g., the description and\npolitical tendency of politicians (vocal) are abundant while not for ordinary\npeople (silent) on the twitter's social network. Predicting the silent majority\nremains a crucial yet challenging problem. However, most existing\nmessage-passing based GNNs assume that all nodes belong to the same domain,\nwithout considering the missing features and distribution-shift between\ndomains, leading to poor ability to deal with VS-Graph. To combat the above\nchallenges, we propose Knowledge Transferable Graph Neural Network (KT-GNN),\nwhich models distribution shifts during message passing and representation\nlearning by transferring knowledge from vocal nodes to silent nodes.\nSpecifically, we design the domain-adapted \"feature completion and message\npassing mechanism\" for node representation learning while preserving domain\ndifference. And a knowledge transferable classifier based on KL-divergence is\nfollowed. Comprehensive experiments on real-world scenarios (i.e., company\nfinancial risk assessment and political elections) demonstrate the superior\nperformance of our method. Our source code has been open sourced.\n","authors":["Wendong Bi","Bingbing Xu","Xiaoqian Sun","Li Xu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.00873v1.pdf","comment":"accepted by WWW2023"},{"id":"http://arxiv.org/abs/2302.00872v1","updated":"2023-02-02T04:46:14Z","published":"2023-02-02T04:46:14Z","title":"Reliable Prediction Intervals with Directly Optimized Inductive\n  Conformal Regression for Deep Learning","summary":"  By generating prediction intervals (PIs) to quantify the uncertainty of each\nprediction in deep learning regression, the risk of wrong predictions can be\neffectively controlled. High-quality PIs need to be as narrow as possible,\nwhilst covering a preset proportion of real labels. At present, many approaches\nto improve the quality of PIs can effectively reduce the width of PIs, but they\ndo not ensure that enough real labels are captured. Inductive Conformal\nPredictor (ICP) is an algorithm that can generate effective PIs which is\ntheoretically guaranteed to cover a preset proportion of data. However,\ntypically ICP is not directly optimized to yield minimal PI width. However, in\nthis study, we use Directly Optimized Inductive Conformal Regression (DOICR)\nthat takes only the average width of PIs as the loss function and increases the\nquality of PIs through an optimized scheme under the validity condition that\nsufficient real labels are captured in the PIs. Benchmark experiments show that\nDOICR outperforms current state-of-the-art algorithms for regression problems\nusing underlying Deep Neural Network structures for both tabular and image\ndata.\n","authors":["Haocheng Lei","Anthony Bellotti"],"pdf_url":"https://arxiv.org/pdf/2302.00872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00869v1","updated":"2023-02-02T04:37:29Z","published":"2023-02-02T04:37:29Z","title":"Disentanglement of Latent Representations via Sparse Causal\n  Interventions","summary":"  The process of generating data such as images is controlled by independent\nand unknown factors of variation. The retrieval of these variables has been\nstudied extensively in the disentanglement, causal representation learning, and\nindependent component analysis fields. Recently, approaches merging these\ndomains together have shown great success. Instead of directly representing the\nfactors of variation, the problem of disentanglement can be seen as finding the\ninterventions on one image that yield a change to a single factor. Following\nthis assumption, we introduce a new method for disentanglement inspired by\ncausal dynamics that combines causality theory with vector-quantized\nvariational autoencoders. Our model considers the quantized vectors as causal\nvariables and links them in a causal graph. It performs causal interventions on\nthe graph and generates atomic transitions affecting a unique factor of\nvariation in the image. We also introduce a new task of action retrieval that\nconsists of finding the action responsible for the transition between two\nimages. We test our method on standard synthetic and real-world disentanglement\ndatasets. We show that it can effectively disentangle the factors of variation\nand perform precise interventions on high-level semantic attributes of an image\nwithout affecting its quality, even with imbalanced data distributions.\n","authors":["Gaël Gendron","Michael Witbrock","Gillian Dobbie"],"pdf_url":"https://arxiv.org/pdf/2302.00869v1.pdf","comment":"16 pages, 10 pages for the main paper and 6 pages for the supplement,\n  14 figures, submitted to IJCAI 2023"},{"id":"http://arxiv.org/abs/2302.00864v1","updated":"2023-02-02T04:27:54Z","published":"2023-02-02T04:27:54Z","title":"CLIPood: Generalizing CLIP to Out-of-Distributions","summary":"  Out-of-distribution (OOD) generalization, where the model needs to handle\ndistribution shifts from training, is a major challenge of machine learning.\nRecently, contrastive language-image pre-training (CLIP) models have shown\nimpressive zero-shot ability, revealing a promising path toward OOD\ngeneralization. However, to boost upon zero-shot performance, further\nadaptation of CLIP on downstream tasks is indispensable but undesirably\ndegrades OOD generalization ability. In this paper, we aim at generalizing CLIP\nto out-of-distribution test data on downstream tasks. Beyond the two canonical\nOOD situations, domain shift and open class, we tackle a more general but\ndifficult in-the-wild setting where both OOD situations may occur on the unseen\ntest data. We propose CLIPood, a simple fine-tuning method that can adapt CLIP\nmodels to all OOD situations. To exploit semantic relations between classes\nfrom the text modality, CLIPood introduces a new training objective, margin\nmetric softmax (MMS), with class adaptive margins for fine-tuning. Moreover, to\nincorporate both the pre-trained zero-shot model and the fine-tuned\ntask-adaptive model, CLIPood proposes a new Beta moving average (BMA) to\nmaintain a temporal ensemble according to Beta distribution. Experiments on\ndiverse datasets with different OOD scenarios show that CLIPood consistently\noutperforms existing generalization techniques.\n","authors":["Yang Shu","Xingzhuo Guo","Jialong Wu","Ximei Wang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2302.00864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16913v2","updated":"2023-02-02T04:12:40Z","published":"2022-10-30T18:31:03Z","title":"Revisiting Simple Regret: Fast Rates for Returning a Good Arm","summary":"  Simple regret is a natural and parameter-free performance criterion for pure\nexploration in multi-armed bandits yet is less popular than the probability of\nmissing the best arm or an $\\epsilon$-good arm, perhaps due to lack of easy\nways to characterize it. In this paper, we make significant progress on\nminimizing simple regret in both data-rich ($T\\ge n$) and data-poor regime ($T\n\\le n$) where $n$ is the number of arms, and $T$ is the number of samples. At\nits heart is our improved instance-dependent analysis of the well-known\nSequential Halving (SH) algorithm, where we bound the probability of returning\nan arm whose mean reward is not within $\\epsilon$ from the best (i.e., not\n$\\epsilon$-good) for \\textit{any} choice of $\\epsilon>0$, although $\\epsilon$\nis not an input to SH. Our bound not only leads to an optimal worst-case simple\nregret bound of $\\sqrt{n/T}$ up to logarithmic factors but also essentially\nmatches the instance-dependent lower bound for returning an $\\epsilon$-good arm\nreported by Katz-Samuels and Jamieson (2020). For the more challenging\ndata-poor regime, we propose Bracketing SH (BSH) that enjoys the same\nimprovement even without sampling each arm at least once. Our empirical study\nshows that BSH outperforms existing methods on real-world tasks.\n","authors":["Yao Zhao","Connor James Stephens","Csaba Szepesvári","Kwang-Sung Jun"],"pdf_url":"https://arxiv.org/pdf/2210.16913v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00861v1","updated":"2023-02-02T04:12:29Z","published":"2023-02-02T04:12:29Z","title":"SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling","summary":"  Time series analysis is widely used in extensive areas. Recently, to reduce\nlabeling expenses and benefit various tasks, self-supervised pre-training has\nattracted immense interest. One mainstream paradigm is masked modeling, which\nsuccessfully pre-trains deep models by learning to reconstruct the masked\ncontent based on the unmasked part. However, since the semantic information of\ntime series is mainly contained in temporal variations, the standard way of\nrandomly masking a portion of time points will ruin vital temporal variations\nof time series seriously, making the reconstruction task too difficult to guide\nrepresentation learning. We thus present SimMTM, a Simple pre-training\nframework for Masked Time-series Modeling. By relating masked modeling to\nmanifold learning, SimMTM proposes to recover masked time points by the\nweighted aggregation of multiple neighbors outside the manifold, which eases\nthe reconstruction task by assembling ruined but complementary temporal\nvariations from multiple masked series. SimMTM further learns to uncover the\nlocal structure of the manifold helpful for masked modeling. Experimentally,\nSimMTM achieves state-of-the-art fine-tuning performance in two canonical time\nseries analysis tasks: forecasting and classification, covering both in- and\ncross-domain settings.\n","authors":["Jiaxiang Dong","Haixu Wu","Haoran Zhang","Li Zhang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2302.00861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00860v1","updated":"2023-02-02T04:08:08Z","published":"2023-02-02T04:08:08Z","title":"Interventional and Counterfactual Inference with Diffusion Models","summary":"  We consider the problem of answering observational, interventional, and\ncounterfactual queries in a causally sufficient setting where only\nobservational data and the causal graph are available. Utilizing the recent\ndevelopments in diffusion models, we introduce diffusion-based causal models\n(DCM) to learn causal mechanisms, that generate unique latent encodings to\nallow for direct sampling under interventions as well as abduction for\ncounterfactuals. We utilize DCM to model structural equations, seeing that\ndiffusion models serve as a natural candidate here since they encode each node\nto a latent representation, a proxy for the exogenous noise, and offer flexible\nand accurate modeling to provide reliable causal statements and estimates. Our\nempirical evaluations demonstrate significant improvements over existing\nstate-of-the-art methods for answering causal queries. Our theoretical results\nprovide a methodology for analyzing the counterfactual error for general\nencoder/decoder models which could be of independent interest.\n","authors":["Patrick Chao","Patrick Blöbaum","Shiva Prasad Kasiviswanathan"],"pdf_url":"https://arxiv.org/pdf/2302.00860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00857v1","updated":"2023-02-02T04:02:49Z","published":"2023-02-02T04:02:49Z","title":"Algorithm Design for Online Meta-Learning with Task Boundary Detection","summary":"  Online meta-learning has recently emerged as a marriage between batch\nmeta-learning and online learning, for achieving the capability of quick\nadaptation on new tasks in a lifelong manner. However, most existing approaches\nfocus on the restrictive setting where the distribution of the online tasks\nremains fixed with known task boundaries. In this work, we relax these\nassumptions and propose a novel algorithm for task-agnostic online\nmeta-learning in non-stationary environments. More specifically, we first\npropose two simple but effective detection mechanisms of task switches and\ndistribution shift based on empirical observations, which serve as a key\nbuilding block for more elegant online model updates in our algorithm: the task\nswitch detection mechanism allows reusing of the best model available for the\ncurrent task at hand, and the distribution shift detection mechanism\ndifferentiates the meta model update in order to preserve the knowledge for\nin-distribution tasks and quickly learn the new knowledge for\nout-of-distribution tasks. In particular, our online meta model updates are\nbased only on the current data, which eliminates the need of storing previous\ndata as required in most existing methods. We further show that a sublinear\ntask-averaged regret can be achieved for our algorithm under mild conditions.\nEmpirical studies on three different benchmarks clearly demonstrate the\nsignificant advantage of our algorithm over related baseline approaches.\n","authors":["Daouda Sow","Sen Lin","Yingbin Liang","Junshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.00857v1.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/1910.13659v3","updated":"2023-02-02T03:59:33Z","published":"2019-10-30T04:32:56Z","title":"Efficient Privacy-Preserving Stochastic Nonconvex Optimization","summary":"  While many solutions for privacy-preserving convex empirical risk\nminimization (ERM) have been developed, privacy-preserving nonconvex ERM\nremains a challenge. We study nonconvex ERM, which takes the form of minimizing\na finite-sum of nonconvex loss functions over a training set. We propose a new\ndifferentially private stochastic gradient descent algorithm for nonconvex ERM\nthat achieves strong privacy guarantees efficiently, and provide a tight\nanalysis of its privacy and utility guarantees, as well as its gradient\ncomplexity. Our algorithm reduces gradient complexity while improves the best\nprevious utility guarantee given by Wang et al. (NeurIPS 2017). Our experiments\non benchmark nonconvex ERM problems demonstrate superior performance in terms\nof both training cost and utility gains compared with previous differentially\nprivate methods using the same privacy budgets.\n","authors":["Lingxiao Wang","Bargav Jayaraman","David Evans","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/1910.13659v3.pdf","comment":"29 pages, 5 figures, 3 tables. This version corrects a miscalculation\n  in the previous proof, resulting in an improved utility bound for the\n  algorithm"},{"id":"http://arxiv.org/abs/2302.00855v1","updated":"2023-02-02T03:49:57Z","published":"2023-02-02T03:49:57Z","title":"Molecular Geometry-aware Transformer for accurate 3D Atomic System\n  modeling","summary":"  Molecular dynamic simulations are important in computational physics,\nchemistry, material, and biology. Machine learning-based methods have shown\nstrong abilities in predicting molecular energy and properties and are much\nfaster than DFT calculations. Molecular energy is at least related to atoms,\nbonds, bond angles, torsion angles, and nonbonding atom pairs. Previous\nTransformer models only use atoms as inputs which lack explicit modeling of the\naforementioned factors. To alleviate this limitation, we propose Moleformer, a\nnovel Transformer architecture that takes nodes (atoms) and edges (bonds and\nnonbonding atom pairs) as inputs and models the interactions among them using\nrotational and translational invariant geometry-aware spatial encoding.\nProposed spatial encoding calculates relative position information including\ndistances and angles among nodes and edges. We benchmark Moleformer on OC20 and\nQM9 datasets, and our model achieves state-of-the-art on the initial state to\nrelaxed energy prediction of OC20 and is very competitive in QM9 on predicting\nquantum chemical properties compared to other Transformer and Graph Neural\nNetwork (GNN) methods which proves the effectiveness of the proposed\ngeometry-aware spatial encoding in Moleformer.\n","authors":["Zheng Yuan","Yaoyun Zhang","Chuanqi Tan","Wei Wang","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2302.00855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00854v1","updated":"2023-02-02T03:47:52Z","published":"2023-02-02T03:47:52Z","title":"Learning PDE Solution Operator for Continuous Modeling of Time-Series","summary":"  Learning underlying dynamics from data is important and challenging in many\nreal-world scenarios. Incorporating differential equations (DEs) to design\ncontinuous networks has drawn much attention recently, however, most prior\nworks make specific assumptions on the type of DEs, making the model\nspecialized for particular problems. This work presents a partial differential\nequation (PDE) based framework which improves the dynamics modeling capability.\nBuilding upon the recent Fourier neural operator, we propose a neural operator\nthat can handle time continuously without requiring iterative operations or\nspecific grids of temporal discretization. A theoretical result demonstrating\nits universality is provided. We also uncover an intrinsic property of neural\noperators that improves data efficiency and model generalization by ensuring\nstability. Our model achieves superior accuracy in dealing with time-dependent\nPDEs compared to existing models. Furthermore, several numerical pieces of\nevidence validate that our method better represents a wide range of dynamics\nand outperforms state-of-the-art DE-based models in real-time-series\napplications. Our framework opens up a new way for a continuous representation\nof neural networks that can be readily adopted for real-world applications.\n","authors":["Yesom Park","Jaemoo Choi","Changyeon Yoon","Chang hoon Song","Myungjoo Kang"],"pdf_url":"https://arxiv.org/pdf/2302.00854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08597v3","updated":"2023-02-02T23:48:35Z","published":"2022-11-16T01:05:41Z","title":"SketchySGD: Reliable Stochastic Optimization via Robust Curvature\n  Estimates","summary":"  We introduce SketchySGD, a stochastic quasi-Newton method that uses sketching\nto approximate the curvature of the loss function. SketchySGD improves upon\nexisting stochastic gradient methods in machine learning by using randomized\nlow-rank approximations to the subsampled Hessian and by introducing an\nautomated stepsize that works well across a wide range of convex machine\nlearning problems. We show theoretically that SketchySGD with a fixed stepsize\nconverges linearly to a small ball around the optimum. Further, in the\nill-conditioned setting we show SketchySGD converges at a faster rate than SGD\nfor least-squares problems. We validate this improvement empirically with ridge\nregression experiments on real data. Numerical experiments on both ridge and\nlogistic regression problems show that SketchySGD can achieve comparable or\nbetter results to popular stochastic gradient methods with minimal\nhyperparameter tuning. The robustness of SketchySGD to hyperparameters is an\nadvantage over other stochastic gradient methods, most of which require careful\nhyperparameter tuning (especially of the learning rate) to obtain good\nperformance.\n","authors":["Zachary Frangella","Pratik Rathore","Shipu Zhao","Madeleine Udell"],"pdf_url":"https://arxiv.org/pdf/2211.08597v3.pdf","comment":"20 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2205.00167v2","updated":"2023-02-02T23:42:12Z","published":"2022-04-30T05:44:34Z","title":"Self-Programming Artificial Intelligence Using Code-Generating Language\n  Models","summary":"  Recent progress in large-scale language models has enabled breakthroughs in\npreviously intractable computer programming tasks. Prior work in meta-learning\nand neural architecture search has led to substantial successes across various\ntask domains, spawning myriad approaches for algorithmically optimizing the\ndesign and learning dynamics of deep learning models. At the intersection of\nthese research areas, we implement a code-generating language model with the\nability to modify its own source code. Self-programming AI algorithms have been\nof interest since the dawn of AI itself. Although various theoretical\nformulations of generalized self-programming AI have been posed, no such system\nhas been successfully implemented to date under real-world computational\nconstraints. Applying AI-based code generation to AI itself, we develop and\nexperimentally validate the first practical implementation of a\nself-programming AI system. We empirically show that a self-programming AI\nimplemented using a code generation model can successfully modify its own\nsource code to improve performance and program sub-models to perform auxiliary\ntasks. Our model can self-modify various properties including model\narchitecture, computational capacity, and learning dynamics.\n","authors":["Alex Sheng","Shankar Padmanabhan"],"pdf_url":"https://arxiv.org/pdf/2205.00167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01463v1","updated":"2023-02-02T23:32:24Z","published":"2023-02-02T23:32:24Z","title":"Convergence of Gradient Descent with Linearly Correlated Noise and\n  Applications to Differentially Private Learning","summary":"  We study stochastic optimization with linearly correlated noise. Our study is\nmotivated by recent methods for optimization with differential privacy (DP),\nsuch as DP-FTRL, which inject noise via matrix factorization mechanisms. We\npropose an optimization problem that distils key facets of these DP methods and\nthat involves perturbing gradients by linearly correlated noise. We derive\nimproved convergence rates for gradient descent in this framework for convex\nand non-convex loss functions. Our theoretical analysis is novel and might be\nof independent interest. We use these convergence rates to develop new,\neffective matrix factorizations for differentially private optimization, and\nhighlight the benefits of these factorizations theoretically and empirically.\n","authors":["Anastasia Koloskova","Ryan McKenna","Zachary Charles","Keith Rush","Brendan McMahan"],"pdf_url":"https://arxiv.org/pdf/2302.01463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15646v2","updated":"2023-02-02T23:23:21Z","published":"2022-11-28T18:52:33Z","title":"Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions\n  with \"Spurious\" Correlations","summary":"  Spurious correlations, or correlations that change across domains where a\nmodel can be deployed, present significant challenges to real-world\napplications of machine learning models. However, such correlations are not\nalways \"spurious\"; often, they provide valuable prior information for a\nprediction. Here, we present a test-time adaptation method that exploits the\nspurious correlation phenomenon, in contrast to recent approaches that attempt\nto eliminate spurious correlations through invariance. We consider situations\nwhere the prior distribution $p(y, z)$, which models the dependence between the\nclass label $y$ and the \"nuisance\" factors $z$, may change across domains, but\nthe generative model for features $p(\\mathbf{x}|y, z)$ is constant. We note\nthat this corresponds to an expanded version of the label shift assumption,\nwhere the labels now also include the nuisance factors $z$. Based on this\nobservation, we train a classifier to predict $p(y, z|\\mathbf{x})$ on the\nsource distribution, and propose a test-time label shift correction that adapts\nto changes in the marginal distribution $p(y, z)$ using unlabeled samples from\nthe target domain. We evaluate our method, which we call \"Test-Time Label-Shift\nAdaptation\" (TTLSA), on two different image datasets -- the CheXpert chest\nX-ray dataset and the Colored MNIST dataset -- and show a significant\nimprovement over baseline methods. Code reproducing experiments is available at\nhttps://github.com/nalzok/test-time-label-shift .\n","authors":["Qingyao Sun","Kevin Murphy","Sayna Ebrahimi","Alexander D'Amour"],"pdf_url":"https://arxiv.org/pdf/2211.15646v2.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.01450v1","updated":"2023-02-02T22:37:47Z","published":"2023-02-02T22:37:47Z","title":"Performance Bounds for Policy-Based Average Reward Reinforcement\n  Learning Algorithms","summary":"  Many policy-based reinforcement learning (RL) algorithms can be viewed as\ninstantiations of approximate policy iteration (PI), i.e., where policy\nimprovement and policy evaluation are both performed approximately. In\napplications where the average reward objective is the meaningful performance\nmetric, often discounted reward formulations are used with the discount factor\nbeing close to 1, which is equivalent to making the expected horizon very\nlarge. However, the corresponding theoretical bounds for error performance\nscale with the square of the horizon. Thus, even after dividing the total\nreward by the length of the horizon, the corresponding performance bounds for\naverage reward problems go to infinity. Therefore, an open problem has been to\nobtain meaningful performance bounds for approximate PI and RL algorithms for\nthe average-reward setting. In this paper, we solve this open problem by\nobtaining the first non-trivial error bounds for average-reward MDPs which go\nto zero in the limit where when policy evaluation and policy improvement errors\ngo to zero.\n","authors":["Yashaswini Murthy","Mehrdad Moharrami","R. Srikant"],"pdf_url":"https://arxiv.org/pdf/2302.01450v1.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2302.01448v1","updated":"2023-02-02T22:32:10Z","published":"2023-02-02T22:32:10Z","title":"Out of Context: Investigating the Bias and Fairness Concerns of\n  \"Artificial Intelligence as a Service\"","summary":"  \"AI as a Service\" (AIaaS) is a rapidly growing market, offering various\nplug-and-play AI services and tools. AIaaS enables its customers (users) - who\nmay lack the expertise, data, and/or resources to develop their own systems -\nto easily build and integrate AI capabilities into their applications. Yet, it\nis known that AI systems can encapsulate biases and inequalities that can have\nsocietal impact. This paper argues that the context-sensitive nature of\nfairness is often incompatible with AIaaS' 'one-size-fits-all' approach,\nleading to issues and tensions. Specifically, we review and systematise the\nAIaaS space by proposing a taxonomy of AI services based on the levels of\nautonomy afforded to the user. We then critically examine the different\ncategories of AIaaS, outlining how these services can lead to biases or be\notherwise harmful in the context of end-user applications. In doing so, we seek\nto draw research attention to the challenges of this emerging area.\n","authors":["Kornel Lewicki","Michelle Seng Ah Lee","Jennifer Cobbe","Jatinder Singh"],"pdf_url":"https://arxiv.org/pdf/2302.01448v1.pdf","comment":"Accepted to CHI '23: ACM Human Factors in Computing, 2023, Hamburg,\n  Germany"},{"id":"http://arxiv.org/abs/2211.16708v2","updated":"2023-02-02T22:24:59Z","published":"2022-11-30T03:11:43Z","title":"Statistical treatment of convolutional neural network super-resolution\n  of inland surface wind for subgrid-scale variability quantification","summary":"  Machine learning models have been employed to perform either physics-free\ndata-driven or hybrid dynamical downscaling of climate data. Most of these\nimplementations operate over relatively small downscaling factors because of\nthe challenge of recovering fine-scale information from coarse data. This\nlimits their compatibility with many global climate model outputs, often\navailable between $\\sim$50--100 km resolution, to scales of interest such as\ncloud resolving or urban scales. This study systematically examines the\ncapability of convolutional neural networks (CNNs) to downscale surface wind\nspeed data over land surface from different coarse resolutions (25 km, 48 km,\nand 100 km resolution) to 3 km. For each downscaling factor, we consider three\nCNN configurations that generate super-resolved predictions of fine-scale wind\nspeed, which take between 1 to 3 input fields: coarse wind speed, fine-scale\ntopography, and diurnal cycle. In addition to fine-scale wind speeds,\nprobability density function parameters are generated, through which sample\nwind speeds can be generated accounting for the intrinsic stochasticity of wind\nspeed. For generalizability assessment, CNN models are tested on regions with\ndifferent topography and climate that are unseen during training. The\nevaluation of super-resolved predictions focuses on subgrid-scale variability\nand the recovery of extremes. Models with coarse wind and fine topography as\ninputs exhibit the best performance compared with other model configurations,\noperating across the same downscaling factor. Our diurnal cycle encoding\nresults in lower out-of-sample generalizability compared with other input\nconfigurations.\n","authors":["Daniel Getter","Julie Bessac","Johann Rudi","Yan Feng"],"pdf_url":"https://arxiv.org/pdf/2211.16708v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.03011v5","updated":"2023-02-02T22:22:41Z","published":"2021-09-07T11:57:07Z","title":"LEAF: Navigating Concept Drift in Cellular Networks","summary":"  Operational networks commonly rely on machine learning models for many tasks,\nincluding detecting anomalies, inferring application performance, and\nforecasting demand. Yet, model accuracy can degrade due to concept drift,\nwhereby the relationship between the features and the target to be predicted\nchanges. Mitigating concept drift is an essential part of operationalizing\nmachine learning models in general, but is of particular importance in\nnetworking's highly dynamic deployment environments. In this paper, we first\ncharacterize concept drift in a large cellular network for a major metropolitan\narea in the United States. We find that concept drift occurs across many\nimportant key performance indicators (KPIs), independently of the model,\ntraining set size, and time interval -- thus necessitating practical approaches\nto detect, explain, and mitigate it. We then show that frequent model\nretraining with newly available data is not sufficient to mitigate concept\ndrift, and can even degrade model accuracy further. Finally, we develop a new\nmethodology for concept drift mitigation, Local Error Approximation of Features\n(LEAF). LEAF works by detecting drift; explaining the features and time\nintervals that contribute the most to drift; and mitigates it using forgetting\nand over-sampling. We evaluate LEAF against industry-standard mitigation\napproaches (notably, periodic retraining) with more than four years of cellular\nKPI data. Our initial tests with a major cellular provider in the US show that\nLEAF consistently outperforms periodic and triggered retraining on complex,\nreal-world data while reducing costly retraining operations.\n","authors":["Shinan Liu","Francesco Bronzino","Paul Schmitt","Arjun Nitin Bhagoji","Nick Feamster","Hector Garcia Crespo","Timothy Coyle","Brian Ward"],"pdf_url":"https://arxiv.org/pdf/2109.03011v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08326v3","updated":"2023-02-02T22:19:44Z","published":"2022-10-15T16:02:33Z","title":"Distributionally Robust Causal Inference with Observational Data","summary":"  We consider the estimation of average treatment effects in observational\nstudies and propose a new framework of robust causal inference with unobserved\nconfounders. Our approach is based on distributionally robust optimization and\nproceeds in two steps. We first specify the maximal degree to which the\ndistribution of unobserved potential outcomes may deviate from that of observed\noutcomes. We then derive sharp bounds on the average treatment effects under\nthis assumption. Our framework encompasses the popular marginal sensitivity\nmodel as a special case, and we demonstrate how the proposed methodology can\naddress a primary challenge of the marginal sensitivity model that it produces\nuninformative results when unobserved confounders substantially affect\ntreatment and outcome. Specifically, we develop an alternative sensitivity\nmodel, called the distributional sensitivity model, under the assumption that\nheterogeneity of treatment effect due to unobserved variables is relatively\nsmall. Unlike the marginal sensitivity model, the distributional sensitivity\nmodel allows for potential lack of overlap and often produces informative\nbounds even when unobserved variables substantially affect both treatment and\noutcome. Finally, we show how to extend the distributional sensitivity model to\ndifference-in-differences designs and settings with instrumental variables.\nThrough simulation and empirical studies, we demonstrate the applicability of\nthe proposed methodology.\n","authors":["Dimitris Bertsimas","Kosuke Imai","Michael Lingzhi Li"],"pdf_url":"https://arxiv.org/pdf/2210.08326v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01441v1","updated":"2023-02-02T22:04:07Z","published":"2023-02-02T22:04:07Z","title":"Commonsense-Aware Prompting for Controllable Empathetic Dialogue\n  Generation","summary":"  Improving the emotional awareness of pre-trained language models is an\nemerging important problem for dialogue generation tasks. Although prior\nstudies have introduced methods to improve empathetic dialogue generation, few\nhave discussed how to incorporate commonsense knowledge into pre-trained\nlanguage models for controllable dialogue generation. In this study, we propose\na novel framework that improves empathetic dialogue generation using\npre-trained language models by 1) incorporating commonsense knowledge through\nprompt verbalization, and 2) controlling dialogue generation using a\nstrategy-driven future discriminator. We conducted experiments to reveal that\nboth the incorporation of social commonsense knowledge and enforcement of\ncontrol over generation help to improve generation performance. Finally, we\ndiscuss the implications of our study for future research.\n","authors":["Yiren Liu","Halil Kilicoglu"],"pdf_url":"https://arxiv.org/pdf/2302.01441v1.pdf","comment":"Accepted to Workshop on Knowledge Augmented Methods for Natural\n  Language Processing, in conjunction with AAAI 2023"},{"id":"http://arxiv.org/abs/2302.01440v1","updated":"2023-02-02T22:02:33Z","published":"2023-02-02T22:02:33Z","title":"Generalized Uncertainty of Deep Neural Networks: Taxonomy and\n  Applications","summary":"  Deep neural networks have seen enormous success in various real-world\napplications. Beyond their predictions as point estimates, increasing attention\nhas been focused on quantifying the uncertainty of their predictions. In this\nreview, we show that the uncertainty of deep neural networks is not only\nimportant in a sense of interpretability and transparency, but also crucial in\nfurther advancing their performance, particularly in learning systems seeking\nrobustness and efficiency. We will generalize the definition of the uncertainty\nof deep neural networks to any number or vector that is associated with an\ninput or an input-label pair, and catalog existing methods on ``mining'' such\nuncertainty from a deep model. We will include those methods from the classic\nfield of uncertainty quantification as well as those methods that are specific\nto deep neural networks. We then show a wide spectrum of applications of such\ngeneralized uncertainty in realistic learning tasks including robust learning\nsuch as noisy learning, adversarially robust learning; data-efficient learning\nsuch as semi-supervised and weakly-supervised learning; and model-efficient\nlearning such as model compression and knowledge distillation.\n","authors":["Chengyu Dong"],"pdf_url":"https://arxiv.org/pdf/2302.01440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01435v1","updated":"2023-02-02T21:56:52Z","published":"2023-02-02T21:56:52Z","title":"Target specific peptide design using latent space approximate trajectory\n  collector","summary":"  Despite the prevalence and many successes of deep learning applications in de\nnovo molecular design, the problem of peptide generation targeting specific\nproteins remains unsolved. A main barrier for this is the scarcity of the\nhigh-quality training data. To tackle the issue, we propose a novel machine\nlearning based peptide design architecture, called Latent Space Approximate\nTrajectory Collector (LSATC). It consists of a series of samplers on an\noptimization trajectory on a highly non-convex energy landscape that\napproximates the distributions of peptides with desired properties in a latent\nspace. The process involves little human intervention and can be implemented in\nan end-to-end manner. We demonstrate the model by the design of peptide\nextensions targeting Beta-catenin, a key nuclear effector protein involved in\ncanonical Wnt signalling. When compared with a random sampler, LSATC can sample\npeptides with $36\\%$ lower binding scores in a $16$ times smaller interquartile\nrange (IQR) and $284\\%$ less hydrophobicity with a $1.4$ times smaller IQR.\nLSATC also largely outperforms other common generative models. Finally, we\nutilized a clustering algorithm to select 4 peptides from the 100 LSATC\ndesigned peptides for experimental validation. The result confirms that all the\nfour peptides extended by LSATC show improved Beta-catenin binding by at least\n$20.0\\%$, and two of the peptides show a $3$ fold increase in binding affinity\nas compared to the base peptide.\n","authors":["Tong Lin","Sijie Chen","Ruchira Basu","Dehu Pei","Xiaolin Cheng","Levent Burak Kara"],"pdf_url":"https://arxiv.org/pdf/2302.01435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.09306v2","updated":"2023-02-02T21:54:16Z","published":"2021-01-22T19:36:40Z","title":"Towards Optimal Branching of Linear and Semidefinite Relaxations for\n  Neural Network Robustness Certification","summary":"  In this paper, we study certifying the robustness of ReLU neural networks\nagainst adversarial input perturbations. To diminish the relaxation error\nsuffered by the popular linear programming (LP) and semidefinite programming\n(SDP) certification methods, we take a branch-and-bound approach to propose\npartitioning the input uncertainty set and solving the relaxations on each part\nseparately. We show that this approach reduces relaxation error, and that the\nerror is eliminated entirely upon performing an LP relaxation with a partition\nintelligently designed to exploit the nature of the ReLU activations. To scale\nthis approach to large networks, we consider using a coarser partition whereby\nthe number of parts in the partition is reduced. We prove that computing such a\ncoarse partition that directly minimizes the LP relaxation error is NP-hard. By\ninstead minimizing the worst-case LP relaxation error, we develop a closed-form\nbranching scheme. We extend the analysis to the SDP, where the feasible set\ngeometry is exploited to design a branching scheme that minimizes the\nworst-case SDP relaxation error. Experiments on MNIST, CIFAR-10, and Wisconsin\nbreast cancer diagnosis classifiers demonstrate significant increases in the\npercentages of test samples certified. By independently increasing the input\nsize and the number of layers, we empirically illustrate under which regimes\nthe branched LP and branched SDP are best applied.\n","authors":["Brendon G. Anderson","Ziye Ma","Jingqi Li","Somayeh Sojoudi"],"pdf_url":"https://arxiv.org/pdf/2101.09306v2.pdf","comment":"This is an extension of our IEEE CDC 2020 conference paper\n  arXiv:2004.00570"},{"id":"http://arxiv.org/abs/2302.01428v1","updated":"2023-02-02T21:41:59Z","published":"2023-02-02T21:41:59Z","title":"Dataset Distillation Fixes Dataset Reconstruction Attacks","summary":"  Modern deep learning requires large volumes of data, which could contain\nsensitive or private information which cannot be leaked. Recent work has shown\nfor homogeneous neural networks a large portion of this training data could be\nreconstructed with only access to the trained network parameters. While the\nattack was shown to work empirically, there exists little formal understanding\nof its effectiveness regime, and ways to defend against it. In this work, we\nfirst build a stronger version of the dataset reconstruction attack and show\nhow it can provably recover its entire training set in the infinite width\nregime. We then empirically study the characteristics of this attack on\ntwo-layer networks and reveal that its success heavily depends on deviations\nfrom the frozen infinite-width Neural Tangent Kernel limit. More importantly,\nwe formally show for the first time that dataset reconstruction attacks are a\nvariation of dataset distillation. This key theoretical result on the\nunification of dataset reconstruction and distillation not only sheds more\nlight on the characteristics of the attack but enables us to design defense\nmechanisms against them via distillation algorithms.\n","authors":["Noel Loo","Ramin Hasani","Mathias Lechner","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2302.01428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01425v1","updated":"2023-02-02T21:32:13Z","published":"2023-02-02T21:32:13Z","title":"Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective","summary":"  The top-k operator returns a k-sparse vector, where the non-zero values\ncorrespond to the k largest values of the input. Unfortunately, because it is a\ndiscontinuous function, it is difficult to incorporate in neural networks\ntrained end-to-end with backpropagation. Recent works have considered\ndifferentiable relaxations, based either on regularization or perturbation\ntechniques. However, to date, no approach is fully differentiable and sparse.\nIn this paper, we propose new differentiable and sparse top-k operators. We\nview the top-k operator as a linear program over the permutahedron, the convex\nhull of permutations. We then introduce a p-norm regularization term to smooth\nout the operator, and show that its computation can be reduced to isotonic\noptimization. Our framework is significantly more general than the existing one\nand allows for example to express top-k operators that select values in\nmagnitude. On the algorithmic side, in addition to pool adjacent violator (PAV)\nalgorithms, we propose a new GPU/TPU-friendly Dykstra algorithm to solve\nisotonic optimization problems. We successfully use our operators to prune\nweights in neural networks, to fine-tune vision transformers, and as a router\nin sparse mixture of experts.\n","authors":["Michael E. Sander","Joan Puigcerver","Josip Djolonga","Gabriel Peyré","Mathieu Blondel"],"pdf_url":"https://arxiv.org/pdf/2302.01425v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2302.01417v1","updated":"2023-02-02T21:10:31Z","published":"2023-02-02T21:10:31Z","title":"A Convolutional-based Model for Early Prediction of Alzheimer's based on\n  the Dementia Stage in the MRI Brain Images","summary":"  Alzheimer's disease is a degenerative brain disease. Being the primary cause\nof Dementia in adults and progressively destroys brain memory. Though\nAlzheimer's disease does not have a cure currently, diagnosing it at an earlier\nstage will help reduce the severity of the disease. Thus, early diagnosis of\nAlzheimer's could help to reduce or stop the disease from progressing. In this\npaper, we proposed a deep convolutional neural network-based model for learning\nmodel using to determine the stage of Dementia in adults based on the Magnetic\nResonance Imaging (MRI) images to detect the early onset of Alzheimer's.\n","authors":["Shrish Pellakur","Nelly Elsayed","Zag ElSayed","Murat Ozer"],"pdf_url":"https://arxiv.org/pdf/2302.01417v1.pdf","comment":"Short paper, Under Review in FLAIRS-36"},{"id":"http://arxiv.org/abs/2302.01416v1","updated":"2023-02-02T21:04:47Z","published":"2023-02-02T21:04:47Z","title":"Neural Insights for Digital Marketing Content Design","summary":"  In digital marketing, experimenting with new website content is one of the\nkey levers to improve customer engagement. However, creating successful\nmarketing content is a manual and time-consuming process that lacks clear\nguiding principles. This paper seeks to close the loop between content creation\nand online experimentation by offering marketers AI-driven actionable insights\nbased on historical data to improve their creative process. We present a\nneural-network-based system that scores and extracts insights from a marketing\ncontent design, namely, a multimodal neural network predicts the attractiveness\nof marketing contents, and a post-hoc attribution method generates actionable\ninsights for marketers to improve their content in specific marketing\nlocations. Our insights not only point out the advantages and drawbacks of a\ngiven current content, but also provide design recommendations based on\nhistorical data. We show that our scoring model and insights work well both\nquantitatively and qualitatively.\n","authors":["Fanjie Kong","Yuan Li","Houssam Nassif","Tanner Fiez","Shreya Chakrabarti","Ricardo Henao"],"pdf_url":"https://arxiv.org/pdf/2302.01416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01409v1","updated":"2023-02-02T20:47:45Z","published":"2023-02-02T20:47:45Z","title":"Hyperbolic Contrastive Learning","summary":"  Learning good image representations that are beneficial to downstream tasks\nis a challenging task in computer vision. As such, a wide variety of\nself-supervised learning approaches have been proposed. Among them, contrastive\nlearning has shown competitive performance on several benchmark datasets. The\nembeddings of contrastive learning are arranged on a hypersphere that results\nin using the inner (dot) product as a distance measurement in Euclidean space.\nHowever, the underlying structure of many scientific fields like social\nnetworks, brain imaging, and computer graphics data exhibit highly\nnon-Euclidean latent geometry. We propose a novel contrastive learning\nframework to learn semantic relationships in the hyperbolic space. Hyperbolic\nspace is a continuous version of trees that naturally owns the ability to model\nhierarchical structures and is thus beneficial for efficient contrastive\nrepresentation learning. We also extend the proposed Hyperbolic Contrastive\nLearning (HCL) to the supervised domain and studied the adversarial robustness\nof HCL. The comprehensive experiments show that our proposed method achieves\nbetter results on self-supervised pretraining, supervised classification, and\nhigher robust accuracy than baseline methods.\n","authors":["Yun Yue","Fangzhou Lin","Kazunori D Yamada","Ziming Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01409v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2212.05301v2","updated":"2023-02-02T09:30:00Z","published":"2022-12-10T14:01:54Z","title":"Leveraging Modality-specific Representations for Audio-visual Speech\n  Recognition via Reinforcement Learning","summary":"  Audio-visual speech recognition (AVSR) has gained remarkable success for\nameliorating the noise-robustness of speech recognition. Mainstream methods\nfocus on fusing audio and visual inputs to obtain modality-invariant\nrepresentations. However, such representations are prone to over-reliance on\naudio modality as it is much easier to recognize than video modality in clean\nconditions. As a result, the AVSR model underestimates the importance of visual\nstream in face of noise corruption. To this end, we leverage visual\nmodality-specific representations to provide stable complementary information\nfor the AVSR task. Specifically, we propose a reinforcement learning (RL) based\nframework called MSRL, where the agent dynamically harmonizes\nmodality-invariant and modality-specific representations in the auto-regressive\ndecoding process. We customize a reward function directly related to\ntask-specific metrics (i.e., word error rate), which encourages the MSRL to\neffectively explore the optimal integration strategy. Experimental results on\nthe LRS3 dataset show that the proposed method achieves state-of-the-art in\nboth clean and various noisy conditions. Furthermore, we demonstrate the better\ngenerality of MSRL system than other baselines when test set contains unseen\nnoises.\n","authors":["Chen Chen","Yuchen Hu","Qiang Zhang","Heqing Zou","Beier Zhu","Eng Siong Chng"],"pdf_url":"https://arxiv.org/pdf/2212.05301v2.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.00819v1","updated":"2023-02-02T01:51:35Z","published":"2023-02-02T01:51:35Z","title":"Introduction to Arithmetic Coding -- Theory and Practice","summary":"  This introduction to arithmetic coding is divided in two parts. The first\nexplains how and why arithmetic coding works. We start presenting it in very\ngeneral terms, so that its simplicity is not lost under layers of\nimplementation details. Next, we show some of its basic properties, which are\nlater used in the computational techniques required for a practical\nimplementation. In the second part, we cover the practical implementation\naspects, including arithmetic operations with low precision, the subdivision of\ncoding and modeling, and the realization of adaptive encoders. We also analyze\nthe arithmetic coding computational complexity, and techniques to reduce it.\n","authors":["Amir Said"],"pdf_url":"https://arxiv.org/pdf/2302.00819v1.pdf","comment":"Hewlett-Packard Laboratories Report; Chapter in Lossless Compression\n  Handbook (ed. K. Sayood), Academic Press"},{"id":"http://arxiv.org/abs/2302.02809v1","updated":"2023-02-02T04:09:23Z","published":"2023-02-02T04:09:23Z","title":"Scene2BIR: Material-aware learning-based binaural impulse response\n  generator for reconstructed real-world 3D scenes","summary":"  We present an end-to-end binaural impulse response generator (BIR) to\ngenerate plausible sounds in real-time for real-world models. Our approach uses\na novel neural-network-based BIR generator (Scene2BIR) for the reconstructed 3D\nmodel. We propose a graph neural network that uses both the material and the\ntopology information of the 3D scenes and generates a scene latent vector.\nMoreover, we use a conditional generative adversarial network (CGAN) to\ngenerate BIRs from the scene latent vector. Our network is able to handle holes\nor other artifacts in the reconstructed 3D mesh model. We present an efficient\ncost function to the generator network to incorporate spatial audio effects.\nGiven the source and the listener position, our approach can generate a BIR in\n0.1 milliseconds on an NVIDIA GeForce RTX 2080 Ti GPU and can easily handle\nmultiple sources. We have evaluated the accuracy of our approach with\nreal-world captured BIRs and an interactive geometric sound propagation\nalgorithm.\n","authors":["Anton Jeran Ratnarajah","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2302.02809v1.pdf","comment":"Project page: https://anton-jeran.github.io/S2BIR/"},{"id":"http://arxiv.org/abs/2302.03497v1","updated":"2023-02-02T02:59:00Z","published":"2023-02-02T02:59:00Z","title":"MMRec: Simplifying Multimodal Recommendation","summary":"  This paper presents an open-source toolbox, MMRec for multimodal\nrecommendation. MMRec simplifies and canonicalizes the process of implementing\nand comparing multimodal recommendation models. The objective of MMRec is to\nprovide a unified and configurable arena that can minimize the effort in\nimplementing and testing multimodal recommendation models. It enables\nmultimodal models, ranging from traditional matrix factorization to modern\ngraph-based algorithms, capable of fusing information from multiple modalities\nsimultaneously. Our documentation, examples, and source code are available at\n\\url{https://github.com/enoche/MMRec}.\n","authors":["Xin Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.03497v1.pdf","comment":"3 pages"}]},"2023-02-03T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2301.12534v2","updated":"2023-02-03T18:50:31Z","published":"2023-01-29T20:39:21Z","title":"Vicarious Offense and Noise Audit of Offensive Speech Classifiers","summary":"  This paper examines social web content moderation from two key perspectives:\nautomated methods (machine moderators) and human evaluators (human moderators).\nWe conduct a noise audit at an unprecedented scale using nine machine\nmoderators trained on well-known offensive speech data sets evaluated on a\ncorpus sampled from 92 million YouTube comments discussing a multitude of\nissues relevant to US politics. We introduce a first-of-its-kind data set of\nvicarious offense. We ask annotators: (1) if they find a given social media\npost offensive; and (2) how offensive annotators sharing different political\nbeliefs would find the same content. Our experiments with machine moderators\nreveal that moderation outcomes wildly vary across different machine\nmoderators. Our experiments with human moderators suggest that (1) political\nleanings considerably affect first-person offense perspective; (2) Republicans\nare the worst predictors of vicarious offense; (3) predicting vicarious offense\nfor the Republicans is most challenging than predicting vicarious offense for\nthe Independents and the Democrats; and (4) disagreement across political\nidentity groups considerably increases when sensitive issues such as\nreproductive rights or gun control/rights are discussed. Both experiments\nsuggest that offense, is indeed, highly subjective and raise important\nquestions concerning content moderation practices.\n","authors":["Tharindu Cyril Weerasooriya","Sujan Dutta","Tharindu Ranasinghe","Marcos Zampieri","Christopher M. Homan","Ashiqur R. KhudaBukhsh"],"pdf_url":"https://arxiv.org/pdf/2301.12534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13631v2","updated":"2023-02-03T17:45:11Z","published":"2023-01-31T13:44:34Z","title":"TopoBERT: Plug and Play Toponym Recognition Module Harnessing Fine-tuned\n  BERT","summary":"  Extracting precise geographical information from textual contents is crucial\nin a plethora of applications. For example, during hazardous events, a robust\nand unbiased toponym extraction framework can provide an avenue to tie the\nlocation concerned to the topic discussed by news media posts and pinpoint\nhumanitarian help requests or damage reports from social media. Early studies\nhave leveraged rule-based, gazetteer-based, deep learning, and hybrid\napproaches to address this problem. However, the performance of existing tools\nis deficient in supporting operations like emergency rescue, which relies on\nfine-grained, accurate geographic information. The emerging pretrained language\nmodels can better capture the underlying characteristics of text information,\nincluding place names, offering a promising pathway to optimize toponym\nrecognition to underpin practical applications. In this paper, TopoBERT, a\ntoponym recognition module based on a one dimensional Convolutional Neural\nNetwork (CNN1D) and Bidirectional Encoder Representation from Transformers\n(BERT), is proposed and fine-tuned. Three datasets (CoNLL2003-Train,\nWikipedia3000, WNUT2017) are leveraged to tune the hyperparameters, discover\nthe best training strategy, and train the model. Another two datasets\n(CoNLL2003-Test and Harvey2017) are used to evaluate the performance. Three\ndistinguished classifiers, linear, multi-layer perceptron, and CNN1D, are\nbenchmarked to determine the optimal model architecture. TopoBERT achieves\nstate-of-the-art performance (f1-score=0.865) compared to the other five\nbaseline models and can be applied to diverse toponym recognition tasks without\nadditional training.\n","authors":["Bing Zhou","Lei Zou","Yingjie Hu","Yi Qiang","Daniel Goldberg"],"pdf_url":"https://arxiv.org/pdf/2301.13631v2.pdf","comment":"8 Pages, 6 figures"},{"id":"http://arxiv.org/abs/2210.01108v2","updated":"2023-02-03T17:32:18Z","published":"2022-10-03T17:48:32Z","title":"SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis","summary":"  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n","authors":["Jiaxin Pei","Vítor Silva","Maarten Bos","Yozon Liu","Leonardo Neves","David Jurgens","Francesco Barbieri"],"pdf_url":"https://arxiv.org/pdf/2210.01108v2.pdf","comment":"SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis"},{"id":"http://arxiv.org/abs/2302.01860v1","updated":"2023-02-03T17:07:23Z","published":"2023-02-03T17:07:23Z","title":"GLADIS: A General and Large Acronym Disambiguation Benchmark","summary":"  Acronym Disambiguation (AD) is crucial for natural language understanding on\nvarious sources, including biomedical reports, scientific papers, and search\nengine queries. However, existing acronym disambiguation benchmarks and tools\nare limited to specific domains, and the size of prior benchmarks is rather\nsmall. To accelerate the research on acronym disambiguation, we construct a new\nbenchmark named GLADIS with three components: (1) a much larger acronym\ndictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus\nwith 160 million sentences; (3) three datasets that cover the general,\nscientific, and biomedical domains. We then pre-train a language model,\n\\emph{AcroBERT}, on our constructed corpus for general acronym disambiguation,\nand show the challenges and values of our new benchmark.\n","authors":["Lihu Chen","Gaël Varoquaux","Fabian M. Suchanek"],"pdf_url":"https://arxiv.org/pdf/2302.01860v1.pdf","comment":"EACL 23"},{"id":"http://arxiv.org/abs/2302.01859v1","updated":"2023-02-03T17:05:59Z","published":"2023-02-03T17:05:59Z","title":"Generalizing to Unseen Elements: A Survey on Knowledge Extrapolation for\n  Knowledge Graphs","summary":"  Knowledge graphs (KGs) have become effective knowledge resources in diverse\napplications, and knowledge graph embedding (KGE) methods have attracted\nincreasing attention in recent years. However, it's still challenging for\nconventional KGE methods to handle unseen entities or relations during the\nmodel test. Much effort has been made in various fields of KGs to address this\nproblem. In this paper, we use a set of general terminologies to unify these\nmethods and refer to them as Knowledge Extrapolation. We comprehensively\nsummarize these methods classified by our proposed taxonomy and describe their\ncorrelations. Next, we introduce the benchmarks and provide comparisons of\nthese methods from aspects that are not reflected by the taxonomy. Finally, we\nsuggest some potential directions for future research.\n","authors":["Mingyang Chen","Wen Zhang","Yuxia Geng","Zezhong Xu","Jeff Z. Pan","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2302.01859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01849v1","updated":"2023-02-03T16:49:46Z","published":"2023-02-03T16:49:46Z","title":"Entity-Agnostic Representation Learning for Parameter-Efficient\n  Knowledge Graph Embedding","summary":"  We propose an entity-agnostic representation learning method for handling the\nproblem of inefficient parameter storage costs brought by embedding knowledge\ngraphs. Conventional knowledge graph embedding methods map elements in a\nknowledge graph, including entities and relations, into continuous vector\nspaces by assigning them one or multiple specific embeddings (i.e., vector\nrepresentations). Thus the number of embedding parameters increases linearly as\nthe growth of knowledge graphs. In our proposed model, Entity-Agnostic\nRepresentation Learning (EARL), we only learn the embeddings for a small set of\nentities and refer to them as reserved entities. To obtain the embeddings for\nthe full set of entities, we encode their distinguishable information from\ntheir connected relations, k-nearest reserved entities, and multi-hop\nneighbors. We learn universal and entity-agnostic encoders for transforming\ndistinguishable information into entity embeddings. This approach allows our\nproposed EARL to have a static, efficient, and lower parameter count than\nconventional knowledge graph embedding methods. Experimental results show that\nEARL uses fewer parameters and performs better on link prediction tasks than\nbaselines, reflecting its parameter efficiency.\n","authors":["Mingyang Chen","Wen Zhang","Zhen Yao","Yushan Zhu","Yang Gao","Jeff Z. Pan","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2302.01849v1.pdf","comment":"Accepted to AAAI 2023 conference"},{"id":"http://arxiv.org/abs/2212.09700v2","updated":"2023-02-03T16:41:06Z","published":"2022-12-19T18:30:09Z","title":"Resolving Open-textured Rules with Templated Interpretive Arguments","summary":"  Open-textured terms in written rules are typically settled through\ninterpretive argumentation. Ongoing work has attempted to catalogue the schemes\nused in such interpretive argumentation. But how can the use of these schemes\naffect the way in which people actually use and reason over the proper\ninterpretations of open-textured terms? Using the interpretive\nargument-eliciting game Aporia as our framework, we carried out an empirical\nstudy to answer this question. Differing from previous work, we did not allow\nparticipants to argue for interpretations arbitrarily, but to only use\narguments that fit with a given set of interpretive argument templates.\nFinally, we analyze the results captured by this new dataset, specifically\nfocusing on practical implications for the development of\ninterpretation-capable artificial reasoners.\n","authors":["John Licato","Logan Fields","Zaid Marji"],"pdf_url":"https://arxiv.org/pdf/2212.09700v2.pdf","comment":"Presented at the 2022 European Conference on Argumentation (ECA)"},{"id":"http://arxiv.org/abs/2302.01842v1","updated":"2023-02-03T16:37:08Z","published":"2023-02-03T16:37:08Z","title":"A Case Study for Compliance as Code with Graphs and Language Models:\n  Public release of the Regulatory Knowledge Graph","summary":"  The paper presents a study on using language models to automate the\nconstruction of executable Knowledge Graph (KG) for compliance. The paper\nfocuses on Abu Dhabi Global Market regulations and taxonomy, involves manual\ntagging a portion of the regulations, training BERT-based models, which are\nthen applied to the rest of the corpus. Coreference resolution and syntax\nanalysis were used to parse the relationships between the tagged entities and\nto form KG stored in a Neo4j database. The paper states that the use of machine\nlearning models released by regulators to automate the interpretation of rules\nis a vital step towards compliance automation, demonstrates the concept\nquerying with Cypher, and states that the produced sub-graphs combined with\nGraph Neural Networks (GNN) will achieve expandability in judgment automation\nsystems. The graph is open sourced on GitHub to provide structured data for\nfuture advancements in the field.\n","authors":["Vladimir Ershov"],"pdf_url":"https://arxiv.org/pdf/2302.01842v1.pdf","comment":"7 pages on RegKG step 1 in collaboration with ADGM"},{"id":"http://arxiv.org/abs/2302.01839v1","updated":"2023-02-03T16:30:09Z","published":"2023-02-03T16:30:09Z","title":"Investigating Stylistic Profiles for the Task of Empathy Classification\n  in Medical Narrative Essays","summary":"  One important aspect of language is how speakers generate utterances and\ntexts to convey their intended meanings. In this paper, we bring various\naspects of the Construction Grammar (CxG) and the Systemic Functional Grammar\n(SFG) theories in a deep learning computational framework to model empathic\nlanguage. Our corpus consists of 440 essays written by premed students as\nnarrated simulated patient-doctor interactions. We start with baseline\nclassifiers (state-of-the-art recurrent neural networks and transformer\nmodels). Then, we enrich these models with a set of linguistic constructions\nproving the importance of this novel approach to the task of empathy\nclassification for this dataset. Our results indicate the potential of such\nconstructions to contribute to the overall empathy profile of first-person\nnarrative essays.\n","authors":["Priyanka Dey","Roxana Girju"],"pdf_url":"https://arxiv.org/pdf/2302.01839v1.pdf","comment":"12 pages, 5 figures; This paper will appear in the ACL Anthology\n  (Association for Computational Linguistics) and will be presented at the\n  Construction Grammars and NLP (CxGs+NLP) Workshop, the Georgetown University\n  Round Table (GURT), March 2023"},{"id":"http://arxiv.org/abs/2302.00762v2","updated":"2023-02-03T16:07:53Z","published":"2023-02-01T21:25:34Z","title":"AmbiCoref: Evaluating Human and Model Sensitivity to Ambiguous\n  Coreference","summary":"  Given a sentence \"Abby told Brittney that she upset Courtney\", one would\nstruggle to understand who \"she\" refers to, and ask for clarification. However,\nif the word \"upset\" were replaced with \"hugged\", \"she\" unambiguously refers to\nAbby. We study if modern coreference resolution models are sensitive to such\npronominal ambiguity. To this end, we construct AmbiCoref, a diagnostic corpus\nof minimal sentence pairs with ambiguous and unambiguous referents. Our\nexamples generalize psycholinguistic studies of human perception of ambiguity\naround particular arrangements of verbs and their arguments. Analysis shows\nthat (1) humans are less sure of referents in ambiguous AmbiCoref examples than\nunambiguous ones, and (2) most coreference models show little difference in\noutput between ambiguous and unambiguous pairs. We release AmbiCoref as a\ndiagnostic corpus for testing whether models treat ambiguity similarly to\nhumans.\n","authors":["Yuewei Yuan","Chaitanya Malaviya","Mark Yatskar"],"pdf_url":"https://arxiv.org/pdf/2302.00762v2.pdf","comment":"EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2302.01823v1","updated":"2023-02-03T15:57:54Z","published":"2023-02-03T15:57:54Z","title":"Lexical Simplification using multi level and modular approach","summary":"  Text Simplification is an ongoing problem in Natural Language Processing,\nsolution to which has varied implications. In conjunction with the TSAR-2022\nWorkshop @EMNLP2022 Lexical Simplification is the process of reducing the\nlexical complexity of a text by replacing difficult words with easier to read\n(or understand) expressions while preserving the original information and\nmeaning. This paper explains the work done by our team \"teamPN\" for English sub\ntask. We created a modular pipeline which combines modern day transformers\nbased models with traditional NLP methods like paraphrasing and verb sense\ndisambiguation. We created a multi level and modular pipeline where the target\ntext is treated according to its semantics(Part of Speech Tag). Pipeline is\nmulti level as we utilize multiple source models to find potential candidates\nfor replacement, It is modular as we can switch the source models and their\nweight-age in the final re-ranking.\n","authors":["Nikita Katyal","Pawan Kumar Rajpoot"],"pdf_url":"https://arxiv.org/pdf/2302.01823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01806v1","updated":"2023-02-03T15:17:53Z","published":"2023-02-03T15:17:53Z","title":"Mitigating Data Scarcity for Large Language Models","summary":"  In recent years, pretrained neural language models (PNLMs) have taken the\nfield of natural language processing by storm, achieving new benchmarks and\nstate-of-the-art performances. These models often rely heavily on annotated\ndata, which may not always be available. Data scarcity are commonly found in\nspecialized domains, such as medical, or in low-resource languages that are\nunderexplored by AI research. In this dissertation, we focus on mitigating data\nscarcity using data augmentation and neural ensemble learning techniques for\nneural language models. In both research directions, we implement neural\nnetwork algorithms and evaluate their impact on assisting neural language\nmodels in downstream NLP tasks. Specifically, for data augmentation, we explore\ntwo techniques: 1) creating positive training data by moving an answer span\naround its original context and 2) using text simplification techniques to\nintroduce a variety of writing styles to the original training data. Our\nresults indicate that these simple and effective solutions improve the\nperformance of neural language models considerably in low-resource NLP domains\nand tasks. For neural ensemble learning, we use a multilabel neural classifier\nto select the best prediction outcome from a variety of individual pretrained\nneural language models trained for a low-resource medical text simplification\ntask.\n","authors":["Hoang Van"],"pdf_url":"https://arxiv.org/pdf/2302.01806v1.pdf","comment":"155 pages, 26 tables, 11 figures"},{"id":"http://arxiv.org/abs/2205.14690v4","updated":"2023-02-03T14:24:48Z","published":"2022-05-29T15:18:37Z","title":"CoNT: Contrastive Neural Text Generation","summary":"  Recently, contrastive learning attracts increasing interests in neural text\ngeneration as a new solution to alleviate the exposure bias problem. It\nintroduces a sequence-level training signal which is crucial to generation\ntasks that always rely on auto-regressive decoding. However, previous methods\nusing contrastive learning in neural text generation usually lead to inferior\nperformance. In this paper, we analyse the underlying reasons and propose a new\nContrastive Neural Text generation framework, CoNT. CoNT addresses bottlenecks\nthat prevent contrastive learning from being widely adopted in generation tasks\nfrom three aspects -- the construction of contrastive examples, the choice of\nthe contrastive loss, and the strategy in decoding. We validate CoNT on five\ngeneration tasks with ten benchmarks, including machine translation,\nsummarization, code comment generation, data-to-text generation and commonsense\ngeneration. Experimental results show that CoNT clearly outperforms the\nconventional training framework on all the ten benchmarks with a convincing\nmargin. Especially, CoNT surpasses previous the most competitive contrastive\nlearning method for text generation, by 1.50 BLEU on machine translation and\n1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art\non summarization, code comment generation (without external data) and\ndata-to-text generation.\n","authors":["Chenxin An","Jiangtao Feng","Kai Lv","Lingpeng Kong","Xipeng Qiu","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2205.14690v4.pdf","comment":"Accepted by NeurIPS 2022"},{"id":"http://arxiv.org/abs/2209.11486v4","updated":"2023-02-03T12:47:29Z","published":"2022-09-23T09:01:05Z","title":"MetaPrompting: Learning to Learn Better Prompts","summary":"  Prompting method is regarded as one of the crucial progress for few-shot\nnature language processing. Recent research on prompting moves from discrete\ntokens based ``hard prompts'' to continuous ``soft prompts'', which employ\nlearnable vectors as pseudo prompt tokens and achieve better performance.\nThough showing promising prospects, these soft-prompting methods are observed\nto rely heavily on good initialization to take effect. Unfortunately, obtaining\na perfect initialization for soft prompts requires understanding of inner\nlanguage models working and elaborate design, which is no easy task and has to\nrestart from scratch for each new task. To remedy this, we propose a\ngeneralized soft prompting method called MetaPrompting, which adopts the\nwell-recognized model-agnostic meta-learning algorithm to automatically find\nbetter prompt initialization that facilitates fast adaptation to new prompting\ntasks.Extensive experiments show MetaPrompting tackles soft prompt\ninitialization problem and brings significant improvement on four different\ndatasets (over 6 points improvement in accuracy for 1-shot setting), achieving\nnew state-of-the-art performance.\n","authors":["Yutai Hou","Hongyuan Dong","Xinghao Wang","Bohan Li","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2209.11486v4.pdf","comment":"Accepted as COLING 2022 long paper"},{"id":"http://arxiv.org/abs/2302.01691v1","updated":"2023-02-03T12:42:45Z","published":"2023-02-03T12:42:45Z","title":"LIQUID: A Framework for List Question Answering Dataset Generation","summary":"  Question answering (QA) models often rely on large-scale training datasets,\nwhich necessitates the development of a data generation framework to reduce the\ncost of manual annotations. Although several recent studies have aimed to\ngenerate synthetic questions with single-span answers, no study has been\nconducted on the creation of list questions with multiple, non-contiguous spans\nas answers. To address this gap, we propose \\ours, an automated framework for\ngenerating list QA datasets from unlabeled corpora. We first convert a passage\nfrom Wikipedia or PubMed into a summary and extract named entities from the\nsummarized text as candidate answers. This allows us to select answers that are\nsemantically correlated in context and is, therefore, suitable for constructing\nlist questions. We then create questions using an off-the-shelf question\ngenerator with the extracted entities and original passage. Finally, iterative\nfiltering and answer expansion are performed to ensure the accuracy and\ncompleteness of the answers. Using our synthetic data, we significantly improve\nthe performance of the previous best list QA models by exact-match F1 scores of\n5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ\nbenchmarks.\n","authors":["Seongyun Lee","Hyunjae Kim","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2302.01691v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2301.11845v2","updated":"2023-02-03T12:29:30Z","published":"2023-01-27T16:49:52Z","title":"Learning the Effects of Physical Actions in a Multi-modal Environment","summary":"  Large Language Models (LLMs) handle physical commonsense information\ninadequately. As a result of being trained in a disembodied setting, LLMs often\nfail to predict an action's outcome in a given environment. However, predicting\nthe effects of an action before it is executed is crucial in planning, where\ncoherent sequences of actions are often needed to achieve a goal. Therefore, we\nintroduce the multi-modal task of predicting the outcomes of actions solely\nfrom realistic sensory inputs (images and text). Next, we extend an LLM to\nmodel latent representations of objects to better predict action outcomes in an\nenvironment. We show that multi-modal models can capture physical commonsense\nwhen augmented with visual information. Finally, we evaluate our model's\nperformance on novel actions and objects and find that combining modalities\nhelp models to generalize and learn physical commonsense reasoning better.\n","authors":["Gautier Dagan","Frank Keller","Alex Lascarides"],"pdf_url":"https://arxiv.org/pdf/2301.11845v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00768v2","updated":"2023-02-03T12:19:26Z","published":"2023-02-01T21:38:47Z","title":"Leveraging task dependency and contrastive learning for Legal Judgement\n  Prediction on the European Court of Human Rights","summary":"  We report on an experiment in legal judgement prediction on European Court of\nHuman Rights cases where our model first learns to predict the convention\narticles allegedly violated by the state from case facts descriptions, and\nsubsequently utilizes that information to predict a finding of a violation by\nthe court. We assess the dependency between these two tasks at the feature and\noutcome level. Furthermore, we leverage a hierarchical contrastive loss to pull\ntogether article specific representations of cases at the higher level level,\nleading to distinctive article clusters, and further pulls the cases in each\narticle cluster based on their outcome leading to sub-clusters of cases with\nsimilar outcomes. Our experiment results demonstrate that, given a static\npre-trained encoder, our models produce a small but consistent improvement in\nprediction performance over single-task and joint models without contrastive\nloss.\n","authors":["T. Y. S. S Santosh","Marcel Perez San Blas","Phillip Kemper","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2302.00768v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.00609v2","updated":"2023-02-03T12:16:25Z","published":"2023-02-01T17:20:52Z","title":"Zero Shot Transfer of Legal Judgement Prediction as Article-aware\n  Entailment for the European Court of Human Rights","summary":"  In this paper, we cast Legal Judgment Prediction (LJP) from text on European\nCourt of Human Rights cases as an entailment task, where the case outcome is\nclassified from a combined input of case facts and convention articles. This\nconfiguration facilitates the model learning legal reasoning ability in mapping\narticle text to specific fact text. It also provides the opportunity to\nevaluate the model's ability to generalize to zero-shot settings when asked to\nclassify the case outcome with respect to articles not seen during training. We\ndevise zero-shot LJP experiments and apply domain adaptation methods based on\ndomain discriminator and Wasserstein distance. Our results demonstrate that the\nentailment architecture outperforms straightforward fact classification. We\nalso find that domain adaptation methods improve zero-shot transfer\nperformance, with article relatedness and encoder pre-training influencing the\neffect.\n","authors":["T. Y. S. S Santosh","Oana Ichim","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2302.00609v2.pdf","comment":"Accepted to EACL Findings 2023"},{"id":"http://arxiv.org/abs/2302.01676v1","updated":"2023-02-03T11:56:38Z","published":"2023-02-03T11:56:38Z","title":"Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction","summary":"  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n","authors":["Davide Costa","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2302.01676v1.pdf","comment":"Accepted paper at The ACM Web Conference 2023, April 30--May 04,\n  2023, Austin, Texas, USA"},{"id":"http://arxiv.org/abs/2210.03765v3","updated":"2023-02-03T10:36:55Z","published":"2022-10-07T18:01:09Z","title":"Visualize Before You Write: Imagination-Guided Open-Ended Text\n  Generation","summary":"  Recent advances in text-to-image synthesis make it possible to visualize\nmachine imaginations for a given context. On the other hand, when generating\ntext, human writers are gifted at creative visualization, which enhances their\nwritings by forming imaginations as blueprints before putting down the stories\nin words. Inspired by such a cognitive process, we ask the natural question of\nwhether we can endow machines with the same ability to utilize visual\ninformation and construct a general picture of the context to guide text\ngeneration. In this work, we propose iNLG that uses machine-generated images to\nguide language models in open-ended text generation. The experiments and\nanalyses demonstrate the effectiveness of iNLG on open-ended text generation\ntasks, including text completion, story generation, and concept-to-text\ngeneration in both few-shot and full-data scenarios. Both automatic metrics and\nhuman evaluations verify that the text snippets generated by our iNLG are\ncoherent and informative while displaying minor degeneration.\n","authors":["Wanrong Zhu","An Yan","Yujie Lu","Wenda Xu","Xin Eric Wang","Miguel Eckstein","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2210.03765v3.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2302.01626v1","updated":"2023-02-03T09:54:27Z","published":"2023-02-03T09:54:27Z","title":"Modeling Sequential Sentence Relation to Improve Cross-lingual Dense\n  Retrieval","summary":"  Recently multi-lingual pre-trained language models (PLM) such as mBERT and\nXLM-R have achieved impressive strides in cross-lingual dense retrieval.\nDespite its successes, they are general-purpose PLM while the multilingual PLM\ntailored for cross-lingual retrieval is still unexplored. Motivated by an\nobservation that the sentences in parallel documents are approximately in the\nsame order, which is universal across languages, we propose to model this\nsequential sentence relation to facilitate cross-lingual representation\nlearning. Specifically, we propose a multilingual PLM called masked sentence\nmodel (MSM), which consists of a sentence encoder to generate the sentence\nrepresentations, and a document encoder applied to a sequence of sentence\nvectors from a document. The document encoder is shared for all languages to\nmodel the universal sequential sentence relation across languages. To train the\nmodel, we propose a masked sentence prediction task, which masks and predicts\nthe sentence vector via a hierarchical contrastive loss with sampled negatives.\nComprehensive experiments on four cross-lingual retrieval tasks show MSM\nsignificantly outperforms existing advanced pre-training models, demonstrating\nthe effectiveness and stronger cross-lingual retrieval capabilities of our\napproach. Code and model will be available.\n","authors":["Shunyu Zhang","Yaobo Liang","Ming Gong","Daxin Jiang","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2302.01626v1.pdf","comment":"Published at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01614v1","updated":"2023-02-03T09:27:12Z","published":"2023-02-03T09:27:12Z","title":"Around the world in 60 words: A generative vocabulary test for online\n  research","summary":"  Conducting experiments with diverse participants in their native languages\ncan uncover insights into culture, cognition, and language that may not be\nrevealed otherwise. However, conducting these experiments online makes it\ndifficult to validate self-reported language proficiency. Furthermore, existing\nproficiency tests are small and cover only a few languages. We present an\nautomated pipeline to generate vocabulary tests using text from Wikipedia. Our\npipeline samples rare nouns and creates pseudowords with the same low-level\nstatistics. Six behavioral experiments (N=236) in six countries and eight\nlanguages show that (a) our test can distinguish between native speakers of\nclosely related languages, (b) the test is reliable ($r=0.82$), and (c)\nperformance strongly correlates with existing tests (LexTale) and self-reports.\nWe further show that test accuracy is negatively correlated with the linguistic\ndistance between the tested and the native language. Our test, available in\neight languages, can easily be extended to other languages.\n","authors":["Pol van Rijn","Yue Sun","Harin Lee","Raja Marjieh","Ilia Sucholutsky","Francesca Lanzarini","Elisabeth André","Nori Jacoby"],"pdf_url":"https://arxiv.org/pdf/2302.01614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01588v1","updated":"2023-02-03T08:04:59Z","published":"2023-02-03T08:04:59Z","title":"Bioformer: an efficient transformer language model for biomedical text\n  mining","summary":"  Pretrained language models such as Bidirectional Encoder Representations from\nTransformers (BERT) have achieved state-of-the-art performance in natural\nlanguage processing (NLP) tasks. Recently, BERT has been adapted to the\nbiomedical domain. Despite the effectiveness, these models have hundreds of\nmillions of parameters and are computationally expensive when applied to\nlarge-scale NLP applications. We hypothesized that the number of parameters of\nthe original BERT can be dramatically reduced with minor impact on performance.\nIn this study, we present Bioformer, a compact BERT model for biomedical text\nmining. We pretrained two Bioformer models (named Bioformer8L and Bioformer16L)\nwhich reduced the model size by 60% compared to BERTBase. Bioformer uses a\nbiomedical vocabulary and was pre-trained from scratch on PubMed abstracts and\nPubMed Central full-text articles. We thoroughly evaluated the performance of\nBioformer as well as existing biomedical BERT models including BioBERT and\nPubMedBERT on 15 benchmark datasets of four different biomedical NLP tasks:\nnamed entity recognition, relation extraction, question answering and document\nclassification. The results show that with 60% fewer parameters, Bioformer16L\nis only 0.1% less accurate than PubMedBERT while Bioformer8L is 0.9% less\naccurate than PubMedBERT. Both Bioformer16L and Bioformer8L outperformed\nBioBERTBase-v1.1. In addition, Bioformer16L and Bioformer8L are 2-3 fold as\nfast as PubMedBERT/BioBERTBase-v1.1. Bioformer has been successfully deployed\nto PubTator Central providing gene annotations over 35 million PubMed abstracts\nand 5 million PubMed Central full-text articles. We make Bioformer publicly\navailable via https://github.com/WGLab/bioformer, including pre-trained models,\ndatasets, and instructions for downstream use.\n","authors":["Li Fang","Qingyu Chen","Chih-Hsuan Wei","Zhiyong Lu","Kai Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01582v1","updated":"2023-02-03T07:27:50Z","published":"2023-02-03T07:27:50Z","title":"Controlling for Stereotypes in Multimodal Language Model Evaluation","summary":"  We propose a methodology and design two benchmark sets for measuring to what\nextent language-and-vision language models use the visual signal in the\npresence or absence of stereotypes. The first benchmark is designed to test for\nstereotypical colors of common objects, while the second benchmark considers\ngender stereotypes. The key idea is to compare predictions when the image\nconforms to the stereotype to predictions when it does not.\n  Our results show that there is significant variation among multimodal models:\nthe recent Transformer-based FLAVA seems to be more sensitive to the choice of\nimage and less affected by stereotypes than older CNN-based models such as\nVisualBERT and LXMERT. This effect is more discernible in this type of\ncontrolled setting than in traditional evaluations where we do not know whether\nthe model relied on the stereotype or the visual signal.\n","authors":["Manuj Malik","Richard Johansson"],"pdf_url":"https://arxiv.org/pdf/2302.01582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01570v1","updated":"2023-02-03T06:47:20Z","published":"2023-02-03T06:47:20Z","title":"Witgenstein's influence on artificial intelligence","summary":"  We examine how much of the contemporary progress in artificial intelligence\n(and, specifically, in natural language processing), can be, more or less\ndirectly, traced back to the seminal work and ideas of the Austrian-British\nphilosopher Ludwig Wittgenstein, with particular focus on his late views.\nDiscussing Wittgenstein's original theses will give us the chance to survey the\nstate of artificial intelligence, and comment on both its strengths and\nweaknesses. A similar text appeared first in Spanish as a chapter of CENTENARIO\nDEL SILENCIO (2021), a book celebrating 100 years since the publication of the\nTractatus.\n","authors":["Piero Molino","Jacopo Tagliabue"],"pdf_url":"https://arxiv.org/pdf/2302.01570v1.pdf","comment":"English pre-print of a Chapter first appeared in Spanish in\n  CENTENARIO DEL SILENCIO (2021)"},{"id":"http://arxiv.org/abs/2302.00902v2","updated":"2023-02-03T05:06:46Z","published":"2023-02-02T06:38:44Z","title":"Language Quantized AutoEncoders: Towards Unsupervised Text-Image\n  Alignment","summary":"  Recent progress in scaling up large language models has shown impressive\ncapabilities in performing few-shot learning across a wide range of text-based\ntasks. However, a key limitation is that these language models fundamentally\nlack visual perception - a crucial attribute needed to extend these models to\nbe able to interact with the real world and solve vision tasks, such as in\nvisual-question answering and robotics. Prior works have largely connected\nimage to text through pretraining and/or fine-tuning on curated image-text\ndatasets, which can be a costly and expensive process. In order to resolve this\nlimitation, we propose a simple yet effective approach called\nLanguage-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to\nalign text-image data in an unsupervised manner by leveraging pretrained\nlanguage models (e.g., BERT, RoBERTa). Our main idea is to encode image as\nsequences of text tokens by directly quantizing image embeddings using a\npretrained language codebook. We then apply random masking followed by a BERT\nmodel, and have the decoder reconstruct the original image from BERT predicted\ntext token embeddings. By doing so, LQAE learns to represent similar images\nwith similar clusters of text tokens, thereby aligning these two modalities\nwithout the use of aligned text-image pairs. This enables few-shot image\nclassification with large language models (e.g., GPT-3) as well as linear\nclassification of images based on BERT text features. To the best of our\nknowledge, our work is the first work that uses unaligned images for multimodal\ntasks by leveraging the power of pretrained language models.\n","authors":["Hao Liu","Wilson Yan","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.00902v2.pdf","comment":"Fixed typos"},{"id":"http://arxiv.org/abs/2302.01536v1","updated":"2023-02-03T04:22:29Z","published":"2023-02-03T04:22:29Z","title":"Using natural language processing and structured medical data to\n  phenotype patients hospitalized due to COVID-19","summary":"  To identify patients who are hospitalized because of COVID-19 as opposed to\nthose who were admitted for other indications, we compared the performance of\ndifferent computable phenotype definitions for COVID-19 hospitalizations that\nuse different types of data from the electronic health records (EHR), including\nstructured EHR data elements, provider notes, or a combination of both data\ntypes. And conduct a retrospective data analysis utilizing chart review-based\nvalidation. Participants are 586 hospitalized individuals who tested positive\nfor SARS-CoV-2 during January 2022. We used natural language processing to\nincorporate data from provider notes and LASSO regression and Random Forests to\nfit classification algorithms that incorporated structured EHR data elements,\nprovider notes, or a combination of structured data and provider notes.\nResults: Based on a chart review, 38% of 586 patients were determined to be\nhospitalized for reasons other than COVID-19 despite having tested positive for\nSARS-CoV-2. A classification algorithm that used provider notes had\nsignificantly better discrimination than one that used structured EHR data\nelements (AUROC: 0.894 vs 0.841, p < 0.001), and performed similarly to a model\nthat combined provider notes with structured data elements (AUROC: 0.894 vs\n0.893). Assessments of hospital outcome metrics significantly differed based on\nwhether the population included all hospitalized patients who tested positive\nfor SARS-CoV-2 versus those who were determined to have been hospitalized due\nto COVID-19. This work demonstrates the utility of natural language processing\napproaches to derive information related to patient hospitalizations in cases\nwhere there may be multiple conditions that could serve as the primary\nindication for hospitalization.\n","authors":["Feier Chang","Jay Krishnan","Jillian H Hurst","Michael E Yarrington","Deverick J Anderson","Emily C O'Brien","Benjamin A Goldstein"],"pdf_url":"https://arxiv.org/pdf/2302.01536v1.pdf","comment":"21 pages, 2 figures, 3 tables, 1 supplemental figure, 2 supplemental\n  tables"},{"id":"http://arxiv.org/abs/2302.01530v1","updated":"2023-02-03T04:09:22Z","published":"2023-02-03T04:09:22Z","title":"Revisiting Intermediate Layer Distillation for Compressing Language\n  Models: An Overfitting Perspective","summary":"  Knowledge distillation (KD) is a highly promising method for mitigating the\ncomputational problems of pre-trained language models (PLMs). Among various KD\napproaches, Intermediate Layer Distillation (ILD) has been a de facto standard\nKD method with its performance efficacy in the NLP field. In this paper, we\nfind that existing ILD methods are prone to overfitting to training datasets,\nalthough these methods transfer more information than the original KD. Next, we\npresent the simple observations to mitigate the overfitting of ILD: distilling\nonly the last Transformer layer and conducting ILD on supplementary tasks.\nBased on our two findings, we propose a simple yet effective\nconsistency-regularized ILD (CR-ILD), which prevents the student model from\noverfitting the training dataset. Substantial experiments on distilling BERT on\nthe GLUE benchmark and several synthetic datasets demonstrate that our proposed\nILD method outperforms other KD techniques. Our code is available at\nhttps://github.com/jongwooko/CR-ILD.\n","authors":["Jongwoo Ko","Seungjoon Park","Minchan Jeong","Sukjin Hong","Euijai Ahn","Du-Seong Chang","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2302.01530v1.pdf","comment":"The 17th Conference of the European Chapter of the Association for\n  Computational Linguistics (Findings)"},{"id":"http://arxiv.org/abs/2301.06660v2","updated":"2023-02-03T03:28:03Z","published":"2023-01-17T02:00:31Z","title":"VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19\n  Vaccination on Twitter","summary":"  Vaccine hesitancy has been a common concern, probably since vaccines were\ncreated and, with the popularisation of social media, people started to express\ntheir concerns about vaccines online alongside those posting pro- and\nanti-vaccine content. Predictably, since the first mentions of a COVID-19\nvaccine, social media users posted about their fears and concerns or about\ntheir support and belief into the effectiveness of these rapidly developing\nvaccines. Identifying and understanding the reasons behind public hesitancy\ntowards COVID-19 vaccines is important for policy markers that need to develop\nactions to better inform the population with the aim of increasing vaccine\ntake-up. In the case of COVID-19, where the fast development of the vaccines\nwas mirrored closely by growth in anti-vaxx disinformation, automatic means of\ndetecting citizen attitudes towards vaccination became necessary. This is an\nimportant computational social sciences task that requires data analysis in\norder to gain in-depth understanding of the phenomena at hand. Annotated data\nis also necessary for training data-driven models for more nuanced analysis of\nattitudes towards vaccination. To this end, we created a new collection of over\n3,101 tweets annotated with users' attitudes towards COVID-19 vaccination\n(stance). Besides, we also develop a domain-specific language model (VaxxBERT)\nthat achieves the best predictive performance (73.0 accuracy and 69.3 F1-score)\nas compared to a robust set of baselines. To the best of our knowledge, these\nare the first dataset and model that model vaccine hesitancy as a category\ndistinct from pro- and anti-vaccine stance.\n","authors":["Yida Mu","Mali Jin","Charlie Grimshaw","Carolina Scarton","Kalina Bontcheva","Xingyi Song"],"pdf_url":"https://arxiv.org/pdf/2301.06660v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07471v2","updated":"2023-02-03T02:12:37Z","published":"2022-10-14T02:46:06Z","title":"\"John is 50 years old, can his son be 65?\" Evaluating NLP Models'\n  Understanding of Feasibility","summary":"  In current NLP research, large-scale language models and their abilities are\nwidely being discussed. Some recent works have also found notable failures of\nthese models. Often these failure examples involve complex reasoning abilities.\nThis work focuses on a simple commonsense ability, reasoning about when an\naction (or its effect) is feasible. To this end, we introduce FeasibilityQA, a\nquestion-answering dataset involving binary classification (BCQ) and\nmulti-choice multi-correct questions (MCQ) that test understanding of\nfeasibility. We show that even state-of-the-art models such as GPT-3, GPT-2,\nand T5 struggle to answer the feasibility questions correctly. Specifically, on\nMCQ and BCQ questions, GPT-3 achieves an accuracy of just (19%, 62%) and (25%,\n64%) in zero-shot and few-shot settings, respectively. We also evaluate models\nby providing relevant knowledge statements required to answer the question. We\nfind that the additional knowledge leads to a 7% gain in performance, but the\noverall performance still remains low. These results make one wonder how much\ncommonsense knowledge about action feasibility is encoded in state-of-the-art\nmodels and how well they can reason about it.\n","authors":["Himanshu Gupta","Neeraj Varshney","Swaroop Mishra","Kuntal Kumar Pal","Saurabh Arjun Sawant","Kevin Scaria","Siddharth Goyal","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2210.07471v2.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2302.01496v1","updated":"2023-02-03T02:10:35Z","published":"2023-02-03T02:10:35Z","title":"Efficient Domain Adaptation for Speech Foundation Models","summary":"  Foundation models (FMs), that are trained on broad data at scale and are\nadaptable to a wide range of downstream tasks, have brought large interest in\nthe research community. Benefiting from the diverse data sources such as\ndifferent modalities, languages and application domains, foundation models have\ndemonstrated strong generalization and knowledge transfer capabilities. In this\npaper, we present a pioneering study towards building an efficient solution for\nFM-based speech recognition systems. We adopt the recently developed\nself-supervised BEST-RQ for pretraining, and propose the joint finetuning with\nboth source and unsupervised target domain data using JUST Hydra. The FM\nencoder adapter and decoder are then finetuned to the target domain with a\nsmall amount of supervised in-domain data. On a large-scale YouTube and Voice\nSearch task, our method is shown to be both data and model parameter efficient.\nIt achieves the same quality with only 21.6M supervised in-domain data and\n130.8M finetuned parameters, compared to the 731.1M model trained from scratch\non additional 300M supervised in-domain data.\n","authors":["Bo Li","Dongseong Hwang","Zhouyuan Huo","Junwen Bai","Guru Prakash","Tara N. Sainath","Khe Chai Sim","Yu Zhang","Wei Han","Trevor Strohman","Francoise Beaufays"],"pdf_url":"https://arxiv.org/pdf/2302.01496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.08696v2","updated":"2023-02-03T01:45:51Z","published":"2022-05-18T02:52:03Z","title":"The Solvability of Interpretability Evaluation Metrics","summary":"  Feature attribution methods are popular for explaining neural network\npredictions, and they are often evaluated on metrics such as comprehensiveness\nand sufficiency. In this paper, we highlight an intriguing property of these\nmetrics: their solvability. Concretely, we can define the problem of optimizing\nan explanation for a metric, which can be solved by beam search. This\nobservation leads to the obvious yet unaddressed question: why do we use\nexplainers (e.g., LIME) not based on solving the target metric, if the metric\nvalue represents explanation quality? We present a series of investigations\nshowing strong performance of this beam search explainer and discuss its\nbroader implication: a definition-evaluation duality of interpretability\nconcepts. We implement the explainer and release the Python solvex package for\nmodels of text, image and tabular domains.\n","authors":["Yilun Zhou","Julie Shah"],"pdf_url":"https://arxiv.org/pdf/2205.08696v2.pdf","comment":"EACL 2023 (Findings). Project website at\n  https://yilunzhou.github.io/solvability/"},{"id":"http://arxiv.org/abs/2210.10109v2","updated":"2023-02-03T01:11:42Z","published":"2022-10-18T19:14:42Z","title":"A Survey of Active Learning for Natural Language Processing","summary":"  In this work, we provide a survey of active learning (AL) for its\napplications in natural language processing (NLP). In addition to a\nfine-grained categorization of query strategies, we also investigate several\nother important aspects of applying AL to NLP problems. These include AL for\nstructured prediction tasks, annotation cost, model learning (especially with\ndeep neural models), and starting and stopping AL. Finally, we conclude with a\ndiscussion of related topics and future directions.\n","authors":["Zhisong Zhang","Emma Strubell","Eduard Hovy"],"pdf_url":"https://arxiv.org/pdf/2210.10109v2.pdf","comment":"EMNLP 2022"},{"id":"http://arxiv.org/abs/2004.05964v3","updated":"2023-02-03T00:29:28Z","published":"2020-04-13T14:35:28Z","title":"Keyword Assisted Topic Models","summary":"  In recent years, fully automated content analysis based on probabilistic\ntopic models has become popular among social scientists because of their\nscalability. The unsupervised nature of the models makes them suitable for\nexploring topics in a corpus without prior knowledge. However, researchers find\nthat these models often fail to measure specific concepts of substantive\ninterest by inadvertently creating multiple topics with similar content and\ncombining distinct themes into a single topic. In this paper, we empirically\ndemonstrate that providing a small number of keywords can substantially enhance\nthe measurement performance of topic models. An important advantage of the\nproposed keyword assisted topic model (keyATM) is that the specification of\nkeywords requires researchers to label topics prior to fitting a model to the\ndata. This contrasts with a widespread practice of post-hoc topic\ninterpretation and adjustments that compromises the objectivity of empirical\nfindings. In our application, we find that keyATM provides more interpretable\nresults, has better document classification performance, and is less sensitive\nto the number of topics than the standard topic models. Finally, we show that\nkeyATM can also incorporate covariates and model time trends. An open-source\nsoftware package is available for implementing the proposed methodology.\n","authors":["Shusei Eshima","Kosuke Imai","Tomoya Sasaki"],"pdf_url":"https://arxiv.org/pdf/2004.05964v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02029v1","updated":"2023-02-03T23:26:59Z","published":"2023-02-03T23:26:59Z","title":"Towards Few-Shot Identification of Morality Frames using In-Context\n  Learning","summary":"  Data scarcity is a common problem in NLP, especially when the annotation\npertains to nuanced socio-linguistic concepts that require specialized\nknowledge. As a result, few-shot identification of these concepts is desirable.\nFew-shot in-context learning using pre-trained Large Language Models (LLMs) has\nbeen recently applied successfully in many NLP tasks. In this paper, we study\nfew-shot identification of a psycho-linguistic concept, Morality Frames (Roy et\nal., 2021), using LLMs. Morality frames are a representation framework that\nprovides a holistic view of the moral sentiment expressed in text, identifying\nthe relevant moral foundation (Haidt and Graham, 2007) and at a finer level of\ngranularity, the moral sentiment expressed towards the entities mentioned in\nthe text. Previous studies relied on human annotation to identify morality\nframes in text which is expensive. In this paper, we propose prompting-based\napproaches using pretrained Large Language Models for identification of\nmorality frames, relying only on few-shot exemplars. We compare our models'\nperformance with few-shot RoBERTa and found promising results.\n","authors":["Shamik Roy","Nishanth Sridhar Nakshatri","Dan Goldwasser"],"pdf_url":"https://arxiv.org/pdf/2302.02029v1.pdf","comment":"Accepted to the 5th Workshop on NLP and CSS at EMNLP 2022"},{"id":"http://arxiv.org/abs/2302.02023v1","updated":"2023-02-03T22:58:07Z","published":"2023-02-03T22:58:07Z","title":"TextShield: Beyond Successfully Detecting Adversarial Sentences in Text\n  Classification","summary":"  Adversarial attack serves as a major challenge for neural network models in\nNLP, which precludes the model's deployment in safety-critical applications. A\nrecent line of work, detection-based defense, aims to distinguish adversarial\nsentences from benign ones. However, {the core limitation of previous detection\nmethods is being incapable of giving correct predictions on adversarial\nsentences unlike defense methods from other paradigms.} To solve this issue,\nthis paper proposes TextShield: (1) we discover a link between text attack and\nsaliency information, and then we propose a saliency-based detector, which can\neffectively detect whether an input sentence is adversarial or not. (2) We\ndesign a saliency-based corrector, which converts the detected adversary\nsentences to benign ones. By combining the saliency-based detector and\ncorrector, TextShield extends the detection-only paradigm to a\ndetection-correction paradigm, thus filling the gap in the existing\ndetection-based defense. Comprehensive experiments show that (a) TextShield\nconsistently achieves higher or comparable performance than state-of-the-art\ndefense methods across various attacks on different benchmarks. (b) our\nsaliency-based detector outperforms existing detectors for detecting\nadversarial sentences.\n","authors":["Lingfeng Shen","Ze Zhang","Haiyun Jiang","Ying Chen"],"pdf_url":"https://arxiv.org/pdf/2302.02023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03127v2","updated":"2023-02-03T22:55:12Z","published":"2023-01-09T00:19:11Z","title":"Logically at Factify 2: A Multi-Modal Fact Checking System Based on\n  Evidence Retrieval techniques and Transformer Encoder Architecture","summary":"  In this paper, we present the Logically submissions to De-Factify 2 challenge\n(DE-FACTIFY 2023) on the task 1 of Multi-Modal Fact Checking. We describes our\nsubmissions to this challenge including explored evidence retrieval and\nselection techniques, pre-trained cross-modal and unimodal models, and a\ncross-modal veracity model based on the well established Transformer Encoder\n(TE) architecture which is heavily relies on the concept of self-attention.\nExploratory analysis is also conducted on this Factify 2 data set that uncovers\nthe salient multi-modal patterns and hypothesis motivating the architecture\nproposed in this work. A series of preliminary experiments were done to\ninvestigate and benchmarking different pre-trained embedding models, evidence\nretrieval settings and thresholds. The final system, a standard two-stage\nevidence based veracity detection system, yields weighted avg. 0.79 on both val\nset and final blind test set on the task 1, which achieves 3rd place with a\nsmall margin to the top performing system on the leaderboard among 9\nparticipants.\n","authors":["Pim Jordi Verschuuren","Jie Gao","Adelize van Eeden","Stylianos Oikonomou","Anil Bandhakavi"],"pdf_url":"https://arxiv.org/pdf/2301.03127v2.pdf","comment":"Accepted in AAAI'23: Second Workshop on Multimodal Fact-Checking and\n  Hate Speech Detection, February 2023, Washington, DC, USA"},{"id":"http://arxiv.org/abs/2302.02016v1","updated":"2023-02-03T21:56:32Z","published":"2023-02-03T21:56:32Z","title":"Improving Interpretability via Explicit Word Interaction Graph Layer","summary":"  Recent NLP literature has seen growing interest in improving model\ninterpretability. Along this direction, we propose a trainable neural network\nlayer that learns a global interaction graph between words and then selects\nmore informative words using the learned word interactions. Our layer, we call\nWIGRAPH, can plug into any neural network-based NLP text classifiers right\nafter its word embedding layer. Across multiple SOTA NLP models and various NLP\ndatasets, we demonstrate that adding the WIGRAPH layer substantially improves\nNLP models' interpretability and enhances models' prediction performance at the\nsame time.\n","authors":["Arshdeep Sekhon","Hanjie Chen","Aman Shrivastava","Zhe Wang","Yangfeng Ji","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2302.02016v1.pdf","comment":"15 pages, AAAI 2023"},{"id":"http://arxiv.org/abs/2302.02008v1","updated":"2023-02-03T21:30:34Z","published":"2023-02-03T21:30:34Z","title":"Witscript: A System for Generating Improvised Jokes in a Conversation","summary":"  A chatbot is perceived as more humanlike and likeable if it includes some\njokes in its output. But most existing joke generators were not designed to be\nintegrated into chatbots. This paper presents Witscript, a novel joke\ngeneration system that can improvise original, contextually relevant jokes,\nsuch as humorous responses during a conversation. The system is based on joke\nwriting algorithms created by an expert comedy writer. Witscript employs\nwell-known tools of natural language processing to extract keywords from a\ntopic sentence and, using wordplay, to link those keywords and related words to\ncreate a punch line. Then a pretrained neural network language model that has\nbeen fine-tuned on a dataset of TV show monologue jokes is used to complete the\njoke response by filling the gap between the topic sentence and the punch line.\nA method of internal scoring filters out jokes that don't meet a preset\nstandard of quality. Human evaluators judged Witscript's responses to input\nsentences to be jokes more than 40% of the time. This is evidence that\nWitscript represents an important next step toward giving a chatbot a humanlike\nsense of humor.\n","authors":["Joe Toplyn"],"pdf_url":"https://arxiv.org/pdf/2302.02008v1.pdf","comment":"10 pages. Published in the Proceedings of the 12th International\n  Conference on Computational Creativity (ICCC 2021), pages 22-31"},{"id":"http://arxiv.org/abs/2302.01984v1","updated":"2023-02-03T20:09:17Z","published":"2023-02-03T20:09:17Z","title":"PSST! Prosodic Speech Segmentation with Transformers","summary":"  Self-attention mechanisms have enabled transformers to achieve\nsuperhuman-level performance on many speech-to-text (STT) tasks, yet the\nchallenge of automatic prosodic segmentation has remained unsolved. In this\npaper we finetune Whisper, a pretrained STT model, to annotate intonation unit\n(IU) boundaries by repurposing low-frequency tokens. Our approach achieves an\naccuracy of 95.8%, outperforming previous methods without the need for\nlarge-scale labeled data or enterprise grade compute resources. We also\ndiminish input signals by applying a series of filters, finding that low pass\nfilters at a 3.2 kHz level improve segmentation performance in out of sample\nand out of distribution contexts. We release our model as both a transcription\ntool and a baseline for further improvements in prosodic segmentation.\n","authors":["Nathan Roll","Calbert Graham","Simon Todd"],"pdf_url":"https://arxiv.org/pdf/2302.01984v1.pdf","comment":"5 pages, 3 figures. For associated repository, see\n  https://github.com/Nathan-Roll1/psst"},{"id":"http://arxiv.org/abs/2301.12564v2","updated":"2023-02-03T19:48:52Z","published":"2023-01-29T22:29:55Z","title":"A Discerning Several Thousand Judgments: GPT-3 Rates the Article +\n  Adjective + Numeral + Noun Construction","summary":"  Knowledge of syntax includes knowledge of rare, idiosyncratic constructions.\nLLMs must overcome frequency biases in order to master such constructions. In\nthis study, I prompt GPT-3 to give acceptability judgments on the\nEnglish-language Article + Adjective + Numeral + Noun construction (e.g., \"a\nlovely five days\"). I validate the prompt using the CoLA corpus of\nacceptability judgments and then zero in on the AANN construction. I compare\nGPT- 3's judgments to crowdsourced human judgments on a subset of sentences.\nGPT-3's judgments are broadly similar to human judgments and generally align\nwith proposed constraints in the literature but, in some cases, GPT-3's\njudgments and human judgments diverge from the literature and from each other.\n","authors":["Kyle Mahowald"],"pdf_url":"https://arxiv.org/pdf/2301.12564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01973v1","updated":"2023-02-03T19:47:22Z","published":"2023-02-03T19:47:22Z","title":"Measuring The Impact Of Programming Language Distribution","summary":"  Current benchmarks for evaluating neural code models focus on only a small\nsubset of programming languages, excluding many popular languages such as Go or\nRust. To ameliorate this issue, we present the BabelCode framework for\nexecution-based evaluation of any benchmark in any language. BabelCode enables\nnew investigations into the qualitative performance of models' memory, runtime,\nand individual test case results. Additionally, we present a new code\ntranslation dataset called Translating Python Programming Puzzles (TP3) from\nthe Python Programming Puzzles (Schuster et al. 2021) benchmark that involves\ntranslating expert-level python functions to any language. With both BabelCode\nand the TP3 benchmark, we investigate if balancing the distributions of 14\nlanguages in a training dataset improves a large language model's performance\non low-resource languages. Training a model on a balanced corpus results in, on\naverage, 12.34% higher $pass@k$ across all tasks and languages compared to the\nbaseline. We find that this strategy achieves 66.48% better $pass@k$ on\nlow-resource languages at the cost of only a 12.94% decrease to high-resource\nlanguages. In our three translation tasks, this strategy yields, on average,\n30.77% better low-resource $pass@k$ while having 19.58% worse high-resource\n$pass@k$.\n","authors":["Gabriel Orlanski","Kefan Xiao","Xavier Garcia","Jeffrey Hui","Joshua Howland","Jonathan Malmaud","Jacob Austin","Rishah Singh","Michele Catasta"],"pdf_url":"https://arxiv.org/pdf/2302.01973v1.pdf","comment":"Code and data release: https://github.com/google-research/babelcode"},{"id":"http://arxiv.org/abs/2212.01944v2","updated":"2023-02-03T19:27:35Z","published":"2022-12-04T22:34:16Z","title":"Learning Automata-Based Task Knowledge Representation from Large-Scale\n  Generative Language Models","summary":"  Automata-based representations play an important role in control and planning\nin sequential decision-making, but obtaining high-level task knowledge for\nbuilding automata is often difficult. Although large-scale generative language\nmodels (GLMs) can help automatically distill task knowledge, the textual\noutputs from GLMs are not amenable for formal verification or use in sequential\ndecision-making. We propose a novel algorithm named GLM2FSA, which obtains\nhigh-level task knowledge represented in a finite state automaton (FSA) from a\ngiven brief description of the task goal. GLM2FSA sends queries to a GLM for\ntask knowledge in textual form and then builds an FSA to represent the textual\nknowledge. It fills the gap between text and automata-based representations,\nand the constructed FSA can be directly utilized in formal verification. We\nprovide an algorithm for iteratively refining the queries to the GLM based on\nthe outcomes, e.g., counter-examples, from verification. We demonstrate the\nalgorithm on examples that range from everyday tasks, e.g., crossing a road and\nmaking coffee, to security applications to laboratory safety protocols.\n","authors":["Yunhao Yang","Jean-Raphaël Gaglione","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2212.01944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02801v1","updated":"2023-02-03T15:14:04Z","published":"2023-02-03T15:14:04Z","title":"LaMPP: Language Models as Probabilistic Priors for Perception and Action","summary":"  Language models trained on large text corpora encode rich distributional\ninformation about real-world environments and action sequences. This\ninformation plays a crucial role in current approaches to language processing\ntasks like question answering and instruction generation. We describe how to\nleverage language models for *non-linguistic* perception and control tasks. Our\napproach casts labeling and decision-making as inference in probabilistic\ngraphical models in which language models parameterize prior distributions over\nlabels, decisions and parameters, making it possible to integrate uncertain\nobservations and incomplete background knowledge in a principled way. Applied\nto semantic segmentation, household navigation, and activity recognition tasks,\nthis approach improves predictions on rare, out-of-distribution, and\nstructurally novel inputs.\n","authors":["Belinda Z. Li","William Chen","Pratyusha Sharma","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2302.02801v1.pdf","comment":"12 pages, 4 tables, 4 figures"},{"id":"http://arxiv.org/abs/2302.01935v1","updated":"2023-02-03T14:31:17Z","published":"2023-02-03T14:31:17Z","title":"CAB: Empathetic Dialogue Generation with Cognition, Affection and\n  Behavior","summary":"  Empathy is an important characteristic to be considered when building a more\nintelligent and humanized dialogue agent. However, existing methods did not\nfully comprehend empathy as a complex process involving three aspects:\ncognition, affection and behavior. In this paper, we propose CAB, a novel\nframework that takes a comprehensive perspective of cognition, affection and\nbehavior to generate empathetic responses. For cognition, we build paths\nbetween critical keywords in the dialogue by leveraging external knowledge.\nThis is because keywords in a dialogue are the core of sentences. Building the\nlogic relationship between keywords, which is overlooked by the majority of\nexisting works, can improve the understanding of keywords and contextual logic,\nthus enhance the cognitive ability. For affection, we capture the emotional\ndependencies with dual latent variables that contain both interlocutors'\nemotions. The reason is that considering both interlocutors' emotions\nsimultaneously helps to learn the emotional dependencies. For behavior, we use\nappropriate dialogue acts to guide the dialogue generation to enhance the\nempathy expression. Extensive experiments demonstrate that our\nmulti-perspective model outperforms the state-of-the-art models in both\nautomatic and manual evaluation.\n","authors":["Pan Gao","Donghong Han","Rui Zhou","Xuejiao Zhang","Zikun Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01935v1.pdf","comment":"accepted as a short paper at DASFAA 2023"},{"id":"http://arxiv.org/abs/2302.02759v1","updated":"2023-02-03T06:22:18Z","published":"2023-02-03T06:22:18Z","title":"Detecting Reddit Users with Depression Using a Hybrid Neural Network","summary":"  Depression is a widespread mental health issue, affecting an estimated 3.8%\nof the global population. It is also one of the main contributors to disability\nworldwide. Recently it is becoming popular for individuals to use social media\nplatforms (e.g., Reddit) to express their difficulties and health issues (e.g.,\ndepression) and seek support from other users in online communities. It opens\ngreat opportunities to automatically identify social media users with\ndepression by parsing millions of posts for potential interventions. Deep\nlearning methods have begun to dominate in the field of machine learning and\nnatural language processing (NLP) because of their ease of use, efficient\nprocessing, and state-of-the-art results on many NLP tasks. In this work, we\npropose a hybrid deep learning model which combines a pretrained sentence BERT\n(SBERT) and convolutional neural network (CNN) to detect individuals with\ndepression with their Reddit posts. The sentence BERT is used to learn the\nmeaningful representation of semantic information in each post. CNN enables the\nfurther transformation of those embeddings and the temporal identification of\nbehavioral patterns of users. We trained and evaluated the model performance to\nidentify Reddit users with depression by utilizing the Self-reported Mental\nHealth Diagnoses (SMHD) data. The hybrid deep learning model achieved an\naccuracy of 0.86 and an F1 score of 0.86 and outperformed the state-of-the-art\ndocumented result (F1 score of 0.79) by other machine learning models in the\nliterature. The results show the feasibility of the hybrid model to identify\nindividuals with depression. Although the hybrid model is validated to detect\ndepression with Reddit posts, it can be easily tuned and applied to other text\nclassification tasks and different clinical applications.\n","authors":["Ziyi Chen","Ren Yang","Sunyang Fu","Nansu Zong","Hongfang Liu","Ming Huang"],"pdf_url":"https://arxiv.org/pdf/2302.02759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03036v1","updated":"2023-02-03T21:51:55Z","published":"2023-02-03T21:51:55Z","title":"Witscript 2: A System for Generating Improvised Jokes Without Wordplay","summary":"  A previous paper presented Witscript, a system for generating conversational\njokes that rely on wordplay. This paper extends that work by presenting\nWitscript 2, which uses a large language model to generate conversational jokes\nthat rely on common sense instead of wordplay. Like Witscript, Witscript 2 is\nbased on joke-writing algorithms created by an expert comedy writer. Human\nevaluators judged Witscript 2's responses to input sentences to be jokes 46% of\nthe time, compared to 70% of the time for human-written responses. This is\nevidence that Witscript 2 represents another step toward giving a chatbot a\nhumanlike sense of humor.\n","authors":["Joe Toplyn"],"pdf_url":"https://arxiv.org/pdf/2302.03036v1.pdf","comment":"5 pages. Published in the Proceedings of the 13th International\n  Conference on Computational Creativity (ICCC 2022), pages 54-58. arXiv admin\n  note: text overlap with arXiv:2301.02695. substantial text overlap with\n  arXiv:2302.02008"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2301.00812v2","updated":"2023-02-03T18:24:56Z","published":"2022-12-16T01:04:52Z","title":"One-shot domain adaptation in video-based assessment of surgical skills","summary":"  Deep Learning (DL) has achieved automatic and objective assessment of\nsurgical skills. However, DL models are data-hungry and restricted to their\ntraining domain. This prevents them from transitioning to new tasks where data\nis limited. Hence, domain adaptation is crucial to implement DL in real life.\nHere, we propose a meta-learning model, A-VBANet, that can deliver\ndomain-agnostic surgical skill classification via one-shot learning. We develop\nthe A-VBANet on five laparoscopic and robotic surgical simulators.\nAdditionally, we test it on operating room (OR) videos of laparoscopic\ncholecystectomy. Our model successfully adapts with accuracies up to 99.5% in\none-shot and 99.9% in few-shot settings for simulated tasks and 89.7% for\nlaparoscopic cholecystectomy. For the first time, we provide a domain-agnostic\nprocedure for video-based assessment of surgical skills. A significant\nimplication of this approach is that it allows the use of data from surgical\nsimulators to assess performance in the operating room.\n","authors":["Erim Yanik","Steven Schwaitzberg","Gene Yang","Xavier Intes","Suvranu De"],"pdf_url":"https://arxiv.org/pdf/2301.00812v2.pdf","comment":"12 pages (+9 pages of Supplementary Materials), 4 figures (+2\n  Supplementary Figures), 2 tables (+5 Supplementary Tables)"},{"id":"http://arxiv.org/abs/2302.01891v1","updated":"2023-02-03T18:05:49Z","published":"2023-02-03T18:05:49Z","title":"Egocentric Video Task Translation @ Ego4D Challenge 2022","summary":"  This technical report describes the EgoTask Translation approach that\nexplores relations among a set of egocentric video tasks in the Ego4D\nchallenge. To improve the primary task of interest, we propose to leverage\nexisting models developed for other related tasks and design a task translator\nthat learns to ''translate'' auxiliary task features to the primary task. With\nno modification to the baseline architectures, our proposed approach achieves\ncompetitive performance on two Ego4D challenges, ranking the 1st in the talking\nto me challenge and the 3rd in the PNR keyframe localization challenge.\n","authors":["Zihui Xue","Yale Song","Kristen Grauman","Lorenzo Torresani"],"pdf_url":"https://arxiv.org/pdf/2302.01891v1.pdf","comment":"The technical report of ECCV@2022 Ego4D challenge"},{"id":"http://arxiv.org/abs/2302.00995v2","updated":"2023-02-03T17:58:57Z","published":"2023-02-02T10:29:23Z","title":"Open-Set Multi-Source Multi-Target Domain Adaptation","summary":"  Single-Source Single-Target Domain Adaptation (1S1T) aims to bridge the gap\nbetween a labelled source domain and an unlabelled target domain. Despite 1S1T\nbeing a well-researched topic, they are typically not deployed to the real\nworld. Methods like Multi-Source Domain Adaptation and Multi-Target Domain\nAdaptation have evolved to model real-world problems but still do not\ngeneralise well. The fact that most of these methods assume a common label-set\nbetween source and target is very restrictive. Recent Open-Set Domain\nAdaptation methods handle unknown target labels but fail to generalise in\nmultiple domains. To overcome these difficulties, first, we propose a novel\ngeneric domain adaptation (DA) setting named Open-Set Multi-Source Multi-Target\nDomain Adaptation (OS-nSmT), with n and m being number of source and target\ndomains respectively. Next, we propose a graph attention based framework named\nDEGAA which can capture information from multiple source and target domains\nwithout knowing the exact label-set of the target. We argue that our method,\nthough offered for multiple sources and multiple targets, can also be agnostic\nto various other DA settings. To check the robustness and versatility of DEGAA,\nwe put forward ample experiments and ablation studies.\n","authors":["Rohit Lal","Arihant Gaur","Aadhithya Iyer","Muhammed Abdullah Shaikh","Ritik Agrawal"],"pdf_url":"https://arxiv.org/pdf/2302.00995v2.pdf","comment":"Accepted in NeurIPS 2021 Workshop on Pre-registration in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2302.01888v1","updated":"2023-02-03T17:53:40Z","published":"2023-02-03T17:53:40Z","title":"Enhancing Once-For-All: A Study on Parallel Blocks, Skip Connections and\n  Early Exits","summary":"  The use of Neural Architecture Search (NAS) techniques to automate the design\nof neural networks has become increasingly popular in recent years. The\nproliferation of devices with different hardware characteristics using such\nneural networks, as well as the need to reduce the power consumption for their\nsearch, has led to the realisation of Once-For-All (OFA), an eco-friendly\nalgorithm characterised by the ability to generate easily adaptable models\nthrough a single learning process. In order to improve this paradigm and\ndevelop high-performance yet eco-friendly NAS techniques, this paper presents\nOFAv2, the extension of OFA aimed at improving its performance while\nmaintaining the same ecological advantage. The algorithm is improved from an\narchitectural point of view by including early exits, parallel blocks and dense\nskip connections. The training process is extended by two new phases called\nElastic Level and Elastic Height. A new Knowledge Distillation technique is\npresented to handle multi-output networks, and finally a new strategy for\ndynamic teacher network selection is proposed. These modifications allow OFAv2\nto improve its accuracy performance on the Tiny ImageNet dataset by up to\n12.07% compared to the original version of OFA, while maintaining the algorithm\nflexibility and advantages.\n","authors":["Simone Sarti","Eugenio Lomurno","Andrea Falanti","Matteo Matteucci"],"pdf_url":"https://arxiv.org/pdf/2302.01888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01881v1","updated":"2023-02-03T17:32:22Z","published":"2023-02-03T17:32:22Z","title":"IKEA-Manual: Seeing Shape Assembly Step by Step","summary":"  Human-designed visual manuals are crucial components in shape assembly\nactivities. They provide step-by-step guidance on how we should move and\nconnect different parts in a convenient and physically-realizable way. While\nthere has been an ongoing effort in building agents that perform assembly\ntasks, the information in human-design manuals has been largely overlooked. We\nidentify that this is due to 1) a lack of realistic 3D assembly objects that\nhave paired manuals and 2) the difficulty of extracting structured information\nfrom purely image-based manuals. Motivated by this observation, we present\nIKEA-Manual, a dataset consisting of 102 IKEA objects paired with assembly\nmanuals. We provide fine-grained annotations on the IKEA objects and assembly\nmanuals, including decomposed assembly parts, assembly plans, manual\nsegmentation, and 2D-3D correspondence between 3D parts and visual manuals. We\nillustrate the broad application of our dataset on four tasks related to shape\nassembly: assembly plan generation, part segmentation, pose estimation, and 3D\npart assembly.\n","authors":["Ruocheng Wang","Yunzhi Zhang","Jiayuan Mao","Ran Zhang","Chin-Yi Cheng","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2302.01881v1.pdf","comment":"NeurIPS 2022 Datasets and Benchmarks Track. Project page:\n  https://cs.stanford.edu/~rcwang/projects/ikea_manual"},{"id":"http://arxiv.org/abs/2302.01872v1","updated":"2023-02-03T17:20:03Z","published":"2023-02-03T17:20:03Z","title":"MOSE: A New Dataset for Video Object Segmentation in Complex Scenes","summary":"  Video object segmentation (VOS) aims at segmenting a particular object\nthroughout the entire video clip sequence. The state-of-the-art VOS methods\nhave achieved excellent performance (e.g., 90+% J&F) on existing datasets.\nHowever, since the target objects in these existing datasets are usually\nrelatively salient, dominant, and isolated, VOS under complex scenes has rarely\nbeen studied. To revisit VOS and make it more applicable in the real world, we\ncollect a new VOS dataset called coMplex video Object SEgmentation (MOSE) to\nstudy the tracking and segmenting objects in complex environments. MOSE\ncontains 2,149 video clips and 5,200 objects from 36 categories, with 431,725\nhigh-quality object segmentation masks. The most notable feature of MOSE\ndataset is complex scenes with crowded and occluded objects. The target objects\nin the videos are commonly occluded by others and disappear in some frames. To\nanalyze the proposed MOSE dataset, we benchmark 18 existing VOS methods under 4\ndifferent settings on the proposed MOSE dataset and conduct comprehensive\ncomparisons. The experiments show that current VOS algorithms cannot well\nperceive objects in complex scenes. For example, under the semi-supervised VOS\nsetting, the highest J&F by existing state-of-the-art VOS methods is only 59.4%\non MOSE, much lower than their ~90% J&F performance on DAVIS. The results\nreveal that although excellent performance has been achieved on existing\nbenchmarks, there are unresolved challenges under complex scenes and more\nefforts are desired to explore these challenges in the future. The proposed\nMOSE dataset has been released at https://henghuiding.github.io/MOSE.\n","authors":["Henghui Ding","Chang Liu","Shuting He","Xudong Jiang","Philip H. S. Torr","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2302.01872v1.pdf","comment":"MOSE Dataset Report"},{"id":"http://arxiv.org/abs/2208.06980v3","updated":"2023-02-03T17:18:22Z","published":"2022-08-15T02:47:33Z","title":"Faster Attention Is What You Need: A Fast Self-Attention Neural Network\n  Backbone Architecture for the Edge via Double-Condensing Attention Condensers","summary":"  With the growing adoption of deep learning for on-device TinyML applications,\nthere has been an ever-increasing demand for efficient neural network backbones\noptimized for the edge. Recently, the introduction of attention condenser\nnetworks have resulted in low-footprint, highly-efficient, self-attention\nneural networks that strike a strong balance between accuracy and speed. In\nthis study, we introduce a faster attention condenser design called\ndouble-condensing attention condensers that allow for highly condensed feature\nembeddings. We further employ a machine-driven design exploration strategy that\nimposes design constraints based on best practices for greater efficiency and\nrobustness to produce the macro-micro architecture constructs of the backbone.\nThe resulting backbone (which we name AttendNeXt) achieves significantly higher\ninference throughput on an embedded ARM processor when compared to several\nother state-of-the-art efficient backbones (>10x faster than FB-Net C at higher\naccuracy and speed and >10x faster than MobileOne-S1 at smaller size) while\nhaving a small model size (>1.37x smaller than MobileNetv3-L at higher accuracy\nand speed) and strong accuracy (1.1% higher top-1 accuracy than MobileViT XS on\nImageNet at higher speed). These promising results demonstrate that exploring\ndifferent efficient architecture designs and self-attention mechanisms can lead\nto interesting new building blocks for TinyML applications.\n","authors":["Alexander Wong","Mohammad Javad Shafiee","Saad Abbasi","Saeejith Nair","Mahmoud Famouri"],"pdf_url":"https://arxiv.org/pdf/2208.06980v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01843v1","updated":"2023-02-03T16:37:38Z","published":"2023-02-03T16:37:38Z","title":"MorDIFF: Recognition Vulnerability and Attack Detectability of Face\n  Morphing Attacks Created by Diffusion Autoencoders","summary":"  Investigating new methods of creating face morphing attacks is essential to\nforesee novel attacks and help mitigate them. Creating morphing attacks is\ncommonly either performed on the image-level or on the representation-level.\nThe representation-level morphing has been performed so far based on generative\nadversarial networks (GAN) where the encoded images are interpolated in the\nlatent space to produce a morphed image based on the interpolated vector. Such\na process was constrained by the limited reconstruction fidelity of GAN\narchitectures. Recent advances in the diffusion autoencoder models have\novercome the GAN limitations, leading to high reconstruction fidelity. This\ntheoretically makes them a perfect candidate to perform representation-level\nface morphing. This work investigates using diffusion autoencoders to create\nface morphing attacks by comparing them to a wide range of image-level and\nrepresentation-level morphs. Our vulnerability analyses on four\nstate-of-the-art face recognition models have shown that such models are highly\nvulnerable to the created attacks, the MorDIFF, especially when compared to\nexisting representation-level morphs. Detailed detectability analyses are also\nperformed on the MorDIFF, showing that they are as challenging to detect as\nother morphing attacks created on the image- or representation-level. Data and\nmorphing script are made public.\n","authors":["Naser Damer","Meiling Fang","Patrick Siebke","Jan Niklas Kolf","Marco Huber","Fadi Boutros"],"pdf_url":"https://arxiv.org/pdf/2302.01843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01838v1","updated":"2023-02-03T16:27:34Z","published":"2023-02-03T16:27:34Z","title":"vMAP: Vectorised Object Mapping for Neural Field SLAM","summary":"  We present vMAP, an object-level dense SLAM system using neural field\nrepresentations. Each object is represented by a small MLP, enabling efficient,\nwatertight object modelling without the need for 3D priors.\n  As an RGB-D camera browses a scene with no prior information, vMAP detects\nobject instances on-the-fly, and dynamically adds them to its map.\nSpecifically, thanks to the power of vectorised training, vMAP can optimise as\nmany as 50 individual objects in a single scene, with an extremely efficient\ntraining speed of 5Hz map update. We experimentally demonstrate significantly\nimproved scene-level and object-level reconstruction quality compared to prior\nneural field SLAM systems.\n","authors":["Xin Kong","Shikun Liu","Marwan Taher","Andrew J. Davison"],"pdf_url":"https://arxiv.org/pdf/2302.01838v1.pdf","comment":"Project Page:https://kxhit.github.io/vMAP"},{"id":"http://arxiv.org/abs/2302.01825v1","updated":"2023-02-03T16:00:48Z","published":"2023-02-03T16:00:48Z","title":"HDFormer: High-order Directed Transformer for 3D Human Pose Estimation","summary":"  Human pose estimation is a complicated structured data sequence modeling\ntask. Most existing methods only consider the pair-wise interaction of human\nbody joints in model learning. Unfortunately, this causes 3D pose estimation to\nfail in difficult cases such as $\\textit{joints overlapping}$, and pose\n$\\textit{fast-changing}$, as pair-wise relations cannot exploit fine-grained\nhuman body priors in pose estimation. To this end, we revamped the 3D pose\nestimation framework with a $\\textit{High-order}$ $\\textit{Directed}$\n$\\textit{Transformer}$ (HDFormer), which coherently exploits the high-order\nbones and joints relevances to boost the performance of pose estimation.\nSpecifically, HDFormer adopts both self-attention and high-order attention\nschemes to build up a multi-order attention module to perform the information\nflow interaction including the first-order\n$\"\\textit{joint$\\leftrightarrow$joint}\"$, second-order\n$\"\\textit{bone$\\leftrightarrow$joint}\"$ as well as high-order\n$\"\\textit{hyperbone$\\leftrightarrow$joint}\"$ relationships (hyperbone is\ndefined as a joint set), compensating the hard cases prediction in\nfast-changing and heavy occlusion scenarios. Moreover, modernized CNN\ntechniques are applied to upgrade the transformer-based architecture to speed\nup the HDFormer, achieving a favorable trade-off between effectiveness and\nefficiency. We compare our model with other SOTA models on the datasets\nHuman3.6M and MPI-INF-3DHP. The results demonstrate that the proposed HDFormer\nachieves superior performance with only $\\textbf{1/10}$ parameters and much\nlower computational cost compared to the current SOTAs. Moreover, HDFormer can\nbe applied to various types of real-world applications, enabling real-time and\naccurate 3D pose estimation. The source code is in\nhttps://github.com/hyer/HDFormer.\n","authors":["Hanyuan Chen","Jun-Yan He","Wangmeng Xiang","Wei Liu","Zhi-Qi Cheng","Hanbing Liu","Bin Luo","Yifeng Geng","Xuansong Xie"],"pdf_url":"https://arxiv.org/pdf/2302.01825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01813v1","updated":"2023-02-03T15:35:54Z","published":"2023-02-03T15:35:54Z","title":"Leveraging weak complementary labels to improve semantic segmentation of\n  hepatocellular carcinoma and cholangiocarcinoma in H&E-stained slides","summary":"  In this paper, we present a deep learning segmentation approach to classify\nand quantify the two most prevalent primary liver cancers - hepatocellular\ncarcinoma and intrahepatic cholangiocarcinoma - from hematoxylin and eosin\n(H&E) stained whole slide images. While semantic segmentation of medical images\ntypically requires costly pixel-level annotations by domain experts, there\noften exists additional information which is routinely obtained in clinical\ndiagnostics but rarely utilized for model training. We propose to leverage such\nweak information from patient diagnoses by deriving complementary labels that\nindicate to which class a sample cannot belong to. To integrate these labels,\nwe formulate a complementary loss for segmentation. Motivated by the medical\napplication, we demonstrate for general segmentation tasks that including\nadditional patches with solely weak complementary labels during model training\ncan significantly improve the predictive performance and robustness of a model.\nOn the task of diagnostic differentiation between hepatocellular carcinoma and\nintrahepatic cholangiocarcinoma, we achieve a balanced accuracy of 0.91 (CI\n95%: 0.86 - 0.95) at case level for 165 hold-out patients. Furthermore, we also\nshow that leveraging complementary labels improves the robustness of\nsegmentation and increases performance at case level.\n","authors":["Miriam Hägele","Johannes Eschrich","Lukas Ruff","Maximilian Alber","Simon Schallenberg","Adrien Guillot","Christoph Roderburg","Frank Tacke","Frederick Klauschen"],"pdf_url":"https://arxiv.org/pdf/2302.01813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01427v4","updated":"2023-02-03T15:35:33Z","published":"2022-10-04T07:35:01Z","title":"Accurate Image Restoration with Attention Retractable Transformer","summary":"  Recently, Transformer-based image restoration networks have achieved\npromising improvements over convolutional neural networks due to\nparameter-independent global interactions. To lower computational cost,\nexisting works generally limit self-attention computation within\nnon-overlapping windows. However, each group of tokens are always from a dense\narea of the image. This is considered as a dense attention strategy since the\ninteractions of tokens are restrained in dense regions. Obviously, this\nstrategy could result in restricted receptive fields. To address this issue, we\npropose Attention Retractable Transformer (ART) for image restoration, which\npresents both dense and sparse attention modules in the network. The sparse\nattention module allows tokens from sparse areas to interact and thus provides\na wider receptive field. Furthermore, the alternating application of dense and\nsparse attention modules greatly enhances representation ability of Transformer\nwhile providing retractable attention on the input image.We conduct extensive\nexperiments on image super-resolution, denoising, and JPEG compression artifact\nreduction tasks. Experimental results validate that our proposed ART\noutperforms state-of-the-art methods on various benchmark datasets both\nquantitatively and visually. We also provide code and models at\nhttps://github.com/gladzhang/ART.\n","authors":["Jiale Zhang","Yulun Zhang","Jinjin Gu","Yongbing Zhang","Linghe Kong","Xin Yuan"],"pdf_url":"https://arxiv.org/pdf/2210.01427v4.pdf","comment":"Accepted to ICLR 2023. Code and models are available at\n  https://github.com/gladzhang/ART"},{"id":"http://arxiv.org/abs/2302.01793v1","updated":"2023-02-03T15:03:07Z","published":"2023-02-03T15:03:07Z","title":"Self-Supervised In-Domain Representation Learning for Remote Sensing\n  Image Scene Classification","summary":"  Transferring the ImageNet pre-trained weights to the various remote sensing\ntasks has produced acceptable results and reduced the need for labeled samples.\nHowever, the domain differences between ground imageries and remote sensing\nimages cause the performance of such transfer learning to be limited. Recent\nresearch has demonstrated that self-supervised learning methods capture visual\nfeatures that are more discriminative and transferable than the supervised\nImageNet weights. We are motivated by these facts to pre-train the in-domain\nrepresentations of remote sensing imagery using contrastive self-supervised\nlearning and transfer the learned features to other related remote sensing\ndatasets. Specifically, we used the SimSiam algorithm to pre-train the\nin-domain knowledge of remote sensing datasets and then transferred the\nobtained weights to the other scene classification datasets. Thus, we have\nobtained state-of-the-art results on five land cover classification datasets\nwith varying numbers of classes and spatial resolutions. In addition, By\nconducting appropriate experiments, including feature pre-training using\ndatasets with different attributes, we have identified the most influential\nfactors that make a dataset a good choice for obtaining in-domain features. We\nhave transferred the features obtained by pre-training SimSiam on remote\nsensing datasets to various downstream tasks and used them as initial weights\nfor fine-tuning. Moreover, we have linearly evaluated the obtained\nrepresentations in cases where the number of samples per class is limited. Our\nexperiments have demonstrated that using a higher-resolution dataset during the\nself-supervised pre-training stage results in learning more discriminative and\ngeneral representations.\n","authors":["Ali Ghanbarzade","Hossein Soleimani"],"pdf_url":"https://arxiv.org/pdf/2302.01793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01791v1","updated":"2023-02-03T14:59:31Z","published":"2023-02-03T14:59:31Z","title":"DilateFormer: Multi-Scale Dilated Transformer for Visual Recognition","summary":"  As a de facto solution, the vanilla Vision Transformers (ViTs) are encouraged\nto model long-range dependencies between arbitrary image patches while the\nglobal attended receptive field leads to quadratic computational cost. Another\nbranch of Vision Transformers exploits local attention inspired by CNNs, which\nonly models the interactions between patches in small neighborhoods. Although\nsuch a solution reduces the computational cost, it naturally suffers from small\nattended receptive fields, which may limit the performance. In this work, we\nexplore effective Vision Transformers to pursue a preferable trade-off between\nthe computational complexity and size of the attended receptive field. By\nanalyzing the patch interaction of global attention in ViTs, we observe two key\nproperties in the shallow layers, namely locality and sparsity, indicating the\nredundancy of global dependency modeling in shallow layers of ViTs.\nAccordingly, we propose Multi-Scale Dilated Attention (MSDA) to model local and\nsparse patch interaction within the sliding window. With a pyramid\narchitecture, we construct a Multi-Scale Dilated Transformer (DilateFormer) by\nstacking MSDA blocks at low-level stages and global multi-head self-attention\nblocks at high-level stages. Our experiment results show that our DilateFormer\nachieves state-of-the-art performance on various vision tasks. On ImageNet-1K\nclassification task, DilateFormer achieves comparable performance with 70%\nfewer FLOPs compared with existing state-of-the-art models. Our\nDilateFormer-Base achieves 85.6% top-1 accuracy on ImageNet-1K classification\ntask, 53.5% box mAP/46.1% mask mAP on COCO object detection/instance\nsegmentation task and 51.1% MS mIoU on ADE20K semantic segmentation task.\n","authors":["Jiayu Jiao","Yu-Ming Tang","Kun-Yu Lin","Yipeng Gao","Jinhua Ma","Yaowei Wang","Wei-Shi Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.01791v1.pdf","comment":"Accepted to IEEE Transaction on Multimedia, 2023 (Submission date:\n  22-Sep-2022)"},{"id":"http://arxiv.org/abs/2302.01790v1","updated":"2023-02-03T14:57:40Z","published":"2023-02-03T14:57:40Z","title":"Understanding metric-related pitfalls in image analysis validation","summary":"  Validation metrics are key for the reliable tracking of scientific progress\nand for bridging the current chasm between artificial intelligence (AI)\nresearch and its translation into practice. However, increasing evidence shows\nthat particularly in image analysis, metrics are often chosen inadequately in\nrelation to the underlying research problem. This could be attributed to a lack\nof accessibility of metric-related knowledge: While taking into account the\nindividual strengths, weaknesses, and limitations of validation metrics is a\ncritical prerequisite to making educated choices, the relevant knowledge is\ncurrently scattered and poorly accessible to individual researchers. Based on a\nmulti-stage Delphi process conducted by a multidisciplinary expert consortium\nas well as extensive community feedback, the present work provides the first\nreliable and comprehensive common point of access to information on pitfalls\nrelated to validation metrics in image analysis. Focusing on biomedical image\nanalysis but with the potential of transfer to other fields, the addressed\npitfalls generalize across application domains and are categorized according to\na newly created, domain-agnostic taxonomy. To facilitate comprehension,\nillustrations and specific examples accompany each pitfall. As a structured\nbody of information accessible to researchers of all levels of expertise, this\nwork enhances global comprehension of a key topic in image analysis validation.\n","authors":["Annika Reinke","Minu D. Tizabi","Michael Baumgartner","Matthias Eisenmann","Doreen Heckmann-Nötzel","A. Emre Kavu","Tim Rädsch","Carole H. Sudre","Laura Acion","Michela Antonelli","Tal Arbel","Spyridon Bakas","Arriel Benis","Matthew Blaschko","Florian Büttner","M. Jorge Cardoso","Veronika Cheplygina","Jianxu Chen","Evangelia Christodoulou","Beth A. Cimini","Gary S. Collins","Keyvan Farahani","Luciana Ferrer","Adrian Galdran","Bram van Ginneken","Ben Glocker","Patrick Godau","Robert Haase","Daniel A. Hashimoto","Michael M. Hoffman","Merel Huisman","Fabian Isensee","Pierre Jannin","Charles E. Kahn","Dagmar Kainmueller","Bernhard Kainz","Alexandros Karargyris","Alan Karthikesalingam","Hannes Kenngott","Jens Kleesiek","Florian Kofler","Thijs Kooi","Annette Kopp-Schneider","Michal Kozubek","Anna Kreshuk","Tahsin Kurc","Bennett A. Landman","Geert Litjens","Amin Madani","Klaus Maier-Hein","Anne L. Martel","Peter Mattson","Erik Meijering","Bjoern Menze","Karel G. M. Moons","Henning Müller","Brennan Nichyporuk","Felix Nickel","Jens Petersen","Susanne M. Rafelski","Nasir Rajpoot","Mauricio Reyes","Michael A. Riegler","Nicola Rieke","Julio Saez-Rodriguez","Clara I. Sánchez","Shravya Shetty","Maarten van Smeden","Ronald M. Summers","Abdel A. Taha","Aleksei Tiulpin","Sotirios A. Tsaftaris","Ben Van Calster","Gaël Varoquaux","Manuel Wiesenfarth","Ziv R. Yaniv","Paul F. Jäger","Lena Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2302.01790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01788v1","updated":"2023-02-03T14:56:10Z","published":"2023-02-03T14:56:10Z","title":"IMPORTANT-Net: Integrated MRI Multi-Parameter Reinforcement Fusion\n  Generator with Attention Network for Synthesizing Absent Data","summary":"  Magnetic resonance imaging (MRI) is highly sensitive for lesion detection in\nthe breasts. Sequences obtained with different settings can capture the\nspecific characteristics of lesions. Such multi-parameter MRI information has\nbeen shown to improve radiologist performance in lesion classification, as well\nas improving the performance of artificial intelligence models in various\ntasks. However, obtaining multi-parameter MRI makes the examination costly in\nboth financial and time perspectives, and there may be safety concerns for\nspecial populations, thus making acquisition of the full spectrum of MRI\nsequences less durable. In this study, different than naive input fusion or\nfeature concatenation from existing MRI parameters, a novel\n$\\textbf{I}$ntegrated MRI $\\textbf{M}$ulti-$\\textbf{P}$arameter\nreinf$\\textbf{O}$rcement fusion generato$\\textbf{R}$ wi$\\textbf{T}$h\n$\\textbf{A}$tte$\\textbf{NT}$ion Network (IMPORTANT-Net) is developed to\ngenerate missing parameters. First, the parameter reconstruction module is used\nto encode and restore the existing MRI parameters to obtain the corresponding\nlatent representation information at any scale level. Then the multi-parameter\nfusion with attention module enables the interaction of the encoded information\nfrom different parameters through a set of algorithmic strategies, and applies\ndifferent weights to the information through the attention mechanism after\ninformation fusion to obtain refined representation information. Finally, a\nreinforcement fusion scheme embedded in a $V^{-}$-shape generation module is\nused to combine the hierarchical representations to generate the missing MRI\nparameter. Results showed that our IMPORTANT-Net is capable of generating\nmissing MRI parameters and outperforms comparable state-of-the-art networks.\nOur code is available at\nhttps://github.com/Netherlands-Cancer-Institute/MRI_IMPORTANT_NET.\n","authors":["Tianyu Zhang","Tao Tan","Luyi Han","Xin Wang","Yuan Gao","Jonas Teuwen","Regina Beets-Tan","Ritse Mann"],"pdf_url":"https://arxiv.org/pdf/2302.01788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10051v2","updated":"2023-02-03T14:05:02Z","published":"2023-01-24T14:50:40Z","title":"Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism","summary":"  The loss function for bounding box regression (BBR) is essential to object\ndetection. Its good definition will bring significant performance improvement\nto the model. Most existing works assume that the examples in the training data\nare high-quality and focus on strengthening the fitting ability of BBR loss. If\nwe blindly strengthen BBR on low-quality examples, it will jeopardize\nlocalization performance. Focal-EIoU v1 was proposed to solve this problem, but\ndue to its static focusing mechanism (FM), the potential of non-monotonic FM\nwas not fully exploited. Based on this idea, we propose an IoU-based loss with\na dynamic non-monotonic FM named Wise-IoU (WIoU). The dynamic non-monotonic FM\nuses the outlier degree instead of IoU to evaluate the quality of anchor boxes\nand provides a wise gradient gain allocation strategy. This strategy reduces\nthe competitiveness of high-quality anchor boxes while also reducing the\nharmful gradient generated by low-quality examples. This allows WIoU to focus\non ordinary-quality anchor boxes and improve the detector's overall\nperformance. When WIoU is applied to the state-of-the-art real-time detector\nYOLOv7, the AP-75 on the MS-COCO dataset is improved from 53.03% to 54.50%.\nCode is available at https://github.com/Instinct323/wiou.\n","authors":["Zanjia Tong","Yuhang Chen","Zewei Xu","Rong Yu"],"pdf_url":"https://arxiv.org/pdf/2301.10051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01740v1","updated":"2023-02-03T14:00:05Z","published":"2023-02-03T14:00:05Z","title":"A Systematic Evaluation of Backdoor Trigger Characteristics in Image\n  Classification","summary":"  Deep learning achieves outstanding results in many machine learning tasks.\nNevertheless, it is vulnerable to backdoor attacks that modify the training set\nto embed a secret functionality in the trained model. The modified training\nsamples have a secret property, i.e., a trigger. At inference time, the secret\nfunctionality is activated when the input contains the trigger, while the model\nfunctions correctly in other cases. While there are many known backdoor attacks\n(and defenses), deploying a stealthy attack is still far from trivial.\nSuccessfully creating backdoor triggers heavily depends on numerous parameters.\nUnfortunately, research has not yet determined which parameters contribute most\nto the attack performance.\n  This paper systematically analyzes the most relevant parameters for the\nbackdoor attacks, i.e., trigger size, position, color, and poisoning rate.\nUsing transfer learning, which is very common in computer vision, we evaluate\nthe attack on numerous state-of-the-art models (ResNet, VGG, AlexNet, and\nGoogLeNet) and datasets (MNIST, CIFAR10, and TinyImageNet). Our attacks cover\nthe majority of backdoor settings in research, providing concrete directions\nfor future works. Our code is publicly available to facilitate the\nreproducibility of our results.\n","authors":["Gorka Abad","Jing Xu","Stefanos Koffas","Behrad Tajalli","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2302.01740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.03043v2","updated":"2023-02-03T13:53:39Z","published":"2022-01-09T16:16:23Z","title":"Semantics-driven Attentive Few-shot Learning over Clean and Noisy\n  Samples","summary":"  Over the last couple of years few-shot learning (FSL) has attracted great\nattention towards minimizing the dependency on labeled training examples. An\ninherent difficulty in FSL is the handling of ambiguities resulting from having\ntoo few training samples per class. To tackle this fundamental challenge in\nFSL, we aim to train meta-learner models that can leverage prior semantic\nknowledge about novel classes to guide the classifier synthesis process. In\nparticular, we propose semantically-conditioned feature attention and sample\nattention mechanisms that estimate the importance of representation dimensions\nand training instances. We also study the problem of sample noise in FSL,\ntowards the utilization of meta-learners in more realistic and imperfect\nsettings. Our experimental results demonstrate the effectiveness of the\nproposed semantic FSL model with and without sample noise.\n","authors":["Orhun Buğra Baran","Ramazan Gökberk Cinbiş"],"pdf_url":"https://arxiv.org/pdf/2201.03043v2.pdf","comment":"25 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.01735v1","updated":"2023-02-03T13:50:25Z","published":"2023-02-03T13:50:25Z","title":"Rethinking Semi-Supervised Medical Image Segmentation: A\n  Variance-Reduction Perspective","summary":"  For medical image segmentation, contrastive learning is the dominant practice\nto improve the quality of visual representations by contrasting semantically\nsimilar and dissimilar pairs of samples. This is enabled by the observation\nthat without accessing ground truth label, negative examples with truly\ndissimilar anatomical features, if sampled, can significantly improve the\nperformance. In reality, however, these samples may come from similar\nanatomical features and the models may struggle to distinguish the minority\ntail-class samples, making the tail classes more prone to misclassification,\nboth of which typically lead to model collapse. In this paper, we propose ARCO,\na semi-supervised contrastive learning (CL) framework with stratified group\nsampling theory in medical image segmentation. In particular, we first propose\nbuilding ARCO through the concept of variance-reduced estimation, and show that\ncertain variance-reduction techniques are particularly beneficial in medical\nimage segmentation tasks with extremely limited labels. Furthermore, we\ntheoretically prove these sampling techniques are universal in variance\nreduction. Finally, we experimentally validate our approaches on three\nbenchmark datasets with different label settings, and our methods consistently\noutperform state-of-the-art semi- and fully-supervised methods. Additionally,\nwe augment the CL frameworks with these sampling techniques and demonstrate\nsignificant gains over previous methods. We believe our work is an important\nstep towards semi-supervised medical image segmentation by quantifying the\nlimitation of current self-supervision objectives for accomplishing medical\nimage analysis tasks.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Fenglin Liu","Xiaoran Zhang","Chen Feng","David A. Clifton","S Kevin Zhou","Lawrence Hamilton Staib","James S Duncan"],"pdf_url":"https://arxiv.org/pdf/2302.01735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01721v1","updated":"2023-02-03T13:18:45Z","published":"2023-02-03T13:18:45Z","title":"TEXTure: Text-Guided Texturing of 3D Shapes","summary":"  In this paper, we present TEXTure, a novel method for text-guided generation,\nediting, and transfer of textures for 3D shapes. Leveraging a pretrained\ndepth-to-image diffusion model, TEXTure applies an iterative scheme that paints\na 3D model from different viewpoints. Yet, while depth-to-image models can\ncreate plausible textures from a single viewpoint, the stochastic nature of the\ngeneration process can cause many inconsistencies when texturing an entire 3D\nobject. To tackle these problems, we dynamically define a trimap partitioning\nof the rendered image into three progression states, and present a novel\nelaborated diffusion sampling process that uses this trimap representation to\ngenerate seamless textures from different views. We then show that one can\ntransfer the generated texture maps to new 3D geometries without requiring\nexplicit surface-to-surface mapping, as well as extract semantic textures from\na set of images without requiring any explicit reconstruction. Finally, we show\nthat TEXTure can be used to not only generate new textures but also edit and\nrefine existing textures using either a text prompt or user-provided scribbles.\nWe demonstrate that our TEXTuring method excels at generating, transferring,\nand editing textures through extensive evaluation, and further close the gap\nbetween 2D image generation and 3D texturing.\n","authors":["Elad Richardson","Gal Metzer","Yuval Alaluf","Raja Giryes","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2302.01721v1.pdf","comment":"Project page available at\n  https://texturepaper.github.io/TEXTurePaper/"},{"id":"http://arxiv.org/abs/2302.01708v1","updated":"2023-02-03T13:06:14Z","published":"2023-02-03T13:06:14Z","title":"Crucial Semantic Classifier-based Adversarial Learning for Unsupervised\n  Domain Adaptation","summary":"  Unsupervised Domain Adaptation (UDA), which aims to explore the transferrable\nfeatures from a well-labeled source domain to a related unlabeled target\ndomain, has been widely progressed. Nevertheless, as one of the mainstream,\nexisting adversarial-based methods neglect to filter the irrelevant semantic\nknowledge, hindering adaptation performance improvement. Besides, they require\nan additional domain discriminator that strives extractor to generate confused\nrepresentations, but discrete designing may cause model collapse. To tackle the\nabove issues, we propose Crucial Semantic Classifier-based Adversarial Learning\n(CSCAL), which pays more attention to crucial semantic knowledge transferring\nand leverages the classifier to implicitly play the role of domain\ndiscriminator without extra network designing. Specifically, in\nintra-class-wise alignment, a Paired-Level Discrepancy (PLD) is designed to\ntransfer crucial semantic knowledge. Additionally, based on classifier\npredictions, a Nuclear Norm-based Discrepancy (NND) is formed that considers\ninter-class-wise information and improves the adaptation performance. Moreover,\nCSCAL can be effortlessly merged into different UDA methods as a regularizer\nand dramatically promote their performance.\n","authors":["Yumin Zhang","Yajun Gao","Hongliu Li","Ating Yin","Duzhen Zhang","Xiuyi Chen"],"pdf_url":"https://arxiv.org/pdf/2302.01708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07182v4","updated":"2023-02-03T12:45:47Z","published":"2022-10-13T17:03:36Z","title":"PDEBENCH: An Extensive Benchmark for Scientific Machine Learning","summary":"  Machine learning-based modeling of physical systems has experienced increased\ninterest in recent years. Despite some impressive progress, there is still a\nlack of benchmarks for Scientific ML that are easy to use but still challenging\nand representative of a wide range of problems. We introduce PDEBench, a\nbenchmark suite of time-dependent simulation tasks based on Partial\nDifferential Equations (PDEs). PDEBench comprises both code and data to\nbenchmark the performance of novel machine learning models against both\nclassical numerical simulations and machine learning baselines. Our proposed\nset of benchmark problems contribute the following unique features: (1) A much\nwider range of PDEs compared to existing benchmarks, ranging from relatively\ncommon examples to more realistic and difficult problems; (2) much larger\nready-to-use datasets compared to prior work, comprising multiple simulation\nruns across a larger number of initial and boundary conditions and PDE\nparameters; (3) more extensible source codes with user-friendly APIs for data\ngeneration and baseline results with popular machine learning models (FNO,\nU-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers to\nextend the benchmark freely for their own purposes using a standardized API and\nto compare the performance of new models to existing baseline methods. We also\npropose new evaluation metrics with the aim to provide a more holistic\nunderstanding of learning methods in the context of Scientific ML. With those\nmetrics we identify tasks which are challenging for recent ML methods and\npropose these tasks as future challenges for the community. The code is\navailable at https://github.com/pdebench/PDEBench.\n","authors":["Makoto Takamoto","Timothy Praditia","Raphael Leiteritz","Dan MacKinlay","Francesco Alesiani","Dirk Pflüger","Mathias Niepert"],"pdf_url":"https://arxiv.org/pdf/2210.07182v4.pdf","comment":"16 pages (main body) + 34 pages (supplemental material), accepted for\n  publication in NeurIPS 2022 Track Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2302.01676v1","updated":"2023-02-03T11:56:38Z","published":"2023-02-03T11:56:38Z","title":"Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction","summary":"  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n","authors":["Davide Costa","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2302.01676v1.pdf","comment":"Accepted paper at The ACM Web Conference 2023, April 30--May 04,\n  2023, Austin, Texas, USA"},{"id":"http://arxiv.org/abs/2302.01665v1","updated":"2023-02-03T11:37:20Z","published":"2023-02-03T11:37:20Z","title":"CVTNet: A Cross-View Transformer Network for Place Recognition Using\n  LiDAR Data","summary":"  LiDAR-based place recognition (LPR) is one of the most crucial components of\nautonomous vehicles to identify previously visited places in GPS-denied\nenvironments. Most existing LPR methods use mundane representations of the\ninput point cloud without considering different views, which may not fully\nexploit the information from LiDAR sensors. In this paper, we propose a\ncross-view transformer-based network, dubbed CVTNet, to fuse the range image\nviews (RIVs) and bird's eye views (BEVs) generated from the LiDAR data. It\nextracts correlations within the views themselves using intra-transformers and\nbetween the two different views using inter-transformers. Based on that, our\nproposed CVTNet generates a yaw-angle-invariant global descriptor for each\nlaser scan end-to-end online and retrieves previously seen places by descriptor\nmatching between the current query scan and the pre-built database. We evaluate\nour approach on three datasets collected with different sensor setups and\nenvironmental conditions. The experimental results show that our method\noutperforms the state-of-the-art LPR methods with strong robustness to\nviewpoint changes and long-time spans. Furthermore, our approach has a good\nreal-time performance that can run faster than the typical LiDAR frame rate.\nThe implementation of our method is released as open source at:\nhttps://github.com/BIT-MJY/CVTNet.\n","authors":["Junyi Ma","Guangming Xiong","Jingyi Xu","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2302.01665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01660v1","updated":"2023-02-03T11:17:59Z","published":"2023-02-03T11:17:59Z","title":"The Learnable Typewriter: A Generative Approach to Text Line Analysis","summary":"  We present a generative document-specific approach to character analysis and\nrecognition in text lines. Our main idea is to build on unsupervised\nmulti-object segmentation methods and in particular those that reconstruct\nimages based on a limited amount of visual elements, called sprites. Our\napproach can learn a large number of different characters and leverage\nline-level annotations when available. Our contribution is twofold. First, we\nprovide the first adaptation and evaluation of a deep unsupervised multi-object\nsegmentation approach for text line analysis. Since these methods have mainly\nbeen evaluated on synthetic data in a completely unsupervised setting,\ndemonstrating that they can be adapted and quantitatively evaluated on real\ntext images and that they can be trained using weak supervision are significant\nprogresses. Second, we demonstrate the potential of our method for new\napplications, more specifically in the field of paleography, which studies the\nhistory and variations of handwriting, and for cipher analysis. We evaluate our\napproach on three very different datasets: a printed volume of the Google1000\ndataset, the Copiale cipher and historical handwritten charters from the 12th\nand early 13th century.\n","authors":["Ioannis Siglidis","Nicolas Gonthier","Julien Gaubil","Tom Monnier","Mathieu Aubry"],"pdf_url":"https://arxiv.org/pdf/2302.01660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11624v2","updated":"2023-02-03T11:00:55Z","published":"2022-03-22T11:20:21Z","title":"High-resolution Iterative Feedback Network for Camouflaged Object\n  Detection","summary":"  Spotting camouflaged objects that are visually assimilated into the\nbackground is tricky for both object detection algorithms and humans who are\nusually confused or cheated by the perfectly intrinsic similarities between the\nforeground objects and the background surroundings. To tackle this challenge,\nwe aim to extract the high-resolution texture details to avoid the detail\ndegradation that causes blurred vision in edges and boundaries. We introduce a\nnovel HitNet to refine the low-resolution representations by high-resolution\nfeatures in an iterative feedback manner, essentially a global loop-based\nconnection among the multi-scale resolutions. In addition, an iterative\nfeedback loss is proposed to impose more constraints on each feedback\nconnection. Extensive experiments on four challenging datasets demonstrate that\nour \\ourmodel~breaks the performance bottleneck and achieves significant\nimprovements compared with 29 state-of-the-art methods. To address the data\nscarcity in camouflaged scenarios, we provide an application example by\nemploying cross-domain learning to extract the features that can reflect the\ncamouflaged object properties and embed the features into salient objects,\nthereby generating more camouflaged training samples from the diverse salient\nobject datasets The code will be available at\nhttps://github.com/HUuxiaobin/HitNet.\n","authors":["Xiaobin Hu","Shuo Wang","Xuebin Qin","Hang Dai","Wenqi Ren","Ying Tai","Chengjie Wang","Ling Shao"],"pdf_url":"https://arxiv.org/pdf/2203.11624v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01653v1","updated":"2023-02-03T10:57:21Z","published":"2023-02-03T10:57:21Z","title":"From slides (through tiles) to pixels: an explainability framework for\n  weakly supervised models in pre-clinical pathology","summary":"  In pre-clinical pathology, there is a paradox between the abundance of raw\ndata (whole slide images from many organs of many individual animals) and the\nlack of pixel-level slide annotations done by pathologists. Due to time\nconstraints and requirements from regulatory authorities, diagnoses are instead\nstored as slide labels. Weakly supervised training is designed to take\nadvantage of those data, and the trained models can be used by pathologists to\nrank slides by their probability of containing a given lesion of interest. In\nthis work, we propose a novel contextualized eXplainable AI (XAI) framework and\nits application to deep learning models trained on Whole Slide Images (WSIs) in\nDigital Pathology. Specifically, we apply our methods to a\nmulti-instance-learning (MIL) model, which is trained solely on slide-level\nlabels, without the need for pixel-level annotations. We validate\nquantitatively our methods by quantifying the agreements of our explanations'\nheatmaps with pathologists' annotations, as well as with predictions from a\nsegmentation model trained on such annotations. We demonstrate the stability of\nthe explanations with respect to input shifts, and the fidelity with respect to\nincreased model performance. We quantitatively evaluate the correlation between\navailable pixel-wise annotations and explainability heatmaps. We show that the\nexplanations on important tiles of the whole slide correlate with tissue\nchanges between healthy regions and lesions, but do not exactly behave like a\nhuman annotator. This result is coherent with the model training strategy.\n","authors":["Marco Bertolini","Van-Khoa Le","Jake Pencharz","Andreas Poehlmann","Djork-Arné Clevert","Santiago Villalba","Floriane Montanari"],"pdf_url":"https://arxiv.org/pdf/2302.01653v1.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.01650v1","updated":"2023-02-03T10:54:52Z","published":"2023-02-03T10:54:52Z","title":"ShadowFormer: Global Context Helps Image Shadow Removal","summary":"  Recent deep learning methods have achieved promising results in image shadow\nremoval. However, most of the existing approaches focus on working locally\nwithin shadow and non-shadow regions, resulting in severe artifacts around the\nshadow boundaries as well as inconsistent illumination between shadow and\nnon-shadow regions. It is still challenging for the deep shadow removal model\nto exploit the global contextual correlation between shadow and non-shadow\nregions. In this work, we first propose a Retinex-based shadow model, from\nwhich we derive a novel transformer-based network, dubbed ShandowFormer, to\nexploit non-shadow regions to help shadow region restoration. A multi-scale\nchannel attention framework is employed to hierarchically capture the global\ninformation. Based on that, we propose a Shadow-Interaction Module (SIM) with\nShadow-Interaction Attention (SIA) in the bottleneck stage to effectively model\nthe context correlation between shadow and non-shadow regions. We conduct\nextensive experiments on three popular public datasets, including ISTD, ISTD+,\nand SRD, to evaluate the proposed method. Our method achieves state-of-the-art\nperformance by using up to 150X fewer model parameters.\n","authors":["Lanqing Guo","Siyu Huang","Ding Liu","Hao Cheng","Bihan Wen"],"pdf_url":"https://arxiv.org/pdf/2302.01650v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.01648v1","updated":"2023-02-03T10:48:31Z","published":"2023-02-03T10:48:31Z","title":"A statistically constrained internal method for single image\n  super-resolution","summary":"  Deep learning based methods for single-image super-resolution (SR) have drawn\na lot of attention lately. In particular, various papers have shown that the\nlearning stage can be performed on a single image, resulting in the so-called\ninternal approaches. The SinGAN method is one of these contributions, where the\ndistribution of image patches is learnt on the image at hand and propagated at\nfiner scales. Now, there are situations where some statistical a priori can be\nassumed for the final image. In particular, many natural phenomena yield images\nhaving power law Fourier spectrum, such as clouds and other texture images. In\nthis work, we show how such a priori information can be integrated into an\ninternal super-resolution approach, by constraining the learned up-sampling\nprocedure of SinGAN. We consider various types of constraints, related to the\nFourier power spectrum, the color histograms and the consistency of the\nupsampling scheme. We demonstrate on various experiments that these constraints\nare indeed satisfied, but also that some perceptual quality measures can be\nimproved by the proposed approach.\n","authors":["Pierrick Chatillon","Yann Gousseau","Sidonie Lefebvre"],"pdf_url":"https://arxiv.org/pdf/2302.01648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01647v1","updated":"2023-02-03T10:48:24Z","published":"2023-02-03T10:48:24Z","title":"Blockwise Self-Supervised Learning at Scale","summary":"  Current state-of-the-art deep networks are all powered by backpropagation. In\nthis paper, we explore alternatives to full backpropagation in the form of\nblockwise learning rules, leveraging the latest developments in self-supervised\nlearning. We show that a blockwise pretraining procedure consisting of training\nindependently the 4 main blocks of layers of a ResNet-50 with Barlow Twins'\nloss function at each block performs almost as well as end-to-end\nbackpropagation on ImageNet: a linear probe trained on top of our blockwise\npretrained model obtains a top-1 classification accuracy of 70.48%, only 1.1%\nbelow the accuracy of an end-to-end pretrained network (71.57% accuracy). We\nperform extensive experiments to understand the impact of different components\nwithin our method and explore a variety of adaptations of self-supervised\nlearning to the blockwise paradigm, building an exhaustive understanding of the\ncritical avenues for scaling local learning rules to large networks, with\nimplications ranging from hardware design to neuroscience.\n","authors":["Shoaib Ahmed Siddiqui","David Krueger","Yann LeCun","Stéphane Deny"],"pdf_url":"https://arxiv.org/pdf/2302.01647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13507v3","updated":"2023-02-03T10:39:37Z","published":"2022-09-27T16:23:12Z","title":"CrossDTR: Cross-view and Depth-guided Transformers for 3D Object\n  Detection","summary":"  To achieve accurate 3D object detection at a low cost for autonomous driving,\nmany multi-camera methods have been proposed and solved the occlusion problem\nof monocular approaches. However, due to the lack of accurate estimated depth,\nexisting multi-camera methods often generate multiple bounding boxes along a\nray of depth direction for difficult small objects such as pedestrians,\nresulting in an extremely low recall. Furthermore, directly applying depth\nprediction modules to existing multi-camera methods, generally composed of\nlarge network architectures, cannot meet the real-time requirements of\nself-driving applications. To address these issues, we propose Cross-view and\nDepth-guided Transformers for 3D Object Detection, CrossDTR. First, our\nlightweight depth predictor is designed to produce precise object-wise sparse\ndepth maps and low-dimensional depth embeddings without extra depth datasets\nduring supervision. Second, a cross-view depth-guided transformer is developed\nto fuse the depth embeddings as well as image features from cameras of\ndifferent views and generate 3D bounding boxes. Extensive experiments\ndemonstrated that our method hugely surpassed existing multi-camera methods by\n10 percent in pedestrian detection and about 3 percent in overall mAP and NDS\nmetrics. Also, computational analyses showed that our method is 5 times faster\nthan prior approaches. Our codes will be made publicly available at\nhttps://github.com/sty61010/CrossDTR.\n","authors":["Ching-Yu Tseng","Yi-Rong Chen","Hsin-Ying Lee","Tsung-Han Wu","Wen-Chin Chen","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2209.13507v3.pdf","comment":"Accepted by IEEE International Conference on Robotics and Automation\n  (ICRA) 2023. The code is available at https://github.com/sty61010/CrossDTR"},{"id":"http://arxiv.org/abs/2205.15357v3","updated":"2023-02-03T10:38:51Z","published":"2022-05-30T18:04:57Z","title":"Searching for the Essence of Adversarial Perturbations","summary":"  Neural networks have demonstrated state-of-the-art performance in various\nmachine learning fields. However, the introduction of malicious perturbations\nin input data, known as adversarial examples, has been shown to deceive neural\nnetwork predictions. This poses potential risks for real-world applications\nsuch as autonomous driving and text identification. In order to mitigate these\nrisks, a comprehensive understanding of the mechanisms underlying adversarial\nexamples is essential. In this study, we demonstrate that adversarial\nperturbations contain human-recognizable information, which is the key\nconspirator responsible for a neural network's incorrect prediction, in\ncontrast to the widely held belief that human-unidentifiable characteristics\nplay a critical role in fooling a network. This concept of human-recognizable\ncharacteristics enables us to explain key features of adversarial\nperturbations, including their existence, transferability among different\nneural networks, and increased interpretability for adversarial training. We\nalso uncover two unique properties of adversarial perturbations that deceive\nneural networks: masking and generation. Additionally, a special class, the\ncomplementary class, is identified when neural networks classify input images.\nThe presence of human-recognizable information in adversarial perturbations\nallows researchers to gain insight into the working principles of neural\nnetworks and may lead to the development of techniques for detecting and\ndefending against adversarial attacks.\n","authors":["Dennis Y. Menn","Tzu-hsun Feng","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2205.15357v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01642v1","updated":"2023-02-03T10:38:20Z","published":"2023-02-03T10:38:20Z","title":"Cluster-CAM: Cluster-Weighted Visual Interpretation of CNNs' Decision in\n  Image Classification","summary":"  Despite the tremendous success of convolutional neural networks (CNNs) in\ncomputer vision, the mechanism of CNNs still lacks clear interpretation.\nCurrently, class activation mapping (CAM), a famous visualization technique to\ninterpret CNN's decision, has drawn increasing attention. Gradient-based CAMs\nare efficient while the performance is heavily affected by gradient vanishing\nand exploding. In contrast, gradient-free CAMs can avoid computing gradients to\nproduce more understandable results. However, existing gradient-free CAMs are\nquite time-consuming because hundreds of forward interference per image are\nrequired. In this paper, we proposed Cluster-CAM, an effective and efficient\ngradient-free CNN interpretation algorithm. Cluster-CAM can significantly\nreduce the times of forward propagation by splitting the feature maps into\nclusters in an unsupervised manner. Furthermore, we propose an artful strategy\nto forge a cognition-base map and cognition-scissors from clustered feature\nmaps. The final salience heatmap will be computed by merging the above\ncognition maps. Qualitative results conspicuously show that Cluster-CAM can\nproduce heatmaps where the highlighted regions match the human's cognition more\nprecisely than existing CAMs. The quantitative evaluation further demonstrates\nthe superiority of Cluster-CAM in both effectiveness and efficiency.\n","authors":["Zhenpeng Feng","Hongbing Ji","Milos Dakovic","Xiyang Cui","Mingzhe Zhu","Ljubisa Stankovic"],"pdf_url":"https://arxiv.org/pdf/2302.01642v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2206.09485v2","updated":"2023-02-03T10:09:22Z","published":"2022-06-19T20:29:34Z","title":"Video frame interpolation for high dynamic range sequences captured with\n  dual-exposure sensors","summary":"  Video frame interpolation (VFI) enables many important applications that\nmight involve the temporal domain, such as slow motion playback, or the spatial\ndomain, such as stop motion sequences. We are focusing on the former task,\nwhere one of the key challenges is handling high dynamic range (HDR) scenes in\nthe presence of complex motion. To this end, we explore possible advantages of\ndual-exposure sensors that readily provide sharp short and blurry long\nexposures that are spatially registered and whose ends are temporally aligned.\nThis way, motion blur registers temporally continuous information on the scene\nmotion that, combined with the sharp reference, enables more precise motion\nsampling within a single camera shot. We demonstrate that this facilitates a\nmore complex motion reconstruction in the VFI task, as well as HDR frame\nreconstruction that so far has been considered only for the originally captured\nframes, not in-between interpolated frames. We design a neural network trained\nin these tasks that clearly outperforms existing solutions. We also propose a\nmetric for scene motion complexity that provides important insights into the\nperformance of VFI methods at the test time.\n","authors":["Ugur Cogalan","Mojtaba Bemana","Hans-Peter Seidel","Karol Myszkowski"],"pdf_url":"https://arxiv.org/pdf/2206.09485v2.pdf","comment":"17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2302.01622v1","updated":"2023-02-03T09:49:13Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in radiology","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure the protection of said data are required. The gold standard for privacy\npreservation is the introduction of differential privacy (DP) to model\ntraining. However, prior work has shown that DP has negative implications on\nmodel accuracy and fairness. Therefore, the purpose of this study is to\ndemonstrate that the privacy-preserving training of AI models for chest\nradiograph diagnosis is possible with high accuracy and fairness compared to\nnon-private training. N=193,311 high quality clinical chest radiographs were\nretrospectively collected and manually labeled by experienced radiologists, who\nassigned one or more of the following diagnoses: cardiomegaly, congestion,\npleural effusion, pneumonic infiltration and atelectasis, to each side (where\napplicable). The non-private AI models were compared with privacy-preserving\n(DP) models with respect to privacy-utility trade-offs (measured as area under\nthe receiver-operator-characteristic curve (AUROC)), and privacy-fairness\ntrade-offs (measured as Pearson-R or Statistical Parity Difference). The\nnon-private AI model achieved an average AUROC score of 0.90 over all labels,\nwhereas the DP AI model with a privacy budget of epsilon=7.89 resulted in an\nAUROC of 0.87, i.e., a mere 2.6% performance decrease compared to non-private\ntraining. The privacy-preserving training of diagnostic AI models can achieve\nhigh performance with a small penalty on model accuracy and does not amplify\ndiscrimination against age, sex or co-morbidity. We thus encourage\npractitioners to integrate state-of-the-art privacy-preserving techniques into\nmedical AI model development.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v1.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2302.01616v1","updated":"2023-02-03T09:28:39Z","published":"2023-02-03T09:28:39Z","title":"A geometrically aware auto-encoder for multi-texture synthesis","summary":"  We propose an auto-encoder architecture for multi-texture synthesis. The\napproach relies on both a compact encoder accounting for second order neural\nstatistics and a generator incorporating adaptive periodic content. Images are\nembedded in a compact and geometrically consistent latent space, where the\ntexture representation and its spatial organisation are disentangled. Texture\nsynthesis and interpolation tasks can be performed directly from these latent\ncodes. Our experiments demonstrate that our model outperforms state-of-the-art\nfeed-forward methods in terms of visual quality and various texture related\nmetrics.\n","authors":["Pierrick Chatillon","Yann Gousseau","Sidonie Lefebvre"],"pdf_url":"https://arxiv.org/pdf/2302.01616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01608v1","updated":"2023-02-03T09:11:50Z","published":"2023-02-03T09:11:50Z","title":"CFFT-GAN: Cross-domain Feature Fusion Transformer for Exemplar-based\n  Image Translation","summary":"  Exemplar-based image translation refers to the task of generating images with\nthe desired style, while conditioning on certain input image. Most of the\ncurrent methods learn the correspondence between two input domains and lack the\nmining of information within the domains. In this paper, we propose a more\ngeneral learning approach by considering two domain features as a whole and\nlearning both inter-domain correspondence and intra-domain potential\ninformation interactions. Specifically, we propose a Cross-domain Feature\nFusion Transformer (CFFT) to learn inter- and intra-domain feature fusion.\nBased on CFFT, the proposed CFFT-GAN works well on exemplar-based image\ntranslation. Moreover, CFFT-GAN is able to decouple and fuse features from\nmultiple domains by cascading CFFT modules. We conduct rich quantitative and\nqualitative experiments on several image translation tasks, and the results\ndemonstrate the superiority of our approach compared to state-of-the-art\nmethods. Ablation studies show the importance of our proposed CFFT. Application\nexperimental results reflect the potential of our method.\n","authors":["Tianxiang Ma","Bingchuan Li","Wei Liu","Miao Hua","Jing Dong","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2302.01608v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.01602v1","updated":"2023-02-03T08:54:55Z","published":"2023-02-03T08:54:55Z","title":"A Feature Selection Method for Driver Stress Detection Using Heart Rate\n  Variability and Breathing Rate","summary":"  Driver stress is a major cause of car accidents and death worldwide.\nFurthermore, persistent stress is a health problem, contributing to\nhypertension and other diseases of the cardiovascular system. Stress has a\nmeasurable impact on heart and breathing rates and stress levels can be\ninferred from such measurements. Galvanic skin response is a common test to\nmeasure the perspiration caused by both physiological and psychological stress,\nas well as extreme emotions. In this paper, galvanic skin response is used to\nestimate the ground truth stress levels. A feature selection technique based on\nthe minimal redundancy-maximal relevance method is then applied to multiple\nheart rate variability and breathing rate metrics to identify a novel and\noptimal combination for use in detecting stress. The support vector machine\nalgorithm with a radial basis function kernel was used along with these\nfeatures to reliably predict stress. The proposed method has achieved a high\nlevel of accuracy on the target dataset.\n","authors":["Ashkan Parsi","David O'Callaghan","Joseph Lemley"],"pdf_url":"https://arxiv.org/pdf/2302.01602v1.pdf","comment":"In Proceedings of the 15th International Conference on Machine Vision\n  (ICMV), Romem Italy, 18-20 November 2022. arXiv admin note: text overlap with\n  arXiv:2206.03222"},{"id":"http://arxiv.org/abs/2212.11720v3","updated":"2023-02-03T08:31:42Z","published":"2022-12-22T14:13:33Z","title":"GOOD: Exploring Geometric Cues for Detecting Objects in an Open World","summary":"  We address the task of open-world class-agnostic object detection, i.e.,\ndetecting every object in an image by learning from a limited number of base\nobject classes. State-of-the-art RGB-based models suffer from overfitting the\ntraining classes and often fail at detecting novel-looking objects. This is\nbecause RGB-based models primarily rely on appearance similarity to detect\nnovel objects and are also prone to overfitting short-cut cues such as textures\nand discriminative parts. To address these shortcomings of RGB-based object\ndetectors, we propose incorporating geometric cues such as depth and normals,\npredicted by general-purpose monocular estimators. Specifically, we use the\ngeometric cues to train an object proposal network for pseudo-labeling\nunannotated novel objects in the training set. Our resulting Geometry-guided\nOpen-world Object Detector (GOOD) significantly improves detection recall for\nnovel object categories and already performs well with only a few training\nclasses. Using a single \"person\" class for training on the COCO dataset, GOOD\nsurpasses SOTA methods by 5.0% AR@100, a relative improvement of 24%.\n","authors":["Haiwen Huang","Andreas Geiger","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11720v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01593v1","updated":"2023-02-03T08:18:34Z","published":"2023-02-03T08:18:34Z","title":"Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation","summary":"  This paper presents a novel end-to-end framework with Explicit box Detection\nfor multi-person Pose estimation, called ED-Pose, where it unifies the\ncontextual learning between human-level (global) and keypoint-level (local)\ninformation. Different from previous one-stage methods, ED-Pose re-considers\nthis task as two explicit box detection processes with a unified representation\nand regression supervision. First, we introduce a human detection decoder from\nencoded tokens to extract global features. It can provide a good initialization\nfor the latter keypoint detection, making the training process converge fast.\nSecond, to bring in contextual information near keypoints, we regard pose\nestimation as a keypoint box detection problem to learn both box positions and\ncontents for each keypoint. A human-to-keypoint detection decoder adopts an\ninteractive learning strategy between human and keypoint features to further\nenhance global and local feature aggregation. In general, ED-Pose is\nconceptually simple without post-processing and dense heatmap supervision. It\ndemonstrates its effectiveness and efficiency compared with both two-stage and\none-stage methods. Notably, explicit box detection boosts the pose estimation\nperformance by 4.5 AP on COCO and 9.9 AP on CrowdPose. For the first time, as a\nfully end-to-end framework with a L1 regression loss, ED-Pose surpasses\nheatmap-based Top-down methods under the same backbone by 1.2 AP on COCO and\nachieves the state-of-the-art with 76.6 AP on CrowdPose without bells and\nwhistles. Code is available at https://github.com/IDEA-Research/ED-Pose.\n","authors":["Jie Yang","Ailing Zeng","Shilong Liu","Feng Li","Ruimao Zhang","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01593v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01585v1","updated":"2023-02-03T07:35:53Z","published":"2023-02-03T07:35:53Z","title":"SegForestNet: Spatial-Partitioning-Based Aerial Image Segmentation","summary":"  Aerial image analysis, specifically the semantic segmentation thereof, is the\nbasis for applications such as automatically creating and updating maps,\ntracking city growth, or tracking deforestation. In true orthophotos, which are\noften used in these applications, many objects and regions can be approximated\nwell by polygons. However, this fact is rarely exploited by state-of-the-art\nsemantic segmentation models. Instead, most models allow unnecessary degrees of\nfreedom in their predictions by allowing arbitrary region shapes. We therefore\npresent a refinement of our deep learning model which predicts binary space\npartitioning trees, an efficient polygon representation. The refinements\ninclude a new feature decoder architecture and a new differentiable BSP tree\nrenderer which both avoid vanishing gradients. Additionally, we designed a\nnovel loss function specifically designed to improve the spatial partitioning\ndefined by the predicted trees. Furthermore, our expanded model can predict\nmultiple trees at once and thus can predict class-specific segmentations.\nTaking all modifications together, our model achieves state-of-the-art\nperformance while using up to 60% fewer model parameters when using a small\nbackbone model or up to 20% fewer model parameters when using a large backbone\nmodel.\n","authors":["Daniel Gritzner","Jörn Ostermann"],"pdf_url":"https://arxiv.org/pdf/2302.01585v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2302.01579v1","updated":"2023-02-03T07:17:46Z","published":"2023-02-03T07:17:46Z","title":"Semantic 3D-aware Portrait Synthesis and Manipulation Based on\n  Compositional Neural Radiance Field","summary":"  Recently 3D-aware GAN methods with neural radiance field have developed\nrapidly. However, current methods model the whole image as an overall neural\nradiance field, which limits the partial semantic editability of synthetic\nresults. Since NeRF renders an image pixel by pixel, it is possible to split\nNeRF in the spatial dimension. We propose a Compositional Neural Radiance Field\n(CNeRF) for semantic 3D-aware portrait synthesis and manipulation. CNeRF\ndivides the image by semantic regions and learns an independent neural radiance\nfield for each region, and finally fuses them and renders the complete image.\nThus we can manipulate the synthesized semantic regions independently, while\nfixing the other parts unchanged. Furthermore, CNeRF is also designed to\ndecouple shape and texture within each semantic region. Compared to\nstate-of-the-art 3D-aware GAN methods, our approach enables fine-grained\nsemantic region manipulation, while maintaining high-quality 3D-consistent\nsynthesis. The ablation studies show the effectiveness of the structure and\nloss function used by our method. In addition real image inversion and cartoon\nportrait 3D editing experiments demonstrate the application potential of our\nmethod.\n","authors":["Tianxiang Ma","Bingchuan Li","Qian He","Jing Dong","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2302.01579v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2205.12564v3","updated":"2023-02-03T07:08:50Z","published":"2022-05-25T08:23:18Z","title":"Spotlights: Probing Shapes from Spherical Viewpoints","summary":"  Recent years have witnessed the surge of learned representations that\ndirectly build upon point clouds. Though becoming increasingly expressive, most\nexisting representations still struggle to generate ordered point sets.\nInspired by spherical multi-view scanners, we propose a novel sampling model\ncalled Spotlights to represent a 3D shape as a compact 1D array of depth\nvalues. It simulates the configuration of cameras evenly distributed on a\nsphere, where each virtual camera casts light rays from its principal point\nthrough sample points on a small concentric spherical cap to probe for the\npossible intersections with the object surrounded by the sphere. The structured\npoint cloud is hence given implicitly as a function of depths. We provide a\ndetailed geometric analysis of this new sampling scheme and prove its\neffectiveness in the context of the point cloud completion task. Experimental\nresults on both synthetic and real data demonstrate that our method achieves\ncompetitive accuracy and consistency while having a significantly reduced\ncomputational cost. Furthermore, we show superior performance on the downstream\npoint cloud registration task over state-of-the-art completion methods.\n","authors":["Jiaxin Wei","Lige Liu","Ran Cheng","Wenqing Jiang","Minghao Xu","Xinyu Jiang","Tao Sun","Soren Schwertfeger","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2205.12564v3.pdf","comment":"accepted by ACCV2022"},{"id":"http://arxiv.org/abs/2301.12831v2","updated":"2023-02-03T07:02:23Z","published":"2023-01-30T12:37:04Z","title":"M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing\n  System","summary":"  Face presentation attacks (FPA), also known as face spoofing, have brought\nincreasing concerns to the public through various malicious applications, such\nas financial fraud and privacy leakage. Therefore, safeguarding face\nrecognition systems against FPA is of utmost importance. Although existing\nlearning-based face anti-spoofing (FAS) models can achieve outstanding\ndetection performance, they lack generalization capability and suffer\nsignificant performance drops in unforeseen environments. Many methodologies\nseek to use auxiliary modality data (e.g., depth and infrared maps) during the\npresentation attack detection (PAD) to address this limitation. However, these\nmethods can be limited since (1) they require specific sensors such as depth\nand infrared cameras for data capture, which are rarely available on commodity\nmobile devices, and (2) they cannot work properly in practical scenarios when\neither modality is missing or of poor quality. In this paper, we devise an\naccurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to\novercome the issues above. The innovation of this work mainly lies in the\nfollowing aspects: (1) To achieve robust PAD, our system combines visual and\nauditory modalities using three pervasively available sensors: camera, speaker,\nand microphone; (2) We design a novel two-branch neural network with three\nhierarchical feature aggregation modules to perform cross-modal feature fusion;\n(3). We propose a multi-head training strategy. The model outputs three\npredictions from the vision, acoustic, and fusion heads, enabling a more\nflexible PAD. Extensive experiments have demonstrated the accuracy, robustness,\nand flexibility of M3FAS under various challenging experimental settings.\n","authors":["Chenqi Kong","Kexin Zheng","Yibing Liu","Shiqi Wang","Anderson Rocha","Haoliang Li"],"pdf_url":"https://arxiv.org/pdf/2301.12831v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01572v1","updated":"2023-02-03T06:50:51Z","published":"2023-02-03T06:50:51Z","title":"Simple, Effective and General: A New Backbone for Cross-view Image\n  Geo-localization","summary":"  In this work, we aim at an important but less explored problem of a simple\nyet effective backbone specific for cross-view geo-localization task. Existing\nmethods for cross-view geo-localization tasks are frequently characterized by\n1) complicated methodologies, 2) GPU-consuming computations, and 3) a stringent\nassumption that aerial and ground images are centrally or orientation aligned.\nTo address the above three challenges for cross-view image matching, we propose\na new backbone network, named Simple Attention-based Image Geo-localization\nnetwork (SAIG). The proposed SAIG effectively represents long-range\ninteractions among patches as well as cross-view correspondence with multi-head\nself-attention layers. The \"narrow-deep\" architecture of our SAIG improves the\nfeature richness without degradation in performance, while its shallow and\neffective convolutional stem preserves the locality, eliminating the loss of\npatchify boundary information. Our SAIG achieves state-of-the-art results on\ncross-view geo-localization, while being far simpler than previous works.\nFurthermore, with only 15.9% of the model parameters and half of the output\ndimension compared to the state-of-the-art, the SAIG adapts well across\nmultiple cross-view datasets without employing any well-designed feature\naggregation modules or feature alignment algorithms. In addition, our SAIG\nattains competitive scores on image retrieval benchmarks, further demonstrating\nits generalizability. As a backbone network, our SAIG is both easy to follow\nand computationally lightweight, which is meaningful in practical scenario.\nMoreover, we propose a simple Spatial-Mixed feature aggregation moDule (SMD)\nthat can mix and project spatial information into a low-dimensional space to\ngenerate feature descriptors... (The code is available at\nhttps://github.com/yanghongji2007/SAIG)\n","authors":["Yingying Zhu","Hongji Yang","Yuxin Lu","Qiang Huang"],"pdf_url":"https://arxiv.org/pdf/2302.01572v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2302.01571v1","updated":"2023-02-03T06:49:27Z","published":"2023-02-03T06:49:27Z","title":"Robust Camera Pose Refinement for Multi-Resolution Hash Encoding","summary":"  Multi-resolution hash encoding has recently been proposed to reduce the\ncomputational cost of neural renderings, such as NeRF. This method requires\naccurate camera poses for the neural renderings of given scenes. However,\ncontrary to previous methods jointly optimizing camera poses and 3D scenes, the\nnaive gradient-based camera pose refinement method using multi-resolution hash\nencoding severely deteriorates performance. We propose a joint optimization\nalgorithm to calibrate the camera pose and learn a geometric representation\nusing efficient multi-resolution hash encoding. Showing that the oscillating\ngradient flows of hash encoding interfere with the registration of camera\nposes, our method addresses the issue by utilizing smooth interpolation\nweighting to stabilize the gradient oscillation for the ray samplings across\nhash grids. Moreover, the curriculum training procedure helps to learn the\nlevel-wise hash encoding, further increasing the pose refinement. Experiments\non the novel-view synthesis datasets validate that our learning frameworks\nachieve state-of-the-art performance and rapid convergence of neural rendering,\neven when initial camera poses are unknown.\n","authors":["Hwan Heo","Taekyung Kim","Jiyoung Lee","Jaewon Lee","Soohyun Kim","Hyunwoo J. Kim","Jin-Hwa Kim"],"pdf_url":"https://arxiv.org/pdf/2302.01571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10812v2","updated":"2023-02-03T06:17:27Z","published":"2022-11-19T22:23:43Z","title":"Face Swapping as A Simple Arithmetic Operation","summary":"  We propose a novel high-fidelity face swapping method called \"Arithmetic Face\nSwapping\" (AFS) that explicitly disentangles the intermediate latent space W+\nof a pretrained StyleGAN into the \"identity\" and \"style\" subspaces so that a\nlatent code in W+ is the sum of an \"identity\" code and a \"style\" code in the\ncorresponding subspaces. Via our disentanglement, face swapping (FS) can be\nregarded as a simple arithmetic operation in W+, i.e., the summation of a\nsource \"identity\" code and a target \"style\" code. This makes AFS more intuitive\nand elegant than other FS methods. In addition, our method can generalize over\nthe standard face swapping to support other interesting operations, e.g.,\ncombining the identity of one source with styles of multiple targets and vice\nversa. We implement our identity-style disentanglement by learning a neural\nnetwork that maps a latent code to a \"style\" code. We provide a condition for\nthis network which theoretically guarantees identity preservation of the source\nface even after a sequence of face swapping operations. Extensive experiments\ndemonstrate the advantage of our method over state-of-the-art FS methods in\nproducing high-quality swapped faces. Our source code was made public at\nhttps://github.com/truongvu2000nd/AFS\n","authors":["Truong Vu","Kien Do","Khang Nguyen","Khoat Than"],"pdf_url":"https://arxiv.org/pdf/2211.10812v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01555v1","updated":"2023-02-03T05:27:52Z","published":"2023-02-03T05:27:52Z","title":"Bridging the Emotional Semantic Gap via Multimodal Relevance Estimation","summary":"  Human beings have rich ways of emotional expressions, including facial\naction, voice, and natural languages. Due to the diversity and complexity of\ndifferent individuals, the emotions expressed by various modalities may be\nsemantically irrelevant. Directly fusing information from different modalities\nmay inevitably make the model subject to the noise from semantically irrelevant\nmodalities. To tackle this problem, we propose a multimodal relevance\nestimation network to capture the relevant semantics among modalities in\nmultimodal emotions. Specifically, we take advantage of an attention mechanism\nto reflect the semantic relevance weights of each modality. Moreover, we\npropose a relevant semantic estimation loss to weakly supervise the semantics\nof each modality. Furthermore, we make use of contrastive learning to optimize\nthe similarity of category-level modality-relevant semantics across different\nmodalities in feature space, thereby bridging the semantic gap between\nheterogeneous modalities. In order to better reflect the emotional state in the\nreal interactive scenarios and perform the semantic relevance analysis, we\ncollect a single-label discrete multimodal emotion dataset named SDME, which\nenables researchers to conduct multimodal semantic relevance research with\nlarge category bias. Experiments on continuous and discrete emotion datasets\nshow that our model can effectively capture the relevant semantics, especially\nfor the large deviations in modal semantics. The code and SDME dataset will be\npublicly available.\n","authors":["Chuan Zhang","Daoxin Zhang","Ruixiu Zhang","Jiawei Li","Jianke Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.01555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00902v2","updated":"2023-02-03T05:06:46Z","published":"2023-02-02T06:38:44Z","title":"Language Quantized AutoEncoders: Towards Unsupervised Text-Image\n  Alignment","summary":"  Recent progress in scaling up large language models has shown impressive\ncapabilities in performing few-shot learning across a wide range of text-based\ntasks. However, a key limitation is that these language models fundamentally\nlack visual perception - a crucial attribute needed to extend these models to\nbe able to interact with the real world and solve vision tasks, such as in\nvisual-question answering and robotics. Prior works have largely connected\nimage to text through pretraining and/or fine-tuning on curated image-text\ndatasets, which can be a costly and expensive process. In order to resolve this\nlimitation, we propose a simple yet effective approach called\nLanguage-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to\nalign text-image data in an unsupervised manner by leveraging pretrained\nlanguage models (e.g., BERT, RoBERTa). Our main idea is to encode image as\nsequences of text tokens by directly quantizing image embeddings using a\npretrained language codebook. We then apply random masking followed by a BERT\nmodel, and have the decoder reconstruct the original image from BERT predicted\ntext token embeddings. By doing so, LQAE learns to represent similar images\nwith similar clusters of text tokens, thereby aligning these two modalities\nwithout the use of aligned text-image pairs. This enables few-shot image\nclassification with large language models (e.g., GPT-3) as well as linear\nclassification of images based on BERT text features. To the best of our\nknowledge, our work is the first work that uses unaligned images for multimodal\ntasks by leveraging the power of pretrained language models.\n","authors":["Hao Liu","Wilson Yan","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.00902v2.pdf","comment":"Fixed typos"},{"id":"http://arxiv.org/abs/2302.01541v1","updated":"2023-02-03T04:34:00Z","published":"2023-02-03T04:34:00Z","title":"Contrastive Learning with Consistent Representations","summary":"  Contrastive learning demonstrates great promise for representation learning.\nData augmentations play a critical role in contrastive learning by providing\ninformative views of the data without needing the labels. However, the\nperformance of the existing works heavily relies on the quality of the employed\ndata augmentation (DA) functions, which are typically hand picked from a\nrestricted set of choices. While exploiting a diverse set of data augmentations\nis appealing, the intricacies of DAs and representation learning may lead to\nperformance degradation. To address this challenge and allow for a systemic use\nof large numbers of data augmentations, this paper proposes Contrastive\nLearning with Consistent Representations (CoCor). At the core of CoCor is a new\nconsistency measure, DA consistency, which dictates the mapping of augmented\ninput data to the representation space such that these instances are mapped to\noptimal locations in a way consistent to the intensity of the DA applied.\nFurthermore, a data-driven approach is proposed to learn the optimal mapping\nlocations as a function of DA while maintaining a desired monotonic property\nwith respect to DA intensity. The proposed techniques give rise to a\nsemi-supervised learning framework based on bi-level optimization, achieving\nnew state-of-the-art results for image recognition.\n","authors":["Zihu Wang","Yu Wang","Hanbin Hu","Peng Li"],"pdf_url":"https://arxiv.org/pdf/2302.01541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01540v1","updated":"2023-02-03T04:31:13Z","published":"2023-02-03T04:31:13Z","title":"DEVICE: DEpth and VIsual ConcEpts Aware Transformer for TextCaps","summary":"  Text-based image captioning is an important but under-explored task, aiming\nto generate descriptions containing visual objects and scene text. Recent\nstudies have made encouraging progress, but they are still suffering from a\nlack of overall understanding of scenes and generating inaccurate captions. One\npossible reason is that current studies mainly focus on constructing the\nplane-level geometric relationship of scene text without depth information.\nThis leads to insufficient scene text relational reasoning so that models may\ndescribe scene text inaccurately. The other possible reason is that existing\nmethods fail to generate fine-grained descriptions of some visual objects. In\naddition, they may ignore essential visual objects, leading to the scene text\nbelonging to these ignored objects not being utilized. To address the above\nissues, we propose a DEpth and VIsual ConcEpts Aware Transformer (DEVICE) for\nTextCaps. Concretely, to construct three-dimensional geometric relations, we\nintroduce depth information and propose a depth-enhanced feature updating\nmodule to ameliorate OCR token features. To generate more precise and\ncomprehensive captions, we introduce semantic features of detected visual\nobject concepts as auxiliary information. Our DEVICE is capable of generalizing\nscenes more comprehensively and boosting the accuracy of described visual\nentities. Sufficient experiments demonstrate the effectiveness of our proposed\nDEVICE, which outperforms state-of-the-art models on the TextCaps test set. Our\ncode will be publicly available.\n","authors":["Dongsheng Xu","Qingbao Huang","Yi Cai"],"pdf_url":"https://arxiv.org/pdf/2302.01540v1.pdf","comment":"9pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.01532v1","updated":"2023-02-03T04:15:51Z","published":"2023-02-03T04:15:51Z","title":"INV: Towards Streaming Incremental Neural Videos","summary":"  Recent works in spatiotemporal radiance fields can produce photorealistic\nfree-viewpoint videos. However, they are inherently unsuitable for interactive\nstreaming scenarios (e.g. video conferencing, telepresence) because have an\ninevitable lag even if the training is instantaneous. This is because these\napproaches consume videos and thus have to buffer chunks of frames (often\nseconds) before processing. In this work, we take a step towards interactive\nstreaming via a frame-by-frame approach naturally free of lag. Conventional\nwisdom believes that per-frame NeRFs are impractical due to prohibitive\ntraining costs and storage. We break this belief by introducing Incremental\nNeural Videos (INV), a per-frame NeRF that is efficiently trained and\nstreamable. We designed INV based on two insights: (1) Our main finding is that\nMLPs naturally partition themselves into Structure and Color Layers, which\nstore structural and color/texture information respectively. (2) We leverage\nthis property to retain and improve upon knowledge from previous frames, thus\namortizing training across frames and reducing redundant learning. As a result,\nwith negligible changes to NeRF, INV can achieve good qualities (>28.6db) in\n8min/frame. It can also outperform prior SOTA in 19% less training time.\nAdditionally, our Temporal Weight Compression reduces the per-frame size to\n0.3MB/frame (6.6% of NeRF). More importantly, INV is free from buffer lag and\nis naturally fit for streaming. While this work does not achieve real-time\ntraining, it shows that incremental approaches like INV present new\npossibilities in interactive 3D streaming. Moreover, our discovery of natural\ninformation partition leads to a better understanding and manipulation of MLPs.\nCode and dataset will be released soon.\n","authors":["Shengze Wang","Alexey Supikov","Joshua Ratcliff","Henry Fuchs","Ronald Azuma"],"pdf_url":"https://arxiv.org/pdf/2302.01532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01526v1","updated":"2023-02-03T03:48:43Z","published":"2023-02-03T03:48:43Z","title":"Example-Based Explainable AI and its Application for Remote Sensing\n  Image Classification","summary":"  We present a method of explainable artificial intelligence (XAI), \"What I\nKnow (WIK)\", to provide additional information to verify the reliability of a\ndeep learning model by showing an example of an instance in a training dataset\nthat is similar to the input data to be inferred and demonstrate it in a remote\nsensing image classification task. One of the expected roles of XAI methods is\nverifying whether inferences of a trained machine learning model are valid for\nan application, and it is an important factor that what datasets are used for\ntraining the model as well as the model architecture. Our data-centric approach\ncan help determine whether the training dataset is sufficient for each\ninference by checking the selected example data. If the selected example looks\nsimilar to the input data, we can confirm that the model was not trained on a\ndataset with a feature distribution far from the feature of the input data.\nWith this method, the criteria for selecting an example are not merely data\nsimilarity with the input data but also data similarity in the context of the\nmodel task. Using a remote sensing image dataset from the Sentinel-2 satellite,\nthe concept was successfully demonstrated with reasonably selected examples.\nThis method can be applied to various machine-learning tasks, including\nclassification and regression.\n","authors":["Shin-nosuke Ishikawa","Masato Todo","Masato Taki","Yasunobu Uchiyama","Kazunari Matsunaga","Peihsuan Lin","Taiki Ogihara","Masao Yasui"],"pdf_url":"https://arxiv.org/pdf/2302.01526v1.pdf","comment":"10 pages, 4 figures, accepted for publication in International\n  Journal of Applied Earth Observation and Geoinformation"},{"id":"http://arxiv.org/abs/2302.01516v1","updated":"2023-02-03T03:08:31Z","published":"2023-02-03T03:08:31Z","title":"Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation","summary":"  Current methods of blended targets domain adaptation (BTDA) usually infer or\nconsider domain label information but underemphasize hybrid categorical feature\nstructures of targets, which yields limited performance, especially under the\nlabel distribution shift. We demonstrate that domain labels are not directly\nnecessary for BTDA if categorical distributions of various domains are\nsufficiently aligned even facing the imbalance of domains and the label\ndistribution shift of classes. However, we observe that the cluster assumption\nin BTDA does not comprehensively hold. The hybrid categorical feature space\nhinders the modeling of categorical distributions and the generation of\nreliable pseudo labels for categorical alignment. To address these, we propose\na categorical domain discriminator guided by uncertainty to explicitly model\nand directly align categorical distributions $P(Z|Y)$. Simultaneously, we\nutilize the low-level features to augment the single source features with\ndiverse target styles to rectify the biased classifier $P(Y|Z)$ among diverse\ntargets. Such a mutual conditional alignment of $P(Z|Y)$ and $P(Y|Z)$ forms a\nmutual reinforced mechanism. Our approach outperforms the state-of-the-art in\nBTDA even compared with methods utilizing domain labels, especially under the\nlabel distribution shift, and in single target DA on DomainNet.\n","authors":["Pengcheng Xu","Boyu Wang","Charles Ling"],"pdf_url":"https://arxiv.org/pdf/2302.01516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01512v1","updated":"2023-02-03T02:57:18Z","published":"2023-02-03T02:57:18Z","title":"Spectral Aware Softmax for Visible-Infrared Person Re-Identification","summary":"  Visible-infrared person re-identification (VI-ReID) aims to match specific\npedestrian images from different modalities. Although suffering an extra\nmodality discrepancy, existing methods still follow the softmax loss training\nparadigm, which is widely used in single-modality classification tasks. The\nsoftmax loss lacks an explicit penalty for the apparent modality gap, which\nadversely limits the performance upper bound of the VI-ReID task. In this\npaper, we propose the spectral-aware softmax (SA-Softmax) loss, which can fully\nexplore the embedding space with the modality information and has clear\ninterpretability. Specifically, SA-Softmax loss utilizes an asynchronous\noptimization strategy based on the modality prototype instead of the\nsynchronous optimization based on the identity prototype in the original\nsoftmax loss. To encourage a high overlapping between two modalities,\nSA-Softmax optimizes each sample by the prototype from another spectrum. Based\non the observation and analysis of SA-Softmax, we modify the SA-Softmax with\nthe Feature Mask and Absolute-Similarity Term to alleviate the ambiguous\noptimization during model training. Extensive experimental evaluations\nconducted on RegDB and SYSU-MM01 demonstrate the superior performance of the\nSA-Softmax over the state-of-the-art methods in such a cross-modality\ncondition.\n","authors":["Lei Tan","Pingyang Dai","Qixiang Ye","Mingliang Xu","Yongjian Wu","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2302.01512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01507v1","updated":"2023-02-03T02:40:54Z","published":"2023-02-03T02:40:54Z","title":"Revisiting Long-tailed Image Classification: Survey and Benchmarks with\n  New Evaluation Metrics","summary":"  Recently, long-tailed image classification harvests lots of research\nattention, since the data distribution is long-tailed in many real-world\nsituations. Piles of algorithms are devised to address the data imbalance\nproblem by biasing the training process towards less frequent classes. However,\nthey usually evaluate the performance on a balanced testing set or multiple\nindependent testing sets having distinct distributions with the training data.\nConsidering the testing data may have arbitrary distributions, existing\nevaluation strategies are unable to reflect the actual classification\nperformance objectively. We set up novel evaluation benchmarks based on a\nseries of testing sets with evolving distributions. A corpus of metrics are\ndesigned for measuring the accuracy, robustness, and bounds of algorithms for\nlearning with long-tailed distribution. Based on our benchmarks, we re-evaluate\nthe performance of existing methods on CIFAR10 and CIFAR100 datasets, which is\nvaluable for guiding the selection of data rebalancing techniques. We also\nrevisit existing methods and categorize them into four types including data\nbalancing, feature balancing, loss balancing, and prediction balancing,\naccording the focused procedure during the training pipeline.\n","authors":["Chaowei Fang","Dingwen Zhang","Wen Zheng","Xue Li","Le Yang","Lechao Cheng","Junwei Han"],"pdf_url":"https://arxiv.org/pdf/2302.01507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01493v1","updated":"2023-02-03T02:00:06Z","published":"2023-02-03T02:00:06Z","title":"Deep Learning (DL)-based Automatic Segmentation of the Internal Pudendal\n  Artery (IPA) for Reduction of Erectile Dysfunction in Definitive Radiotherapy\n  of Localized Prostate Cancer","summary":"  Background and purpose: Radiation-induced erectile dysfunction (RiED) is\ncommonly seen in prostate cancer patients. Clinical trials have been developed\nin multiple institutions to investigate whether dose-sparing to the\ninternal-pudendal-arteries (IPA) will improve retention of sexual potency. The\nIPA is usually not considered a conventional organ-at-risk (OAR) due to\nsegmentation difficulty. In this work, we propose a deep learning (DL)-based\nauto-segmentation model for the IPA that utilizes CT and MRI or CT alone as the\ninput image modality to accommodate variation in clinical practice. Materials\nand methods: 86 patients with CT and MRI images and noisy IPA labels were\nrecruited in this study. We split the data into 42/14/30 for model training,\ntesting, and a clinical observer study, respectively. There were three major\ninnovations in this model: 1) we designed an architecture with\nsqueeze-and-excite blocks and modality attention for effective feature\nextraction and production of accurate segmentation, 2) a novel loss function\nwas used for training the model effectively with noisy labels, and 3) modality\ndropout strategy was used for making the model capable of segmentation in the\nabsence of MRI. Results: The DSC, ASD, and HD95 values for the test dataset\nwere 62.2%, 2.54mm, and 7mm, respectively. AI segmented contours were\ndosimetrically equivalent to the expert physician's contours. The observer\nstudy showed that expert physicians' scored AI contours (mean=3.7) higher than\ninexperienced physicians' contours (mean=3.1). When inexperienced physicians\nstarted with AI contours, the score improved to 3.7. Conclusion: The proposed\nmodel achieved good quality IPA contours to improve uniformity of segmentation\nand to facilitate introduction of standardized IPA segmentation into clinical\ntrials and practice.\n","authors":["Anjali Balagopal","Michael Dohopolski","Young Suk Kwon","Steven Montalvo","Howard Morgan","Ti Bai","Dan Nguyen","Xiao Liang","Xinran Zhong","Mu-Han Lin","Neil Desai","Steve Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.01493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.01723v2","updated":"2023-02-03T00:16:53Z","published":"2021-11-02T16:44:06Z","title":"CPSeg: Cluster-free Panoptic Segmentation of 3D LiDAR Point Clouds","summary":"  A fast and accurate panoptic segmentation system for LiDAR point clouds is\ncrucial for autonomous driving vehicles to understand the surrounding objects\nand scenes. Existing approaches usually rely on proposals or clustering to\nsegment foreground instances. As a result, they struggle to achieve real-time\nperformance. In this paper, we propose a novel real-time end-to-end panoptic\nsegmentation network for LiDAR point clouds, called CPSeg. In particular, CPSeg\ncomprises a shared encoder, a dual-decoder, and a cluster-free instance\nsegmentation head, which is able to dynamically pillarize foreground points\naccording to the learned embedding. Then, it acquires instance labels by\nfinding connected pillars with a pairwise embedding comparison. Thus, the\nconventional proposal-based or clustering-based instance segmentation is\ntransformed into a binary segmentation problem on the pairwise embedding\ncomparison matrix. To help the network regress instance embedding, a fast and\ndeterministic depth completion algorithm is proposed to calculate the surface\nnormal of each point cloud in real-time. The proposed method is benchmarked on\ntwo large-scale autonomous driving datasets: SemanticKITTI and nuScenes.\nNotably, extensive experimental results show that CPSeg achieves\nstate-of-the-art results among real-time approaches on both datasets.\n","authors":["Enxu Li","Ryan Razani","Yixuan Xu","Bingbing Liu"],"pdf_url":"https://arxiv.org/pdf/2111.01723v2.pdf","comment":"Accepted at ICRA 2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.01842v1","updated":"2023-02-03T16:37:08Z","published":"2023-02-03T16:37:08Z","title":"A Case Study for Compliance as Code with Graphs and Language Models:\n  Public release of the Regulatory Knowledge Graph","summary":"  The paper presents a study on using language models to automate the\nconstruction of executable Knowledge Graph (KG) for compliance. The paper\nfocuses on Abu Dhabi Global Market regulations and taxonomy, involves manual\ntagging a portion of the regulations, training BERT-based models, which are\nthen applied to the rest of the corpus. Coreference resolution and syntax\nanalysis were used to parse the relationships between the tagged entities and\nto form KG stored in a Neo4j database. The paper states that the use of machine\nlearning models released by regulators to automate the interpretation of rules\nis a vital step towards compliance automation, demonstrates the concept\nquerying with Cypher, and states that the produced sub-graphs combined with\nGraph Neural Networks (GNN) will achieve expandability in judgment automation\nsystems. The graph is open sourced on GitHub to provide structured data for\nfuture advancements in the field.\n","authors":["Vladimir Ershov"],"pdf_url":"https://arxiv.org/pdf/2302.01842v1.pdf","comment":"7 pages on RegKG step 1 in collaboration with ADGM"},{"id":"http://arxiv.org/abs/2302.01733v1","updated":"2023-02-03T13:48:59Z","published":"2023-02-03T13:48:59Z","title":"Committed Private Information Retrieval","summary":"  A private information retrieval (PIR) scheme allows a client to retrieve a\ndata item $x_i$ among $n$ items $x_1,x_2,...,x_n$ from $k$ servers, without\nrevealing what $i$ is even when $t < k$ servers collude and try to learn $i$.\nSuch a PIR scheme is said to be $t$-private. A PIR scheme is $v$-verifiable if\nthe client can verify the correctness of the retrieved $x_i$ even when $v \\leq\nk$ servers collude and try to fool the client by sending manipulated data. Most\nof the previous works in the literature on PIR assumed that $v < k$, leaving\nthe case of all-colluding servers open. We propose a generic construction that\ncombines a linear map commitment (LMC) and an arbitrary linear PIR scheme to\nproduce a $k$-verifiable PIR scheme, termed a committed PIR scheme. Such a\nscheme guarantees that even in the worst scenario, when all servers are under\nthe control of an attacker, although the privacy is unavoidably lost, the\nclient won't be fooled into accepting an incorrect $x_i$. We demonstrate the\npracticality of our proposal by implementing the committed PIR schemes based on\nthe Lai-Malavolta LMC and three well-known PIR schemes using the GMP library\nand \\texttt{blst}, the current fastest C library for elliptic curve pairings.\n","authors":["Quang Cao","Hong Yen Tran","Son Hoang Dau","Xun Yi","Emanuele Viterbo","Chen Feng","Yu-Chih Huang","Jingge Zhu","Stanislav Kruglik","Han Mao Kiah"],"pdf_url":"https://arxiv.org/pdf/2302.01733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01724v1","updated":"2023-02-03T13:25:43Z","published":"2023-02-03T13:25:43Z","title":"Reinforcing User Retention in a Billion Scale Short Video Recommender\n  System","summary":"  Recently, short video platforms have achieved rapid user growth by\nrecommending interesting content to users. The objective of the recommendation\nis to optimize user retention, thereby driving the growth of DAU (Daily Active\nUsers). Retention is a long-term feedback after multiple interactions of users\nand the system, and it is hard to decompose retention reward to each item or a\nlist of items. Thus traditional point-wise and list-wise models are not able to\noptimize retention. In this paper, we choose reinforcement learning methods to\noptimize the retention as they are designed to maximize the long-term\nperformance. We formulate the problem as an infinite-horizon request-based\nMarkov Decision Process, and our objective is to minimize the accumulated time\ninterval of multiple sessions, which is equal to improving the app open\nfrequency and user retention. However, current reinforcement learning\nalgorithms can not be directly applied in this setting due to uncertainty,\nbias, and long delay time incurred by the properties of user retention. We\npropose a novel method, dubbed RLUR, to address the aforementioned challenges.\nBoth offline and live experiments show that RLUR can significantly improve user\nretention. RLUR has been fully launched in Kuaishou app for a long time, and\nachieves consistent performance improvement on user retention and DAU.\n","authors":["Qingpeng Cai","Shuchang Liu","Xueliang Wang","Tianyou Zuo","Wentao Xie","Bin Yang","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01680v1","updated":"2023-02-03T12:02:54Z","published":"2023-02-03T12:02:54Z","title":"Two-Stage Constrained Actor-Critic fo Short Video Recommendation","summary":"  The wide popularity of short videos on social media poses new opportunities\nand challenges to optimize recommender systems on the video-sharing platforms.\nUsers sequentially interact with the system and provide complex and\nmulti-faceted responses, including watch time and various types of interactions\nwith multiple videos. One the one hand, the platforms aims at optimizing the\nusers' cumulative watch time (main goal) in long term, which can be effectively\noptimized by Reinforcement Learning. On the other hand, the platforms also\nneeds to satisfy the constraint of accommodating the responses of multiple user\ninteractions (auxiliary goals) such like, follow, share etc. In this paper, we\nformulate the problem of short video recommendation as a Constrained Markov\nDecision Process (CMDP). We find that traditional constrained reinforcement\nlearning algorithms can not work well in this setting. We propose a novel\ntwo-stage constrained actor-critic method: At stage one, we learn individual\npolicies to optimize each auxiliary signal. At stage two, we learn a policy to\n(i) optimize the main signal and (ii) stay close to policies learned at the\nfirst stage, which effectively guarantees the performance of this main policy\non the auxiliaries. Through extensive offline evaluations, we demonstrate\neffectiveness of our method over alternatives in both optimizing the main goal\nas well as balancing the others. We further show the advantage of our method in\nlive experiments of short video recommendations, where it significantly\noutperforms other baselines in terms of both watch time and interactions. Our\napproach has been fully launched in the production system to optimize user\nexperiences on the platform.\n","authors":["Qingpeng Cai","Zhenghai Xue","Chi Zhang","Wanqi Xue","Shuchang Liu","Ruohan Zhan","Xueliang Wang","Tianyou Zuo","Wentao Xie","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01680v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.13248"},{"id":"http://arxiv.org/abs/2302.01626v1","updated":"2023-02-03T09:54:27Z","published":"2023-02-03T09:54:27Z","title":"Modeling Sequential Sentence Relation to Improve Cross-lingual Dense\n  Retrieval","summary":"  Recently multi-lingual pre-trained language models (PLM) such as mBERT and\nXLM-R have achieved impressive strides in cross-lingual dense retrieval.\nDespite its successes, they are general-purpose PLM while the multilingual PLM\ntailored for cross-lingual retrieval is still unexplored. Motivated by an\nobservation that the sentences in parallel documents are approximately in the\nsame order, which is universal across languages, we propose to model this\nsequential sentence relation to facilitate cross-lingual representation\nlearning. Specifically, we propose a multilingual PLM called masked sentence\nmodel (MSM), which consists of a sentence encoder to generate the sentence\nrepresentations, and a document encoder applied to a sequence of sentence\nvectors from a document. The document encoder is shared for all languages to\nmodel the universal sequential sentence relation across languages. To train the\nmodel, we propose a masked sentence prediction task, which masks and predicts\nthe sentence vector via a hierarchical contrastive loss with sampled negatives.\nComprehensive experiments on four cross-lingual retrieval tasks show MSM\nsignificantly outperforms existing advanced pre-training models, demonstrating\nthe effectiveness and stronger cross-lingual retrieval capabilities of our\napproach. Code and model will be available.\n","authors":["Shunyu Zhang","Yaobo Liang","Ming Gong","Daxin Jiang","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2302.01626v1.pdf","comment":"Published at ICLR 2023"},{"id":"http://arxiv.org/abs/2204.11209v2","updated":"2023-02-03T05:16:39Z","published":"2022-04-24T07:18:04Z","title":"Locality Sensitive Hashing for Structured Data: A Survey","summary":"  Data similarity (or distance) computation is a fundamental research topic\nwhich fosters a variety of similarity-based machine learning and data mining\napplications. In big data analytics, it is impractical to compute the exact\nsimilarity of data instances due to high computational cost. To this end, the\nLocality Sensitive Hashing (LSH) technique has been proposed to provide\naccurate estimators for various similarity measures between sets or vectors in\nan efficient manner without the learning process. Structured data (e.g.,\nsequences, trees and graphs), which are composed of elements and relations\nbetween the elements, are commonly seen in the real world, but the traditional\nLSH algorithms cannot preserve the structure information represented as\nrelations between elements. In order to conquer the issue, researchers have\nbeen devoted to the family of the hierarchical LSH algorithms. In this paper,\nwe explore the present progress of the research into hierarchical LSH from the\nfollowing perspectives: 1) Data structures, where we review various\nhierarchical LSH algorithms for three typical data structures and uncover their\ninherent connections; 2) Applications, where we review the hierarchical LSH\nalgorithms in multiple application scenarios; 3) Challenges, where we discuss\nsome potential challenges as future directions.\n","authors":["Wei Wu","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2204.11209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01522v1","updated":"2023-02-03T03:35:28Z","published":"2023-02-03T03:35:28Z","title":"Improving Recommendation Relevance by simulating User Interest","summary":"  Most if not all on-line item-to-item recommendation systems rely on\nestimation of a distance like measure (rank) of similarity between items. For\non-line recommendation systems, time sensitivity of this similarity measure is\nextremely important. We observe that recommendation \"recency\" can be\nstraightforwardly and transparently maintained by iterative reduction of ranks\nof inactive items. The paper briefly summarizes algorithmic developments based\non this self-explanatory observation. The basic idea behind this work is\npatented in a context of online recommendation systems.\n","authors":["Alexander Kushkuley","Joshua Correa"],"pdf_url":"https://arxiv.org/pdf/2302.01522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01501v1","updated":"2023-02-03T02:31:12Z","published":"2023-02-03T02:31:12Z","title":"ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics","summary":"  As the amount of text data generated by humans and machines increases, the\nnecessity of understanding large corpora and finding a way to extract insights\nfrom them is becoming more crucial than ever. Dynamic topic models are\neffective methods that primarily focus on studying the evolution of topics\npresent in a collection of documents. These models are widely used for\nunderstanding trends, exploring public opinion in social networks, or tracking\nresearch progress and discoveries in scientific archives. Since topics are\ndefined as clusters of semantically similar documents, it is necessary to\nobserve the changes in the content or themes of these clusters in order to\nunderstand how topics evolve as new knowledge is discovered over time. In this\npaper, we introduce the Aligned Neural Topic Model (ANTM), a dynamic neural\ntopic model that uses document embeddings to compute clusters of semantically\nsimilar documents at different periods and to align document clusters to\nrepresent their evolution. This alignment procedure preserves the temporal\nsimilarity of document clusters over time and captures the semantic change of\nwords characterized by their context within different periods. Experiments on\nfour different datasets show that ANTM outperforms probabilistic dynamic topic\nmodels (e.g. DTM, DETM) and significantly improves topic coherence and\ndiversity over other existing dynamic neural topic models (e.g. BERTopic).\n","authors":["Hamed Rahimi","Hubert Naacke","Camelia Constantin","Bernd Amann"],"pdf_url":"https://arxiv.org/pdf/2302.01501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.13937v3","updated":"2023-02-03T22:46:31Z","published":"2022-12-28T16:29:52Z","title":"Towards Disentangling Relevance and Bias in Unbiased Learning to Rank","summary":"  Unbiased learning to rank (ULTR) studies the problem of mitigating various\nbiases from implicit user feedback data such as clicks, and has been receiving\nconsiderable attention recently. A popular ULTR approach for real-world\napplications uses a two-tower architecture, where click modeling is factorized\ninto a relevance tower with regular input features, and a bias tower with\nbias-relevant inputs such as the position of a document. A successful\nfactorization will allow the relevance tower to be exempt from biases. In this\nwork, we identify a critical issue that existing ULTR methods ignored - the\nbias tower can be confounded with the relevance tower via the underlying true\nrelevance. In particular, the positions were determined by the logging policy,\ni.e., the previous production model, which would possess relevance information.\nWe give both theoretical analysis and empirical results to show the negative\neffects on relevance tower due to such a correlation. We then propose three\nmethods to mitigate the negative confounding effects by better disentangling\nrelevance and bias. Empirical results on both controlled public datasets and a\nlarge-scale industry dataset show the effectiveness of the proposed approaches.\n","authors":["Yunan Zhang","Le Yan","Zhen Qin","Honglei Zhuang","Jiaming Shen","Xuanhui Wang","Michael Bendersky","Marc Najork"],"pdf_url":"https://arxiv.org/pdf/2212.13937v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10517v2","updated":"2023-02-03T22:28:50Z","published":"2022-10-19T12:50:15Z","title":"Evaluation Metrics for Measuring Bias in Search Engine Results","summary":"  Search engines decide what we see for a given search query. Since many people\nare exposed to information through search engines, it is fair to expect that\nsearch engines are neutral. However, search engine results do not necessarily\ncover all the viewpoints of a search query topic, and they can be biased\ntowards a specific view since search engine results are returned based on\nrelevance, which is calculated using many features and sophisticated algorithms\nwhere search neutrality is not necessarily the focal point. Therefore, it is\nimportant to evaluate the search engine results with respect to bias. In this\nwork we propose novel web search bias evaluation measures which take into\naccount the rank and relevance. We also propose a framework to evaluate web\nsearch bias using the proposed measures and test our framework on two popular\nsearch engines based on 57 controversial query topics such as abortion, medical\nmarijuana, and gay marriage. We measure the stance bias (in support or\nagainst), as well as the ideological bias (conservative or liberal). We observe\nthat the stance does not necessarily correlate with the ideological leaning,\ne.g. a positive stance on abortion indicates a liberal leaning but a positive\nstance on Cuba embargo indicates a conservative leaning. Our experiments show\nthat neither of the search engines suffers from stance bias. However, both\nsearch engines suffer from ideological bias, both favouring one ideological\nleaning to the other, which is more significant from the perspective of\npolarisation in our society.\n","authors":["Gizem Gezici","Aldo Lipani","Yucel Saygin","Emine Yilmaz"],"pdf_url":"https://arxiv.org/pdf/2210.10517v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07089v2","updated":"2023-02-03T21:07:10Z","published":"2022-10-13T15:14:30Z","title":"Experimenting with Selected Automated Approaches for Bias Analysis","summary":"  This work first presents our attempts to establish an automated model using\nstate-of-the-art approaches for analysing bias in search results of Bing and\nGoogle. Experimental results indicate that the current class-wise F1-scores of\nour best model are not sufficient to establish an automated model for bias\nanalysis. Thus, we decided not to continue with this approach.\n","authors":["Gizem Gezici"],"pdf_url":"https://arxiv.org/pdf/2210.07089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01971v1","updated":"2023-02-03T19:37:35Z","published":"2023-02-03T19:37:35Z","title":"How Bad is Top-$K$ Recommendation under Competing Content Creators?","summary":"  Content creators compete for exposure on recommendation platforms, and such\nstrategic behavior leads to a dynamic shift over the content distribution.\nHowever, how the creators' competition impacts user welfare and how the\nrelevance-driven recommendation influences the dynamics in the long run are\nstill largely unknown.\n  This work provides theoretical insights into these research questions. We\nmodel the creators' competition under the assumptions that: 1) the platform\nemploys an innocuous top-$K$ recommendation policy; 2) user decisions follow\nthe Random Utility model; 3) content creators compete for user engagement and,\nwithout knowing their utility function in hindsight, apply arbitrary no-regret\nlearning algorithms to update their strategies. We study the user welfare\nguarantee through the lens of Price of Anarchy and show that the fraction of\nuser welfare loss due to creator competition is always upper bounded by a small\nconstant depending on $K$ and randomness in user decisions; we also prove the\ntightness of this bound. Our result discloses an intrinsic merit of the myopic\napproach to the recommendation, i.e., relevance-driven matching performs\nreasonably well in the long run, as long as users' decisions involve randomness\nand the platform provides reasonably many alternatives to its users.\n","authors":["Fan Yao","Chuanhao Li","Denis Nekipelov","Hongning Wang","Haifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2302.01971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03495v1","updated":"2023-02-03T01:28:25Z","published":"2023-02-03T01:28:25Z","title":"Can ChatGPT Write a Good Boolean Query for Systematic Review Literature\n  Search?","summary":"  Systematic reviews are comprehensive reviews of the literature for a highly\nfocused research question. These reviews are often treated as the highest form\nof evidence in evidence-based medicine, and are the key strategy to answer\nresearch questions in the medical field. To create a high-quality systematic\nreview, complex Boolean queries are often constructed to retrieve studies for\nthe review topic. However, it often takes a long time for systematic review\nresearchers to construct a high quality systematic review Boolean query, and\noften the resulting queries are far from effective. Poor queries may lead to\nbiased or invalid reviews, because they missed to retrieve key evidence, or to\nextensive increase in review costs, because they retrieved too many irrelevant\nstudies. Recent advances in Transformer-based generative models have shown\ngreat potential to effectively follow instructions from users and generate\nanswers based on the instructions being made. In this paper, we investigate the\neffectiveness of the latest of such models, ChatGPT, in generating effective\nBoolean queries for systematic review literature search. Through a number of\nextensive experiments on standard test collections for the task, we find that\nChatGPT is capable of generating queries that lead to high search precision,\nalthough trading-off this for recall. Overall, our study demonstrates the\npotential of ChatGPT in generating effective Boolean queries for systematic\nreview literature search. The ability of ChatGPT to follow complex instructions\nand generate queries with high precision makes it a valuable tool for\nresearchers conducting systematic reviews, particularly for rapid reviews where\ntime is a constraint and often trading-off higher precision for lower recall is\nacceptable.\n","authors":["Shuai Wang","Harrisen Scells","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2302.03495v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.01928v1","updated":"2023-02-03T18:59:55Z","published":"2023-02-03T18:59:55Z","title":"Aligning Robot and Human Representations","summary":"  To act in the world, robots rely on a representation of salient task aspects:\nfor example, to carry a cup of coffee, a robot must consider movement\nefficiency and cup orientation in its behaviour. However, if we want robots to\nact for and with people, their representations must not be just functional but\nalso reflective of what humans care about, i.e. their representations must be\naligned with humans'. In this survey, we pose that current reward and imitation\nlearning approaches suffer from representation misalignment, where the robot's\nlearned representation does not capture the human's representation. We suggest\nthat because humans will be the ultimate evaluator of robot performance in the\nworld, it is critical that we explicitly focus our efforts on aligning learned\ntask representations with humans, in addition to learning the downstream task.\nWe advocate that current representation learning approaches in robotics should\nbe studied from the perspective of how well they accomplish the objective of\nrepresentation alignment. To do so, we mathematically define the problem,\nidentify its key desiderata, and situate current robot learning methods within\nthis formalism. We conclude the survey by suggesting future directions for\nexploring open challenges.\n","authors":["Andreea Bobu","Andi Peng","Pulkit Agrawal","Julie Shah","Anca D. Dragan"],"pdf_url":"https://arxiv.org/pdf/2302.01928v1.pdf","comment":"19 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2302.01925v1","updated":"2023-02-03T18:57:17Z","published":"2023-02-03T18:57:17Z","title":"Learning a Fourier Transform for Linear Relative Positional Encodings in\n  Transformers","summary":"  We propose a new class of linear Transformers called\nFourierLearner-Transformers (FLTs), which incorporate a wide range of relative\npositional encoding mechanisms (RPEs). These include regular RPE techniques\napplied for nongeometric data, as well as novel RPEs operating on the sequences\nof tokens embedded in higher-dimensional Euclidean spaces (e.g. point clouds).\nFLTs construct the optimal RPE mechanism implicitly by learning its spectral\nrepresentation. As opposed to other architectures combining efficient low-rank\nlinear attention with RPEs, FLTs remain practical in terms of their memory\nusage and do not require additional assumptions about the structure of the\nRPE-mask. FLTs allow also for applying certain structural inductive bias\ntechniques to specify masking strategies, e.g. they provide a way to learn the\nso-called local RPEs introduced in this paper and providing accuracy gains as\ncompared with several other linear Transformers for language modeling. We also\nthoroughly tested FLTs on other data modalities and tasks, such as: image\nclassification and 3D molecular modeling. For 3D-data FLTs are, to the best of\nour knowledge, the first Transformers architectures providing RPE-enhanced\nlinear attention.\n","authors":["Krzysztof Marcin Choromanski","Shanda Li","Valerii Likhosherstov","Kumar Avinava Dubey","Shengjie Luo","Di He","Yiming Yang","Tamas Sarlos","Thomas Weingarten","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2302.01925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01918v1","updated":"2023-02-03T18:52:09Z","published":"2023-02-03T18:52:09Z","title":"PyGlove: Efficiently Exchanging ML Ideas as Code","summary":"  The increasing complexity and scale of machine learning (ML) has led to the\nneed for more efficient collaboration among multiple teams. For example, when a\nresearch team invents a new architecture like \"ResNet,\" it is desirable for\nmultiple engineering teams to adopt it. However, the effort required for each\nteam to study and understand the invention does not scale well with the number\nof teams or inventions. In this paper, we present an extension of our PyGlove\nlibrary to easily and scalably share ML ideas. PyGlove represents ideas as\nsymbolic rule-based patches, enabling researchers to write down the rules for\nmodels they have not seen. For example, an inventor can write rules that will\n\"add skip-connections.\" This permits a network effect among teams: at once, any\nteam can issue patches to all other teams. Such a network effect allows users\nto quickly surmount the cost of adopting PyGlove by writing less code quicker,\nproviding a benefit that scales with time. We describe the new paradigm of\norganizing ML through symbolic patches and compare it to existing approaches.\nWe also perform a case study of a large codebase where PyGlove led to an 80%\nreduction in the number of lines of code.\n","authors":["Daiyi Peng","Xuanyi Dong","Esteban Real","Yifeng Lu","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2302.01918v1.pdf","comment":"8 pages, 10 figures, 1 table"},{"id":"http://arxiv.org/abs/2301.12534v2","updated":"2023-02-03T18:50:31Z","published":"2023-01-29T20:39:21Z","title":"Vicarious Offense and Noise Audit of Offensive Speech Classifiers","summary":"  This paper examines social web content moderation from two key perspectives:\nautomated methods (machine moderators) and human evaluators (human moderators).\nWe conduct a noise audit at an unprecedented scale using nine machine\nmoderators trained on well-known offensive speech data sets evaluated on a\ncorpus sampled from 92 million YouTube comments discussing a multitude of\nissues relevant to US politics. We introduce a first-of-its-kind data set of\nvicarious offense. We ask annotators: (1) if they find a given social media\npost offensive; and (2) how offensive annotators sharing different political\nbeliefs would find the same content. Our experiments with machine moderators\nreveal that moderation outcomes wildly vary across different machine\nmoderators. Our experiments with human moderators suggest that (1) political\nleanings considerably affect first-person offense perspective; (2) Republicans\nare the worst predictors of vicarious offense; (3) predicting vicarious offense\nfor the Republicans is most challenging than predicting vicarious offense for\nthe Independents and the Democrats; and (4) disagreement across political\nidentity groups considerably increases when sensitive issues such as\nreproductive rights or gun control/rights are discussed. Both experiments\nsuggest that offense, is indeed, highly subjective and raise important\nquestions concerning content moderation practices.\n","authors":["Tharindu Cyril Weerasooriya","Sujan Dutta","Tharindu Ranasinghe","Marcos Zampieri","Christopher M. Homan","Ashiqur R. KhudaBukhsh"],"pdf_url":"https://arxiv.org/pdf/2301.12534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01680v2","updated":"2023-02-03T18:44:47Z","published":"2022-10-04T15:22:56Z","title":"New Machine Learning Techniques for Simulation-Based Inference:\n  InferoStatic Nets, Kernel Score Estimation, and Kernel Likelihood Ratio\n  Estimation","summary":"  We propose an intuitive, machine-learning approach to multiparameter\ninference, dubbed the InferoStatic Networks (ISN) method, to model the score\nand likelihood ratio estimators in cases when the probability density can be\nsampled but not computed directly. The ISN uses a backend neural network that\nmodels a scalar function called the inferostatic potential $\\varphi$. In\naddition, we introduce new strategies, respectively called Kernel Score\nEstimation (KSE) and Kernel Likelihood Ratio Estimation (KLRE), to learn the\nscore and the likelihood ratio functions from simulated data. We illustrate the\nnew techniques with some toy examples and compare to existing approaches in the\nliterature. We mention en passant some new loss functions that optimally\nincorporate latent information from simulations into the training procedure.\n","authors":["Kyoungchul Kong","Konstantin T. Matchev","Stephen Mrenna","Prasanth Shyamsundar"],"pdf_url":"https://arxiv.org/pdf/2210.01680v2.pdf","comment":"36 pages, 10 figures. Submission to SciPost"},{"id":"http://arxiv.org/abs/2210.13148v4","updated":"2023-02-03T18:31:31Z","published":"2022-10-24T12:04:52Z","title":"Transformers over Directed Acyclic Graphs","summary":"  Transformer models have recently gained popularity in graph representation\nlearning as they have the potential to learn complex relationships beyond the\nones captured by regular graph neural networks. The main research question is\nhow to inject the structural bias of graphs into the transformer architecture,\nand several proposals have been made for undirected molecular graphs and,\nrecently, also for larger network graphs. In this paper, we study transformers\nover directed acyclic graphs (DAGs) and propose architecture adaptations\ntailored to DAGs: (1) An attention mechanism that is more efficient than the\nregular quadratic complexity of transformers and at the same time faithfully\ncaptures the DAG structure, and (2) a positional encoding of the DAG's partial\norder, complementing the former. We rigorously evaluate our framework in\nablation studies and show that it is effective in improving different kinds of\nbaseline transformers over various types of data, in experiments ranging from\nclassifying source code graphs to nodes in self-citation networks. In\nparticular, our proposal makes (graph) transformers competitive to or\noutperform graph neural networks tailored to DAGs.\n","authors":["Yuankai Luo","Veronika Thost","Yicheng Pan","Lei Shi"],"pdf_url":"https://arxiv.org/pdf/2210.13148v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00812v2","updated":"2023-02-03T18:24:56Z","published":"2022-12-16T01:04:52Z","title":"One-shot domain adaptation in video-based assessment of surgical skills","summary":"  Deep Learning (DL) has achieved automatic and objective assessment of\nsurgical skills. However, DL models are data-hungry and restricted to their\ntraining domain. This prevents them from transitioning to new tasks where data\nis limited. Hence, domain adaptation is crucial to implement DL in real life.\nHere, we propose a meta-learning model, A-VBANet, that can deliver\ndomain-agnostic surgical skill classification via one-shot learning. We develop\nthe A-VBANet on five laparoscopic and robotic surgical simulators.\nAdditionally, we test it on operating room (OR) videos of laparoscopic\ncholecystectomy. Our model successfully adapts with accuracies up to 99.5% in\none-shot and 99.9% in few-shot settings for simulated tasks and 89.7% for\nlaparoscopic cholecystectomy. For the first time, we provide a domain-agnostic\nprocedure for video-based assessment of surgical skills. A significant\nimplication of this approach is that it allows the use of data from surgical\nsimulators to assess performance in the operating room.\n","authors":["Erim Yanik","Steven Schwaitzberg","Gene Yang","Xavier Intes","Suvranu De"],"pdf_url":"https://arxiv.org/pdf/2301.00812v2.pdf","comment":"12 pages (+9 pages of Supplementary Materials), 4 figures (+2\n  Supplementary Figures), 2 tables (+5 Supplementary Tables)"},{"id":"http://arxiv.org/abs/2302.01888v1","updated":"2023-02-03T17:53:40Z","published":"2023-02-03T17:53:40Z","title":"Enhancing Once-For-All: A Study on Parallel Blocks, Skip Connections and\n  Early Exits","summary":"  The use of Neural Architecture Search (NAS) techniques to automate the design\nof neural networks has become increasingly popular in recent years. The\nproliferation of devices with different hardware characteristics using such\nneural networks, as well as the need to reduce the power consumption for their\nsearch, has led to the realisation of Once-For-All (OFA), an eco-friendly\nalgorithm characterised by the ability to generate easily adaptable models\nthrough a single learning process. In order to improve this paradigm and\ndevelop high-performance yet eco-friendly NAS techniques, this paper presents\nOFAv2, the extension of OFA aimed at improving its performance while\nmaintaining the same ecological advantage. The algorithm is improved from an\narchitectural point of view by including early exits, parallel blocks and dense\nskip connections. The training process is extended by two new phases called\nElastic Level and Elastic Height. A new Knowledge Distillation technique is\npresented to handle multi-output networks, and finally a new strategy for\ndynamic teacher network selection is proposed. These modifications allow OFAv2\nto improve its accuracy performance on the Tiny ImageNet dataset by up to\n12.07% compared to the original version of OFA, while maintaining the algorithm\nflexibility and advantages.\n","authors":["Simone Sarti","Eugenio Lomurno","Andrea Falanti","Matteo Matteucci"],"pdf_url":"https://arxiv.org/pdf/2302.01888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01887v1","updated":"2023-02-03T17:47:42Z","published":"2023-02-03T17:47:42Z","title":"Analyzing the impact of climate change on critical infrastructure from\n  the scientific literature: A weakly supervised NLP approach","summary":"  Natural language processing (NLP) is a promising approach for analyzing large\nvolumes of climate-change and infrastructure-related scientific literature.\nHowever, best-in-practice NLP techniques require large collections of relevant\ndocuments (corpus). Furthermore, NLP techniques using machine learning and deep\nlearning techniques require labels grouping the articles based on user-defined\ncriteria for a significant subset of a corpus in order to train the supervised\nmodel. Even labeling a few hundred documents with human subject-matter experts\nis a time-consuming process. To expedite this process, we developed a weak\nsupervision-based NLP approach that leverages semantic similarity between\ncategories and documents to (i) establish a topic-specific corpus by subsetting\na large-scale open-access corpus and (ii) generate category labels for the\ntopic-specific corpus. In comparison with a months-long process of\nsubject-matter expert labeling, we assign category labels to the whole corpus\nusing weak supervision and supervised learning in about 13 hours. The labeled\nclimate and NCF corpus enable targeted, efficient identification of documents\ndiscussing a topic (or combination of topics) of interest and identification of\nvarious effects of climate change on critical infrastructure, improving the\nusability of scientific literature and ultimately supporting enhanced policy\nand decision making. To demonstrate this capability, we conduct topic modeling\non pairs of climate hazards and NCFs to discover trending topics at the\nintersection of these categories. This method is useful for analysts and\ndecision-makers to quickly grasp the relevant topics and most important\ndocuments linked to the topic.\n","authors":["Tanwi Mallick","Joshua David Bergerson","Duane R. Verner","John K Hutchison","Leslie-Anne Levy","Prasanna Balaprakash"],"pdf_url":"https://arxiv.org/pdf/2302.01887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01108v2","updated":"2023-02-03T17:32:18Z","published":"2022-10-03T17:48:32Z","title":"SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis","summary":"  We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,372\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).\n","authors":["Jiaxin Pei","Vítor Silva","Maarten Bos","Yozon Liu","Leonardo Neves","David Jurgens","Francesco Barbieri"],"pdf_url":"https://arxiv.org/pdf/2210.01108v2.pdf","comment":"SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis"},{"id":"http://arxiv.org/abs/2302.01877v1","updated":"2023-02-03T17:28:59Z","published":"2023-02-03T17:28:59Z","title":"AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners","summary":"  Diffusion models have demonstrated their powerful generative capability in\nmany tasks, with great potential to serve as a paradigm for offline\nreinforcement learning. However, the quality of the diffusion model is limited\nby the insufficient diversity of training data, which hinders the performance\nof planning and the generalizability to new tasks. This paper introduces\nAdaptDiffuser, an evolutionary planning method with diffusion that can\nself-evolve to improve the diffusion model hence a better planner, not only for\nseen tasks but can also adapt to unseen tasks. AdaptDiffuser enables the\ngeneration of rich synthetic expert data for goal-conditioned tasks using\nguidance from reward gradients. It then selects high-quality data via a\ndiscriminator to finetune the diffusion model, which improves the\ngeneralization ability to unseen tasks. Empirical experiments on two benchmark\nenvironments and two carefully designed unseen tasks in KUKA industrial robot\narm and Maze2D environments demonstrate the effectiveness of AdaptDiffuser. For\nexample, AdaptDiffuser not only outperforms the previous art Diffuser by 20.8%\non Maze2D and 7.5% on MuJoCo locomotion, but also adapts better to new tasks,\ne.g., KUKA pick-and-place, by 27.9% without requiring additional expert data.\n","authors":["Zhixuan Liang","Yao Mu","Mingyu Ding","Fei Ni","Masayoshi Tomizuka","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2302.01877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12095v2","updated":"2023-02-03T17:22:07Z","published":"2023-01-28T05:30:51Z","title":"MetaNO: How to Transfer Your Knowledge on Learning Hidden Physics","summary":"  Gradient-based meta-learning methods have primarily been applied to classical\nmachine learning tasks such as image classification. Recently, PDE-solving deep\nlearning methods, such as neural operators, are starting to make an important\nimpact on learning and predicting the response of a complex physical system\ndirectly from observational data. Since the data acquisition in this context is\ncommonly challenging and costly, the call of utilization and transfer of\nexisting knowledge to new and unseen physical systems is even more acute.\nHerein, we propose a novel meta-learning approach for neural operators, which\ncan be seen as transferring the knowledge of solution operators between\ngoverning (unknown) PDEs with varying parameter fields. Our approach is a\nprovably universal solution operator for multiple PDE solving tasks, with a key\ntheoretical observation that underlying parameter fields can be captured in the\nfirst layer of neural operator models, in contrast to typical final-layer\ntransfer in existing meta-learning methods. As applications, we demonstrate the\nefficacy of our proposed approach on PDE-based datasets and a real-world\nmaterial modeling problem, illustrating that our method can handle complex and\nnonlinear physical response learning tasks while greatly improving the sampling\nefficiency in unseen tasks.\n","authors":["Lu Zhang","Huaiqian You","Tian Gao","Mo Yu","Chung-Hao Lee","Yue Yu"],"pdf_url":"https://arxiv.org/pdf/2301.12095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15375v3","updated":"2023-02-03T17:14:34Z","published":"2022-11-24T06:08:24Z","title":"Software Simulation and Visualization of Quantum Multi-Drone\n  Reinforcement Learning","summary":"  Quantum machine learning (QML) has received a lot of attention according to\nits light training parameter numbers and speeds; and the advances of QML lead\nto active research on quantum multi-agent reinforcement learning (QMARL).\nExisting classical multi-agent reinforcement learning (MARL) features\nnon-stationarity and uncertain properties. Therefore, this paper presents a\nsimulation software framework for novel QMARL to control autonomous\nmulti-drones, i.e., quantum multi-drone reinforcement learning. Our proposed\nframework accomplishes reasonable reward convergence and service quality\nperformance with fewer trainable parameters. Furthermore, it shows more stable\ntraining results. Lastly, our proposed software allows us to analyze the\ntraining process and results.\n","authors":["Chanyoung Park","Jae Pyoung Kim","Won Joon Yun","Soohyun Park","Soyi Jung","Joongheon Kim"],"pdf_url":"https://arxiv.org/pdf/2211.15375v3.pdf","comment":"Revise paper"},{"id":"http://arxiv.org/abs/2201.01854v2","updated":"2023-02-03T17:10:46Z","published":"2022-01-04T10:02:48Z","title":"Learning finite difference methods for reaction-diffusion type equations\n  with FCNN","summary":"  In recent years, Physics-informed neural networks (PINNs) have been widely\nused to solve partial differential equations alongside numerical methods\nbecause PINNs can be trained without observations and deal with continuous-time\nproblems directly. In contrast, optimizing the parameters of such models is\ndifficult, and individual training sessions must be performed to predict the\nevolutions of each different initial condition. To alleviate the first problem,\nobserved data can be injected directly into the loss function part. To solve\nthe second problem, a network architecture can be built as a framework to learn\na finite difference method. In view of the two motivations, we propose\nFive-point stencil CNNs (FCNNs) containing a five-point stencil kernel and a\ntrainable approximation function for reaction-diffusion type equations\nincluding the heat, Fisher's, Allen-Cahn, and other reaction-diffusion\nequations with trigonometric function terms. We show that FCNNs can learn\nfinite difference schemes using few data and achieve the low relative errors of\ndiverse reaction-diffusion evolutions with unseen initial conditions.\nFurthermore, we demonstrate that FCNNs can still be trained well even with\nusing noisy data.\n","authors":["Yongho Kim","Yongho Choi"],"pdf_url":"https://arxiv.org/pdf/2201.01854v2.pdf","comment":"9 figures"},{"id":"http://arxiv.org/abs/2301.12056v4","updated":"2023-02-03T17:10:40Z","published":"2023-01-28T02:20:03Z","title":"Variational Latent Branching Model for Off-Policy Evaluation","summary":"  Model-based methods have recently shown great potential for off-policy\nevaluation (OPE); offline trajectories induced by behavioral policies are\nfitted to transitions of Markov decision processes (MDPs), which are used to\nrollout simulated trajectories and estimate the performance of policies.\nModel-based OPE methods face two key challenges. First, as offline trajectories\nare usually fixed, they tend to cover limited state and action space. Second,\nthe performance of model-based methods can be sensitive to the initialization\nof their parameters. In this work, we propose the variational latent branching\nmodel (VLBM) to learn the transition function of MDPs by formulating the\nenvironmental dynamics as a compact latent space, from which the next states\nand rewards are then sampled. Specifically, VLBM leverages and extends the\nvariational inference framework with the recurrent state alignment (RSA), which\nis designed to capture as much information underlying the limited training\ndata, by smoothing out the information flow between the variational (encoding)\nand generative (decoding) part of VLBM. Moreover, we also introduce the\nbranching architecture to improve the model's robustness against randomly\ninitialized model weights. The effectiveness of the VLBM is evaluated on the\ndeep OPE (DOPE) benchmark, from which the training trajectories are designed to\nresult in varied coverage of the state-action space. We show that the VLBM\noutperforms existing state-of-the-art OPE methods in general.\n","authors":["Qitong Gao","Ge Gao","Min Chi","Miroslav Pajic"],"pdf_url":"https://arxiv.org/pdf/2301.12056v4.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01855v1","updated":"2023-02-03T16:57:57Z","published":"2023-02-03T16:57:57Z","title":"From Robustness to Privacy and Back","summary":"  We study the relationship between two desiderata of algorithms in statistical\ninference and machine learning: differential privacy and robustness to\nadversarial data corruptions. Their conceptual similarity was first observed by\nDwork and Lei (STOC 2009), who observed that private algorithms satisfy\nrobustness, and gave a general method for converting robust algorithms to\nprivate ones. However, all general methods for transforming robust algorithms\ninto private ones lead to suboptimal error rates. Our work gives the first\nblack-box transformation that converts any adversarially robust algorithm into\none that satisfies pure differential privacy. Moreover, we show that for any\nlow-dimensional estimation task, applying our transformation to an optimal\nrobust estimator results in an optimal private estimator. Thus, we conclude\nthat for any low-dimensional task, the optimal error rate for\n$\\varepsilon$-differentially private estimators is essentially the same as the\noptimal error rate for estimators that are robust to adversarially corrupting\n$1/\\varepsilon$ training samples. We apply our transformation to obtain new\noptimal private estimators for several high-dimensional tasks, including\nGaussian (sparse) linear regression and PCA. Finally, we present an extension\nof our transformation that leads to approximate differentially private\nalgorithms whose error does not depend on the range of the output space, which\nis impossible under pure differential privacy.\n","authors":["Hilal Asi","Jonathan Ullman","Lydia Zakynthinou"],"pdf_url":"https://arxiv.org/pdf/2302.01855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01851v1","updated":"2023-02-03T16:53:32Z","published":"2023-02-03T16:53:32Z","title":"Unsupervised hierarchical clustering using the learning dynamics of RBMs","summary":"  Datasets in the real world are often complex and to some degree hierarchical,\nwith groups and sub-groups of data sharing common characteristics at different\nlevels of abstraction. Understanding and uncovering the hidden structure of\nthese datasets is an important task that has many practical applications. To\naddress this challenge, we present a new and general method for building\nrelational data trees by exploiting the learning dynamics of the Restricted\nBoltzmann Machine (RBM). Our method is based on the mean-field approach,\nderived from the Plefka expansion, and developed in the context of disordered\nsystems. It is designed to be easily interpretable. We tested our method in an\nartificially created hierarchical dataset and on three different real-world\ndatasets (images of digits, mutations in the human genome, and a homologous\nfamily of proteins). The method is able to automatically identify the\nhierarchical structure of the data. This could be useful in the study of\nhomologous protein sequences, where the relationships between proteins are\ncritical for understanding their function and evolution.\n","authors":["Aurélien Decelle","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2302.01851v1.pdf","comment":"33 pages, 17 figures"},{"id":"http://arxiv.org/abs/2302.01842v1","updated":"2023-02-03T16:37:08Z","published":"2023-02-03T16:37:08Z","title":"A Case Study for Compliance as Code with Graphs and Language Models:\n  Public release of the Regulatory Knowledge Graph","summary":"  The paper presents a study on using language models to automate the\nconstruction of executable Knowledge Graph (KG) for compliance. The paper\nfocuses on Abu Dhabi Global Market regulations and taxonomy, involves manual\ntagging a portion of the regulations, training BERT-based models, which are\nthen applied to the rest of the corpus. Coreference resolution and syntax\nanalysis were used to parse the relationships between the tagged entities and\nto form KG stored in a Neo4j database. The paper states that the use of machine\nlearning models released by regulators to automate the interpretation of rules\nis a vital step towards compliance automation, demonstrates the concept\nquerying with Cypher, and states that the produced sub-graphs combined with\nGraph Neural Networks (GNN) will achieve expandability in judgment automation\nsystems. The graph is open sourced on GitHub to provide structured data for\nfuture advancements in the field.\n","authors":["Vladimir Ershov"],"pdf_url":"https://arxiv.org/pdf/2302.01842v1.pdf","comment":"7 pages on RegKG step 1 in collaboration with ADGM"},{"id":"http://arxiv.org/abs/2302.01834v1","updated":"2023-02-03T16:19:43Z","published":"2023-02-03T16:19:43Z","title":"Coinductive guide to inductive transformer heads","summary":"  We argue that all building blocks of transformer models can be expressed with\na single concept: combinatorial Hopf algebra. Transformer learning emerges as a\nresult of the subtle interplay between the algebraic and coalgebraic operations\nof the combinatorial Hopf algebra. Viewed through this lens, the transformer\nmodel becomes a linear time-invariant system where the attention mechanism\ncomputes a generalized convolution transform and the residual stream serves as\na unit impulse. Attention-only transformers then learn by enforcing an\ninvariant between these two paths. We call this invariant Hopf coherence. Due\nto this, with a degree of poetic license, one could call combinatorial Hopf\nalgebras \"tensors with a built-in loss function gradient\". This loss function\ngradient occurs within the single layers and no backward pass is needed. This\nis in contrast to automatic differentiation which happens across the whole\ngraph and needs a explicit backward pass. This property is the result of the\nfact that combinatorial Hopf algebras have the surprising property of\ncalculating eigenvalues by repeated squaring.\n","authors":["Adam Nemecek"],"pdf_url":"https://arxiv.org/pdf/2302.01834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13521v2","updated":"2023-02-03T16:05:26Z","published":"2022-05-26T17:40:52Z","title":"Discovering Policies with DOMiNO: Diversity Optimization Maintaining\n  Near Optimality","summary":"  Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method\nfor Diversity Optimization Maintaining Near Optimality. We formalize the\nproblem as a Constrained Markov Decision Process where the objective is to find\ndiverse policies, measured by the distance between the state occupancies of the\npolicies in the set, while remaining near-optimal with respect to the extrinsic\nreward. We demonstrate that the method can discover diverse and meaningful\nbehaviors in various domains, such as different locomotion patterns in the\nDeepMind Control Suite. We perform extensive analysis of our approach, compare\nit with other multi-objective baselines, demonstrate that we can control both\nthe quality and the diversity of the set via interpretable hyperparameters, and\nshow that the discovered set is robust to perturbations.\n","authors":["Tom Zahavy","Yannick Schroecker","Feryal Behbahani","Kate Baumli","Sebastian Flennerhag","Shaobo Hou","Satinder Singh"],"pdf_url":"https://arxiv.org/pdf/2205.13521v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01827v1","updated":"2023-02-03T16:03:49Z","published":"2023-02-03T16:03:49Z","title":"Online Ad Allocation with Predictions","summary":"  Display Ads and the generalized assignment problem are two well-studied\nonline packing problems with important applications in ad allocation and other\nareas. In both problems, ad impressions arrive online and have to be allocated\nimmediately to budget-constrained advertisers. Worst-case algorithms that\nachieve the ideal competitive ratio are known, but might act overly\nconservative given the predictable and usually tame nature of real-world input.\nGiven this discrepancy, we develop an algorithm for both problems that\nincorporate machine-learned predictions and can thus improve the performance\nbeyond the worst-case. Our algorithm is based on the work of Feldman et al.\n(2009) and similar in nature to Mahdian et al. (2007) who were the first to\ndevelop a learning-augmented algorithm for the related, but more structured Ad\nWords problem. We use a novel analysis to show that our algorithm is able to\ncapitalize on a good prediction, while being robust against poor predictions.\nWe experimentally evaluate our algorithm on synthetic and real-world data on a\nwide range of predictions. Our algorithm is consistently outperforming the\nworst-case algorithm without predictions.\n","authors":["Fabian Spaeh","Alina Ene"],"pdf_url":"https://arxiv.org/pdf/2302.01827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12485v2","updated":"2023-02-03T15:51:22Z","published":"2023-01-29T16:44:19Z","title":"Generating Novel, Designable, and Diverse Protein Structures by\n  Equivariantly Diffusing Oriented Residue Clouds","summary":"  Proteins power a vast array of functional processes in living cells. The\ncapability to create new proteins with designed structures and functions would\nthus enable the engineering of cellular behavior and development of\nprotein-based therapeutics and materials. Structure-based protein design aims\nto find structures that are designable (can be realized by a protein sequence),\nnovel (have dissimilar geometry from natural proteins), and diverse (span a\nwide range of geometries). While advances in protein structure prediction have\nmade it possible to predict structures of novel protein sequences, the\ncombinatorially large space of sequences and structures limits the practicality\nof search-based methods. Generative models provide a compelling alternative, by\nimplicitly learning the low-dimensional structure of complex data\ndistributions. Here, we leverage recent advances in denoising diffusion\nprobabilistic models and equivariant neural networks to develop Genie, a\ngenerative model of protein structures that performs discrete-time diffusion\nusing a cloud of oriented reference frames in 3D space. Through in silico\nevaluations, we demonstrate that Genie generates protein backbones that are\nmore designable, novel, and diverse than existing models. This indicates that\nGenie is capturing key aspects of the distribution of protein structure space\nand facilitates protein design with high success rates. Code for generating new\nproteins and training new versions of Genie is available at\nhttps://github.com/aqlaboratory/genie.\n","authors":["Yeqing Lin","Mohammed AlQuraishi"],"pdf_url":"https://arxiv.org/pdf/2301.12485v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.07911v4","updated":"2023-02-03T15:37:23Z","published":"2021-11-15T17:00:03Z","title":"On the Tradeoff between Energy, Precision, and Accuracy in Federated\n  Quantized Neural Networks","summary":"  Deploying federated learning (FL) over wireless networks with\nresource-constrained devices requires balancing between accuracy, energy\nefficiency, and precision. Prior art on FL often requires devices to train deep\nneural networks (DNNs) using a 32-bit precision level for data representation\nto improve accuracy. However, such algorithms are impractical for\nresource-constrained devices since DNNs could require execution of millions of\noperations. Thus, training DNNs with a high precision level incurs a high\nenergy cost for FL. In this paper, a quantized FL framework, that represents\ndata with a finite level of precision in both local training and uplink\ntransmission, is proposed. Here, the finite level of precision is captured\nthrough the use of quantized neural networks (QNNs) that quantize weights and\nactivations in fixed-precision format. In the considered FL model, each device\ntrains its QNN and transmits a quantized training result to the base station.\nEnergy models for the local training and the transmission with the quantization\nare rigorously derived. An energy minimization problem is formulated with\nrespect to the level of precision while ensuring convergence. To solve the\nproblem, we first analytically derive the FL convergence rate and use a line\nsearch method. Simulation results show that our FL framework can reduce energy\nconsumption by up to 53% compared to a standard FL model. The results also shed\nlight on the tradeoff between precision, energy, and accuracy in FL over\nwireless networks.\n","authors":["Minsu Kim","Walid Saad","Mohammad Mozaffari","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2111.07911v4.pdf","comment":"This paper is accepted by IEEE International Conference on\n  Communications 2022"},{"id":"http://arxiv.org/abs/2302.01813v1","updated":"2023-02-03T15:35:54Z","published":"2023-02-03T15:35:54Z","title":"Leveraging weak complementary labels to improve semantic segmentation of\n  hepatocellular carcinoma and cholangiocarcinoma in H&E-stained slides","summary":"  In this paper, we present a deep learning segmentation approach to classify\nand quantify the two most prevalent primary liver cancers - hepatocellular\ncarcinoma and intrahepatic cholangiocarcinoma - from hematoxylin and eosin\n(H&E) stained whole slide images. While semantic segmentation of medical images\ntypically requires costly pixel-level annotations by domain experts, there\noften exists additional information which is routinely obtained in clinical\ndiagnostics but rarely utilized for model training. We propose to leverage such\nweak information from patient diagnoses by deriving complementary labels that\nindicate to which class a sample cannot belong to. To integrate these labels,\nwe formulate a complementary loss for segmentation. Motivated by the medical\napplication, we demonstrate for general segmentation tasks that including\nadditional patches with solely weak complementary labels during model training\ncan significantly improve the predictive performance and robustness of a model.\nOn the task of diagnostic differentiation between hepatocellular carcinoma and\nintrahepatic cholangiocarcinoma, we achieve a balanced accuracy of 0.91 (CI\n95%: 0.86 - 0.95) at case level for 165 hold-out patients. Furthermore, we also\nshow that leveraging complementary labels improves the robustness of\nsegmentation and increases performance at case level.\n","authors":["Miriam Hägele","Johannes Eschrich","Lukas Ruff","Maximilian Alber","Simon Schallenberg","Adrien Guillot","Christoph Roderburg","Frank Tacke","Frederick Klauschen"],"pdf_url":"https://arxiv.org/pdf/2302.01813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01810v1","updated":"2023-02-03T15:27:50Z","published":"2023-02-03T15:27:50Z","title":"PINN Training using Biobjective Optimization: The Trade-off between Data\n  Loss and Residual Loss","summary":"  Physics informed neural networks (PINNs) have proven to be an efficient tool\nto represent problems for which measured data are available and for which the\ndynamics in the data are expected to follow some physical laws. In this paper,\nwe suggest a multiobjective perspective on the training of PINNs by treating\nthe data loss and the residual loss as two individual objective functions in a\ntruly biobjective optimization approach. As a showcase example, we consider\nCOVID-19 predictions in Germany and built an extended\nsusceptibles-infected-recovered (SIR) model with additionally considered\nleaky-vaccinated and hospitalized populations (SVIHR model) to model the\ntransition rates and to predict future infections. SIR-type models are\nexpressed by systems of ordinary differential equations (ODEs). We investigate\nthe suitability of the generated PINN for COVID-19 predictions and compare the\nresulting predicted curves with those obtained by applying the method of\nnon-standard finite differences to the system of ODEs and initial data. The\napproach is applicable to various systems of ODEs that define dynamical\nregimes. Those regimes do not need to be SIR-type models, and the corresponding\nunderlying data sets do not have to be associated with COVID-19.\n","authors":["Fabian Heldmann","Sarah Berkhahn","Matthias Ehrhardt","Kathrin Klamroth"],"pdf_url":"https://arxiv.org/pdf/2302.01810v1.pdf","comment":"47 pages"},{"id":"http://arxiv.org/abs/2302.01800v1","updated":"2023-02-03T15:11:39Z","published":"2023-02-03T15:11:39Z","title":"Creating Probabilistic Forecasts from Arbitrary Deterministic Forecasts\n  using Conditional Invertible Neural Networks","summary":"  In various applications, probabilistic forecasts are required to quantify the\ninherent uncertainty associated with the forecast. However, numerous modern\nforecasting methods are still designed to create deterministic forecasts.\nTransforming these deterministic forecasts into probabilistic forecasts is\noften challenging and based on numerous assumptions that may not hold in\nreal-world situations. Therefore, the present article proposes a novel approach\nfor creating probabilistic forecasts from arbitrary deterministic forecasts. In\norder to implement this approach, we use a conditional Invertible Neural\nNetwork (cINN). More specifically, we apply a cINN to learn the underlying\ndistribution of the data and then combine the uncertainty from this\ndistribution with an arbitrary deterministic forecast to generate accurate\nprobabilistic forecasts. Our approach enables the simple creation of\nprobabilistic forecasts without complicated statistical loss functions or\nfurther assumptions. Besides showing the mathematical validity of our approach,\nwe empirically show that our approach noticeably outperforms traditional\nmethods for including uncertainty in deterministic forecasts and generally\noutperforms state-of-the-art probabilistic forecasting benchmarks.\n","authors":["Kaleb Phipps","Benedikt Heidrich","Marian Turowski","Moritz Wittig","Ralf Mikut","Veit Hagenmeyer"],"pdf_url":"https://arxiv.org/pdf/2302.01800v1.pdf","comment":"Preprint submitted to the International Journal of Forecasting"},{"id":"http://arxiv.org/abs/2302.01798v1","updated":"2023-02-03T15:10:17Z","published":"2023-02-03T15:10:17Z","title":"Interpretations of Domain Adaptations via Layer Variational Analysis","summary":"  Transfer learning is known to perform efficiently in many applications\nempirically, yet limited literature reports the mechanism behind the scene.\nThis study establishes both formal derivations and heuristic analysis to\nformulate the theory of transfer learning in deep learning. Our framework\nutilizing layer variational analysis proves that the success of transfer\nlearning can be guaranteed with corresponding data conditions. Moreover, our\ntheoretical calculation yields intuitive interpretations towards the knowledge\ntransfer process. Subsequently, an alternative method for network-based\ntransfer learning is derived. The method shows an increase in efficiency and\naccuracy for domain adaptation. It is particularly advantageous when new domain\ndata is sufficiently sparse during adaptation. Numerical experiments over\ndiverse tasks validated our theory and verified that our analytic expression\nachieved better performance in domain adaptation than the gradient descent\nmethod.\n","authors":["Huan-Hsin Tseng","Hsin-Yi Lin","Kuo-Hsuan Hung","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2302.01798v1.pdf","comment":"To be published at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01772v1","updated":"2023-02-03T14:30:25Z","published":"2023-02-03T14:30:25Z","title":"Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity","summary":"  Byzantine machine learning (ML) aims to ensure the resilience of distributed\nlearning algorithms to misbehaving (or Byzantine) machines. Although this\nproblem received significant attention, prior works often assume the data held\nby the machines to be homogeneous, which is seldom true in practical settings.\nData heterogeneity makes Byzantine ML considerably more challenging, since a\nByzantine machine can hardly be distinguished from a non-Byzantine outlier. A\nfew solutions have been proposed to tackle this issue, but these provide\nsuboptimal probabilistic guarantees and fare poorly in practice. This paper\ncloses the theoretical gap, achieving optimality and inducing good empirical\nresults. In fact, we show how to automatically adapt existing solutions for\n(homogeneous) Byzantine ML to the heterogeneous setting through a powerful\nmechanism, we call nearest neighbor mixing (NNM), which boosts any standard\nrobust distributed gradient descent variant to yield optimal Byzantine\nresilience under heterogeneity. We obtain similar guarantees (in expectation)\nby plugging NNM in the distributed stochastic heavy ball method, a practical\nsubstitute to distributed gradient descent. We obtain empirical results that\nsignificantly outperform state-of-the-art Byzantine ML solutions.\n","authors":["Youssef Allouah","Sadegh Farhadkhani","Rachid Guerraoui","Nirupam Gupta","Rafael Pinot","John Stephan"],"pdf_url":"https://arxiv.org/pdf/2302.01772v1.pdf","comment":"Accepted paper at AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.01771v1","updated":"2023-02-03T14:29:31Z","published":"2023-02-03T14:29:31Z","title":"Using Explainability to Inform Statistical Downscaling Based on Deep\n  Learning Beyond Standard Validation Approaches","summary":"  Deep learning (DL) has emerged as a promising tool to downscale climate\nprojections at regional-to-local scales from large-scale atmospheric fields\nfollowing the perfect-prognosis (PP) approach. Given their complexity, it is\ncrucial to properly evaluate these methods, especially when applied to changing\nclimatic conditions where the ability to extrapolate/generalise is key. In this\nwork, we intercompare several DL models extracted from the literature for the\nsame challenging use-case (downscaling temperature in the CORDEX North America\ndomain) and expand standard evaluation methods building on eXplainable\nartifical intelligence (XAI) techniques. We show how these techniques can be\nused to unravel the internal behaviour of these models, providing new\nevaluation dimensions and aiding in their diagnostic and design. These results\nshow the usefulness of incorporating XAI techniques into statistical\ndownscaling evaluation frameworks, especially when working with large regions\nand/or under climate change conditions.\n","authors":["Jose González-Abad","Jorge Baño-Medina","José Manuel Gutiérrez"],"pdf_url":"https://arxiv.org/pdf/2302.01771v1.pdf","comment":"Under review for Journal of Advances in Modeling Earth Systems"},{"id":"http://arxiv.org/abs/2302.01075v2","updated":"2023-02-03T14:04:56Z","published":"2023-02-02T13:05:27Z","title":"MonoFlow: Rethinking Divergence GANs via the Perspective of Differential\n  Equations","summary":"  The conventional understanding of adversarial training in generative\nadversarial networks (GANs) is that the discriminator is trained to estimate a\ndivergence, and the generator learns to minimize this divergence. We argue that\ndespite the fact that many variants of GANs were developed following this\nparadigm, the current theoretical understanding of GANs and their practical\nalgorithms are inconsistent. In this paper, we leverage Wasserstein gradient\nflows which characterize the evolution of particles in the sample space, to\ngain theoretical insights and algorithmic inspiration of GANs. We introduce a\nunified generative modeling framework - MonoFlow: the particle evolution is\nrescaled via a monotonically increasing mapping of the log density ratio. Under\nour framework, adversarial training can be viewed as a procedure first\nobtaining MonoFlow's vector field via training the discriminator and the\ngenerator learns to draw the particle flow defined by the corresponding vector\nfield. We also reveal the fundamental difference between variational divergence\nminimization and adversarial training. This analysis helps us to identify what\ntypes of generator loss functions can lead to the successful training of GANs\nand suggest that GANs may have more loss designs beyond the literature (e.g.,\nnon-saturated loss), as long as they realize MonoFlow. Consistent empirical\nstudies are included to validate the effectiveness of our framework.\n","authors":["Mingxuan Yi","Zhanxing Zhu","Song Liu"],"pdf_url":"https://arxiv.org/pdf/2302.01075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01740v1","updated":"2023-02-03T14:00:05Z","published":"2023-02-03T14:00:05Z","title":"A Systematic Evaluation of Backdoor Trigger Characteristics in Image\n  Classification","summary":"  Deep learning achieves outstanding results in many machine learning tasks.\nNevertheless, it is vulnerable to backdoor attacks that modify the training set\nto embed a secret functionality in the trained model. The modified training\nsamples have a secret property, i.e., a trigger. At inference time, the secret\nfunctionality is activated when the input contains the trigger, while the model\nfunctions correctly in other cases. While there are many known backdoor attacks\n(and defenses), deploying a stealthy attack is still far from trivial.\nSuccessfully creating backdoor triggers heavily depends on numerous parameters.\nUnfortunately, research has not yet determined which parameters contribute most\nto the attack performance.\n  This paper systematically analyzes the most relevant parameters for the\nbackdoor attacks, i.e., trigger size, position, color, and poisoning rate.\nUsing transfer learning, which is very common in computer vision, we evaluate\nthe attack on numerous state-of-the-art models (ResNet, VGG, AlexNet, and\nGoogLeNet) and datasets (MNIST, CIFAR10, and TinyImageNet). Our attacks cover\nthe majority of backdoor settings in research, providing concrete directions\nfor future works. Our code is publicly available to facilitate the\nreproducibility of our results.\n","authors":["Gorka Abad","Jing Xu","Stefanos Koffas","Behrad Tajalli","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2302.01740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01738v1","updated":"2023-02-03T13:55:30Z","published":"2023-02-03T13:55:30Z","title":"AIROGS: Artificial Intelligence for RObust Glaucoma Screening Challenge","summary":"  The early detection of glaucoma is essential in preventing visual impairment.\nArtificial intelligence (AI) can be used to analyze color fundus photographs\n(CFPs) in a cost-effective manner, making glaucoma screening more accessible.\nWhile AI models for glaucoma screening from CFPs have shown promising results\nin laboratory settings, their performance decreases significantly in real-world\nscenarios due to the presence of out-of-distribution and low-quality images. To\naddress this issue, we propose the Artificial Intelligence for Robust Glaucoma\nScreening (AIROGS) challenge. This challenge includes a large dataset of around\n113,000 images from about 60,000 patients and 500 different screening centers,\nand encourages the development of algorithms that are robust to ungradable and\nunexpected input data. We evaluated solutions from 14 teams in this paper, and\nfound that the best teams performed similarly to a set of 20 expert\nophthalmologists and optometrists. The highest-scoring team achieved an area\nunder the receiver operating characteristic curve of 0.99 (95% CI: 0.98-0.99)\nfor detecting ungradable images on-the-fly. Additionally, many of the\nalgorithms showed robust performance when tested on three other publicly\navailable datasets. These results demonstrate the feasibility of robust\nAI-enabled glaucoma screening.\n","authors":["Coen de Vente","Koenraad A. Vermeer","Nicolas Jaccard","He Wang","Hongyi Sun","Firas Khader","Daniel Truhn","Temirgali Aimyshev","Yerkebulan Zhanibekuly","Tien-Dung Le","Adrian Galdran","Miguel Ángel González Ballester","Gustavo Carneiro","Devika R G","Hrishikesh P S","Densen Puthussery","Hong Liu","Zekang Yang","Satoshi Kondo","Satoshi Kasai","Edward Wang","Ashritha Durvasula","Jónathan Heras","Miguel Ángel Zapata","Teresa Araújo","Guilherme Aresta","Hrvoje Bogunović","Mustafa Arikan","Yeong Chan Lee","Hyun Bin Cho","Yoon Ho Choi","Abdul Qayyum","Imran Razzak","Bram van Ginneken","Hans G. Lemij","Clara I. Sánchez"],"pdf_url":"https://arxiv.org/pdf/2302.01738v1.pdf","comment":"19 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2210.09789v2","updated":"2023-02-03T13:55:14Z","published":"2022-10-18T12:04:55Z","title":"Anti-Symmetric DGN: a stable architecture for Deep Graph Networks","summary":"  Deep Graph Networks (DGNs) currently dominate the research landscape of\nlearning from graphs, due to their efficiency and ability to implement an\nadaptive message-passing scheme between the nodes. However, DGNs are typically\nlimited in their ability to propagate and preserve long-term dependencies\nbetween nodes, i.e., they suffer from the over-squashing phenomena. This\nreduces their effectiveness, since predictive problems may require to capture\ninteractions at different, and possibly large, radii in order to be effectively\nsolved. In this work, we present Anti-Symmetric Deep Graph Networks (A-DGNs), a\nframework for stable and non-dissipative DGN design, conceived through the lens\nof ordinary differential equations. We give theoretical proof that our method\nis stable and non-dissipative, leading to two key results: long-range\ninformation between nodes is preserved, and no gradient vanishing or explosion\noccurs in training. We empirically validate the proposed approach on several\ngraph benchmarks, showing that A-DGN yields to improved performance and enables\nto learn effectively even when dozens of layers are used.\n","authors":["Alessio Gravina","Davide Bacciu","Claudio Gallicchio"],"pdf_url":"https://arxiv.org/pdf/2210.09789v2.pdf","comment":"Accepted at ICLR 2023 (https://openreview.net/forum?id=J3Y7cgZOOS)"},{"id":"http://arxiv.org/abs/2302.01278v2","updated":"2023-02-03T13:54:04Z","published":"2023-02-02T18:12:08Z","title":"Convolutional Autoencoders, Clustering and POD for Low-dimensional\n  Parametrization of Navier-Stokes Equations","summary":"  Simulations of large-scale dynamical systems require expensive computations.\nLow-dimensional parametrization of high-dimensional states such as Proper\nOrthogonal Decomposition (POD) can be a solution to lessen the burdens by\nproviding a certain compromise between accuracy and model complexity. However,\nfor really low-dimensional parametrizations (for example for controller design)\nlinear methods like the POD come to their natural limits so that nonlinear\napproaches will be the methods of choice. In this work we propose a\nconvolutional autoencoder (CAE) consisting of a nonlinear encoder and an affine\nlinear decoder and consider combinations with k-means clustering for improved\nencoding performance. The proposed set of methods is compared to the standard\nPOD approach in two cylinder-wake scenarios modeled by the incompressible\nNavier-Stokes equations.\n","authors":["Yongho Kim","Jan Heiland"],"pdf_url":"https://arxiv.org/pdf/2302.01278v2.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.01735v1","updated":"2023-02-03T13:50:25Z","published":"2023-02-03T13:50:25Z","title":"Rethinking Semi-Supervised Medical Image Segmentation: A\n  Variance-Reduction Perspective","summary":"  For medical image segmentation, contrastive learning is the dominant practice\nto improve the quality of visual representations by contrasting semantically\nsimilar and dissimilar pairs of samples. This is enabled by the observation\nthat without accessing ground truth label, negative examples with truly\ndissimilar anatomical features, if sampled, can significantly improve the\nperformance. In reality, however, these samples may come from similar\nanatomical features and the models may struggle to distinguish the minority\ntail-class samples, making the tail classes more prone to misclassification,\nboth of which typically lead to model collapse. In this paper, we propose ARCO,\na semi-supervised contrastive learning (CL) framework with stratified group\nsampling theory in medical image segmentation. In particular, we first propose\nbuilding ARCO through the concept of variance-reduced estimation, and show that\ncertain variance-reduction techniques are particularly beneficial in medical\nimage segmentation tasks with extremely limited labels. Furthermore, we\ntheoretically prove these sampling techniques are universal in variance\nreduction. Finally, we experimentally validate our approaches on three\nbenchmark datasets with different label settings, and our methods consistently\noutperform state-of-the-art semi- and fully-supervised methods. Additionally,\nwe augment the CL frameworks with these sampling techniques and demonstrate\nsignificant gains over previous methods. We believe our work is an important\nstep towards semi-supervised medical image segmentation by quantifying the\nlimitation of current self-supervision objectives for accomplishing medical\nimage analysis tasks.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Fenglin Liu","Xiaoran Zhang","Chen Feng","David A. Clifton","S Kevin Zhou","Lawrence Hamilton Staib","James S Duncan"],"pdf_url":"https://arxiv.org/pdf/2302.01735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01734v1","updated":"2023-02-03T13:50:23Z","published":"2023-02-03T13:50:23Z","title":"Stochastic Policy Gradient Methods: Improved Sample Complexity for\n  Fisher-non-degenerate Policies","summary":"  Recently, the impressive empirical success of policy gradient (PG) methods\nhas catalyzed the development of their theoretical foundations. Despite the\nhuge efforts directed at the design of efficient stochastic PG-type algorithms,\nthe understanding of their convergence to a globally optimal policy is still\nlimited. In this work, we develop improved global convergence guarantees for a\ngeneral class of Fisher-non-degenerate parameterized policies which allows to\naddress the case of continuous state action spaces. First, we propose a\nNormalized Policy Gradient method with Implicit Gradient Transport (N-PG-IGT)\nand derive a $\\tilde{\\mathcal{O}}(\\varepsilon^{-2.5})$ sample complexity of\nthis method for finding a global $\\varepsilon$-optimal policy. Improving over\nthe previously known $\\tilde{\\mathcal{O}}(\\varepsilon^{-3})$ complexity, this\nalgorithm does not require the use of importance sampling or second-order\ninformation and samples only one trajectory per iteration. Second, we further\nimprove this complexity to $\\tilde{ \\mathcal{\\mathcal{O}} }(\\varepsilon^{-2})$\nby considering a Hessian-Aided Recursive Policy Gradient ((N)-HARPG) algorithm\nenhanced with a correction based on a Hessian-vector product. Interestingly,\nboth algorithms are $(i)$ simple and easy to implement: single-loop, do not\nrequire large batches of trajectories and sample at most two trajectories per\niteration; $(ii)$ computationally and memory efficient: they do not require\nexpensive subroutines at each iteration and can be implemented with memory\nlinear in the dimension of parameters.\n","authors":["Ilyas Fatkhullin","Anas Barakat","Anastasia Kireeva","Niao He"],"pdf_url":"https://arxiv.org/pdf/2302.01734v1.pdf","comment":"This work was initially submitted in October 2022"},{"id":"http://arxiv.org/abs/2302.01727v1","updated":"2023-02-03T13:43:02Z","published":"2023-02-03T13:43:02Z","title":"Distributional constrained reinforcement learning for supply chain\n  optimization","summary":"  This work studies reinforcement learning (RL) in the context of multi-period\nsupply chains subject to constraints, e.g., on production and inventory. We\nintroduce Distributional Constrained Policy Optimization (DCPO), a novel\napproach for reliable constraint satisfaction in RL. Our approach is based on\nConstrained Policy Optimization (CPO), which is subject to approximation errors\nthat in practice lead it to converge to infeasible policies. We address this\nissue by incorporating aspects of distributional RL into DCPO. Specifically, we\nrepresent the return and cost value functions using neural networks that output\ndiscrete distributions, and we reshape costs based on the associated\nconfidence. Using a supply chain case study, we show that DCPO improves the\nrate at which the RL policy converges and ensures reliable constraint\nsatisfaction by the end of training. The proposed method also improves\npredictability, greatly reducing the variance of returns between runs,\nrespectively; this result is significant in the context of policy gradient\nmethods, which intrinsically introduce significant variance during training.\n","authors":["Jaime Sabal Bermúdez","Antonio del Rio Chanona","Calvin Tsay"],"pdf_url":"https://arxiv.org/pdf/2302.01727v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2209.09674v3","updated":"2023-02-03T13:31:04Z","published":"2022-09-20T12:26:06Z","title":"Testing Rare Downstream Safety Violations via Upstream Adaptive Sampling\n  of Perception Error Models","summary":"  Testing black-box perceptual-control systems in simulation faces two\ndifficulties. Firstly, perceptual inputs in simulation lack the fidelity of\nreal-world sensor inputs. Secondly, for a reasonably accurate perception\nsystem, encountering a rare failure trajectory may require running infeasibly\nmany simulations. This paper combines perception error models -- surrogates for\na sensor-based detection system -- with state-dependent adaptive importance\nsampling. This allows us to efficiently assess the rare failure probabilities\nfor real-world perceptual control systems within simulation. Our experiments\nwith an autonomous braking system equipped with an RGB obstacle-detector show\nthat our method can calculate accurate failure probabilities with an\ninexpensive number of simulations. Further, we show how choice of safety metric\ncan influence the process of learning proposal distributions capable of\nreliably sampling high-probability failures.\n","authors":["Craig Innes","Subramanian Ramamoorthy"],"pdf_url":"https://arxiv.org/pdf/2209.09674v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01724v1","updated":"2023-02-03T13:25:43Z","published":"2023-02-03T13:25:43Z","title":"Reinforcing User Retention in a Billion Scale Short Video Recommender\n  System","summary":"  Recently, short video platforms have achieved rapid user growth by\nrecommending interesting content to users. The objective of the recommendation\nis to optimize user retention, thereby driving the growth of DAU (Daily Active\nUsers). Retention is a long-term feedback after multiple interactions of users\nand the system, and it is hard to decompose retention reward to each item or a\nlist of items. Thus traditional point-wise and list-wise models are not able to\noptimize retention. In this paper, we choose reinforcement learning methods to\noptimize the retention as they are designed to maximize the long-term\nperformance. We formulate the problem as an infinite-horizon request-based\nMarkov Decision Process, and our objective is to minimize the accumulated time\ninterval of multiple sessions, which is equal to improving the app open\nfrequency and user retention. However, current reinforcement learning\nalgorithms can not be directly applied in this setting due to uncertainty,\nbias, and long delay time incurred by the properties of user retention. We\npropose a novel method, dubbed RLUR, to address the aforementioned challenges.\nBoth offline and live experiments show that RLUR can significantly improve user\nretention. RLUR has been fully launched in Kuaishou app for a long time, and\nachieves consistent performance improvement on user retention and DAU.\n","authors":["Qingpeng Cai","Shuchang Liu","Xueliang Wang","Tianyou Zuo","Wentao Xie","Bin Yang","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01722v1","updated":"2023-02-03T13:18:52Z","published":"2023-02-03T13:18:52Z","title":"Leveraging Contaminated Datasets to Learn Clean-Data Distribution with\n  Purified Generative Adversarial Networks","summary":"  Generative adversarial networks (GANs) are known for their strong abilities\non capturing the underlying distribution of training instances. Since the\nseminal work of GAN, many variants of GAN have been proposed. However, existing\nGANs are almost established on the assumption that the training dataset is\nclean. But in many real-world applications, this may not hold, that is, the\ntraining dataset may be contaminated by a proportion of undesired instances.\nWhen training on such datasets, existing GANs will learn a mixture distribution\nof desired and contaminated instances, rather than the desired distribution of\ndesired data only (target distribution). To learn the target distribution from\ncontaminated datasets, two purified generative adversarial networks (PuriGAN)\nare developed, in which the discriminators are augmented with the capability to\ndistinguish between target and contaminated instances by leveraging an extra\ndataset solely composed of contamination instances. We prove that under some\nmild conditions, the proposed PuriGANs are guaranteed to converge to the\ndistribution of desired instances. Experimental results on several datasets\ndemonstrate that the proposed PuriGANs are able to generate much better images\nfrom the desired distribution than comparable baselines when trained on\ncontaminated datasets. In addition, we also demonstrate the usefulness of\nPuriGAN on downstream applications by applying it to the tasks of\nsemi-supervised anomaly detection on contaminated datasets and PU-learning.\nExperimental results show that PuriGAN is able to deliver the best performance\nover comparable baselines on both tasks.\n","authors":["Bowen Tian","Qinliang Su","Jianxing Yu"],"pdf_url":"https://arxiv.org/pdf/2302.01722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01714v1","updated":"2023-02-03T13:11:57Z","published":"2023-02-03T13:11:57Z","title":"Learning End-to-End Channel Coding with Diffusion Models","summary":"  It is a known problem that deep-learning-based end-to-end (E2E) channel\ncoding systems depend on a known and differentiable channel model, due to the\nlearning process and based on the gradient-descent optimization methods. This\nplaces the challenge to approximate or generate the channel or its derivative\nfrom samples generated by pilot signaling in real-world scenarios. Currently,\nthere are two prevalent methods to solve this problem. One is to generate the\nchannel via a generative adversarial network (GAN), and the other is to, in\nessence, approximate the gradient via reinforcement learning methods. Other\nmethods include using score-based methods, variational autoencoders, or\nmutual-information-based methods. In this paper, we focus on generative models\nand, in particular, on a new promising method called diffusion models, which\nhave shown a higher quality of generation in image-based tasks. We will show\nthat diffusion models can be used in wireless E2E scenarios and that they work\nas good as Wasserstein GANs while having a more stable training procedure and a\nbetter generalization ability in testing.\n","authors":["Muah Kim","Rick Fritschek","Rafael F. Schaefer"],"pdf_url":"https://arxiv.org/pdf/2302.01714v1.pdf","comment":"6 pages, WSA/SCC 2023"},{"id":"http://arxiv.org/abs/2302.01706v1","updated":"2023-02-03T13:04:12Z","published":"2023-02-03T13:04:12Z","title":"GTV: Generating Tabular Data via Vertical Federated Learning","summary":"  Generative Adversarial Networks (GANs) have achieved state-of-the-art results\nin tabular data synthesis, under the presumption of direct accessible training\ndata. Vertical Federated Learning (VFL) is a paradigm which allows to\ndistributedly train machine learning model with clients possessing unique\nfeatures pertaining to the same individuals, where the tabular data learning is\nthe primary use case. However, it is unknown if tabular GANs can be learned in\nVFL. Demand for secure data transfer among clients and GAN during training and\ndata synthesizing poses extra challenge. Conditional vector for tabular GANs is\na valuable tool to control specific features of generated data. But it contains\nsensitive information from real data - risking privacy guarantees. In this\npaper, we propose GTV, a VFL framework for tabular GANs, whose key components\nare generator, discriminator and the conditional vector. GTV proposes an unique\ndistributed training architecture for generator and discriminator to access\ntraining data in a privacy-preserving manner. To accommodate conditional vector\ninto training without privacy leakage, GTV designs a mechanism\ntraining-with-shuffling to ensure that no party can reconstruct training data\nwith conditional vector. We evaluate the effectiveness of GTV in terms of\nsynthetic data quality, and overall training scalability. Results show that GTV\ncan consistently generate high-fidelity synthetic tabular data of comparable\nquality to that generated by centralized GAN algorithm. The difference on\nmachine learning utility can be as low as to 2.7%, even under extremely\nimbalanced data distributions across clients and different number of clients.\n","authors":["Zilong Zhao","Han Wu","Aad Van Moorsel","Lydia Y. Chen"],"pdf_url":"https://arxiv.org/pdf/2302.01706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.13718v2","updated":"2023-02-03T13:03:43Z","published":"2022-02-28T12:26:47Z","title":"Fast Feature Selection with Fairness Constraints","summary":"  We study the fundamental problem of selecting optimal features for model\nconstruction. This problem is computationally challenging on large datasets,\neven with the use of greedy algorithm variants. To address this challenge, we\nextend the adaptive query model, recently proposed for the greedy forward\nselection for submodular functions, to the faster paradigm of Orthogonal\nMatching Pursuit for non-submodular functions. The proposed algorithm achieves\nexponentially fast parallel run time in the adaptive query model, scaling much\nbetter than prior work. Furthermore, our extension allows the use of\ndownward-closed constraints, which can be used to encode certain fairness\ncriteria into the feature selection process. We prove strong approximation\nguarantees for the algorithm based on standard assumptions. These guarantees\nare applicable to many parametric models, including Generalized Linear Models.\nFinally, we demonstrate empirically that the proposed algorithm competes\nfavorably with state-of-the-art techniques for feature selection, on real-world\nand synthetic datasets.\n","authors":["Francesco Quinzan","Rajiv Khanna","Moshik Hershcovitch","Sarel Cohen","Daniel G. Waddington","Tobias Friedrich","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2202.13718v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09768v2","updated":"2023-02-03T12:57:32Z","published":"2022-07-20T09:23:35Z","title":"Learning Counterfactually Invariant Predictors","summary":"  Counterfactual invariance has proven an essential property for predictors\nthat are fair, robust, and generalizable in the real world. We propose a\ngeneral definition of counterfactual invariance and provide simple graphical\ncriteria that yield a sufficient condition for a predictor to be\ncounterfactually invariant in terms of (conditional independence in) the\nobservational distribution. Any predictor that satisfies our criterion is\nprovably counterfactually invariant. In order to learn such predictors, we\npropose a model-agnostic framework, called Counterfactual Invariance Prediction\n(CIP), based on a kernel-based conditional dependence measure called\nHilbert-Schmidt Conditional Independence Criterion (HSCIC). Our experimental\nresults demonstrate the effectiveness of CIP in enforcing counterfactual\ninvariance across various types of data including tabular, high-dimensional,\nand real-world dataset.\n","authors":["Francesco Quinzan","Cecilia Casolo","Krikamol Muandet","Yucen Luo","Niki Kilbertus"],"pdf_url":"https://arxiv.org/pdf/2207.09768v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01701v1","updated":"2023-02-03T12:55:08Z","published":"2023-02-03T12:55:08Z","title":"Where and How to Improve Graph-based Spatio-temporal Predictors","summary":"  This paper introduces a novel residual correlation analysis, called\nAZ-analysis, to assess the optimality of spatio-temporal predictive models. The\nproposed AZ-analysis constitutes a valuable asset for discovering and\nhighlighting those space-time regions where the model can be improved with\nrespect to performance. The AZ-analysis operates under very mild assumptions\nand is based on a spatio-temporal graph that encodes serial and functional\ndependencies in the data; asymptotically distribution-free summary statistics\nidentify existing residual correlation in space and time regions, hence\nlocalizing time frames and/or communities of sensors, where the predictor can\nbe improved.\n","authors":["Daniele Zambon","Cesare Alippi"],"pdf_url":"https://arxiv.org/pdf/2302.01701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11027v2","updated":"2023-02-03T12:52:38Z","published":"2022-05-23T04:01:11Z","title":"When Data Geometry Meets Deep Function: Generalizing Offline\n  Reinforcement Learning","summary":"  In offline reinforcement learning (RL), one detrimental issue to policy\nlearning is the error accumulation of deep Q function in out-of-distribution\n(OOD) areas. Unfortunately, existing offline RL methods are often\nover-conservative, inevitably hurting generalization performance outside data\ndistribution. In our study, one interesting observation is that deep Q\nfunctions approximate well inside the convex hull of training data. Inspired by\nthis, we propose a new method, DOGE (Distance-sensitive Offline RL with better\nGEneralization). DOGE marries dataset geometry with deep function approximators\nin offline RL, and enables exploitation in generalizable OOD areas rather than\nstrictly constraining policy within data distribution. Specifically, DOGE\ntrains a state-conditioned distance function that can be readily plugged into\nstandard actor-critic methods as a policy constraint. Simple yet elegant, our\nalgorithm enjoys better generalization compared to state-of-the-art methods on\nD4RL benchmarks. Theoretical analysis demonstrates the superiority of our\napproach to existing methods that are solely based on data distribution or\nsupport constraints.\n","authors":["Jianxiong Li","Xianyuan Zhan","Haoran Xu","Xiangyu Zhu","Jingjing Liu","Ya-Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.11027v2.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2210.07182v4","updated":"2023-02-03T12:45:47Z","published":"2022-10-13T17:03:36Z","title":"PDEBENCH: An Extensive Benchmark for Scientific Machine Learning","summary":"  Machine learning-based modeling of physical systems has experienced increased\ninterest in recent years. Despite some impressive progress, there is still a\nlack of benchmarks for Scientific ML that are easy to use but still challenging\nand representative of a wide range of problems. We introduce PDEBench, a\nbenchmark suite of time-dependent simulation tasks based on Partial\nDifferential Equations (PDEs). PDEBench comprises both code and data to\nbenchmark the performance of novel machine learning models against both\nclassical numerical simulations and machine learning baselines. Our proposed\nset of benchmark problems contribute the following unique features: (1) A much\nwider range of PDEs compared to existing benchmarks, ranging from relatively\ncommon examples to more realistic and difficult problems; (2) much larger\nready-to-use datasets compared to prior work, comprising multiple simulation\nruns across a larger number of initial and boundary conditions and PDE\nparameters; (3) more extensible source codes with user-friendly APIs for data\ngeneration and baseline results with popular machine learning models (FNO,\nU-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers to\nextend the benchmark freely for their own purposes using a standardized API and\nto compare the performance of new models to existing baseline methods. We also\npropose new evaluation metrics with the aim to provide a more holistic\nunderstanding of learning methods in the context of Scientific ML. With those\nmetrics we identify tasks which are challenging for recent ML methods and\npropose these tasks as future challenges for the community. The code is\navailable at https://github.com/pdebench/PDEBench.\n","authors":["Makoto Takamoto","Timothy Praditia","Raphael Leiteritz","Dan MacKinlay","Francesco Alesiani","Dirk Pflüger","Mathias Niepert"],"pdf_url":"https://arxiv.org/pdf/2210.07182v4.pdf","comment":"16 pages (main body) + 34 pages (supplemental material), accepted for\n  publication in NeurIPS 2022 Track Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2209.04142v4","updated":"2023-02-03T12:29:29Z","published":"2022-09-09T06:50:37Z","title":"Causal Modeling of Policy Interventions From Sequences of Treatments and\n  Outcomes using Gaussian Processes","summary":"  A treatment policy defines when and what treatments are applied to affect\nsome outcome of interest. Data-driven decision-making requires the ability to\npredict what happens if a policy is changed. Existing methods that predict how\nthe outcome evolves under different scenarios assume that the tentative\nsequences of future treatments are fixed in advance, while in practice the\ntreatments are determined stochastically by a policy and may depend for example\non the efficiency of previous treatments. Therefore, the current methods are\nnot applicable if the treatment policy is unknown or a counterfactual analysis\nis needed. To handle these limitations, we model the treatments and outcomes\njointly in continuous time, by combining Gaussian processes and point\nprocesses. Our model enables the estimation of a treatment policy from\nobservational sequences of treatments and outcomes, and it can predict the\ninterventional and counterfactual progression of the outcome after an\nintervention on the treatment policy (in contrast with the causal effect of a\nsingle treatment). We show with real-world and semi-synthetic data on blood\nglucose progression that our method can answer causal queries more accurately\nthan existing alternatives.\n","authors":["Çağlar Hızlı","ST John","Anne Juuti","Tuure Saarinen","Kirsi Pietiläinen","Pekka Marttinen"],"pdf_url":"https://arxiv.org/pdf/2209.04142v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01687v1","updated":"2023-02-03T12:19:42Z","published":"2023-02-03T12:19:42Z","title":"Better Training of GFlowNets with Local Credit and Incomplete\n  Trajectories","summary":"  Generative Flow Networks or GFlowNets are related to Monte-Carlo Markov chain\nmethods (as they sample from a distribution specified by an energy function),\nreinforcement learning (as they learn a policy to sample composed objects\nthrough a sequence of steps), generative models (as they learn to represent and\nsample from a distribution) and amortized variational methods (as they can be\nused to learn to approximate and sample from an otherwise intractable\nposterior, given a prior and a likelihood). They are trained to generate an\nobject $x$ through a sequence of steps with probability proportional to some\nreward function $R(x)$ (or $\\exp(-\\mathcal{E}(x))$ with $\\mathcal{E}(x)$\ndenoting the energy function), given at the end of the generative trajectory.\nLike for other RL settings where the reward is only given at the end, the\nefficiency of training and credit assignment may suffer when those trajectories\nare longer. With previous GFlowNet work, no learning was possible from\nincomplete trajectories (lacking a terminal state and the computation of the\nassociated reward). In this paper, we consider the case where the energy\nfunction can be applied not just to terminal states but also to intermediate\nstates. This is for example achieved when the energy function is additive, with\nterms available along the trajectory. We show how to reparameterize the\nGFlowNet state flow function to take advantage of the partial reward already\naccrued at each state. This enables a training objective that can be applied to\nupdate parameters even with incomplete trajectories. Even when complete\ntrajectories are available, being able to obtain more localized credit and\ngradients is found to speed up training convergence, as demonstrated across\nmany simulations.\n","authors":["Ling Pan","Nikolay Malkin","Dinghuai Zhang","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2302.01687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01681v1","updated":"2023-02-03T12:10:24Z","published":"2023-02-03T12:10:24Z","title":"Improving the Timing Resolution of Positron Emission Tomography\n  Detectors using Boosted Learning -- A Residual Physics Approach","summary":"  Artificial intelligence is finding its way into medical imaging, usually\nfocusing on image reconstruction or enhancing analytical reconstructed images.\nHowever, optimizations along the complete processing chain, from detecting\nsignals to computing data, enable significant improvements. Thus, we present an\napproach toward detector optimization using boosted learning by exploiting the\nconcept of residual physics. In our work, we improve the coincidence time\nresolution (CTR) of positron emission tomography (PET) detectors. PET enables\nimaging of metabolic processes by detecting {\\gamma}-photons with scintillation\ndetectors. Current research exploits light-sharing detectors, where the\nscintillation light is distributed over and digitized by an array of readout\nchannels. While these detectors demonstrate excellent performance parameters,\ne.g., regarding spatial resolution, extracting precise timing information for\ntime-of-flight (TOF) becomes more challenging due to deteriorating effects\ncalled time skews. Conventional correction methods mainly rely on analytical\nformulations, theoretically capable of covering all time skew effects, e.g.,\ncaused by signal runtimes or physical effects. However, additional effects are\ninvolved for light-sharing detectors, so finding suitable analytical\nformulations can become arbitrarily complicated. The residual physics-based\nstrategy uses gradient tree boosting (GTB) and a physics-informed data\ngeneration mimicking an actual imaging process by shifting a radiation source.\nWe used clinically relevant detectors with a height of 19 mm, coupled to\ndigital photosensor arrays. All trained models improved the CTR significantly.\nUsing the best model, we achieved CTRs down to 198 ps (185 ps) for energies\nranging from 300 keV to 700 keV (450 keV to 550 keV).\n","authors":["Stephan Naunheim","Yannick Kuhl","David Schug","Volkmar Schulz","Florian Mueller"],"pdf_url":"https://arxiv.org/pdf/2302.01681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.04746v3","updated":"2023-02-03T12:06:15Z","published":"2021-11-08T19:00:00Z","title":"Realizable Learning is All You Need","summary":"  The equivalence of realizable and agnostic learnability is a fundamental\nphenomenon in learning theory. With variants ranging from classical settings\nlike PAC learning and regression to recent trends such as adversarially robust\nlearning, it's surprising that we still lack a unified theory; traditional\nproofs of the equivalence tend to be disparate, and rely on strong\nmodel-specific assumptions like uniform convergence and sample compression.\n  In this work, we give the first model-independent framework explaining the\nequivalence of realizable and agnostic learnability: a three-line blackbox\nreduction that simplifies, unifies, and extends our understanding across a wide\nvariety of settings. This includes models with no known characterization of\nlearnability such as learning with arbitrary distributional assumptions and\nmore general loss functions, as well as a host of other popular settings such\nas robust learning, partial learning, fair learning, and the statistical query\nmodel.\n  More generally, we argue that the equivalence of realizable and agnostic\nlearning is actually a special case of a broader phenomenon we call property\ngeneralization: any desirable property of a learning algorithm (e.g. noise\ntolerance, privacy, stability) that can be satisfied over finite hypothesis\nclasses extends (possibly in some variation) to any learnable hypothesis class.\n","authors":["Max Hopkins","Daniel M. Kane","Shachar Lovett","Gaurav Mahajan"],"pdf_url":"https://arxiv.org/pdf/2111.04746v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01680v1","updated":"2023-02-03T12:02:54Z","published":"2023-02-03T12:02:54Z","title":"Two-Stage Constrained Actor-Critic fo Short Video Recommendation","summary":"  The wide popularity of short videos on social media poses new opportunities\nand challenges to optimize recommender systems on the video-sharing platforms.\nUsers sequentially interact with the system and provide complex and\nmulti-faceted responses, including watch time and various types of interactions\nwith multiple videos. One the one hand, the platforms aims at optimizing the\nusers' cumulative watch time (main goal) in long term, which can be effectively\noptimized by Reinforcement Learning. On the other hand, the platforms also\nneeds to satisfy the constraint of accommodating the responses of multiple user\ninteractions (auxiliary goals) such like, follow, share etc. In this paper, we\nformulate the problem of short video recommendation as a Constrained Markov\nDecision Process (CMDP). We find that traditional constrained reinforcement\nlearning algorithms can not work well in this setting. We propose a novel\ntwo-stage constrained actor-critic method: At stage one, we learn individual\npolicies to optimize each auxiliary signal. At stage two, we learn a policy to\n(i) optimize the main signal and (ii) stay close to policies learned at the\nfirst stage, which effectively guarantees the performance of this main policy\non the auxiliaries. Through extensive offline evaluations, we demonstrate\neffectiveness of our method over alternatives in both optimizing the main goal\nas well as balancing the others. We further show the advantage of our method in\nlive experiments of short video recommendations, where it significantly\noutperforms other baselines in terms of both watch time and interactions. Our\napproach has been fully launched in the production system to optimize user\nexperiences on the platform.\n","authors":["Qingpeng Cai","Zhenghai Xue","Chi Zhang","Wanqi Xue","Shuchang Liu","Ruohan Zhan","Xueliang Wang","Tianyou Zuo","Wentao Xie","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01680v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.13248"},{"id":"http://arxiv.org/abs/2302.01677v1","updated":"2023-02-03T11:58:14Z","published":"2023-02-03T11:58:14Z","title":"Revisiting Personalized Federated Learning: Robustness Against Backdoor\n  Attacks","summary":"  In this work, besides improving prediction accuracy, we study whether\npersonalization could bring robustness benefits to backdoor attacks. We conduct\nthe first study of backdoor attacks in the pFL framework, testing 4 widely used\nbackdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and\nCIFAR-10, a total of 600 experiments. The study shows that pFL methods with\npartial model-sharing can significantly boost robustness against backdoor\nattacks. In contrast, pFL methods with full model-sharing do not show\nrobustness. To analyze the reasons for varying robustness performances, we\nprovide comprehensive ablation studies on different pFL methods. Based on our\nfindings, we further propose a lightweight defense method, Simple-Tuning, which\nempirically improves defense performance against backdoor attacks. We believe\nthat our work could provide both guidance for pFL application in terms of its\nrobustness and offer valuable insights to design more robust FL methods in the\nfuture.\n","authors":["Zeyu Qin","Liuyi Yao","Daoyuan Chen","Yaliang Li","Bolin Ding","Minhao Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.01677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01676v1","updated":"2023-02-03T11:56:38Z","published":"2023-02-03T11:56:38Z","title":"Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction","summary":"  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n","authors":["Davide Costa","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2302.01676v1.pdf","comment":"Accepted paper at The ACM Web Conference 2023, April 30--May 04,\n  2023, Austin, Texas, USA"},{"id":"http://arxiv.org/abs/2302.01667v1","updated":"2023-02-03T11:39:50Z","published":"2023-02-03T11:39:50Z","title":"Mind the Gap: Offline Policy Optimization for Imperfect Rewards","summary":"  Reward function is essential in reinforcement learning (RL), serving as the\nguiding signal to incentivize agents to solve given tasks, however, is also\nnotoriously difficult to design. In many cases, only imperfect rewards are\navailable, which inflicts substantial performance loss for RL agents. In this\nstudy, we propose a unified offline policy optimization approach, \\textit{RGM\n(Reward Gap Minimization)}, which can smartly handle diverse types of imperfect\nrewards. RGM is formulated as a bi-level optimization problem: the upper layer\noptimizes a reward correction term that performs visitation distribution\nmatching w.r.t. some expert data; the lower layer solves a pessimistic RL\nproblem with the corrected rewards. By exploiting the duality of the lower\nlayer, we derive a tractable algorithm that enables sampled-based learning\nwithout any online interactions. Comprehensive experiments demonstrate that RGM\nachieves superior performance to existing methods under diverse settings of\nimperfect rewards. Further, RGM can effectively correct wrong or inconsistent\nrewards against expert preference and retrieve useful information from biased\nrewards.\n","authors":["Jianxiong Li","Xiao Hu","Haoran Xu","Jingjing Liu","Xianyuan Zhan","Qing-Shan Jia","Ya-Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01667v1.pdf","comment":"Accept by ICLR2023. The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2208.12584v2","updated":"2023-02-03T11:32:23Z","published":"2022-08-26T11:01:55Z","title":"Socially Fair Reinforcement Learning","summary":"  We consider the problem of episodic reinforcement learning where there are\nmultiple stakeholders with different reward functions. Our goal is to output a\npolicy that is socially fair with respect to different reward functions. Prior\nworks have proposed different objectives that a fair policy must optimize\nincluding minimum welfare, and generalized Gini welfare. We first take an\naxiomatic view of the problem, and propose four axioms that any such fair\nobjective must satisfy. We show that the Nash social welfare is the unique\nobjective that uniquely satisfies all four objectives, whereas prior objectives\nfail to satisfy all four axioms. We then consider the learning version of the\nproblem where the underlying model i.e. Markov decision process is unknown. We\nconsider the problem of minimizing regret with respect to the fair policies\nmaximizing three different fair objectives -- minimum welfare, generalized Gini\nwelfare, and Nash social welfare. Based on optimistic planning, we propose a\ngeneric learning algorithm and derive its regret bound with respect to the\nthree different policies. For the objective of Nash social welfare, we also\nderive a lower bound in regret that grows exponentially with $n$, the number of\nagents. Finally, we show that for the objective of minimum welfare, one can\nimprove regret by a factor of $O(H)$ for a weaker notion of regret.\n","authors":["Debmalya Mandal","Jiarui Gan"],"pdf_url":"https://arxiv.org/pdf/2208.12584v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01653v1","updated":"2023-02-03T10:57:21Z","published":"2023-02-03T10:57:21Z","title":"From slides (through tiles) to pixels: an explainability framework for\n  weakly supervised models in pre-clinical pathology","summary":"  In pre-clinical pathology, there is a paradox between the abundance of raw\ndata (whole slide images from many organs of many individual animals) and the\nlack of pixel-level slide annotations done by pathologists. Due to time\nconstraints and requirements from regulatory authorities, diagnoses are instead\nstored as slide labels. Weakly supervised training is designed to take\nadvantage of those data, and the trained models can be used by pathologists to\nrank slides by their probability of containing a given lesion of interest. In\nthis work, we propose a novel contextualized eXplainable AI (XAI) framework and\nits application to deep learning models trained on Whole Slide Images (WSIs) in\nDigital Pathology. Specifically, we apply our methods to a\nmulti-instance-learning (MIL) model, which is trained solely on slide-level\nlabels, without the need for pixel-level annotations. We validate\nquantitatively our methods by quantifying the agreements of our explanations'\nheatmaps with pathologists' annotations, as well as with predictions from a\nsegmentation model trained on such annotations. We demonstrate the stability of\nthe explanations with respect to input shifts, and the fidelity with respect to\nincreased model performance. We quantitatively evaluate the correlation between\navailable pixel-wise annotations and explainability heatmaps. We show that the\nexplanations on important tiles of the whole slide correlate with tissue\nchanges between healthy regions and lesions, but do not exactly behave like a\nhuman annotator. This result is coherent with the model training strategy.\n","authors":["Marco Bertolini","Van-Khoa Le","Jake Pencharz","Andreas Poehlmann","Djork-Arné Clevert","Santiago Villalba","Floriane Montanari"],"pdf_url":"https://arxiv.org/pdf/2302.01653v1.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.01649v1","updated":"2023-02-03T10:49:52Z","published":"2023-02-03T10:49:52Z","title":"Structure-informed Language Models Are Protein Designers","summary":"  This paper demonstrates that language models are strong structure-based\nprotein designers. We present LM-Design, a generic approach to reprogramming\nsequence-based protein language models (pLMs), that have learned massive\nsequential evolutionary knowledge from the universe of natural protein\nsequences, to acquire an immediate capability to design preferable protein\nsequences for given folds. We conduct a structural surgery on pLMs, where a\nlightweight structural adapter is implanted into pLMs and endows it with\nstructural awareness. During inference, iterative refinement is performed to\neffectively optimize the generated protein sequences. Experiments show that our\napproach outperforms the state-of-the-art methods by a large margin, leading to\nup to 4% to 12% accuracy gains in sequence recovery (e.g., 55.65% and 56.63% on\nCATH 4.2 and 4.3 single-chain benchmarks, and >60% when designing protein\ncomplexes). We provide extensive and in-depth analyses, which verify that\nLM-Design can (1) indeed leverage both structural and sequential knowledge to\naccurately handle structurally non-deterministic regions, (2) benefit from\nscaling data and model size, and (3) generalize to other proteins (e.g.,\nantibodies and de novo proteins)\n","authors":["Zaixiang Zheng","Yifan Deng","Dongyu Xue","Yi Zhou","Fei YE","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2302.01649v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2203.04706v2","updated":"2023-02-03T10:49:21Z","published":"2022-03-09T13:34:52Z","title":"Data Representativity for Machine Learning and AI Systems","summary":"  Data representativity is crucial when drawing inference from data through\nmachine learning models. Scholars have increased focus on unraveling the bias\nand fairness in models, also in relation to inherent biases in the input data.\nHowever, limited work exists on the representativity of samples (datasets) for\nappropriate inference in AI systems. This paper reviews definitions and notions\nof a representative sample and surveys their use in scientific AI literature.\nWe introduce three measurable concepts to help focus the notions and evaluate\ndifferent data samples. Furthermore, we demonstrate that the contrast between a\nrepresentative sample in the sense of coverage of the input space, versus a\nrepresentative sample mimicking the distribution of the target population is of\nparticular relevance when building AI systems. Through empirical demonstrations\non US Census data, we evaluate the opposing inherent qualities of these\nconcepts. Finally, we propose a framework of questions for creating and\ndocumenting data with data representativity in mind, as an addition to existing\ndataset documentation templates.\n","authors":["Line H. Clemmensen","Rune D. Kjærsgaard"],"pdf_url":"https://arxiv.org/pdf/2203.04706v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01647v1","updated":"2023-02-03T10:48:24Z","published":"2023-02-03T10:48:24Z","title":"Blockwise Self-Supervised Learning at Scale","summary":"  Current state-of-the-art deep networks are all powered by backpropagation. In\nthis paper, we explore alternatives to full backpropagation in the form of\nblockwise learning rules, leveraging the latest developments in self-supervised\nlearning. We show that a blockwise pretraining procedure consisting of training\nindependently the 4 main blocks of layers of a ResNet-50 with Barlow Twins'\nloss function at each block performs almost as well as end-to-end\nbackpropagation on ImageNet: a linear probe trained on top of our blockwise\npretrained model obtains a top-1 classification accuracy of 70.48%, only 1.1%\nbelow the accuracy of an end-to-end pretrained network (71.57% accuracy). We\nperform extensive experiments to understand the impact of different components\nwithin our method and explore a variety of adaptations of self-supervised\nlearning to the blockwise paradigm, building an exhaustive understanding of the\ncritical avenues for scaling local learning rules to large networks, with\nimplications ranging from hardware design to neuroscience.\n","authors":["Shoaib Ahmed Siddiqui","David Krueger","Yann LeCun","Stéphane Deny"],"pdf_url":"https://arxiv.org/pdf/2302.01647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15357v3","updated":"2023-02-03T10:38:51Z","published":"2022-05-30T18:04:57Z","title":"Searching for the Essence of Adversarial Perturbations","summary":"  Neural networks have demonstrated state-of-the-art performance in various\nmachine learning fields. However, the introduction of malicious perturbations\nin input data, known as adversarial examples, has been shown to deceive neural\nnetwork predictions. This poses potential risks for real-world applications\nsuch as autonomous driving and text identification. In order to mitigate these\nrisks, a comprehensive understanding of the mechanisms underlying adversarial\nexamples is essential. In this study, we demonstrate that adversarial\nperturbations contain human-recognizable information, which is the key\nconspirator responsible for a neural network's incorrect prediction, in\ncontrast to the widely held belief that human-unidentifiable characteristics\nplay a critical role in fooling a network. This concept of human-recognizable\ncharacteristics enables us to explain key features of adversarial\nperturbations, including their existence, transferability among different\nneural networks, and increased interpretability for adversarial training. We\nalso uncover two unique properties of adversarial perturbations that deceive\nneural networks: masking and generation. Additionally, a special class, the\ncomplementary class, is identified when neural networks classify input images.\nThe presence of human-recognizable information in adversarial perturbations\nallows researchers to gain insight into the working principles of neural\nnetworks and may lead to the development of techniques for detecting and\ndefending against adversarial attacks.\n","authors":["Dennis Y. Menn","Tzu-hsun Feng","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2205.15357v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01018v2","updated":"2023-02-03T10:38:44Z","published":"2023-02-02T11:12:51Z","title":"Graph Neural Networks for temporal graphs: State of the art, open\n  challenges, and opportunities","summary":"  Graph Neural Networks (GNNs) have become the leading paradigm for learning on\n(static) graph-structured data. However, many real-world systems are dynamic in\nnature, since the graph and node/edge attributes change over time. In recent\nyears, GNN-based models for temporal graphs have emerged as a promising area of\nresearch to extend the capabilities of GNNs. In this work, we provide the first\ncomprehensive overview of the current state-of-the-art of temporal GNN,\nintroducing a rigorous formalization of learning settings and tasks and a novel\ntaxonomy categorizing existing approaches in terms of how the temporal aspect\nis represented and processed. We conclude the survey with a discussion of the\nmost relevant open challenges for the field, from both research and application\nperspectives.\n","authors":["Antonio Longa","Veronica Lachi","Gabriele Santin","Monica Bianchini","Bruno Lepri","Pietro Lio","Franco Scarselli","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2302.01018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03113v2","updated":"2023-02-03T10:25:08Z","published":"2022-10-06T17:59:08Z","title":"IR-MCL: Implicit Representation-Based Online Global Localization","summary":"  Determining the state of a mobile robot is an essential building block of\nrobot navigation systems. In this paper, we address the problem of estimating\nthe robots pose in an indoor environment using 2D LiDAR data and investigate\nhow modern environment models can improve gold standard Monte-Carlo\nlocalization (MCL) systems. We propose a neural occupancy field to implicitly\nrepresent the scene using a neural network. With the pretrained network, we can\nsynthesize 2D LiDAR scans for an arbitrary robot pose through volume rendering.\nBased on the implicit representation, we can obtain the similarity between a\nsynthesized and actual scan as an observation model and integrate it into an\nMCL system to perform accurate localization. We evaluate our approach on\nself-recorded datasets and three publicly available ones. We show that we can\naccurately and efficiently localize a robot using our approach surpassing the\nlocalization performance of state-of-the-art methods. The experiments suggest\nthat the presented implicit representation is able to predict more accurate 2D\nLiDAR scans leading to an improved observation model for our particle\nfilter-based localization. The code of our approach will be available at:\nhttps://github.com/PRBonn/ir-mcl.\n","authors":["Haofei Kuang","Xieyuanli Chen","Tiziano Guadagnino","Nicky Zimmerman","Jens Behley","Cyrill Stachniss"],"pdf_url":"https://arxiv.org/pdf/2210.03113v2.pdf","comment":"8 pages, 5 figures. Accepted to IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2302.01633v1","updated":"2023-02-03T10:04:44Z","published":"2023-02-03T10:04:44Z","title":"Convergence Analysis of Split Learning on Non-IID Data","summary":"  Split Learning (SL) is one promising variant of Federated Learning (FL),\nwhere the AI model is split and trained at the clients and the server\ncollaboratively. By offloading the computation-intensive portions to the\nserver, SL enables efficient model training on resource-constrained clients.\nDespite its booming applications, SL still lacks rigorous convergence analysis\non non-IID data, which is critical for hyperparameter selection. In this paper,\nwe first prove that SL exhibits an $\\mathcal{O}(1/\\sqrt{R})$ convergence rate\nfor non-convex objectives on non-IID data, where $R$ is the number of total\ntraining rounds. The derived convergence results can facilitate understanding\nthe effect of some crucial factors in SL (e.g., data heterogeneity and\nsynchronization interval). Furthermore, comparing with the convergence result\nof FL, we show that the guarantee of SL is worse than FL in terms of training\nrounds on non-IID data. The experimental results verify our theory. More\nfindings on the comparison between FL and SL in cross-device settings are also\nreported.\n","authors":["Yipeng Li","Xinchen Lyu"],"pdf_url":"https://arxiv.org/pdf/2302.01633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12272v3","updated":"2023-02-03T10:01:57Z","published":"2022-06-24T13:15:43Z","title":"Physically Consistent Learning of Conservative Lagrangian Systems with\n  Gaussian Processes","summary":"  This paper proposes a physically consistent Gaussian Process (GP) enabling\nthe identification of uncertain Lagrangian systems. The function space is\ntailored according to the energy components of the Lagrangian and the\ndifferential equation structure, analytically guaranteeing physical and\nmathematical properties such as energy conservation and quadratic form. The\nnovel formulation of Cholesky decomposed matrix kernels allow the probabilistic\npreservation of positive definiteness. Only differential input-to-output\nmeasurements of the function map are required while Gaussian noise is permitted\nin torques, velocities, and accelerations. We demonstrate the effectiveness of\nthe approach in numerical simulation.\n","authors":["Giulio Evangelisti","Sandra Hirche"],"pdf_url":"https://arxiv.org/pdf/2206.12272v3.pdf","comment":"Accepted version of paper published by IEEE in 2022 IEEE 61st\n  Conference on Decision and Control (CDC). Final published paper can be found\n  at https://doi.org/10.1109/CDC51059.2022.9993123"},{"id":"http://arxiv.org/abs/2302.01629v1","updated":"2023-02-03T09:58:31Z","published":"2023-02-03T09:58:31Z","title":"Beyond the Universal Law of Robustness: Sharper Laws for Random Features\n  and Neural Tangent Kernels","summary":"  Machine learning models are vulnerable to adversarial perturbations, and a\nthought-provoking paper by Bubeck and Sellke has analyzed this phenomenon\nthrough the lens of over-parameterization: interpolating smoothly the data\nrequires significantly more parameters than simply memorizing it. However, this\n\"universal\" law provides only a necessary condition for robustness, and it is\nunable to discriminate between models. In this paper, we address these gaps by\nfocusing on empirical risk minimization in two prototypical settings, namely,\nrandom features and the neural tangent kernel (NTK). We prove that, for random\nfeatures, the model is not robust for any degree of over-parameterization, even\nwhen the necessary condition coming from the universal law of robustness is\nsatisfied. In contrast, for even activations, the NTK model meets the universal\nlower bound, and it is robust as soon as the necessary condition on\nover-parameterization is fulfilled. This also addresses a conjecture in prior\nwork by Bubeck, Li and Nagaraj. Our analysis decouples the effect of the kernel\nof the model from an \"interaction matrix\", which describes the interaction with\nthe test data and captures the effect of the activation. Our theoretical\nresults are corroborated by numerical evidence on both synthetic and standard\ndatasets (MNIST, CIFAR-10).\n","authors":["Simone Bombari","Shayan Kiyani","Marco Mondelli"],"pdf_url":"https://arxiv.org/pdf/2302.01629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01622v1","updated":"2023-02-03T09:49:13Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in radiology","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure the protection of said data are required. The gold standard for privacy\npreservation is the introduction of differential privacy (DP) to model\ntraining. However, prior work has shown that DP has negative implications on\nmodel accuracy and fairness. Therefore, the purpose of this study is to\ndemonstrate that the privacy-preserving training of AI models for chest\nradiograph diagnosis is possible with high accuracy and fairness compared to\nnon-private training. N=193,311 high quality clinical chest radiographs were\nretrospectively collected and manually labeled by experienced radiologists, who\nassigned one or more of the following diagnoses: cardiomegaly, congestion,\npleural effusion, pneumonic infiltration and atelectasis, to each side (where\napplicable). The non-private AI models were compared with privacy-preserving\n(DP) models with respect to privacy-utility trade-offs (measured as area under\nthe receiver-operator-characteristic curve (AUROC)), and privacy-fairness\ntrade-offs (measured as Pearson-R or Statistical Parity Difference). The\nnon-private AI model achieved an average AUROC score of 0.90 over all labels,\nwhereas the DP AI model with a privacy budget of epsilon=7.89 resulted in an\nAUROC of 0.87, i.e., a mere 2.6% performance decrease compared to non-private\ntraining. The privacy-preserving training of diagnostic AI models can achieve\nhigh performance with a small penalty on model accuracy and does not amplify\ndiscrimination against age, sex or co-morbidity. We thus encourage\npractitioners to integrate state-of-the-art privacy-preserving techniques into\nmedical AI model development.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v1.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2302.00981v2","updated":"2023-02-03T09:10:01Z","published":"2023-02-02T10:00:46Z","title":"Predicting Molecule-Target Interaction by Learning Biomedical Network\n  and Molecule Representations","summary":"  The study of molecule-target interaction is quite important for drug\ndiscovery in terms of target identification, hit identification, pathway study,\ndrug-drug interaction, etc. Most existing methodologies utilize either\nbiomedical network information or molecule structural features to predict\npotential interaction link. However, the biomedical network information based\nmethods usually suffer from cold start problem, while structure based methods\noften give limited performance due to the structure/interaction assumption and\ndata quality. To address these issues, we propose a pseudo-siamese Graph Neural\nNetwork method, namely MTINet+, which learns both biomedical network\ntopological and molecule structural/chemical information as representations to\npredict potential interaction of given molecule and target pair. In MTINet+,\n1-hop subgraphs of given molecule and target pair are extracted from known\ninteraction of biomedical network as topological information, meanwhile the\nmolecule structural and chemical attributes are processed as molecule\ninformation. MTINet+ learns these two types of information as embedding\nfeatures for predicting the pair link. In the experiments of different\nmolecule-target interaction tasks, MTINet+ significantly outperforms over the\nstate-of-the-art baselines. In addition, in our designed network sparsity\nexperiments , MTINet+ shows strong robustness against different sparse\nbiomedical networks.\n","authors":["Jinjiang Guo","Jie Li"],"pdf_url":"https://arxiv.org/pdf/2302.00981v2.pdf","comment":"9 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:2102.01649"},{"id":"http://arxiv.org/abs/2210.13206v3","updated":"2023-02-03T09:02:12Z","published":"2022-10-24T13:28:43Z","title":"Post-Selection Confidence Bounds for Prediction Performance","summary":"  In machine learning, the selection of a promising model from a potentially\nlarge number of competing models and the assessment of its generalization\nperformance are critical tasks that need careful consideration. Typically,\nmodel selection and evaluation are strictly separated endeavors, splitting the\nsample at hand into a training, validation, and evaluation set, and only\ncompute a single confidence interval for the prediction performance of the\nfinal selected model. We however propose an algorithm how to compute valid\nlower confidence bounds for multiple models that have been selected based on\ntheir prediction performances in the evaluation set by interpreting the\nselection problem as a simultaneous inference problem. We use bootstrap tilting\nand a maxT-type multiplicity correction. The approach is universally applicable\nfor any combination of prediction models, any model selection strategy, and any\nprediction performance measure that accepts weights. We conducted various\nsimulation experiments which show that our proposed approach yields lower\nconfidence bounds that are at least comparably good as bounds from standard\napproaches, and that reliably reach the nominal coverage probability. In\naddition, especially when sample size is small, our proposed approach yields\nbetter performing prediction models than the default selection of only one\nmodel for evaluation does.\n","authors":["Pascal Rink","Werner Brannath"],"pdf_url":"https://arxiv.org/pdf/2210.13206v3.pdf","comment":"17 pages, 13 figures, 3 tables. Submitted to the Springer Machine\n  Learning Journal. Changes to version 2: made figures easier to read;\n  corrected a minor typo"},{"id":"http://arxiv.org/abs/2302.01602v1","updated":"2023-02-03T08:54:55Z","published":"2023-02-03T08:54:55Z","title":"A Feature Selection Method for Driver Stress Detection Using Heart Rate\n  Variability and Breathing Rate","summary":"  Driver stress is a major cause of car accidents and death worldwide.\nFurthermore, persistent stress is a health problem, contributing to\nhypertension and other diseases of the cardiovascular system. Stress has a\nmeasurable impact on heart and breathing rates and stress levels can be\ninferred from such measurements. Galvanic skin response is a common test to\nmeasure the perspiration caused by both physiological and psychological stress,\nas well as extreme emotions. In this paper, galvanic skin response is used to\nestimate the ground truth stress levels. A feature selection technique based on\nthe minimal redundancy-maximal relevance method is then applied to multiple\nheart rate variability and breathing rate metrics to identify a novel and\noptimal combination for use in detecting stress. The support vector machine\nalgorithm with a radial basis function kernel was used along with these\nfeatures to reliably predict stress. The proposed method has achieved a high\nlevel of accuracy on the target dataset.\n","authors":["Ashkan Parsi","David O'Callaghan","Joseph Lemley"],"pdf_url":"https://arxiv.org/pdf/2302.01602v1.pdf","comment":"In Proceedings of the 15th International Conference on Machine Vision\n  (ICMV), Romem Italy, 18-20 November 2022. arXiv admin note: text overlap with\n  arXiv:2206.03222"},{"id":"http://arxiv.org/abs/2205.06540v2","updated":"2023-02-03T08:47:59Z","published":"2022-05-13T10:03:56Z","title":"Accelerometry-based classification of circulatory states during\n  out-of-hospital cardiac arrest","summary":"  Objective: Exploit accelerometry data for an automatic, reliable, and prompt\ndetection of spontaneous circulation during cardiac arrest, as this is both\nvital for patient survival and practically challenging. Methods: We developed a\nmachine learning algorithm to automatically predict the circulatory state\nduring cardiopulmonary resuscitation from 4-second-long snippets of\naccelerometry and electrocardiogram (ECG) data from pauses of chest\ncompressions of real-world defibrillator records. The algorithm was trained\nbased on 422 cases from the German Resuscitation Registry, for which ground\ntruth labels were created by a manual annotation of physicians. It uses a\nkernelized Support Vector Machine classifier based on 49 features, which\npartially reflect the correlation between accelerometry and electrocardiogram\ndata. Results: Evaluating 50 different test-training data splits, the proposed\nalgorithm exhibits a balanced accuracy of 81.2%, a sensitivity of 80.6%, and a\nspecificity of 81.8%, whereas using only ECG leads to a balanced accuracy of\n76.5%, a sensitivity of 80.2%, and a specificity of 72.8%. Conclusion: The\nfirst method employing accelerometry for pulse/no-pulse decision yields a\nsignificant increase in performance compared to single ECG-signal usage.\nSignificance: This shows that accelerometry provides relevant information for\npulse/no-pulse decisions. In application, such an algorithm may be used to\nsimplify retrospective annotation for quality management and, moreover, to\nsupport clinicians to assess circulatory state during cardiac arrest treatment.\n","authors":["Wolfgang J. Kern","Simon Orlob","Andreas Bohn","Wolfgang Toller","Jan Wnent","Jan-Thorsten Gräsner","Martin Holler"],"pdf_url":"https://arxiv.org/pdf/2205.06540v2.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.01599v1","updated":"2023-02-03T08:43:55Z","published":"2023-02-03T08:43:55Z","title":"SCCAM: Supervised Contrastive Convolutional Attention Mechanism for\n  Ante-hoc Interpretable Fault Diagnosis with Limited Fault Samples","summary":"  In real industrial processes, fault diagnosis methods are required to learn\nfrom limited fault samples since the procedures are mainly under normal\nconditions and the faults rarely occur. Although attention mechanisms have\nbecome popular in the field of fault diagnosis, the existing attention-based\nmethods are still unsatisfying for the above practical applications. First,\npure attention-based architectures like transformers need a large number of\nfault samples to offset the lack of inductive biases thus performing poorly\nunder limited fault samples. Moreover, the poor fault classification dilemma\nfurther leads to the failure of the existing attention-based methods to\nidentify the root causes. To address the aforementioned issues, we innovatively\npropose a supervised contrastive convolutional attention mechanism (SCCAM) with\nante-hoc interpretability, which solves the root cause analysis problem under\nlimited fault samples for the first time. The proposed SCCAM method is tested\non a continuous stirred tank heater and the Tennessee Eastman industrial\nprocess benchmark. Three common fault diagnosis scenarios are covered,\nincluding a balanced scenario for additional verification and two scenarios\nwith limited fault samples (i.e., imbalanced scenario and long-tail scenario).\nThe comprehensive results demonstrate that the proposed SCCAM method can\nachieve better performance compared with the state-of-the-art methods on fault\nclassification and root cause analysis.\n","authors":["Mengxuan Li","Peng Peng","Jingxin Zhang","Hongwei Wang","Weiming Shen"],"pdf_url":"https://arxiv.org/pdf/2302.01599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01596v1","updated":"2023-02-03T08:35:49Z","published":"2023-02-03T08:35:49Z","title":"A Novel Fuzzy Bi-Clustering Algorithm with AFS for Identification of\n  Co-Regulated Genes","summary":"  The identification of co-regulated genes and their transcription-factor\nbinding sites (TFBS) are the key steps toward understanding transcription\nregulation. In addition to effective laboratory assays, various bi-clustering\nalgorithms for detection of the co-expressed genes have been developed.\nBi-clustering methods are used to discover subgroups of genes with similar\nexpression patterns under to-be-identified subsets of experimental conditions\nwhen applied to gene expression data. By building two fuzzy partition matrices\nof the gene expression data with the Axiomatic Fuzzy Set (AFS) theory, this\npaper proposes a novel fuzzy bi-clustering algorithm for identification of\nco-regulated genes. Specifically, the gene expression data is transformed into\ntwo fuzzy partition matrices via sub-preference relations theory of AFS at\nfirst. One of the matrices is considering the genes as the universe and the\nconditions as the concept, the other one is considering the genes as the\nconcept and the conditions as the universe. The identification of the\nco-regulated genes (bi-clusters) is carried out on the two partition matrices\nat the same time. Then, a novel fuzzy-based similarity criterion is defined\nbased on the partition matrixes, and a cyclic optimization algorithm is\ndesigned to discover the significant bi-clusters at expression level. The above\nprocedures guarantee that the generated bi-clusters have more significant\nexpression values than that of extracted by the traditional bi-clustering\nmethods. Finally, the performance of the proposed method is evaluated with the\nperformance of the three well-known bi-clustering algorithms on publicly\navailable real microarray datasets. The experimental results are in agreement\nwith the theoretical analysis and show that the proposed algorithm can\neffectively detect the co-regulated genes without any prior knowledge of the\ngene expression data.\n","authors":["Kaijie Xu"],"pdf_url":"https://arxiv.org/pdf/2302.01596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01595v1","updated":"2023-02-03T08:33:33Z","published":"2023-02-03T08:33:33Z","title":"Deep Reinforcement Learning for Cyber System Defense under Dynamic\n  Adversarial Uncertainties","summary":"  Development of autonomous cyber system defense strategies and action\nrecommendations in the real-world is challenging, and includes characterizing\nsystem state uncertainties and attack-defense dynamics. We propose a\ndata-driven deep reinforcement learning (DRL) framework to learn proactive,\ncontext-aware, defense countermeasures that dynamically adapt to evolving\nadversarial behaviors while minimizing loss of cyber system operations. A\ndynamic defense optimization problem is formulated with multiple protective\npostures against different types of adversaries with varying levels of skill\nand persistence. A custom simulation environment was developed and experiments\nwere devised to systematically evaluate the performance of four model-free DRL\nalgorithms against realistic, multi-stage attack sequences. Our results suggest\nthe efficacy of DRL algorithms for proactive cyber defense under multi-stage\nattack profiles and system uncertainties.\n","authors":["Ashutosh Dutta","Samrat Chatterjee","Arnab Bhattacharya","Mahantesh Halappanavar"],"pdf_url":"https://arxiv.org/pdf/2302.01595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11720v3","updated":"2023-02-03T08:31:42Z","published":"2022-12-22T14:13:33Z","title":"GOOD: Exploring Geometric Cues for Detecting Objects in an Open World","summary":"  We address the task of open-world class-agnostic object detection, i.e.,\ndetecting every object in an image by learning from a limited number of base\nobject classes. State-of-the-art RGB-based models suffer from overfitting the\ntraining classes and often fail at detecting novel-looking objects. This is\nbecause RGB-based models primarily rely on appearance similarity to detect\nnovel objects and are also prone to overfitting short-cut cues such as textures\nand discriminative parts. To address these shortcomings of RGB-based object\ndetectors, we propose incorporating geometric cues such as depth and normals,\npredicted by general-purpose monocular estimators. Specifically, we use the\ngeometric cues to train an object proposal network for pseudo-labeling\nunannotated novel objects in the training set. Our resulting Geometry-guided\nOpen-world Object Detector (GOOD) significantly improves detection recall for\nnovel object categories and already performs well with only a few training\nclasses. Using a single \"person\" class for training on the COCO dataset, GOOD\nsurpasses SOTA methods by 5.0% AR@100, a relative improvement of 24%.\n","authors":["Haiwen Huang","Andreas Geiger","Dan Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.11720v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2210.16484v2","updated":"2023-02-03T08:30:51Z","published":"2022-10-29T03:53:11Z","title":"A Systematic Survey of Molecular Pre-trained Models","summary":"  Deep learning has achieved remarkable success in learning representations for\nmolecules, which is crucial for various biochemical applications, ranging from\nproperty prediction to drug design. However, training Deep Neural Networks\n(DNNs) from scratch often requires abundant labeled molecules, which are\nexpensive to acquire in the real world. To alleviate this issue, tremendous\nefforts have been devoted to Molecular Pre-trained Models (MPMs), where DNNs\nare pre-trained using large-scale unlabeled molecular databases and then\nfine-tuned over specific downstream tasks. Despite the prosperity, there lacks\na systematic review of this fast-growing field. In this paper, we present the\nfirst survey that summarizes the current progress of MPMs. We first highlight\nthe limitations of training molecular representation models from scratch to\nmotivate MPM studies. Next, we systematically review recent advances on this\ntopic from several key perspectives, including molecular descriptors, encoder\narchitectures, pre-training strategies, and applications. We also highlight the\nchallenges and promising avenues for future research, providing a useful\nresource for both machine learning and scientific communities.\n","authors":["Jun Xia","Yanqiao Zhu","Yuanqi Du","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2210.16484v2.pdf","comment":"9 pages, work in progress"},{"id":"http://arxiv.org/abs/2302.01581v1","updated":"2023-02-03T07:24:58Z","published":"2023-02-03T07:24:58Z","title":"Learning to Decouple Complex Systems","summary":"  A complex system with cluttered observations may be a coupled mixture of\nmultiple simple sub-systems corresponding to latent entities. Such sub-systems\nmay hold distinct dynamics in the continuous-time domain; therein, complicated\ninteractions between sub-systems also evolve over time. This setting is fairly\ncommon in the real world but has been less considered. In this paper, we\npropose a sequential learning approach under this setting by decoupling a\ncomplex system for handling irregularly sampled and cluttered sequential\nobservations. Such decoupling brings about not only subsystems describing the\ndynamics of each latent entity but also a meta-system capturing the interaction\nbetween entities over time. Specifically, we argue that the meta-system\nevolving within a simplex is governed by projected differential equations\n(ProjDEs). We further analyze and provide neural-friendly projection operators\nin the context of Bregman divergence. Experimental results on synthetic and\nreal-world datasets show the advantages of our approach when facing complex and\ncluttered sequential data compared to the state-of-the-art.\n","authors":["Zihan Zhou","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2302.01581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01576v1","updated":"2023-02-03T07:12:55Z","published":"2023-02-03T07:12:55Z","title":"ResMem: Learn what you can and memorize the rest","summary":"  The impressive generalization performance of modern neural networks is\nattributed in part to their ability to implicitly memorize complex training\npatterns. Inspired by this, we explore a novel mechanism to improve model\ngeneralization via explicit memorization. Specifically, we propose the\nresidual-memorization (ResMem) algorithm, a new method that augments an\nexisting prediction model (e.g. a neural network) by fitting the model's\nresiduals with a $k$-nearest neighbor based regressor. The final prediction is\nthen the sum of the original model and the fitted residual regressor. By\nconstruction, ResMem can explicitly memorize the training labels. Empirically,\nwe show that ResMem consistently improves the test set generalization of the\noriginal prediction model across various standard vision and natural language\nprocessing benchmarks. Theoretically, we formulate a stylized linear regression\nproblem and rigorously show that ResMem results in a more favorable test risk\nover the base predictor.\n","authors":["Zitong Yang","Michal Lukasik","Vaishnavh Nagarajan","Zonglin Li","Ankit Singh Rawat","Manzil Zaheer","Aditya Krishna Menon","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2302.01576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01574v1","updated":"2023-02-03T07:04:33Z","published":"2023-02-03T07:04:33Z","title":"An Operational Perspective to Fairness Interventions: Where and How to\n  Intervene","summary":"  As AI-based decision systems proliferate, their successful operationalization\nrequires balancing multiple desiderata: predictive performance, disparity\nacross groups, safeguarding sensitive group attributes (e.g., race), and\nengineering cost. We present a holistic framework for evaluating and\ncontextualizing fairness interventions with respect to the above desiderata.\nThe two key points of practical consideration are where (pre-, in-,\npost-processing) and how (in what way the sensitive group data is used) the\nintervention is introduced. We demonstrate our framework using a thorough\nbenchmarking study on predictive parity; we study close to 400 methodological\nvariations across two major model types (XGBoost vs. Neural Net) and ten\ndatasets. Methodological insights derived from our empirical study inform the\npractical design of ML workflow with fairness as a central concern. We find\npredictive parity is difficult to achieve without using group data, and despite\nrequiring group data during model training (but not inference),\ndistributionally robust methods provide significant Pareto improvement.\nMoreover, a plain XGBoost model often Pareto-dominates neural networks with\nfairness interventions, highlighting the importance of model inductive bias.\n","authors":["Brian Hsu","Xiaotong Chen","Ying Han","Hongseok Namkoong","Kinjal Basu"],"pdf_url":"https://arxiv.org/pdf/2302.01574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04798v2","updated":"2023-02-03T07:02:48Z","published":"2022-06-07T01:01:36Z","title":"A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs","summary":"  Reasoning on large-scale knowledge graphs has been long dominated by\nembedding methods. While path-based methods possess the inductive capacity that\nembeddings lack, they suffer from the scalability issue due to the exponential\nnumber of paths. Here we present A*Net, a scalable path-based method for\nknowledge graph reasoning. Inspired by the A* algorithm for shortest path\nproblems, our A*Net learns a priority function to select important nodes and\nedges at each iteration, to reduce time and memory footprint for both training\nand inference. The ratio of selected nodes and edges can be specified to trade\noff between performance and efficiency. Experiments on both transductive and\ninductive knowledge graph reasoning benchmarks show that A*Net achieves\ncompetitive performance with existing state-of-the-art path-based methods,\nwhile merely visiting 10% nodes and 10% edges at each iteration. On a\nmillion-scale dataset ogbl-wikikg2, A*Net achieves competitive performance with\nembedding methods and converges faster. To our best knowledge, A*Net is the\nfirst path-based method for knowledge graph reasoning at such a scale.\n","authors":["Zhaocheng Zhu","Xinyu Yuan","Michael Galkin","Sophie Xhonneux","Ming Zhang","Maxime Gazeau","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2206.04798v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01571v1","updated":"2023-02-03T06:49:27Z","published":"2023-02-03T06:49:27Z","title":"Robust Camera Pose Refinement for Multi-Resolution Hash Encoding","summary":"  Multi-resolution hash encoding has recently been proposed to reduce the\ncomputational cost of neural renderings, such as NeRF. This method requires\naccurate camera poses for the neural renderings of given scenes. However,\ncontrary to previous methods jointly optimizing camera poses and 3D scenes, the\nnaive gradient-based camera pose refinement method using multi-resolution hash\nencoding severely deteriorates performance. We propose a joint optimization\nalgorithm to calibrate the camera pose and learn a geometric representation\nusing efficient multi-resolution hash encoding. Showing that the oscillating\ngradient flows of hash encoding interfere with the registration of camera\nposes, our method addresses the issue by utilizing smooth interpolation\nweighting to stabilize the gradient oscillation for the ray samplings across\nhash grids. Moreover, the curriculum training procedure helps to learn the\nlevel-wise hash encoding, further increasing the pose refinement. Experiments\non the novel-view synthesis datasets validate that our learning frameworks\nachieve state-of-the-art performance and rapid convergence of neural rendering,\neven when initial camera poses are unknown.\n","authors":["Hwan Heo","Taekyung Kim","Jiyoung Lee","Jaewon Lee","Soohyun Kim","Hyunwoo J. Kim","Jin-Hwa Kim"],"pdf_url":"https://arxiv.org/pdf/2302.01571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01569v1","updated":"2023-02-03T06:43:08Z","published":"2023-02-03T06:43:08Z","title":"Uniform tensor clustering by jointly exploring sample affinities of\n  various orders","summary":"  Conventional clustering methods based on pairwise affinity usually suffer\nfrom the concentration effect while processing huge dimensional features yet\nlow sample sizes data, resulting in inaccuracy to encode the sample proximity\nand suboptimal performance in clustering. To address this issue, we propose a\nunified tensor clustering method (UTC) that characterizes sample proximity\nusing multiple samples' affinity, thereby supplementing rich spatial sample\ndistributions to boost clustering. Specifically, we find that the triadic\ntensor affinity can be constructed via the Khari-Rao product of two affinity\nmatrices. Furthermore, our early work shows that the fourth-order tensor\naffinity is defined by the Kronecker product. Therefore, we utilize\narithmetical products, Khatri-Rao and Kronecker products, to mathematically\nintegrate different orders of affinity into a unified tensor clustering\nframework. Thus, the UTC jointly learns a joint low-dimensional embedding to\ncombine various orders. Finally, a numerical scheme is designed to solve the\nproblem. Experiments on synthetic datasets and real-world datasets demonstrate\nthat 1) the usage of high-order tensor affinity could provide a supplementary\ncharacterization of sample proximity to the popular affinity matrix; 2) the\nproposed method of UTC is affirmed to enhance clustering by exploiting\ndifferent order affinities when processing high-dimensional data.\n","authors":["Hongmin Cai","Fei Qi","Junyu Li","Yu Hu","Yue Zhang","Yiu-ming Cheung","Bin Hu"],"pdf_url":"https://arxiv.org/pdf/2302.01569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01568v1","updated":"2023-02-03T06:33:28Z","published":"2023-02-03T06:33:28Z","title":"DynaMIX: Resource Optimization for DNN-Based Real-Time Applications on a\n  Multi-Tasking System","summary":"  As deep neural networks (DNNs) prove their importance and feasibility, more\nand more DNN-based apps, such as detection and classification of objects, have\nbeen developed and deployed on autonomous vehicles (AVs). To meet their growing\nexpectations and requirements, AVs should \"optimize\" use of their limited\nonboard computing resources for multiple concurrent in-vehicle apps while\nsatisfying their timing requirements (especially for safety). That is,\nreal-time AV apps should share the limited on-board resources with other\nconcurrent apps without missing their deadlines dictated by the frame rate of a\ncamera that generates and provides input images to the apps. However, most, if\nnot all, of existing DNN solutions focus on enhancing the concurrency of their\nspecific hardware without dynamically optimizing/modifying the DNN apps'\nresource requirements, subject to the number of running apps, owing to their\nhigh computational cost. To mitigate this limitation, we propose DynaMIX\n(Dynamic MIXed-precision model construction), which optimizes the resource\nrequirement of concurrent apps and aims to maximize execution accuracy. To\nrealize a real-time resource optimization, we formulate an optimization problem\nusing app performance profiles to consider both the accuracy and worst-case\nlatency of each app. We also propose dynamic model reconfiguration by lazy\nloading only the selected layers at runtime to reduce the overhead of loading\nthe entire model. DynaMIX is evaluated in terms of constraint satisfaction and\ninference accuracy for a multi-tasking system and compared against\nstate-of-the-art solutions, demonstrating its effectiveness and feasibility\nunder various environmental/operating conditions.\n","authors":["Minkyoung Cho","Kang G. Shin"],"pdf_url":"https://arxiv.org/pdf/2302.01568v1.pdf","comment":"13 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.01567v1","updated":"2023-02-03T06:28:54Z","published":"2023-02-03T06:28:54Z","title":"Deep Reinforcement Learning for Online Error Detection in Cyber-Physical\n  Systems","summary":"  Reliability is one of the major design criteria in Cyber-Physical Systems\n(CPSs). This is because of the existence of some critical applications in CPSs\nand their failure is catastrophic. Therefore, employing strong error detection\nand correction mechanisms in CPSs is inevitable. CPSs are composed of a variety\nof units, including sensors, networks, and microcontrollers. Each of these\nunits is probable to be in a faulty state at any time and the occurred fault\ncan result in erroneous output. The fault may cause the units of CPS to\nmalfunction and eventually crash. Traditional fault-tolerant approaches include\nredundancy time, hardware, information, and/or software. However, these\napproaches impose significant overheads besides their low error coverage, which\nlimits their applicability. In addition, the interval between error occurrence\nand detection is too long in these approaches. In this paper, based on Deep\nReinforcement Learning (DRL), a new error detection approach is proposed that\nnot only detects errors with high accuracy but also can perform error detection\nat the moment due to very low inference time. The proposed approach can\ncategorize different types of errors from normal data and predict whether the\nsystem will fail. The evaluation results illustrate that the proposed approach\nhas improved more than 2x in terms of accuracy and more than 5x in terms of\ninference time compared to other approaches.\n","authors":["Seyyedamirhossein Saeidi","Forouzan Fallah","Saeed Samieezafarghandi","Hamed Farbeh"],"pdf_url":"https://arxiv.org/pdf/2302.01567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10839v2","updated":"2023-02-03T06:23:57Z","published":"2022-12-21T08:27:49Z","title":"Consistent Range Approximation for Fair Predictive Modeling","summary":"  This paper proposes a novel framework for certifying the fairness of\npredictive models trained on biased data. It draws from query answering for\nincomplete and inconsistent databases to formulate the problem of consistent\nrange approximation (CRA) of fairness queries for a predictive model on a\ntarget population. The framework employs background knowledge of the data\ncollection process and biased data, working with or without limited statistics\nabout the target population, to compute a range of answers for fairness\nqueries. Using CRA, the framework builds predictive models that are certifiably\nfair on the target population, regardless of the availability of external data\nduring training. The framework's efficacy is demonstrated through evaluations\non real data, showing substantial improvement over existing state-of-the-art\nmethods.\n","authors":["Jiongli Zhu","Sainyam Galhotra","Nazanin Sabri","Babak Salimi"],"pdf_url":"https://arxiv.org/pdf/2212.10839v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01563v1","updated":"2023-02-03T06:22:00Z","published":"2023-02-03T06:22:00Z","title":"Causal Inference Based Single-branch Ensemble Trees For Uplift Modeling","summary":"  In this manuscript (ms), we propose causal inference based single-branch\nensemble trees for uplift modeling, namely CIET. Different from standard\nclassification methods for predictive probability modeling, CIET aims to\nachieve the change in the predictive probability of outcome caused by an action\nor a treatment. According to our CIET, two partition criteria are specifically\ndesigned to maximize the difference in outcome distribution between the\ntreatment and control groups. Next, a novel single-branch tree is built by\ntaking a top-down node partition approach, and the remaining samples are\ncensored since they are not covered by the upper node partition logic.\nRepeating the tree-building process on the censored data, single-branch\nensemble trees with a set of inference rules are thus formed. Moreover, CIET is\nexperimentally demonstrated to outperform previous approaches for uplift\nmodeling in terms of both area under uplift curve (AUUC) and Qini coefficient\nsignificantly. At present, CIET has already been applied to online personal\nloans in a national financial holdings group in China. CIET will also be of use\nto analysts applying machine learning techniques to causal inference in broader\nbusiness domains such as web advertising, medicine and economics.\n","authors":["Fanglan Zheng","Menghan Wang","Kun Li","Jiang Tian","Xiaojia Xiang"],"pdf_url":"https://arxiv.org/pdf/2302.01563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.02013v2","updated":"2023-02-03T05:34:24Z","published":"2022-04-05T06:30:03Z","title":"RL4ReAl: Reinforcement Learning for Register Allocation","summary":"  We aim to automate decades of research and experience in register allocation,\nleveraging machine learning. We tackle this problem by embedding a multi-agent\nreinforcement learning algorithm within LLVM, training it with the state of the\nart techniques. We formalize the constraints that precisely define the problem\nfor a given instruction-set architecture, while ensuring that the generated\ncode preserves semantic correctness. We also develop a gRPC based framework\nproviding a modular and efficient compiler interface for training and\ninference. Our approach is architecture independent: we show experimental\nresults targeting Intel x86 and ARM AArch64. Our results match or out-perform\nthe heavily tuned, production-grade register allocators of LLVM.\n","authors":["S. VenkataKeerthy","Siddharth Jain","Anilava Kundu","Rohit Aggarwal","Albert Cohen","Ramakrishna Upadrasta"],"pdf_url":"https://arxiv.org/pdf/2204.02013v2.pdf","comment":"Published in CC'23"},{"id":"http://arxiv.org/abs/2302.01556v1","updated":"2023-02-03T05:28:02Z","published":"2023-02-03T05:28:02Z","title":"Machine Learning for UAV Propeller Fault Detection based on a Hybrid\n  Data Generation Model","summary":"  This paper describes the development of an on-board data-driven system that\ncan monitor and localize the fault in a quadrotor unmanned aerial vehicle (UAV)\nand at the same time, evaluate the degree of damage of the fault under real\nscenarios. To achieve offline training data generation, a hybrid approach is\nproposed for the development of a virtual data-generative model using a\ncombination of data-driven models as well as well-established dynamic models\nthat describe the kinematics of the UAV. To effectively represent the drop in\nperformance of a faulty propeller, a variation of the deep neural network, a\nLSTM network is proposed. With the RPM of the propeller as input and based on\nthe fault condition of the propeller, the proposed propeller model estimates\nthe resultant torque and thrust. Then, flight datasets of the UAV under various\nfault scenarios are generated via simulation using the developed\ndata-generative model. Lastly, a fault classifier using a CNN model is proposed\nto identify as well as evaluate the degree of damage to the damaged propeller.\nThe scope of this paper focuses on the identification of faulty propellers and\nclassification of the fault level for quadrotor UAVs using RPM as well as\nflight data. Doing so allows for early minor fault detection to prevent serious\nfaults from occurring if the fault is left unrepaired. To further validate the\nworkability of this approach outside of simulation, a real-flight test is\nconducted indoors. The real flight data is collected and a simulation to real\nsim-real test is conducted. Due to the imperfections in the build of our\nexperimental UAV, a slight calibration approach to our simulation model is\nfurther proposed and the experimental results obtained show that our trained\nmodel can identify the location of propeller fault as well as the degree/type\nof damage. Currently, the diagnosis accuracy on the testing set is over 80%.\n","authors":["J. J. Tong","W. Zhang","F. Liao","C. F. Li","Y. F. Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00861v2","updated":"2023-02-03T05:25:58Z","published":"2023-02-02T04:12:29Z","title":"SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling","summary":"  Time series analysis is widely used in extensive areas. Recently, to reduce\nlabeling expenses and benefit various tasks, self-supervised pre-training has\nattracted immense interest. One mainstream paradigm is masked modeling, which\nsuccessfully pre-trains deep models by learning to reconstruct the masked\ncontent based on the unmasked part. However, since the semantic information of\ntime series is mainly contained in temporal variations, the standard way of\nrandomly masking a portion of time points will ruin vital temporal variations\nof time series seriously, making the reconstruction task too difficult to guide\nrepresentation learning. We thus present SimMTM, a Simple pre-training\nframework for Masked Time-series Modeling. By relating masked modeling to\nmanifold learning, SimMTM proposes to recover masked time points by the\nweighted aggregation of multiple neighbors outside the manifold, which eases\nthe reconstruction task by assembling ruined but complementary temporal\nvariations from multiple masked series. SimMTM further learns to uncover the\nlocal structure of the manifold helpful for masked modeling. Experimentally,\nSimMTM achieves state-of-the-art fine-tuning performance in two canonical time\nseries analysis tasks: forecasting and classification, covering both in- and\ncross-domain settings.\n","authors":["Jiaxiang Dong","Haixu Wu","Haoran Zhang","Li Zhang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2302.00861v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01550v1","updated":"2023-02-03T05:13:40Z","published":"2023-02-03T05:13:40Z","title":"Vertical Federated Learning: Taxonomies, Threats, and Prospects","summary":"  Federated learning (FL) is the most popular distributed machine learning\ntechnique. FL allows machine-learning models to be trained without acquiring\nraw data to a single point for processing. Instead, local models are trained\nwith local data; the models are then shared and combined. This approach\npreserves data privacy as locally trained models are shared instead of the raw\ndata themselves. Broadly, FL can be divided into horizontal federated learning\n(HFL) and vertical federated learning (VFL). For the former, different parties\nhold different samples over the same set of features; for the latter, different\nparties hold different feature data belonging to the same set of samples. In a\nnumber of practical scenarios, VFL is more relevant than HFL as different\ncompanies (e.g., bank and retailer) hold different features (e.g., credit\nhistory and shopping history) for the same set of customers. Although VFL is an\nemerging area of research, it is not well-established compared to HFL. Besides,\nVFL-related studies are dispersed, and their connections are not intuitive.\nThus, this survey aims to bring these VFL-related studies to one place.\nFirstly, we classify existing VFL structures and algorithms. Secondly, we\npresent the threats from security and privacy perspectives to VFL. Thirdly, for\nthe benefit of future researchers, we discussed the challenges and prospects of\nVFL in detail.\n","authors":["Qun Li","Chandra Thapa","Lawrence Ong","Yifeng Zheng","Hua Ma","Seyit A. Camtepe","Anmin Fu","Yansong Gao"],"pdf_url":"https://arxiv.org/pdf/2302.01550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00902v2","updated":"2023-02-03T05:06:46Z","published":"2023-02-02T06:38:44Z","title":"Language Quantized AutoEncoders: Towards Unsupervised Text-Image\n  Alignment","summary":"  Recent progress in scaling up large language models has shown impressive\ncapabilities in performing few-shot learning across a wide range of text-based\ntasks. However, a key limitation is that these language models fundamentally\nlack visual perception - a crucial attribute needed to extend these models to\nbe able to interact with the real world and solve vision tasks, such as in\nvisual-question answering and robotics. Prior works have largely connected\nimage to text through pretraining and/or fine-tuning on curated image-text\ndatasets, which can be a costly and expensive process. In order to resolve this\nlimitation, we propose a simple yet effective approach called\nLanguage-Quantized AutoEncoder (LQAE), a modification of VQ-VAE that learns to\nalign text-image data in an unsupervised manner by leveraging pretrained\nlanguage models (e.g., BERT, RoBERTa). Our main idea is to encode image as\nsequences of text tokens by directly quantizing image embeddings using a\npretrained language codebook. We then apply random masking followed by a BERT\nmodel, and have the decoder reconstruct the original image from BERT predicted\ntext token embeddings. By doing so, LQAE learns to represent similar images\nwith similar clusters of text tokens, thereby aligning these two modalities\nwithout the use of aligned text-image pairs. This enables few-shot image\nclassification with large language models (e.g., GPT-3) as well as linear\nclassification of images based on BERT text features. To the best of our\nknowledge, our work is the first work that uses unaligned images for multimodal\ntasks by leveraging the power of pretrained language models.\n","authors":["Hao Liu","Wilson Yan","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.00902v2.pdf","comment":"Fixed typos"},{"id":"http://arxiv.org/abs/2102.08501v4","updated":"2023-02-03T05:00:34Z","published":"2021-02-16T23:50:35Z","title":"DEUP: Direct Epistemic Uncertainty Prediction","summary":"  Epistemic Uncertainty is a measure of the lack of knowledge of a learner\nwhich diminishes with more evidence. While existing work focuses on using the\nvariance of the Bayesian posterior due to parameter uncertainty as a measure of\nepistemic uncertainty, we argue that this does not capture the part of lack of\nknowledge induced by model misspecification. We discuss how the excess risk,\nwhich is the gap between the generalization error of a predictor and the Bayes\npredictor, is a sound measure of epistemic uncertainty which captures the\neffect of model misspecification. We thus propose a principled framework for\ndirectly estimating the excess risk by learning a secondary predictor for the\ngeneralization error and subtracting an estimate of aleatoric uncertainty,\ni.e., intrinsic unpredictability. We discuss the merits of this novel measure\nof epistemic uncertainty, and highlight how it differs from variance-based\nmeasures of epistemic uncertainty and addresses its major pitfall. Our\nframework, Direct Epistemic Uncertainty Prediction (DEUP) is particularly\ninteresting in interactive learning environments, where the learner is allowed\nto acquire novel examples in each round. Through a wide set of experiments, we\nillustrate how existing methods in sequential model optimization can be\nimproved with epistemic uncertainty estimates from DEUP, and how DEUP can be\nused to drive exploration in reinforcement learning. We also evaluate the\nquality of uncertainty estimates from DEUP for probabilistic image\nclassification and predicting synergies of drug combinations.\n","authors":["Salem Lahlou","Moksh Jain","Hadi Nekoei","Victor Ion Butoi","Paul Bertin","Jarrid Rector-Brooks","Maksym Korablyov","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2102.08501v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01546v1","updated":"2023-02-03T04:51:54Z","published":"2023-02-03T04:51:54Z","title":"Group Fairness in Non-monotone Submodular Maximization","summary":"  Maximizing a submodular function has a wide range of applications in machine\nlearning and data mining. One such application is data summarization whose goal\nis to select a small set of representative and diverse data items from a large\ndataset. However, data items might have sensitive attributes such as race or\ngender, in this setting, it is important to design \\emph{fairness-aware}\nalgorithms to mitigate potential algorithmic bias that may cause over- or\nunder- representation of particular groups. Motivated by that, we propose and\nstudy the classic non-monotone submodular maximization problem subject to novel\ngroup fairness constraints. Our goal is to select a set of items that maximizes\na non-monotone submodular function, while ensuring that the number of selected\nitems from each group is proportionate to its size, to the extent specified by\nthe decision maker. We develop the first constant-factor approximation\nalgorithms for this problem. We also extend the basic model to incorporate an\nadditional global size constraint on the total number of selected items.\n","authors":["Jing Yuan","Shaojie Tang"],"pdf_url":"https://arxiv.org/pdf/2302.01546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01544v1","updated":"2023-02-03T04:47:14Z","published":"2023-02-03T04:47:14Z","title":"Optimality of Thompson Sampling with Noninformative Priors for Pareto\n  Bandits","summary":"  In the stochastic multi-armed bandit problem, a randomized probability\nmatching policy called Thompson sampling (TS) has shown excellent performance\nin various reward models. In addition to the empirical performance, TS has been\nshown to achieve asymptotic problem-dependent lower bounds in several models.\nHowever, its optimality has been mainly addressed under light-tailed or\none-parameter models that belong to exponential families. In this paper, we\nconsider the optimality of TS for the Pareto model that has a heavy tail and is\nparameterized by two unknown parameters. Specifically, we discuss the\noptimality of TS with probability matching priors that include the Jeffreys\nprior and the reference priors. We first prove that TS with certain probability\nmatching priors can achieve the optimal regret bound. Then, we show the\nsuboptimality of TS with other priors, including the Jeffreys and the reference\npriors. Nevertheless, we find that TS with the Jeffreys and reference priors\ncan achieve the asymptotic lower bound if one uses a truncation procedure.\nThese results suggest carefully choosing noninformative priors to avoid\nsuboptimality and show the effectiveness of truncation procedures in TS-based\npolicies.\n","authors":["Jongyeong Lee","Junya Honda","Chao-Kai Chiang","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2302.01544v1.pdf","comment":"49 pages, a preprint"},{"id":"http://arxiv.org/abs/2302.01543v1","updated":"2023-02-03T04:38:00Z","published":"2023-02-03T04:38:00Z","title":"Multiplier Bootstrap-based Exploration","summary":"  Despite the great interest in the bandit problem, designing efficient\nalgorithms for complex models remains challenging, as there is typically no\nanalytical way to quantify uncertainty. In this paper, we propose Multiplier\nBootstrap-based Exploration (MBE), a novel exploration strategy that is\napplicable to any reward model amenable to weighted loss minimization. We prove\nboth instance-dependent and instance-independent rate-optimal regret bounds for\nMBE in sub-Gaussian multi-armed bandits. With extensive simulation and real\ndata experiments, we show the generality and adaptivity of MBE.\n","authors":["Runzhe Wan","Haoyu Wei","Branislav Kveton","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2302.01543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01539v1","updated":"2023-02-03T04:30:17Z","published":"2023-02-03T04:30:17Z","title":"A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization","summary":"  One of the most critical problems in machine learning is HyperParameter\nOptimization (HPO), since choice of hyperparameters has a significant impact on\nfinal model performance. Although there are many HPO algorithms, they either\nhave no theoretical guarantees or require strong assumptions. To this end, we\nintroduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes\nLipschitz continuity of the objective function. BLiE exploits the landscape of\nthe objective function to adaptively search over the hyperparameter space.\nTheoretically, we show that $(i)$ BLiE finds an $\\epsilon$-optimal\nhyperparameter with $O \\left( \\frac{1}{\\epsilon} \\right)^{d_z + \\beta}$ total\nbudgets, where $d_z$ and $\\beta$ are problem intrinsic; $(ii)$ BLiE is highly\nparallelizable. Empirically, we demonstrate that BLiE outperforms the\nstate-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to\nsearch for noise schedule of diffusion models. Comparison with the default\nschedule shows that BLiE schedule greatly improves the sampling speed.\n","authors":["Yasong Feng","Weijian Luo","Yimin Huang","Tianyu Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01538v1","updated":"2023-02-03T04:24:49Z","published":"2023-02-03T04:24:49Z","title":"DCM: Deep energy method based on the principle of minimum complementary\n  energy","summary":"  The principle of minimum potential and complementary energy are the most\nimportant variational principles in solid mechanics. The deep energy method\n(DEM), which has received much attention, is based on the principle of minimum\npotential energy and lacks the important form of minimum complementary energy.\nThus, we propose the deep energy method based on the principle of minimum\ncomplementary energy (DCM). The output function of DCM is the stress function\nthat naturally satisfies the equilibrium equation. We extend the proposed DCM\nalgorithm (DCM-P), adding the terms that naturally satisfy the biharmonic\nequation in the Airy stress function. We combine operator learning with\nphysical equations and propose a deep complementary energy operator method\n(DCM-O), including branch net, trunk net, basis net, and particular net. DCM-O\nfirst combines existing high-fidelity numerical results to train DCM-O through\ndata. Then the complementary energy is used to train the branch net and trunk\nnet in DCM-O. To analyze DCM performance, we present the numerical result of\nthe most common stress functions, the Prandtl and Airy stress function. The\nproposed method DCM is used to model the representative mechanical problems\nwith the different types of boundary conditions. We compare DCM with the\nexisting PINNs and DEM algorithms. The result shows the advantage of the\nproposed DCM is suitable for dealing with problems of dominated displacement\nboundary conditions, which is reflected in theory and our numerical\nexperiments. DCM-P and DCM-O improve the accuracy of DCM and the speed of\ncalculation convergence. DCM is an essential supplementary energy form of the\ndeep energy method. We believe that operator learning based on the energy\nmethod can balance data and physical equations well, giving computational\nmechanics broad research prospects.\n","authors":["Yizheng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01538v1.pdf","comment":"46 pages, 23 figures"},{"id":"http://arxiv.org/abs/2302.01536v1","updated":"2023-02-03T04:22:29Z","published":"2023-02-03T04:22:29Z","title":"Using natural language processing and structured medical data to\n  phenotype patients hospitalized due to COVID-19","summary":"  To identify patients who are hospitalized because of COVID-19 as opposed to\nthose who were admitted for other indications, we compared the performance of\ndifferent computable phenotype definitions for COVID-19 hospitalizations that\nuse different types of data from the electronic health records (EHR), including\nstructured EHR data elements, provider notes, or a combination of both data\ntypes. And conduct a retrospective data analysis utilizing chart review-based\nvalidation. Participants are 586 hospitalized individuals who tested positive\nfor SARS-CoV-2 during January 2022. We used natural language processing to\nincorporate data from provider notes and LASSO regression and Random Forests to\nfit classification algorithms that incorporated structured EHR data elements,\nprovider notes, or a combination of structured data and provider notes.\nResults: Based on a chart review, 38% of 586 patients were determined to be\nhospitalized for reasons other than COVID-19 despite having tested positive for\nSARS-CoV-2. A classification algorithm that used provider notes had\nsignificantly better discrimination than one that used structured EHR data\nelements (AUROC: 0.894 vs 0.841, p < 0.001), and performed similarly to a model\nthat combined provider notes with structured data elements (AUROC: 0.894 vs\n0.893). Assessments of hospital outcome metrics significantly differed based on\nwhether the population included all hospitalized patients who tested positive\nfor SARS-CoV-2 versus those who were determined to have been hospitalized due\nto COVID-19. This work demonstrates the utility of natural language processing\napproaches to derive information related to patient hospitalizations in cases\nwhere there may be multiple conditions that could serve as the primary\nindication for hospitalization.\n","authors":["Feier Chang","Jay Krishnan","Jillian H Hurst","Michael E Yarrington","Deverick J Anderson","Emily C O'Brien","Benjamin A Goldstein"],"pdf_url":"https://arxiv.org/pdf/2302.01536v1.pdf","comment":"21 pages, 2 figures, 3 tables, 1 supplemental figure, 2 supplemental\n  tables"},{"id":"http://arxiv.org/abs/2302.01535v1","updated":"2023-02-03T04:20:25Z","published":"2023-02-03T04:20:25Z","title":"Support Recovery in Sparse PCA with Non-Random Missing Data","summary":"  We analyze a practical algorithm for sparse PCA on incomplete and noisy data\nunder a general non-random sampling scheme. The algorithm is based on a\nsemidefinite relaxation of the $\\ell_1$-regularized PCA problem. We provide\ntheoretical justification that under certain conditions, we can recover the\nsupport of the sparse leading eigenvector with high probability by obtaining a\nunique solution. The conditions involve the spectral gap between the largest\nand second-largest eigenvalues of the true data matrix, the magnitude of the\nnoise, and the structural properties of the observed entries. The concepts of\nalgebraic connectivity and irregularity are used to describe the structural\nproperties of the observed entries. We empirically justify our theorem with\nsynthetic and real data analysis. We also show that our algorithm outperforms\nseveral other sparse PCA approaches especially when the observed entries have\ngood structural properties. As a by-product of our analysis, we provide two\ntheorems to handle a deterministic sampling scheme, which can be applied to\nother matrix-related problems.\n","authors":["Hanbyul Lee","Qifan Song","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2302.01535v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2205.15215"},{"id":"http://arxiv.org/abs/2302.01530v1","updated":"2023-02-03T04:09:22Z","published":"2023-02-03T04:09:22Z","title":"Revisiting Intermediate Layer Distillation for Compressing Language\n  Models: An Overfitting Perspective","summary":"  Knowledge distillation (KD) is a highly promising method for mitigating the\ncomputational problems of pre-trained language models (PLMs). Among various KD\napproaches, Intermediate Layer Distillation (ILD) has been a de facto standard\nKD method with its performance efficacy in the NLP field. In this paper, we\nfind that existing ILD methods are prone to overfitting to training datasets,\nalthough these methods transfer more information than the original KD. Next, we\npresent the simple observations to mitigate the overfitting of ILD: distilling\nonly the last Transformer layer and conducting ILD on supplementary tasks.\nBased on our two findings, we propose a simple yet effective\nconsistency-regularized ILD (CR-ILD), which prevents the student model from\noverfitting the training dataset. Substantial experiments on distilling BERT on\nthe GLUE benchmark and several synthetic datasets demonstrate that our proposed\nILD method outperforms other KD techniques. Our code is available at\nhttps://github.com/jongwooko/CR-ILD.\n","authors":["Jongwoo Ko","Seungjoon Park","Minchan Jeong","Sukjin Hong","Euijai Ahn","Du-Seong Chang","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2302.01530v1.pdf","comment":"The 17th Conference of the European Chapter of the Association for\n  Computational Linguistics (Findings)"},{"id":"http://arxiv.org/abs/2302.01526v1","updated":"2023-02-03T03:48:43Z","published":"2023-02-03T03:48:43Z","title":"Example-Based Explainable AI and its Application for Remote Sensing\n  Image Classification","summary":"  We present a method of explainable artificial intelligence (XAI), \"What I\nKnow (WIK)\", to provide additional information to verify the reliability of a\ndeep learning model by showing an example of an instance in a training dataset\nthat is similar to the input data to be inferred and demonstrate it in a remote\nsensing image classification task. One of the expected roles of XAI methods is\nverifying whether inferences of a trained machine learning model are valid for\nan application, and it is an important factor that what datasets are used for\ntraining the model as well as the model architecture. Our data-centric approach\ncan help determine whether the training dataset is sufficient for each\ninference by checking the selected example data. If the selected example looks\nsimilar to the input data, we can confirm that the model was not trained on a\ndataset with a feature distribution far from the feature of the input data.\nWith this method, the criteria for selecting an example are not merely data\nsimilarity with the input data but also data similarity in the context of the\nmodel task. Using a remote sensing image dataset from the Sentinel-2 satellite,\nthe concept was successfully demonstrated with reasonably selected examples.\nThis method can be applied to various machine-learning tasks, including\nclassification and regression.\n","authors":["Shin-nosuke Ishikawa","Masato Todo","Masato Taki","Yasunobu Uchiyama","Kazunari Matsunaga","Peihsuan Lin","Taiki Ogihara","Masao Yasui"],"pdf_url":"https://arxiv.org/pdf/2302.01526v1.pdf","comment":"10 pages, 4 figures, accepted for publication in International\n  Journal of Applied Earth Observation and Geoinformation"},{"id":"http://arxiv.org/abs/2210.02720v2","updated":"2023-02-03T03:40:58Z","published":"2022-10-06T07:12:54Z","title":"Understanding Gradient Regularization in Deep Learning: Efficient\n  Finite-Difference Computation and Implicit Bias","summary":"  Gradient regularization (GR) is a method that penalizes the gradient norm of\nthe training loss during training. While some studies have reported that GR can\nimprove generalization performance, little attention has been paid to it from\nthe algorithmic perspective, that is, the algorithms of GR that efficiently\nimprove the performance. In this study, we first reveal that a specific\nfinite-difference computation, composed of both gradient ascent and descent\nsteps, reduces the computational cost of GR. Next, we show that the\nfinite-difference computation also works better in the sense of generalization\nperformance. We theoretically analyze a solvable model, a diagonal linear\nnetwork, and clarify that GR has a desirable implicit bias to so-called rich\nregime and finite-difference computation strengthens this bias. Furthermore,\nfinite-difference GR is closely related to some other algorithms based on\niterative ascent and descent steps for exploring flat minima. In particular, we\nreveal that the flooding method can perform finite-difference GR in an implicit\nway. Thus, this work broadens our understanding of GR for both practice and\ntheory.\n","authors":["Ryo Karakida","Tomoumi Takase","Tomohiro Hayase","Kazuki Osawa"],"pdf_url":"https://arxiv.org/pdf/2210.02720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01524v1","updated":"2023-02-03T03:38:50Z","published":"2023-02-03T03:38:50Z","title":"Ordered GNN: Ordering Message Passing to Deal with Heterophily and\n  Over-smoothing","summary":"  Most graph neural networks follow the message passing mechanism. However, it\nfaces the over-smoothing problem when multiple times of message passing is\napplied to a graph, causing indistinguishable node representations and prevents\nthe model to effectively learn dependencies between farther-away nodes. On the\nother hand, features of neighboring nodes with different labels are likely to\nbe falsely mixed, resulting in the heterophily problem. In this work, we\npropose to order the messages passing into the node representation, with\nspecific blocks of neurons targeted for message passing within specific hops.\nThis is achieved by aligning the hierarchy of the rooted-tree of a central node\nwith the ordered neurons in its node representation. Experimental results on an\nextensive set of datasets show that our model can simultaneously achieve the\nstate-of-the-art in both homophily and heterophily settings, without any\ntargeted design. Moreover, its performance maintains pretty well while the\nmodel becomes really deep, effectively preventing the over-smoothing problem.\nFinally, visualizing the gating vectors shows that our model learns to behave\ndifferently between homophily and heterophily settings, providing an\nexplainable graph neural model.\n","authors":["Yunchong Song","Chenghu Zhou","Xinbing Wang","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2302.01524v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01523v1","updated":"2023-02-03T03:38:19Z","published":"2023-02-03T03:38:19Z","title":"Multi-channel Autobidding with Budget and ROI Constraints","summary":"  In digital online advertising, advertisers procure ad impressions\nsimultaneously on multiple platforms, or so-called channels, such as Google\nAds, Meta Ads Manager, etc., each of which consists of numerous ad auctions. We\nstudy how an advertiser maximizes total conversion (e.g. ad clicks) while\nsatisfying aggregate return-on-investment (ROI) and budget constraints across\nall channels. In practice, an advertiser does not have control over, and thus\ncannot globally optimize, which individual ad auctions she participates in for\neach channel, and instead authorizes a channel to procure impressions on her\nbehalf: the advertiser can only utilize two levers on each channel, namely\nsetting a per-channel budget and per-channel target ROI. In this work, we first\nanalyze the effectiveness of each of these levers for solving the advertiser's\nglobal multi-channel problem. We show that when an advertiser only optimizes\nover per-channel ROIs, her total conversion can be arbitrarily worse than what\nshe could have obtained in the global problem. Further, we show that the\nadvertiser can achieve the global optimal conversion when she only optimizes\nover per-channel budgets. In light of this finding, under a bandit feedback\nsetting that mimics real-world scenarios where advertisers have limited\ninformation on ad auctions in each channels and how channels procure ads, we\npresent an efficient learning algorithm that produces per-channel budgets whose\nresulting conversion approximates that of the global optimal problem. Finally,\nwe argue that all our results hold for both single-item and multi-item auctions\nfrom which channels procure impressions on advertisers' behalf.\n","authors":["Yuan Deng","Negin Golrezaei","Patrick Jaillet","Jason Cheuk Nam Liang","Vahab Mirrokni"],"pdf_url":"https://arxiv.org/pdf/2302.01523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01522v1","updated":"2023-02-03T03:35:28Z","published":"2023-02-03T03:35:28Z","title":"Improving Recommendation Relevance by simulating User Interest","summary":"  Most if not all on-line item-to-item recommendation systems rely on\nestimation of a distance like measure (rank) of similarity between items. For\non-line recommendation systems, time sensitivity of this similarity measure is\nextremely important. We observe that recommendation \"recency\" can be\nstraightforwardly and transparently maintained by iterative reduction of ranks\nof inactive items. The paper briefly summarizes algorithmic developments based\non this self-explanatory observation. The basic idea behind this work is\npatented in a context of online recommendation systems.\n","authors":["Alexander Kushkuley","Joshua Correa"],"pdf_url":"https://arxiv.org/pdf/2302.01522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12351v2","updated":"2023-02-03T03:27:57Z","published":"2023-01-29T04:10:12Z","title":"On the Opportunity of Causal Deep Generative Models: A Survey and Future\n  Directions","summary":"  Deep generative models have gained popularity in recent years due to their\nability to accurately replicate inherent empirical distributions and yield\nnovel samples. In particular, certain advances are proposed wherein the model\nengenders data examples following specified attributes. Nevertheless, several\nchallenges still exist and are to be overcome, i.e., difficulty in\nextrapolating out-of-sample data and insufficient learning of disentangled\nrepresentations. Structural causal models (SCMs), on the other hand,\nencapsulate the causal factors that govern a generative process and\ncharacterize a generative model based on causal relationships, providing\ncrucial insights for addressing the current obstacles in deep generative\nmodels. In this paper, we present a comprehensive survey of Causal deep\nGenerative Models (CGMs), which combine SCMs and deep generative models in a\nway that boosts several trustworthy properties such as robustness, fairness,\nand interpretability. We provide an overview of the recent advances in CGMs,\ncategorize them based on generative types, and discuss how causality is\nintroduced into the family of deep generative models. We also explore potential\navenues for future research in this field.\n","authors":["Guanglin Zhou","Lina Yao","Xiwei Xu","Chen Wang","Liming Zhu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.12351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01518v1","updated":"2023-02-03T03:26:08Z","published":"2023-02-03T03:26:08Z","title":"LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex\n  Geometry","summary":"  We present a novel loss formulation for efficient learning of complex\ndynamics from governing physics, typically described by partial differential\nequations (PDEs), using physics-informed neural networks (PINNs). In our\nexperiments, existing versions of PINNs are seen to learn poorly in many\nproblems, especially for complex geometries, as it becomes increasingly\ndifficult to establish appropriate sampling strategy at the near boundary\nregion. Overly dense sampling can adversely impede training convergence if the\nlocal gradient behaviors are too complex to be adequately modelled by PINNs. On\nthe other hand, if the samples are too sparse, existing PINNs tend to overfit\nthe near boundary region, leading to incorrect solution. To prevent such\nissues, we propose a new Boundary Connectivity (BCXN) loss function which\nprovides linear local structure approximation (LSA) to the gradient behaviors\nat the boundary for PINN. Our BCXN-loss implicitly imposes local structure\nduring training, thus facilitating fast physics-informed learning across entire\nproblem domains with order of magnitude sparser training samples. This LSA-PINN\nmethod shows a few orders of magnitude smaller errors than existing methods in\nterms of the standard L2-norm metric, while using dramatically fewer training\nsamples and iterations. Our proposed LSA-PINN does not pose any requirement on\nthe differentiable property of the networks, and we demonstrate its benefits\nand ease of implementation on both multi-layer perceptron and convolutional\nneural network versions as commonly used in current PINN literature.\n","authors":["Jian Cheng Wong","Pao-Hsiung Chiu","Chinchun Ooi","My Ha Dao","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2302.01518v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.01517v1","updated":"2023-02-03T03:19:14Z","published":"2023-02-03T03:19:14Z","title":"Pseudonorm Approachability and Applications to Regret Minimization","summary":"  Blackwell's celebrated approachability theory provides a general framework\nfor a variety of learning problems, including regret minimization. However,\nBlackwell's proof and implicit algorithm measure approachability using the\n$\\ell_2$ (Euclidean) distance. We argue that in many applications such as\nregret minimization, it is more useful to study approachability under other\ndistance metrics, most commonly the $\\ell_\\infty$-metric. But, the time and\nspace complexity of the algorithms designed for $\\ell_\\infty$-approachability\ndepend on the dimension of the space of the vectorial payoffs, which is often\nprohibitively large. Thus, we present a framework for converting\nhigh-dimensional $\\ell_\\infty$-approachability problems to low-dimensional\npseudonorm approachability problems, thereby resolving such issues. We first\nshow that the $\\ell_\\infty$-distance between the average payoff and the\napproachability set can be equivalently defined as a pseudodistance between a\nlower-dimensional average vector payoff and a new convex set we define. Next,\nwe develop an algorithmic theory of pseudonorm approachability, analogous to\nprevious work on approachability for $\\ell_2$ and other norms, showing that it\ncan be achieved via online linear optimization (OLO) over a convex set given by\nthe Fenchel dual of the unit pseudonorm ball. We then use that to show, modulo\nmild normalization assumptions, that there exists an\n$\\ell_\\infty$-approachability algorithm whose convergence is independent of the\ndimension of the original vectorial payoff. We further show that that algorithm\nadmits a polynomial-time complexity, assuming that the original\n$\\ell_\\infty$-distance can be computed efficiently. We also give an\n$\\ell_\\infty$-approachability algorithm whose convergence is logarithmic in\nthat dimension using an FTRL algorithm with a maximum-entropy regularizer.\n","authors":["Christoph Dann","Yishay Mansour","Mehryar Mohri","Jon Schneider","Balasubramanian Sivan"],"pdf_url":"https://arxiv.org/pdf/2302.01517v1.pdf","comment":"To appear at ALT 2023"},{"id":"http://arxiv.org/abs/2208.06073v4","updated":"2023-02-03T03:10:59Z","published":"2022-08-12T01:00:59Z","title":"Conditional Antibody Design as 3D Equivariant Graph Translation","summary":"  Antibody design is valuable for therapeutic usage and biological research.\nExisting deep-learning-based methods encounter several key issues: 1)\nincomplete context for Complementarity-Determining Regions (CDRs) generation;\n2) incapability of capturing the entire 3D geometry of the input structure; 3)\ninefficient prediction of the CDR sequences in an autoregressive manner. In\nthis paper, we propose Multi-channel Equivariant Attention Network (MEAN) to\nco-design 1D sequences and 3D structures of CDRs. To be specific, MEAN\nformulates antibody design as a conditional graph translation problem by\nimporting extra components including the target antigen and the light chain of\nthe antibody. Then, MEAN resorts to E(3)-equivariant message passing along with\na proposed attention mechanism to better capture the geometrical correlation\nbetween different components. Finally, it outputs both the 1D sequences and 3D\nstructure via a multi-round progressive full-shot scheme, which enjoys more\nefficiency and precision against previous autoregressive approaches. Our method\nsignificantly surpasses state-of-the-art models in sequence and structure\nmodeling, antigen-binding CDR design, and binding affinity optimization.\nSpecifically, the relative improvement to baselines is about 23% in\nantigen-binding CDR design and 34% for affinity optimization.\n","authors":["Xiangzhe Kong","Wenbing Huang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2208.06073v4.pdf","comment":"Accepted to ICLR 2023 as oral presentation"},{"id":"http://arxiv.org/abs/2302.01513v1","updated":"2023-02-03T03:02:38Z","published":"2023-02-03T03:02:38Z","title":"Towards Practical Preferential Bayesian Optimization with Skew Gaussian\n  Processes","summary":"  We study preferential Bayesian optimization (BO) where reliable feedback is\nlimited to pairwise comparison called duels. An important challenge in\npreferential BO, which uses the preferential Gaussian process (GP) model to\nrepresent flexible preference structure, is that the posterior distribution is\na computationally intractable skew GP. The most widely used approach for\npreferential BO is Gaussian approximation, which ignores the skewness of the\ntrue posterior. Alternatively, Markov chain Monte Carlo (MCMC) based\npreferential BO is also proposed. In this work, we first verify the accuracy of\nGaussian approximation, from which we reveal the critical problem that the\npredictive probability of duels can be inaccurate. This observation motivates\nus to improve the MCMC-based estimation for skew GP, for which we show the\npractical efficiency of Gibbs sampling and derive the low variance MC\nestimator. However, the computational time of MCMC can still be a bottleneck in\npractice. Towards building a more practical preferential BO, we develop a new\nmethod that achieves both high computational efficiency and low sample\ncomplexity, and then demonstrate its effectiveness through extensive numerical\nexperiments.\n","authors":["Shion Takeno","Masahiro Nomura","Masayuki Karasuyama"],"pdf_url":"https://arxiv.org/pdf/2302.01513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13771v2","updated":"2023-02-03T03:02:13Z","published":"2022-08-26T23:57:41Z","title":"Fast Bayesian Optimization of Needle-in-a-Haystack Problems using\n  Zooming Memory-Based Initialization (ZoMBI)","summary":"  Needle-in-a-Haystack problems exist across a wide range of applications\nincluding rare disease prediction, ecological resource management, fraud\ndetection, and material property optimization. A Needle-in-a-Haystack problem\narises when there is an extreme imbalance of optimum conditions relative to the\nsize of the dataset. For example, only $0.82\\%$ out of $146$k total materials\nin the open-access Materials Project database have a negative Poisson's ratio.\nHowever, current state-of-the-art optimization algorithms are not designed with\nthe capabilities to find solutions to these challenging multidimensional\nNeedle-in-a-Haystack problems, resulting in slow convergence to a global\noptimum or pigeonholing into a local minimum. In this paper, we present a\nZooming Memory-Based Initialization algorithm, entitled ZoMBI. ZoMBI actively\nextracts knowledge from the previously best-performing evaluated experiments to\niteratively zoom in the sampling search bounds towards the global optimum\n\"needle\" and then prunes the memory of low-performing historical experiments to\naccelerate compute times by reducing the algorithm time complexity from\n$O(n^3)$ to $O(\\phi^3)$ for $\\phi$ forward experiments per activation, which\ntrends to a constant $O(1)$ over several activations. Additionally, ZoMBI\nimplements two custom adaptive acquisition functions to further guide the\nsampling of new experiments toward the global optimum. We validate the\nalgorithm's optimization performance on three real-world datasets exhibiting\nNeedle-in-a-Haystack and further stress-test the algorithm's performance on an\nadditional 174 analytical datasets. The ZoMBI algorithm demonstrates compute\ntime speed-ups of 400x compared to traditional Bayesian optimization as well as\nefficiently discovering optima in under 100 experiments that are up to 3x more\nhighly optimized than those discovered by similar methods MiP-EGO, TuRBO, and\nHEBO.\n","authors":["Alexander E. Siemenn","Zekun Ren","Qianxiao Li","Tonio Buonassisi"],"pdf_url":"https://arxiv.org/pdf/2208.13771v2.pdf","comment":"Paper 16 pages; SI 6 pages"},{"id":"http://arxiv.org/abs/2201.10879v2","updated":"2023-02-03T02:56:38Z","published":"2022-01-26T11:31:21Z","title":"S$^3$NN: Time Step Reduction of Spiking Surrogate Gradients for Training\n  Energy Efficient Single-Step Spiking Neural Networks","summary":"  As the scales of neural networks increase, techniques that enable them to run\nwith low computational cost and energy efficiency are required. From such\ndemands, various efficient neural network paradigms, such as spiking neural\nnetworks (SNNs) or binary neural networks (BNNs), have been proposed. However,\nthey have sticky drawbacks, such as degraded inference accuracy and latency. To\nsolve these problems, we propose a single-step spiking neural network\n(S$^3$NN), an energy-efficient neural network with low computational cost and\nhigh precision. The proposed S$^3$NN processes the information between hidden\nlayers by spikes as SNNs. Nevertheless, it has no temporal dimension so that\nthere is no latency within training and inference phases as BNNs. Thus, the\nproposed S$^3$NN has a lower computational cost than SNNs that require\ntime-series processing. However, S$^3$NN cannot adopt na\\\"{i}ve backpropagation\nalgorithms due to the non-differentiability nature of spikes. We deduce a\nsuitable neuron model by reducing the surrogate gradient for multi-time step\nSNNs to a single-time step. We experimentally demonstrated that the obtained\nsurrogate gradient allows S$^3$NN to be trained appropriately. We also showed\nthat the proposed S$^3$NN could achieve comparable accuracy to full-precision\nnetworks while being highly energy-efficient.\n","authors":["Kazuma Suetake","Shin-ichi Ikegawa","Ryuji Saiin","Yoshihide Sawada"],"pdf_url":"https://arxiv.org/pdf/2201.10879v2.pdf","comment":"23 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.01511v1","updated":"2023-02-03T02:48:48Z","published":"2023-02-03T02:48:48Z","title":"Randomized Gaussian Process Upper Confidence Bound with Tight Bayesian\n  Regret Bounds","summary":"  Gaussian process upper confidence bound (GP-UCB) is a theoretically promising\napproach for black-box optimization; however, the confidence parameter $\\beta$\nis considerably large in the theorem and chosen heuristically in practice.\nThen, randomized GP-UCB (RGP-UCB) uses a randomized confidence parameter, which\nfollows the Gamma distribution, to mitigate the impact of manually specifying\n$\\beta$. This study first generalizes the regret analysis of RGP-UCB to a wider\nclass of distributions, including the Gamma distribution. Furthermore, we\npropose improved RGP-UCB (IRGP-UCB) based on a two-parameter exponential\ndistribution, which achieves tight Bayesian regret bounds. IRGP-UCB does not\nrequire an increase in the confidence parameter in terms of the number of\niterations, which avoids over-exploration in the later iterations. Finally, we\ndemonstrate the effectiveness of IRGP-UCB through extensive experiments.\n","authors":["Shion Takeno","Yu Inatsu","Masayuki Karasuyama"],"pdf_url":"https://arxiv.org/pdf/2302.01511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01503v1","updated":"2023-02-03T02:33:07Z","published":"2023-02-03T02:33:07Z","title":"LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation","summary":"  Recent works have demonstrated the benefits of capturing long-distance\ndependency in graphs by deeper graph neural networks (GNNs). But deeper GNNs\nsuffer from the long-lasting scalability challenge due to the neighborhood\nexplosion problem in large-scale graphs. In this work, we propose to capture\nlong-distance dependency in graphs by shallower models instead of deeper\nmodels, which leads to a much more efficient model, LazyGNN, for graph\nrepresentation learning. Moreover, we demonstrate that LazyGNN is compatible\nwith existing scalable approaches (such as sampling methods) for further\naccelerations through the development of mini-batch LazyGNN. Comprehensive\nexperiments demonstrate its superior prediction performance and scalability on\nlarge-scale benchmarks. LazyGNN also achieves state-of-art performance on the\nOGB leaderboard.\n","authors":["Rui Xue","Haoyu Han","MohamadAli Torkamani","Jian Pei","Xiaorui Liu"],"pdf_url":"https://arxiv.org/pdf/2302.01503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01501v1","updated":"2023-02-03T02:31:12Z","published":"2023-02-03T02:31:12Z","title":"ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics","summary":"  As the amount of text data generated by humans and machines increases, the\nnecessity of understanding large corpora and finding a way to extract insights\nfrom them is becoming more crucial than ever. Dynamic topic models are\neffective methods that primarily focus on studying the evolution of topics\npresent in a collection of documents. These models are widely used for\nunderstanding trends, exploring public opinion in social networks, or tracking\nresearch progress and discoveries in scientific archives. Since topics are\ndefined as clusters of semantically similar documents, it is necessary to\nobserve the changes in the content or themes of these clusters in order to\nunderstand how topics evolve as new knowledge is discovered over time. In this\npaper, we introduce the Aligned Neural Topic Model (ANTM), a dynamic neural\ntopic model that uses document embeddings to compute clusters of semantically\nsimilar documents at different periods and to align document clusters to\nrepresent their evolution. This alignment procedure preserves the temporal\nsimilarity of document clusters over time and captures the semantic change of\nwords characterized by their context within different periods. Experiments on\nfour different datasets show that ANTM outperforms probabilistic dynamic topic\nmodels (e.g. DTM, DETM) and significantly improves topic coherence and\ndiversity over other existing dynamic neural topic models (e.g. BERTopic).\n","authors":["Hamed Rahimi","Hubert Naacke","Camelia Constantin","Bernd Amann"],"pdf_url":"https://arxiv.org/pdf/2302.01501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01500v1","updated":"2023-02-03T02:30:00Z","published":"2023-02-03T02:30:00Z","title":"Spiking Synaptic Penalty: Appropriate Penalty Term for Energy-Efficient\n  Spiking Neural Networks","summary":"  Spiking neural networks (SNNs) are energy-efficient neural networks because\nof their spiking nature. However, as the spike firing rate of SNNs increases,\nthe energy consumption does as well, and thus, the advantage of SNNs\ndiminishes. Here, we tackle this problem by introducing a novel penalty term\nfor the spiking activity into the objective function in the training phase. Our\nmethod is designed so as to optimize the energy consumption metric directly\nwithout modifying the network architecture. Therefore, the proposed method can\nreduce the energy consumption more than other methods while maintaining the\naccuracy. We conducted experiments for image classification tasks, and the\nresults indicate the effectiveness of the proposed method, which mitigates the\ndilemma of the energy--accuracy trade-off.\n","authors":["Kazuma Suetake","Takuya Ushimaru","Ryuji Saiin","Yoshihide Sawada"],"pdf_url":"https://arxiv.org/pdf/2302.01500v1.pdf","comment":"19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.05777v2","updated":"2023-02-03T02:20:49Z","published":"2023-01-13T22:21:58Z","title":"Lung airway geometry as an early predictor of autism: A preliminary\n  machine learning-based study","summary":"  The goal of this study is to assess the feasibility of airway geometry as a\nbiomarker for ASD. Chest CT images of children with a documented diagnosis of\nASD as well as healthy controls were identified retrospectively. 54 scans were\nobtained for analysis, including 31 ASD cases and 23 age and sex-matched\ncontrols. A feature selection and classification procedure using principal\ncomponent analysis (PCA) and support vector machine (SVM) achieved a peak cross\nvalidation accuracy of nearly 89% using a feature set of 8 airway branching\nangles. Sensitivity was 94%, but specificity was only 78%. The results suggest\na measurable difference in airway branchpoint angles between children with ASD\nand the control population.\n  Under review at Scientific Reports\n","authors":["Asef Islam","Anthony Ronco","Stephen M. Becker","Jeremiah Blackburn","Johannes C. Schittny","Kyoungmi Kim","Rebecca Stein-Wexler","Anthony S. Wexler"],"pdf_url":"https://arxiv.org/pdf/2301.05777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01497v1","updated":"2023-02-03T02:12:09Z","published":"2023-02-03T02:12:09Z","title":"Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained\n  Models","summary":"  Domain generalization aims to build generalized models that perform well on\nunseen domains when only source domains are available for model optimization.\nRecent studies have demonstrated that large-scale pre-trained models could play\nan important role in domain generalization by providing their generalization\npower. However, large-scale pre-trained models are not fully equipped with\ntarget task-specific knowledge due to a discrepancy between the pre-training\nobjective and the target task. Although the task-specific knowledge could be\nlearned from source domains by fine-tuning, this hurts the generalization power\nof the pre-trained models because of gradient bias toward the source domains.\nTo address this issue, we propose a new domain generalization method that\nestimates unobservable gradients that reduce potential risks in unseen domains,\nusing a large-scale pre-trained model. Our proposed method allows the\npre-trained model to learn task-specific knowledge further while preserving its\ngeneralization ability with the estimated gradients. Experimental results show\nthat our proposed method outperforms baseline methods on DomainBed, a standard\nbenchmark in domain generalization. We also provide extensive analyses to\ndemonstrate that the estimated unobserved gradients relieve the gradient bias,\nand the pre-trained model learns the task-specific knowledge without\nsacrificing its generalization power.\n","authors":["Byunggyu Lew","Donghyun Son","Buru Chang"],"pdf_url":"https://arxiv.org/pdf/2302.01497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01496v1","updated":"2023-02-03T02:10:35Z","published":"2023-02-03T02:10:35Z","title":"Efficient Domain Adaptation for Speech Foundation Models","summary":"  Foundation models (FMs), that are trained on broad data at scale and are\nadaptable to a wide range of downstream tasks, have brought large interest in\nthe research community. Benefiting from the diverse data sources such as\ndifferent modalities, languages and application domains, foundation models have\ndemonstrated strong generalization and knowledge transfer capabilities. In this\npaper, we present a pioneering study towards building an efficient solution for\nFM-based speech recognition systems. We adopt the recently developed\nself-supervised BEST-RQ for pretraining, and propose the joint finetuning with\nboth source and unsupervised target domain data using JUST Hydra. The FM\nencoder adapter and decoder are then finetuned to the target domain with a\nsmall amount of supervised in-domain data. On a large-scale YouTube and Voice\nSearch task, our method is shown to be both data and model parameter efficient.\nIt achieves the same quality with only 21.6M supervised in-domain data and\n130.8M finetuned parameters, compared to the 731.1M model trained from scratch\non additional 300M supervised in-domain data.\n","authors":["Bo Li","Dongseong Hwang","Zhouyuan Huo","Junwen Bai","Guru Prakash","Tara N. Sainath","Khe Chai Sim","Yu Zhang","Wei Han","Trevor Strohman","Francoise Beaufays"],"pdf_url":"https://arxiv.org/pdf/2302.01496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.07384v6","updated":"2023-02-03T01:59:38Z","published":"2022-05-15T21:32:44Z","title":"Incorporating Prior Knowledge into Neural Networks through an Implicit\n  Composite Kernel","summary":"  It is challenging to guide neural network (NN) learning with prior knowledge.\nIn contrast, many known properties, such as spatial smoothness or seasonality,\nare straightforward to model by choosing an appropriate kernel in a Gaussian\nprocess (GP). Many deep learning applications could be enhanced by modeling\nsuch known properties. For example, convolutional neural networks (CNNs) are\nfrequently used in remote sensing, which is subject to strong seasonal effects.\nWe propose to blend the strengths of deep learning and the clear modeling\ncapabilities of GPs by using a composite kernel that combines a kernel\nimplicitly defined by a neural network with a second kernel function chosen to\nmodel known properties (e.g., seasonality). We implement this idea by combining\na deep network and an efficient mapping based on the Nystrom approximation,\nwhich we call Implicit Composite Kernel (ICK). We then adopt a\nsample-then-optimize approach to approximate the full GP posterior\ndistribution. We demonstrate that ICK has superior performance and flexibility\non both synthetic and real-world data sets. We believe that ICK framework can\nbe used to include prior information into neural networks in many applications.\n","authors":["Ziyang Jiang","Tongshu Zheng","Yiling Liu","David Carlson"],"pdf_url":"https://arxiv.org/pdf/2205.07384v6.pdf","comment":"23 pages, 14 figures, 3 tables, 2 algorithms"},{"id":"http://arxiv.org/abs/2301.11351v2","updated":"2023-02-03T01:57:26Z","published":"2023-01-26T19:05:18Z","title":"Estimating Causal Effects using a Multi-task Deep Ensemble","summary":"  Over the past few decades, a number of methods have been proposed for causal\neffect estimation, yet few have been demonstrated to be effective in handling\ndata with complex structures, such as images. To fill this gap, we propose a\nCausal Multi-task Deep Ensemble (CMDE) framework to learn both shared and\ngroup-specific information from the study population and prove its equivalence\nto a multi-task Gaussian process (GP) with coregionalization kernel a priori.\nCompared to multi-task GP, CMDE efficiently handles high-dimensional and\nmulti-modal covariates and provides pointwise uncertainty estimates of causal\neffects. We evaluate our method across various types of datasets and tasks and\nfind that CMDE outperforms state-of-the-art methods on a majority of these\ntasks.\n","authors":["Ziyang Jiang","Zhuoran Hou","Yiling Liu","Yiman Ren","Keyu Li","David Carlson"],"pdf_url":"https://arxiv.org/pdf/2301.11351v2.pdf","comment":"17 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.01488v1","updated":"2023-02-03T01:49:33Z","published":"2023-02-03T01:49:33Z","title":"Perfect Is the Enemy of Test Oracle","summary":"  Automation of test oracles is one of the most challenging facets of software\ntesting, but remains comparatively less addressed compared to automated test\ninput generation. Test oracles rely on a ground-truth that can distinguish\nbetween the correct and buggy behavior to determine whether a test fails\n(detects a bug) or passes. What makes the oracle problem challenging and\nundecidable is the assumption that the ground-truth should know the exact\nexpected, correct, or buggy behavior. However, we argue that one can still\nbuild an accurate oracle without knowing the exact correct or buggy behavior,\nbut how these two might differ. This paper presents SEER, a learning-based\napproach that in the absence of test assertions or other types of oracle, can\ndetermine whether a unit test passes or fails on a given method under test\n(MUT). To build the ground-truth, SEER jointly embeds unit tests and the\nimplementation of MUTs into a unified vector space, in such a way that the\nneural representation of tests are similar to that of MUTs they pass on them,\nbut dissimilar to MUTs they fail on them. The classifier built on top of this\nvector representation serves as the oracle to generate \"fail\" labels, when test\ninputs detect a bug in MUT or \"pass\" labels, otherwise. Our extensive\nexperiments on applying SEER to more than 5K unit tests from a diverse set of\nopen-source Java projects show that the produced oracle is (1) effective in\npredicting the fail or pass labels, achieving an overall accuracy, precision,\nrecall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predicting\nthe labels for the unit test of projects that were not in training or\nvalidation set with negligible performance drop, and (3) efficient, detecting\nthe existence of bugs in only 6.5 milliseconds on average.\n","authors":["Ali Reza Ibrahimzada","Yigit Varli","Dilara Tekinoglu","Reyhaneh Jabbarvand"],"pdf_url":"https://arxiv.org/pdf/2302.01488v1.pdf","comment":"Published in ESEC/FSE 2022"},{"id":"http://arxiv.org/abs/2302.01486v1","updated":"2023-02-03T01:46:03Z","published":"2023-02-03T01:46:03Z","title":"Xtal2DoS: Attention-based Crystal to Sequence Learning for Density of\n  States Prediction","summary":"  Modern machine learning techniques have been extensively applied to materials\nscience, especially for property prediction tasks. A majority of these methods\naddress scalar property predictions, while more challenging spectral properties\nremain less emphasized. We formulate a crystal-to-sequence learning task and\npropose a novel attention-based learning method, Xtal2DoS, which decodes the\nsequential representation of the material density of states (DoS) properties by\nincorporating the learned atomic embeddings through attention networks.\nExperiments show Xtal2DoS is faster than the existing models, and consistently\noutperforms other state-of-the-art methods on four metrics for two fundamental\nspectral properties, phonon and electronic DoS.\n","authors":["Junwen Bai","Yuanqi Du","Yingheng Wang","Shufeng Kong","John Gregoire","Carla Gomes"],"pdf_url":"https://arxiv.org/pdf/2302.01486v1.pdf","comment":"Accepted to NeurIPS 2022 AI for Science Workshop"},{"id":"http://arxiv.org/abs/2205.08696v2","updated":"2023-02-03T01:45:51Z","published":"2022-05-18T02:52:03Z","title":"The Solvability of Interpretability Evaluation Metrics","summary":"  Feature attribution methods are popular for explaining neural network\npredictions, and they are often evaluated on metrics such as comprehensiveness\nand sufficiency. In this paper, we highlight an intriguing property of these\nmetrics: their solvability. Concretely, we can define the problem of optimizing\nan explanation for a metric, which can be solved by beam search. This\nobservation leads to the obvious yet unaddressed question: why do we use\nexplainers (e.g., LIME) not based on solving the target metric, if the metric\nvalue represents explanation quality? We present a series of investigations\nshowing strong performance of this beam search explainer and discuss its\nbroader implication: a definition-evaluation duality of interpretability\nconcepts. We implement the explainer and release the Python solvex package for\nmodels of text, image and tabular domains.\n","authors":["Yilun Zhou","Julie Shah"],"pdf_url":"https://arxiv.org/pdf/2205.08696v2.pdf","comment":"EACL 2023 (Findings). Project website at\n  https://yilunzhou.github.io/solvability/"},{"id":"http://arxiv.org/abs/2302.01483v1","updated":"2023-02-03T01:36:38Z","published":"2023-02-03T01:36:38Z","title":"SPADE: Self-supervised Pretraining for Acoustic DisEntanglement","summary":"  Self-supervised representation learning approaches have grown in popularity\ndue to the ability to train models on large amounts of unlabeled data and have\ndemonstrated success in diverse fields such as natural language processing,\ncomputer vision, and speech. Previous self-supervised work in the speech domain\nhas disentangled multiple attributes of speech such as linguistic content,\nspeaker identity, and rhythm. In this work, we introduce a self-supervised\napproach to disentangle room acoustics from speech and use the acoustic\nrepresentation on the downstream task of device arbitration. Our results\ndemonstrate that our proposed approach significantly improves performance over\na baseline when labeled training data is scarce, indicating that our\npretraining scheme learns to encode room acoustic information while remaining\ninvariant to other attributes of the speech signal.\n","authors":["John Harvill","Jarred Barber","Arun Nair","Ramin Pishehvar"],"pdf_url":"https://arxiv.org/pdf/2302.01483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01478v1","updated":"2023-02-03T01:20:49Z","published":"2023-02-03T01:20:49Z","title":"Clustered Embedding Learning for Recommender Systems","summary":"  In recent years, recommender systems have advanced rapidly, where embedding\nlearning for users and items plays a critical role. A standard method learns a\nunique embedding vector for each user and item. However, such a method has two\nimportant limitations in real-world applications: 1) it is hard to learn\nembeddings that generalize well for users and items with rare interactions on\ntheir own; and 2) it may incur unbearably high memory costs when the number of\nusers and items scales up. Existing approaches either can only address one of\nthe limitations or have flawed overall performances. In this paper, we propose\nClustered Embedding Learning (CEL) as an integrated solution to these two\nproblems. CEL is a plug-and-play embedding learning framework that can be\ncombined with any differentiable feature interaction model. It is capable of\nachieving improved performance, especially for cold users and items, with\nreduced memory cost. CEL enables automatic and dynamic clustering of users and\nitems in a top-down fashion, where clustered entities jointly learn a shared\nembedding. The accelerated version of CEL has an optimal time complexity, which\nsupports efficient online updates. Theoretically, we prove the identifiability\nand the existence of a unique optimal number of clusters for CEL in the context\nof nonnegative matrix factorization. Empirically, we validate the effectiveness\nof CEL on three public datasets and one business dataset, showing its\nconsistently superior performance against current state-of-the-art methods. In\nparticular, when incorporating CEL into the business model, it brings an\nimprovement of $+0.6\\%$ in AUC, which translates into a significant revenue\ngain; meanwhile, the size of the embedding table gets $2650$ times smaller.\n","authors":["Yizhou Chen","Guangda Huzhang","Anxiang Zeng","Qingtao Yu","Hui Sun","Hengyi Li","Jingyi Li","Yabo Ni","Han Yu","Zhiming Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.01478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01477v1","updated":"2023-02-03T01:16:09Z","published":"2023-02-03T01:16:09Z","title":"A Reduction-based Framework for Sequential Decision Making with Delayed\n  Feedback","summary":"  We study stochastic delayed feedback in general multi-agent sequential\ndecision making, which includes bandits, single-agent Markov decision processes\n(MDPs), and Markov games (MGs). We propose a novel reduction-based framework,\nwhich turns any multi-batched algorithm for sequential decision making with\ninstantaneous feedback into a sample-efficient algorithm that can handle\nstochastic delays in sequential decision making. By plugging different\nmulti-batched algorithms into our framework, we provide several examples\ndemonstrating that our framework not only matches or improves existing results\nfor bandits, tabular MDPs, and tabular MGs, but also provides the first line of\nstudies on delays in sequential decision making with function approximation. In\nsummary, we provide a complete set of sharp results for multi-agent sequential\ndecision making with delayed feedback.\n","authors":["Yunchang Yang","Han Zhong","Tianhao Wu","Bin Liu","Liwei Wang","Simon S. Du"],"pdf_url":"https://arxiv.org/pdf/2302.01477v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2110.14555 by other authors"},{"id":"http://arxiv.org/abs/2106.12732v2","updated":"2023-02-03T00:43:55Z","published":"2021-06-24T02:38:27Z","title":"Online Verification of Deep Neural Networks under Domain Shift or\n  Network Updates","summary":"  Although neural networks are widely used, it remains challenging to formally\nverify the safety and robustness of neural networks in real-world applications.\nExisting methods are designed to verify the network before deployment, which\nare limited to relatively simple specifications and fixed networks. These\nmethods are not ready to be applied to real-world problems with complex and/or\ndynamically changing specifications and networks. To effectively handle such\nproblems, verification needs to be performed online when these changes take\nplace. However, it is still challenging to run existing verification algorithms\nonline. Our key insight is that we can leverage the temporal dependencies of\nthese changes to accelerate the verification process. This paper establishes a\nnovel framework for scalable online verification to solve real-world\nverification problems with dynamically changing specifications and/or networks.\nWe propose three types of acceleration algorithms: Branch Management to reduce\nrepetitive computation, Perturbation Tolerance to tolerate changes, and\nIncremental Computation to reuse previous results. Experiment results show that\nour algorithms achieve up to $100\\times$ acceleration, and thus show a\npromising way to extend neural network verification to real-world applications.\n","authors":["Tianhao Wei","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2106.12732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01474v1","updated":"2023-02-03T00:41:01Z","published":"2023-02-03T00:41:01Z","title":"Defensive ML: Defending Architectural Side-channels with Adversarial\n  Obfuscation","summary":"  Side-channel attacks that use machine learning (ML) for signal analysis have\nbecome prominent threats to computer security, as ML models easily find\npatterns in signals. To address this problem, this paper explores using\nAdversarial Machine Learning (AML) methods as a defense at the computer\narchitecture layer to obfuscate side channels. We call this approach Defensive\nML, and the generator to obfuscate signals, defender. Defensive ML is a\nworkflow to design, implement, train, and deploy defenders for different\nenvironments. First, we design a defender architecture given the physical\ncharacteristics and hardware constraints of the side-channel. Next, we use our\nDefenderGAN structure to train the defender. Finally, we apply defensive ML to\nthwart two side-channel attacks: one based on memory contention and the other\non application power. The former uses a hardware defender with ns-level\nresponse time that attains a high level of security with half the performance\nimpact of a traditional scheme; the latter uses a software defender with\nms-level response time that provides better security than a traditional scheme\nwith only 70% of its power overhead.\n","authors":["Hyoungwook Nam","Raghavendra Pradyumna Pothukuchi","Bo Li","Nam Sung Kim","Josep Torrellas"],"pdf_url":"https://arxiv.org/pdf/2302.01474v1.pdf","comment":"Submitted to ICML 2023"},{"id":"http://arxiv.org/abs/2210.15906v3","updated":"2023-02-03T00:31:41Z","published":"2022-10-28T05:25:23Z","title":"Relative Behavioral Attributes: Filling the Gap between Symbolic Goal\n  Specification and Reward Learning from Human Preferences","summary":"  Generating complex behaviors that satisfy the preferences of non-expert users\nis a crucial requirement on AI agents. Interactive reward learning from\ntrajectory comparisons is one way to allow non-expert users to convey complex\nobjectives by expressing preferences over short clips of agent behaviors. Even\nthough this parametric method can encode complex tacit knowledge present in the\nunderlying tasks, it implicitly assumes that the human is unable to provide\nricher feedback than binary preference labels, leading to intolerably high\nfeedback complexity and poor user experience. While providing a detailed\nsymbolic closed-form specification of the objectives might be tempting, it is\nnot always feasible even for an expert user. However, in most cases, humans are\naware of how the agent should change its behavior along meaningful axes to\nfulfill their underlying purpose, even if they are not able to fully specify\ntask objectives symbolically. Using this as motivation, we introduce the notion\nof Relative Behavioral Attributes, which allows the users to tweak the agent\nbehavior through symbolic concepts (e.g., increasing the softness or speed of\nagents' movement). We propose two practical methods that can learn to model any\nkind of behavioral attributes from ordered behavior clips. We demonstrate the\neffectiveness of our methods on four tasks with nine different behavioral\nattributes, showing that once the attributes are learned, end users can produce\ndesirable agent behaviors relatively effortlessly, by providing feedback just\naround ten times. This is over an order of magnitude less than that required by\nthe popular learning-from-human-preferences baselines. The supplementary video\nand source code are available at: https://guansuns.github.io/pages/rba.\n","authors":["Lin Guan","Karthik Valmeekam","Subbarao Kambhampati"],"pdf_url":"https://arxiv.org/pdf/2210.15906v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.01471v1","updated":"2023-02-03T00:12:12Z","published":"2023-02-03T00:12:12Z","title":"User-centric Heterogeneous-action Deep Reinforcement Learning for\n  Virtual Reality in the Metaverse over Wireless Networks","summary":"  The Metaverse is emerging as maturing technologies are empowering the\ndifferent facets. Virtual Reality (VR) technologies serve as the backbone of\nthe virtual universe within the Metaverse to offer a highly immersive user\nexperience. As mobility is emphasized in the Metaverse context, VR devices\nreduce their weights at the sacrifice of local computation abilities. In this\npaper, for a system consisting of a Metaverse server and multiple VR users, we\nconsider two cases of (i) the server generating frames and transmitting them to\nusers, and (ii) users generating frames locally and thus consuming device\nenergy. Moreover, in our multi-user VR scenario for the Metaverse, users have\ndifferent characteristics and demands for Frames Per Second (FPS). Then the\nchannel access arrangement (including the decisions on frame generation\nlocation), and transmission powers for the downlink communications from the\nserver to the users are jointly optimized to improve the utilities of users.\nThis joint optimization is addressed by deep reinforcement learning (DRL) with\nheterogeneous actions. Our proposed user-centric DRL algorithm is called\nUser-centric Critic with Heterogenous Actors (UCHA). Extensive experiments\ndemonstrate that our UCHA algorithm leads to remarkable results under various\nrequirements and constraints.\n","authors":["Wenhan Yu","Terence Jie Chua","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.01471v1.pdf","comment":"The paper has been submitted to IEEE Transactions on Wireless\n  Communications, 2023"},{"id":"http://arxiv.org/abs/2302.01470v1","updated":"2023-02-03T00:11:02Z","published":"2023-02-03T00:11:02Z","title":"Learning to Optimize for Reinforcement Learning","summary":"  In recent years, by leveraging more data, computation, and diverse tasks,\nlearned optimizers have achieved remarkable success in supervised learning\noptimization, outperforming classical hand-designed optimizers. However, in\npractice, these learned optimizers fail to generalize to reinforcement learning\ntasks due to unstable and complex loss landscapes. Moreover, neither\nhand-designed optimizers nor learned optimizers have been specifically designed\nto address the unique optimization properties in reinforcement learning. In\nthis work, we take a data-driven approach to learn to optimize for\nreinforcement learning using meta-learning. We introduce a novel optimizer\nstructure that significantly improves the training efficiency of learned\noptimizers, making it possible to learn an optimizer for reinforcement learning\nfrom scratch. Although trained in toy tasks, our learned optimizer demonstrates\nits generalization ability to unseen complex tasks. Finally, we design a set of\nsmall gridworlds to train the first general-purpose optimizer for reinforcement\nlearning.\n","authors":["Qingfeng Lan","A. Rupam Mahmood","Shuicheng Yan","Zhongwen Xu"],"pdf_url":"https://arxiv.org/pdf/2302.01470v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2301.12831v2","updated":"2023-02-03T07:02:23Z","published":"2023-01-30T12:37:04Z","title":"M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing\n  System","summary":"  Face presentation attacks (FPA), also known as face spoofing, have brought\nincreasing concerns to the public through various malicious applications, such\nas financial fraud and privacy leakage. Therefore, safeguarding face\nrecognition systems against FPA is of utmost importance. Although existing\nlearning-based face anti-spoofing (FAS) models can achieve outstanding\ndetection performance, they lack generalization capability and suffer\nsignificant performance drops in unforeseen environments. Many methodologies\nseek to use auxiliary modality data (e.g., depth and infrared maps) during the\npresentation attack detection (PAD) to address this limitation. However, these\nmethods can be limited since (1) they require specific sensors such as depth\nand infrared cameras for data capture, which are rarely available on commodity\nmobile devices, and (2) they cannot work properly in practical scenarios when\neither modality is missing or of poor quality. In this paper, we devise an\naccurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to\novercome the issues above. The innovation of this work mainly lies in the\nfollowing aspects: (1) To achieve robust PAD, our system combines visual and\nauditory modalities using three pervasively available sensors: camera, speaker,\nand microphone; (2) We design a novel two-branch neural network with three\nhierarchical feature aggregation modules to perform cross-modal feature fusion;\n(3). We propose a multi-head training strategy. The model outputs three\npredictions from the vision, acoustic, and fusion heads, enabling a more\nflexible PAD. Extensive experiments have demonstrated the accuracy, robustness,\nand flexibility of M3FAS under various challenging experimental settings.\n","authors":["Chenqi Kong","Kexin Zheng","Yibing Liu","Shiqi Wang","Anderson Rocha","Haoliang Li"],"pdf_url":"https://arxiv.org/pdf/2301.12831v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03127v2","updated":"2023-02-03T22:55:12Z","published":"2023-01-09T00:19:11Z","title":"Logically at Factify 2: A Multi-Modal Fact Checking System Based on\n  Evidence Retrieval techniques and Transformer Encoder Architecture","summary":"  In this paper, we present the Logically submissions to De-Factify 2 challenge\n(DE-FACTIFY 2023) on the task 1 of Multi-Modal Fact Checking. We describes our\nsubmissions to this challenge including explored evidence retrieval and\nselection techniques, pre-trained cross-modal and unimodal models, and a\ncross-modal veracity model based on the well established Transformer Encoder\n(TE) architecture which is heavily relies on the concept of self-attention.\nExploratory analysis is also conducted on this Factify 2 data set that uncovers\nthe salient multi-modal patterns and hypothesis motivating the architecture\nproposed in this work. A series of preliminary experiments were done to\ninvestigate and benchmarking different pre-trained embedding models, evidence\nretrieval settings and thresholds. The final system, a standard two-stage\nevidence based veracity detection system, yields weighted avg. 0.79 on both val\nset and final blind test set on the task 1, which achieves 3rd place with a\nsmall margin to the top performing system on the leaderboard among 9\nparticipants.\n","authors":["Pim Jordi Verschuuren","Jie Gao","Adelize van Eeden","Stylianos Oikonomou","Anil Bandhakavi"],"pdf_url":"https://arxiv.org/pdf/2301.03127v2.pdf","comment":"Accepted in AAAI'23: Second Workshop on Multimodal Fact-Checking and\n  Hate Speech Detection, February 2023, Washington, DC, USA"}]},"2023-02-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.02997v1","updated":"2023-02-06T18:32:17Z","published":"2023-02-06T18:32:17Z","title":"Erasure of Unaligned Attributes from Neural Representations","summary":"  We present the Assignment-Maximization Spectral Attribute removaL (AMSAL)\nalgorithm, which aims at removing information from neural representations when\nthe information to be erased is implicit rather than directly being aligned to\neach input example. Our algorithm works by alternating between two steps. In\none, it finds an assignment of the input representations to the information to\nbe erased, and in the other, it creates projections of both the input\nrepresentations and the information to be erased into a joint latent space. We\ntest our algorithm on an extensive array of datasets, including a Twitter\ndataset with multiple guarded attributes, the BiasBios dataset and the\nBiasBench benchmark. The latter benchmark includes four datasets with various\ntypes of protected attributes. Our results demonstrate that bias can often be\nremoved in our setup. We also discuss the limitations of our approach when\nthere is a strong entanglement between the main task and the information to be\nerased.\n","authors":["Shun Shao","Yftah Ziser","Shay Cohen"],"pdf_url":"https://arxiv.org/pdf/2302.02997v1.pdf","comment":"Accepted to Transactions of the Association for Computational\n  Linguistics, 22 pages (pre-MIT Press publication version)"},{"id":"http://arxiv.org/abs/2302.00674v2","updated":"2023-02-06T18:21:56Z","published":"2023-02-01T18:59:36Z","title":"Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary\n  Data","summary":"  Few-shot learning involves learning an effective model from only a few\nlabeled datapoints. The use of a small training set makes it difficult to avoid\noverfitting but also makes few-shot learning applicable to many important\nreal-world settings. In this work, we focus on Few-shot Learning with Auxiliary\nData (FLAD), a training paradigm that assumes access to auxiliary data during\nfew-shot learning in hopes of improving generalization. Introducing auxiliary\ndata during few-shot learning leads to essential design choices where\nhand-designed heuristics can lead to sub-optimal performance. In this work, we\nfocus on automated sampling strategies for FLAD and relate them to the\nexplore-exploit dilemma that is central in multi-armed bandit settings. Based\non this connection we propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and\ncompare them with methods that either explore or exploit, finding that the\ncombination of exploration and exploitation is crucial. Using our proposed\nalgorithms to train T5 yields a 9% absolute improvement over the explicitly\nmulti-task pre-trained T0 model across 11 datasets.\n","authors":["Alon Albalak","Colin Raffel","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00674v2.pdf","comment":"19 pages, 7 figures, code available at\n  https://github.com/alon-albalak/FLAD"},{"id":"http://arxiv.org/abs/2208.09715v2","updated":"2023-02-06T17:55:00Z","published":"2022-08-20T16:06:53Z","title":"Wolfies at SemEval-2022 Task 8: Feature extraction pipeline with\n  transformers for Multi-lingual news article similarity","summary":"  This work is about finding the similarity between a pair of news articles.\nThere are seven different objective similarity metrics provided in the dataset\nfor each pair and the news articles are in multiple different languages. On top\nof the pre-trained embedding model, we calculated cosine similarity for\nbaseline results and feed-forward neural network was then trained on top of it\nto improve the results. We also built separate pipelines for each similarity\nmetric for feature extraction. We could see significant improvement from\nbaseline results using feature extraction and feed-forward neural network.\n","authors":["Nikhil Goel","Ranjith Reddy"],"pdf_url":"https://arxiv.org/pdf/2208.09715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02962v1","updated":"2023-02-06T17:49:27Z","published":"2023-02-06T17:49:27Z","title":"LoFT: Enhancing Faithfulness and Diversity for Table-to-Text Generation\n  via Logic Form Control","summary":"  Logical Table-to-Text (LT2T) generation is tasked with generating logically\nfaithful sentences from tables. There currently exists two challenges in the\nfield: 1) Faithfulness: how to generate sentences that are factually correct\ngiven the table content; 2) Diversity: how to generate multiple sentences that\noffer different perspectives on the table. This work proposes LoFT, which\nutilizes logic forms as fact verifiers and content planners to control LT2T\ngeneration. Experimental results on the LogicNLG dataset demonstrate that LoFT\nis the first model that addresses unfaithfulness and lack of diversity issues\nsimultaneously. Our code is publicly available at\nhttps://github.com/Yale-LILY/LoFT.\n","authors":["Yilun Zhao","Zhenting Qi","Linyong Nan","Lorenzo Jaime Yu Flores","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2302.02962v1.pdf","comment":"Accepted at EACL 2023 as a short paper"},{"id":"http://arxiv.org/abs/2201.11176v4","updated":"2023-02-06T17:46:49Z","published":"2022-01-26T20:28:26Z","title":"DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence","summary":"  Recently, there has been a growing interest in designing text generation\nsystems from a discourse coherence perspective, e.g., modeling the\ninterdependence between sentences. Still, recent BERT-based evaluation metrics\nare weak in recognizing coherence, and thus are not reliable in a way to spot\nthe discourse-level improvements of those text generation systems. In this\nwork, we introduce DiscoScore, a parametrized discourse metric, which uses BERT\nto model discourse coherence from different perspectives, driven by Centering\ntheory. Our experiments encompass 16 non-discourse and discourse metrics,\nincluding DiscoScore and popular coherence models, evaluated on summarization\nand document-level machine translation (MT). We find that (i) the majority of\nBERT-based metrics correlate much worse with human rated coherence than early\ndiscourse metrics, invented a decade ago; (ii) the recent state-of-the-art\nBARTScore is weak when operated at system level -- which is particularly\nproblematic as systems are typically compared in this manner. DiscoScore, in\ncontrast, achieves strong system-level correlation with human ratings, not only\nin coherence but also in factual consistency and other aspects, and surpasses\nBARTScore by over 10 correlation points on average. Further, aiming to\nunderstand DiscoScore, we provide justifications to the importance of discourse\ncoherence for evaluation metrics, and explain the superiority of one variant\nover another. Our code is available at\n\\url{https://github.com/AIPHES/DiscoScore}.\n","authors":["Wei Zhao","Michael Strube","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2201.11176v4.pdf","comment":"EACL2023 Camera Ready"},{"id":"http://arxiv.org/abs/2202.00666v5","updated":"2023-02-06T17:00:36Z","published":"2022-02-01T18:58:45Z","title":"Locally Typical Sampling","summary":"  Today's probabilistic language generators fall short when it comes to\nproducing coherent and fluent text despite the fact that the underlying models\nperform well under standard metrics, e.g., perplexity. This discrepancy has\npuzzled the language generation community for the last few years. In this work,\nwe posit that the abstraction of natural language generation as a discrete\nstochastic process--which allows for an information-theoretic analysis--can\nprovide new insights into the behavior of probabilistic language generators,\ne.g., why high-probability texts can be dull or repetitive. Humans use language\nas a means of communicating information, aiming to do so in a simultaneously\nefficient and error-minimizing manner; in fact, psycholinguistics research\nsuggests humans choose each word in a string with this subconscious goal in\nmind. We formally define the set of strings that meet this criterion: those for\nwhich each word has an information content close to the expected information\ncontent, i.e., the conditional entropy of our model. We then propose a simple\nand efficient procedure for enforcing this criterion when generating from\nprobabilistic models, which we call locally typical sampling. Automatic and\nhuman evaluations show that, in comparison to nucleus and top-k sampling,\nlocally typical sampling offers competitive performance (in both abstractive\nsummarization and story generation) in terms of quality while consistently\nreducing degenerate repetitions.\n","authors":["Clara Meister","Tiago Pimentel","Gian Wiher","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2202.00666v5.pdf","comment":"TACL 2022"},{"id":"http://arxiv.org/abs/2302.02900v1","updated":"2023-02-06T16:09:27Z","published":"2023-02-06T16:09:27Z","title":"Controllable Lexical Simplification for English","summary":"  Fine-tuning Transformer-based approaches have recently shown exciting results\non sentence simplification task. However, so far, no research has applied\nsimilar approaches to the Lexical Simplification (LS) task. In this paper, we\npresent ConLS, a Controllable Lexical Simplification system fine-tuned with T5\n(a Transformer-based model pre-trained with a BERT-style approach and several\nother tasks). The evaluation results on three datasets (LexMTurk, BenchLS, and\nNNSeval) have shown that our model performs comparable to LSBert (the current\nstate-of-the-art) and even outperforms it in some cases. We also conducted a\ndetailed comparison on the effectiveness of control tokens to give a clear view\nof how each token contributes to the model.\n","authors":["Kim Cheng Sheang","Daniel Ferrés","Horacio Saggion"],"pdf_url":"https://arxiv.org/pdf/2302.02900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05575v3","updated":"2023-02-06T15:54:51Z","published":"2022-01-14T17:35:16Z","title":"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph\n  Embeddings","summary":"  Previous knowledge graph embedding approaches usually map entities to\nrepresentations and utilize score functions to predict the target entities, yet\nthey typically struggle to reason rare or emerging unseen entities. In this\npaper, we propose kNN-KGE, a new knowledge graph embedding approach with\npre-trained language models, by linearly interpolating its entity distribution\nwith k-nearest neighbors. We compute the nearest neighbors based on the\ndistance in the entity embedding space from the knowledge store. Our approach\ncan allow rare or emerging entities to be memorized explicitly rather than\nimplicitly in model parameters. Experimental results demonstrate that our\napproach can improve inductive and transductive link prediction results and\nyield better performance for low-resource settings with only a few triples,\nwhich might be easier to reason via explicit memory. Code is available at\nhttps://github.com/zjunlp/KNN-KG.\n","authors":["Ningyu Zhang","Xin Xie","Xiang Chen","Yongheng Wang","Xu Cheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2201.05575v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.02888v1","updated":"2023-02-06T15:53:51Z","published":"2023-02-06T15:53:51Z","title":"Findings of the TSAR-2022 Shared Task on Multilingual Lexical\n  Simplification","summary":"  We report findings of the TSAR-2022 shared task on multilingual lexical\nsimplification, organized as part of the Workshop on Text Simplification,\nAccessibility, and Readability TSAR-2022 held in conjunction with EMNLP 2022.\nThe task called the Natural Language Processing research community to\ncontribute with methods to advance the state of the art in multilingual lexical\nsimplification for English, Portuguese, and Spanish. A total of 14 teams\nsubmitted the results of their lexical simplification systems for the provided\ntest data. Results of the shared task indicate new benchmarks in Lexical\nSimplification with English lexical simplification quantitative results\nnoticeably higher than those obtained for Spanish and (Brazilian) Portuguese.\n","authors":["Horacio Saggion","Sanja Štajner","Daniel Ferrés","Kim Cheng Sheang","Matthew Shardlow","Kai North","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2302.02888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10481v2","updated":"2023-02-06T15:53:12Z","published":"2023-01-25T09:30:32Z","title":"FewShotTextGCN: K-hop neighborhood regularization for few-shot learning\n  on graphs","summary":"  We present FewShotTextGCN, a novel method designed to effectively utilize the\nproperties of word-document graphs for improved learning in low-resource\nsettings. We introduce K-hop Neighbourhood Regularization, a regularizer for\nheterogeneous graphs, and show that it stabilizes and improves learning when\nonly a few training samples are available. We furthermore propose a\nsimplification in the graph-construction method, which results in a graph that\nis $\\sim$7 times less dense and yields better performance in little-resource\nsettings while performing on par with the state of the art in high-resource\nsettings. Finally, we introduce a new variant of Adaptive Pseudo-Labeling\ntailored for word-document graphs. When using as little as 20 samples for\ntraining, we outperform a strong TextGCN baseline with 17% in absolute accuracy\non average over eight languages. We demonstrate that our method can be applied\nto document classification without any language model pretraining on a wide\nrange of typologically diverse languages while performing on par with large\npretrained language models.\n","authors":["Niels van der Heijden","Ekaterina Shutova","Helen Yannakoudakis"],"pdf_url":"https://arxiv.org/pdf/2301.10481v2.pdf","comment":"8 pages, 4 figures, EACL 2023"},{"id":"http://arxiv.org/abs/2210.12809v5","updated":"2023-02-06T15:36:02Z","published":"2022-10-23T18:13:30Z","title":"Data Augmentation for Automated Essay Scoring using Transformer Models","summary":"  Automated essay scoring is one of the most important problem in Natural\nLanguage Processing. It has been explored for a number of years, and it remains\npartially solved. In addition to its economic and educational usefulness, it\npresents research problems. Transfer learning has proved to be beneficial in\nNLP. Data augmentation techniques have also helped build state-of-the-art\nmodels for automated essay scoring. Many works in the past have attempted to\nsolve this problem by using RNNs, LSTMs, etc. This work examines the\ntransformer models like BERT, RoBERTa, etc. We empirically demonstrate the\neffectiveness of transformer models and data augmentation for automated essay\ngrading across many topics using a single model.\n","authors":["Kshitij Gupta"],"pdf_url":"https://arxiv.org/pdf/2210.12809v5.pdf","comment":"Accepted at ICCMST 2022"},{"id":"http://arxiv.org/abs/2302.02852v1","updated":"2023-02-06T15:21:41Z","published":"2023-02-06T15:21:41Z","title":"Guide the Learner: Controlling Product of Experts Debiasing Method Based\n  on Token Attribution Similarities","summary":"  Several proposals have been put forward in recent years for improving\nout-of-distribution (OOD) performance through mitigating dataset biases. A\npopular workaround is to train a robust model by re-weighting training examples\nbased on a secondary biased model. Here, the underlying assumption is that the\nbiased model resorts to shortcut features. Hence, those training examples that\nare correctly predicted by the biased model are flagged as being biased and are\ndown-weighted during the training of the main model. However, assessing the\nimportance of an instance merely based on the predictions of the biased model\nmay be too naive. It is possible that the prediction of the main model can be\nderived from another decision-making process that is distinct from the behavior\nof the biased model. To circumvent this, we introduce a fine-tuning strategy\nthat incorporates the similarity between the main and biased model attribution\nscores in a Product of Experts (PoE) loss function to further improve OOD\nperformance. With experiments conducted on natural language inference and fact\nverification benchmarks, we show that our method improves OOD results while\nmaintaining in-distribution (ID) performance.\n","authors":["Ali Modarressi","Hossein Amirkhani","Mohammad Taher Pilehvar"],"pdf_url":"https://arxiv.org/pdf/2302.02852v1.pdf","comment":"Accepted to EACL 2023 (main conference)"},{"id":"http://arxiv.org/abs/2301.05453v2","updated":"2023-02-06T14:42:24Z","published":"2023-01-13T09:40:19Z","title":"It's Just a Matter of Time: Detecting Depression with Time-Enriched\n  Multimodal Transformers","summary":"  Depression detection from user-generated content on the internet has been a\nlong-lasting topic of interest in the research community, providing valuable\nscreening tools for psychologists. The ubiquitous use of social media platforms\nlays out the perfect avenue for exploring mental health manifestations in posts\nand interactions with other users. Current methods for depression detection\nfrom social media mainly focus on text processing, and only a few also utilize\nimages posted by users. In this work, we propose a flexible time-enriched\nmultimodal transformer architecture for detecting depression from social media\nposts, using pretrained models for extracting image and text embeddings. Our\nmodel operates directly at the user-level, and we enrich it with the relative\ntime between posts by using time2vec positional embeddings. Moreover, we\npropose another model variant, which can operate on randomly sampled and\nunordered sets of posts to be more robust to dataset noise. We show that our\nmethod, using EmoBERTa and CLIP embeddings, surpasses other methods on two\nmultimodal datasets, obtaining state-of-the-art results of 0.931 F1 score on a\npopular multimodal Twitter dataset, and 0.902 F1 score on the only multimodal\nReddit dataset.\n","authors":["Ana-Maria Bucur","Adrian Cosma","Paolo Rosso","Liviu P. Dinu"],"pdf_url":"https://arxiv.org/pdf/2301.05453v2.pdf","comment":"Accepted at ECIR 2023"},{"id":"http://arxiv.org/abs/2302.02813v1","updated":"2023-02-06T14:36:33Z","published":"2023-02-06T14:36:33Z","title":"Migration Reframed? A multilingual analysis on the stance shift in\n  Europe during the Ukrainian crisis","summary":"  The war in Ukraine seems to have positively changed the attitude toward the\ncritical societal topic of migration in Europe -- at least towards refugees\nfrom Ukraine. We investigate whether this impression is substantiated by how\nthe topic is reflected in online news and social media, thus linking the\nrepresentation of the issue on the Web to its perception in society. For this\npurpose, we combine and adapt leading-edge automatic text processing for a\nnovel multilingual stance detection approach. Starting from 5.5M Twitter posts\npublished by 565 European news outlets in one year, beginning September 2021,\nplus replies, we perform a multilingual analysis of migration-related media\ncoverage and associated social media interaction for Europe and selected\nEuropean countries.\n  The results of our analysis show that there is actually a reframing of the\ndiscussion illustrated by the terminology change, e.g., from \"migrant\" to\n\"refugee\", often even accentuated with phrases such as \"real refugees\".\nHowever, concerning a stance shift in public perception, the picture is more\ndiverse than expected. All analyzed cases show a noticeable temporal stance\nshift around the start of the war in Ukraine. Still, there are apparent\nnational differences in the size and stability of this shift.\n","authors":["Sergej Wildemann","Claudia Niederée","Erick Elejalde"],"pdf_url":"https://arxiv.org/pdf/2302.02813v1.pdf","comment":"To be published in The Web Conference 2023"},{"id":"http://arxiv.org/abs/2302.02780v1","updated":"2023-02-06T13:50:57Z","published":"2023-02-06T13:50:57Z","title":"Coherence and Diversity through Noise: Self-Supervised Paraphrase\n  Generation via Structure-Aware Denoising","summary":"  In this paper, we propose SCANING, an unsupervised framework for paraphrasing\nvia controlled noise injection. We focus on the novel task of paraphrasing\nalgebraic word problems having practical applications in online pedagogy as a\nmeans to reduce plagiarism as well as ensure understanding on the part of the\nstudent instead of rote memorization. This task is more complex than\nparaphrasing general-domain corpora due to the difficulty in preserving\ncritical information for solution consistency of the paraphrased word problem,\nmanaging the increased length of the text and ensuring diversity in the\ngenerated paraphrase. Existing approaches fail to demonstrate adequate\nperformance on at least one, if not all, of these facets, necessitating the\nneed for a more comprehensive solution. To this end, we model the noising\nsearch space as a composition of contextual and syntactic aspects and sample\nnoising functions consisting of either one or both aspects. This allows for\nlearning a denoising function that operates over both aspects and produces\nsemantically equivalent and syntactically diverse outputs through grounded\nnoise injection. The denoising function serves as a foundation for learning a\nparaphrasing function which operates solely in the input-paraphrase space\nwithout carrying any direct dependency on noise. We demonstrate SCANING\nconsiderably improves performance in terms of both semantic preservation and\nproducing diverse paraphrases through extensive automated and manual evaluation\nacross 4 datasets.\n","authors":["Rishabh Gupta","Venktesh V.","Mukesh Mohania","Vikram Goyal"],"pdf_url":"https://arxiv.org/pdf/2302.02780v1.pdf","comment":"12 pages (main}; 22 pages in total"},{"id":"http://arxiv.org/abs/2210.04878v2","updated":"2023-02-06T12:26:37Z","published":"2022-10-10T17:50:42Z","title":"Translate First Reorder Later: Leveraging Monotonicity in Semantic\n  Parsing","summary":"  Prior work in semantic parsing has shown that conventional seq2seq models\nfail at compositional generalization tasks. This limitation led to a resurgence\nof methods that model alignments between sentences and their corresponding\nmeaning representations, either implicitly through latent variables or\nexplicitly by taking advantage of alignment annotations. We take the second\ndirection and propose TPOL, a two-step approach that first translates input\nsentences monotonically and then reorders them to obtain the correct output.\nThis is achieved with a modular framework comprising a Translator and a\nReorderer component. We test our approach on two popular semantic parsing\ndatasets. Our experiments show that by means of the monotonic translations,\nTPOL can learn reliable lexico-logical patterns from aligned data,\nsignificantly improving compositional generalization both over conventional\nseq2seq models, as well as over other approaches that exploit gold alignments.\n","authors":["Francesco Cazzaro","Davide Locatelli","Ariadna Quattoni","Xavier Carreras"],"pdf_url":"https://arxiv.org/pdf/2210.04878v2.pdf","comment":"Accepted at Findings of ACL: EACL 2023. 8 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2301.13819v2","updated":"2023-02-06T12:03:38Z","published":"2023-01-24T19:23:38Z","title":"Causal-Discovery Performance of ChatGPT in the context of Neuropathic\n  Pain Diagnosis","summary":"  ChatGPT has demonstrated exceptional proficiency in natural language\nconversation, e.g., it can answer a wide range of questions while no previous\nlarge language models can. Thus, we would like to push its limit and explore\nits ability to answer causal discovery questions by using a medical benchmark\n(Tu et al. 2019) in causal discovery.\n","authors":["Ruibo Tu","Chao Ma","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01676v2","updated":"2023-02-06T10:44:21Z","published":"2023-02-03T11:56:38Z","title":"Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction","summary":"  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n","authors":["Davide Costa","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2302.01676v2.pdf","comment":"Accepted paper at The ACM Web Conference 2023, April 30--May 04,\n  2023, Austin, Texas, USA"},{"id":"http://arxiv.org/abs/2301.09279v2","updated":"2023-02-06T10:42:47Z","published":"2023-01-23T05:32:42Z","title":"StockEmotions: Discover Investor Emotions for Financial Sentiment\n  Analysis and Multivariate Time Series","summary":"  There has been growing interest in applying NLP techniques in the financial\ndomain, however, resources are extremely limited. This paper introduces\nStockEmotions, a new dataset for detecting emotions in the stock market that\nconsists of 10,000 English comments collected from StockTwits, a financial\nsocial media platform. Inspired by behavioral finance, it proposes 12\nfine-grained emotion classes that span the roller coaster of investor emotion.\nUnlike existing financial sentiment datasets, StockEmotions presents granular\nfeatures such as investor sentiment classes, fine-grained emotions, emojis, and\ntime series data. To demonstrate the usability of the dataset, we perform a\ndataset analysis and conduct experimental downstream tasks. For financial\nsentiment/emotion classification tasks, DistilBERT outperforms other baselines,\nand for multivariate time series forecasting, a Temporal Attention LSTM model\ncombining price index, text, and emotion features achieves the best performance\nthan using a single feature.\n","authors":["Jean Lee","Hoyoul Luis Youn","Josiah Poon","Soyeon Caren Han"],"pdf_url":"https://arxiv.org/pdf/2301.09279v2.pdf","comment":"Preprint - Accepted by the AAAI-23 Bridge Program (AI for Financial\n  Services)"},{"id":"http://arxiv.org/abs/2302.02676v1","updated":"2023-02-06T10:28:16Z","published":"2023-02-06T10:28:16Z","title":"Languages are Rewards: Hindsight Finetuning using Human Feedback","summary":"  Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values.\nExisting works focus on supervised finetuning of pretrained models, based on\ncurated model generations that are preferred by human labelers. Such works have\nachieved remarkable successes in understanding and following instructions\n(e.g., InstructGPT, ChatGPT, etc). However, to date, a key limitation of\nsupervised finetuning is that it cannot learn from negative ratings; models are\nonly trained on positive-rated data, which makes it data inefficient. Because\ncollecting human feedback data is both time consuming and expensive, it is\nvital for the model to learn from all feedback, akin to the remarkable ability\nof humans to learn from diverse feedback. In this work, we propose a novel\ntechnique called Hindsight Finetuning for making language models learn from\ndiverse human feedback. In fact, our idea is motivated by how humans learn from\nhindsight experience. We condition the model on a sequence of model generations\npaired with hindsight feedback, and finetune the model to predict the most\npreferred output. By doing so, models can learn to identify and correct\nnegative attributes or errors. Applying the method to GPT-J, we observe that it\nsignificantly improves results on summarization and dialogue tasks using the\nsame amount of human feedback.\n","authors":["Hao Liu","Carmelo Sferrazza","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02655v1","updated":"2023-02-06T09:50:48Z","published":"2023-02-06T09:50:48Z","title":"Evolution of grammatical forms: some quantitative approaches","summary":"  Grammatical forms are said to evolve via two main mechanisms. These are,\nrespectively, the `descent' mechanism, where current forms can be seen to have\ndescended (albeit with occasional modifications) from their roots in ancient\nlanguages, and the `contact' mechanism, where evolution in a given language\noccurs via borrowing from other languages with which it is in contact. We use\nideas and concepts from statistical physics to formulate a series of static and\ndynamical models which illustrate these issues in general terms. The static\nmodels emphasise the relative numbers of rules and exceptions, while the\ndynamical models focus on the emergence of exceptional forms. These unlikely\nsurvivors among various competing grammatical forms are winners against the\nodds. Our analysis suggests that they emerge when the influence of neighbouring\nlanguages exceeds the generic tendency towards regularisation within individual\nlanguages.\n","authors":["Jean-Marc Luck","Anita Mehta"],"pdf_url":"https://arxiv.org/pdf/2302.02655v1.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2210.07295v2","updated":"2023-02-06T09:13:31Z","published":"2022-10-13T18:49:59Z","title":"Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog","summary":"  Traditional systems designed for task oriented dialog utilize knowledge\npresent only in structured knowledge sources to generate responses. However,\nrelevant information required to generate responses may also reside in\nunstructured sources, such as documents. Recent state of the art models such as\nHyKnow and SeKnow aimed at overcoming these challenges make limiting\nassumptions about the knowledge sources. For instance, these systems assume\nthat certain types of information, such as a phone number, is always present in\na structured knowledge base (KB) while information about aspects such as\nentrance ticket prices, would always be available in documents.\n  In this paper, we create a modified version of the MutliWOZ-based dataset\nprepared by SeKnow to demonstrate how current methods have significant\ndegradation in performance when strict assumptions about the source of\ninformation are removed. Then, in line with recent work exploiting pre-trained\nlanguage models, we fine-tune a BART based model using prompts for the tasks of\nquerying knowledge sources, as well as, for response generation, without making\nassumptions about the information present in each knowledge source. Through a\nseries of experiments, we demonstrate that our model is robust to perturbations\nto knowledge modality (source of information), and that it can fuse information\nfrom structured as well as unstructured knowledge to generate responses.\n","authors":["Mayank Mishra","Danish Contractor","Dinesh Raghu"],"pdf_url":"https://arxiv.org/pdf/2210.07295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10405v2","updated":"2023-02-06T09:10:32Z","published":"2023-01-25T04:45:06Z","title":"Editing Language Model-based Knowledge Graph Embeddings","summary":"  Recently decades have witnessed the empirical success of framing Knowledge\nGraph (KG) embeddings via language models. However, language model-based KG\nembeddings are usually deployed as static artifacts, which are challenging to\nmodify without re-training after deployment. To address this issue, we propose\na new task of editing language model-based KG embeddings in this paper. The\nproposed task aims to enable data-efficient and fast updates to KG embeddings\nwithout damaging the performance of the rest. We build four new datasets:\nE-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge\nediting baselines demonstrating the limited ability of previous models to\nhandle the proposed challenging task. We further propose a simple yet strong\nbaseline dubbed KGEditor, which utilizes additional parametric layers of the\nhyper network to edit/add facts. Comprehensive experimental results demonstrate\nthat KGEditor can perform better when updating specific facts while not\naffecting the rest with low training resources. Code and datasets will be\navailable in https://github.com/zjunlp/PromptKG/tree/main/deltaKG.\n","authors":["Siyuan Cheng","Ningyu Zhang","Bozhong Tian","Zelin Dai","Feiyu Xiong","Wei Guo","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2301.10405v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/KGE_Editing/"},{"id":"http://arxiv.org/abs/2302.01691v2","updated":"2023-02-06T08:04:56Z","published":"2023-02-03T12:42:45Z","title":"LIQUID: A Framework for List Question Answering Dataset Generation","summary":"  Question answering (QA) models often rely on large-scale training datasets,\nwhich necessitates the development of a data generation framework to reduce the\ncost of manual annotations. Although several recent studies have aimed to\ngenerate synthetic questions with single-span answers, no study has been\nconducted on the creation of list questions with multiple, non-contiguous spans\nas answers. To address this gap, we propose LIQUID, an automated framework for\ngenerating list QA datasets from unlabeled corpora. We first convert a passage\nfrom Wikipedia or PubMed into a summary and extract named entities from the\nsummarized text as candidate answers. This allows us to select answers that are\nsemantically correlated in context and is, therefore, suitable for constructing\nlist questions. We then create questions using an off-the-shelf question\ngenerator with the extracted entities and original passage. Finally, iterative\nfiltering and answer expansion are performed to ensure the accuracy and\ncompleteness of the answers. Using our synthetic data, we significantly improve\nthe performance of the previous best list QA models by exact-match F1 scores of\n5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ\nbenchmarks.\n","authors":["Seongyun Lee","Hyunjae Kim","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2302.01691v2.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2301.07067v2","updated":"2023-02-06T08:03:15Z","published":"2023-01-17T18:31:12Z","title":"Transformers as Algorithms: Generalization and Stability in In-context\n  Learning","summary":"  In-context learning (ICL) is a type of prompting where a transformer model\noperates on a sequence of (input, output) examples and performs inference\non-the-fly. In this work, we formalize in-context learning as an algorithm\nlearning problem where a transformer model implicitly constructs a hypothesis\nfunction at inference-time. We first explore the statistical aspects of this\nabstraction through the lens of multitask learning: We obtain generalization\nbounds for ICL when the input prompt is (1) a sequence of i.i.d. (input, label)\npairs or (2) a trajectory arising from a dynamical system. The crux of our\nanalysis is relating the excess risk to the stability of the algorithm\nimplemented by the transformer. We characterize when transformer/attention\narchitecture provably obeys the stability condition and also provide empirical\nverification. For generalization on unseen tasks, we identify an inductive bias\nphenomenon in which the transfer learning risk is governed by the task\ncomplexity and the number of MTL tasks in a highly predictable manner. Finally,\nwe provide numerical evaluations that (1) demonstrate transformers can indeed\nimplement near-optimal algorithms on classical regression problems with i.i.d.\nand dynamic data, (2) provide insights on stability, and (3) verify our\ntheoretical predictions.\n","authors":["Yingcong Li","M. Emrullah Ildiz","Dimitris Papailiopoulos","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2301.07067v2.pdf","comment":"Revised version significantly improves the stability guarantees and\n  provides new experiments"},{"id":"http://arxiv.org/abs/2301.12868v2","updated":"2023-02-06T07:06:53Z","published":"2023-01-30T13:21:00Z","title":"On Robustness of Prompt-based Semantic Parsing with Large Pre-trained\n  Language Model: An Empirical Study on Codex","summary":"  Semantic parsing is a technique aimed at constructing a structured\nrepresentation of the meaning of a natural-language question. Recent\nadvancements in few-shot language models trained on code have demonstrated\nsuperior performance in generating these representations compared to\ntraditional unimodal language models, which are trained on downstream tasks.\nDespite these advancements, existing fine-tuned neural semantic parsers are\nsusceptible to adversarial attacks on natural-language inputs. While it has\nbeen established that the robustness of smaller semantic parsers can be\nenhanced through adversarial training, this approach is not feasible for large\nlanguage models in real-world scenarios, as it requires both substantial\ncomputational resources and expensive human annotation on in-domain semantic\nparsing data. This paper presents the first empirical study on the adversarial\nrobustness of a large prompt-based language model of code, \\codex. Our results\ndemonstrate that the state-of-the-art (SOTA) code-language models are\nvulnerable to carefully crafted adversarial examples. To address this\nchallenge, we propose methods for improving robustness without the need for\nsignificant amounts of labeled data or heavy computational resources.\n","authors":["Terry Yue Zhuo","Zhuang Li","Yujin Huang","Fatemeh Shiri","Weiqing Wang","Gholamreza Haffari","Yuan-Fang Li"],"pdf_url":"https://arxiv.org/pdf/2301.12868v2.pdf","comment":"Accepted at EACL2023 (main)"},{"id":"http://arxiv.org/abs/2208.03219v2","updated":"2023-02-06T05:22:05Z","published":"2022-08-05T15:07:23Z","title":"Construction of English Resume Corpus and Test with Pre-trained Language\n  Models","summary":"  Information extraction(IE) has always been one of the essential tasks of NLP.\nMoreover, one of the most critical application scenarios of information\nextraction is the information extraction of resumes. Constructed text is\nobtained by classifying each part of the resume. It is convenient to store\nthese texts for later search and analysis. Furthermore, the constructed resume\ndata can also be used in the AI resume screening system. Significantly reduce\nthe labor cost of HR. This study aims to transform the information extraction\ntask of resumes into a simple sentence classification task. Based on the\nEnglish resume dataset produced by the prior study. The classification rules\nare improved to create a larger and more fine-grained classification dataset of\nresumes. This corpus is also used to test some current mainstream Pre-training\nlanguage models (PLMs) performance.Furthermore, in order to explore the\nrelationship between the number of training samples and the correctness rate of\nthe resume dataset, we also performed comparison experiments with training sets\nof different train set sizes.The final multiple experimental results show that\nthe resume dataset with improved annotation rules and increased sample size of\nthe dataset improves the accuracy of the original resume dataset.\n","authors":["Chengguang Gan","Tatsunori Mori"],"pdf_url":"https://arxiv.org/pdf/2208.03219v2.pdf","comment":"The Association for Natural Language Processing in Japan. Submit in\n  NLP2023"},{"id":"http://arxiv.org/abs/2302.02568v1","updated":"2023-02-06T05:11:27Z","published":"2023-02-06T05:11:27Z","title":"Less is More: Understanding Word-level Textual Adversarial Attack via\n  n-gram Frequency Descend","summary":"  Word-level textual adversarial attacks have achieved striking performance in\nfooling natural language processing models. However, the fundamental questions\nof why these attacks are effective, and the intrinsic properties of the\nadversarial examples (AEs), are still not well understood. This work attempts\nto interpret textual attacks through the lens of $n$-gram frequency.\nSpecifically, it is revealed that existing word-level attacks exhibit a strong\ntendency toward generation of examples with $n$-gram frequency descend\n($n$-FD). Intuitively, this finding suggests a natural way to improve model\nrobustness by training the model on the $n$-FD examples. To verify this idea,\nwe devise a model-agnostic and gradient-free AE generation approach that relies\nsolely on the $n$-gram frequency information, and further integrate it into the\nrecently proposed convex hull framework for adversarial training. Surprisingly,\nthe resultant method performs quite similarly to the original gradient-based\nmethod in terms of model robustness. These findings provide a\nhuman-understandable perspective for interpreting word-level textual\nadversarial attacks, and a new direction to improve model robustness.\n","authors":["Ning Lu","Zhirui Zhang","Qi Wang","Haifeng Liu","Ke Tang","Shengcai Liu"],"pdf_url":"https://arxiv.org/pdf/2302.02568v1.pdf","comment":"8 pages, 4 figures. In progress"},{"id":"http://arxiv.org/abs/2209.14500v2","updated":"2023-02-06T04:07:43Z","published":"2022-09-29T01:35:57Z","title":"Bidirectional Language Models Are Also Few-shot Learners","summary":"  Large language models such as GPT-3 (Brown et al., 2020) can perform\narbitrary tasks without undergoing fine-tuning after being prompted with only a\nfew labeled examples. An arbitrary task can be reformulated as a natural\nlanguage prompt, and a language model can be asked to generate the completion,\nindirectly performing the task in a paradigm known as prompt-based learning. To\ndate, emergent prompt-based learning capabilities have mainly been demonstrated\nfor unidirectional language models. However, bidirectional language models\npre-trained on denoising objectives such as masked language modeling produce\nstronger learned representations for transfer learning. This motivates the\npossibility of prompting bidirectional models, but their pre-training\nobjectives have made them largely incompatible with the existing prompting\nparadigm. We present SAP (Sequential Autoregressive Prompting), a technique\nthat enables the prompting of bidirectional models. Utilizing the machine\ntranslation task as a case study, we prompt the bidirectional mT5 model (Xue et\nal., 2021) with SAP and demonstrate its few-shot and zero-shot translations\noutperform the few-shot translations of unidirectional models like GPT-3 and\nXGLM (Lin et al., 2021), despite mT5's approximately 50% fewer parameters. We\nfurther show SAP is effective on question answering and summarization. For the\nfirst time, our results demonstrate prompt-based learning is an emergent\nproperty of a broader class of language models, rather than only unidirectional\nmodels.\n","authors":["Ajay Patel","Bryan Li","Mohammad Sadegh Rasooli","Noah Constant","Colin Raffel","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2209.14500v2.pdf","comment":"To appear at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.12609v2","updated":"2023-02-06T03:17:34Z","published":"2023-01-30T02:05:24Z","title":"Knowledge Distillation $\\approx$ Label Smoothing: Fact or Fallacy?","summary":"  Contrary to its original interpretation as a facilitator of knowledge\ntransfer from one model to another, some recent studies have suggested that\nknowledge distillation (KD) is instead a form of regularization. Perhaps the\nstrongest support of all for this claim is found in its apparent similarities\nwith label smoothing (LS). This paper investigates the stated equivalence of\nthese two methods by examining the predictive uncertainties of the models they\ntrain. Experiments on four text classification tasks involving teachers and\nstudents of different capacities show that: (a) In most settings, KD and LS\ndrive model uncertainty (entropy) in completely opposite directions, and (b) In\nKD, the student's predictive uncertainty is a direct function of that of its\nteacher, reinforcing the knowledge transfer view.\n","authors":["Md Arafat Sultan"],"pdf_url":"https://arxiv.org/pdf/2301.12609v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06987v2","updated":"2023-02-06T00:08:56Z","published":"2022-11-13T18:31:45Z","title":"BiFSMNv2: Pushing Binary Neural Networks for Keyword Spotting to\n  Real-Network Performance","summary":"  Deep neural networks, such as the Deep-FSMN, have been widely studied for\nkeyword spotting (KWS) applications while suffering expensive computation and\nstorage. Therefore, network compression technologies like binarization are\nstudied to deploy KWS models on edge. In this paper, we present a strong yet\nefficient binary neural network for KWS, namely BiFSMNv2, pushing it to the\nreal-network accuracy performance. First, we present a Dual-scale Thinnable\n1-bit-Architecture to recover the representation capability of the binarized\ncomputation units by dual-scale activation binarization and liberate the\nspeedup potential from an overall architecture perspective. Second, we also\nconstruct a Frequency Independent Distillation scheme for KWS\nbinarization-aware training, which distills the high and low-frequency\ncomponents independently to mitigate the information mismatch between\nfull-precision and binarized representations. Moreover, we propose the Learning\nPropagation Binarizer, a general and efficient binarizer that enables the\nforward and backward propagation of binary KWS networks to be continuously\nimproved through learning. We implement and deploy the BiFSMNv2 on ARMv8\nreal-world hardware with a novel Fast Bitwise Computation Kernel, which is\nproposed to fully utilize registers and increase instruction throughput.\nComprehensive experiments show our BiFSMNv2 outperforms existing binary\nnetworks for KWS by convincing margins across different datasets and achieves\ncomparable accuracy with the full-precision networks (only a tiny 1.51% drop on\nSpeech Commands V1-12). We highlight that benefiting from the compact\narchitecture and optimized hardware kernel, BiFSMNv2 can achieve an impressive\n25.1x speedup and 20.2x storage-saving on edge hardware.\n","authors":["Haotong Qin","Xudong Ma","Yifu Ding","Xiaoyang Li","Yang Zhang","Zejun Ma","Jiakai Wang","Jie Luo","Xianglong Liu"],"pdf_url":"https://arxiv.org/pdf/2211.06987v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.06483"},{"id":"http://arxiv.org/abs/2302.03169v1","updated":"2023-02-06T23:57:56Z","published":"2023-02-06T23:57:56Z","title":"Data Selection for Language Models via Importance Resampling","summary":"  Selecting a suitable training dataset is crucial for both general-domain\n(e.g., GPT-3) and domain-specific (e.g., Codex) language models (LMs). We\nformalize this data selection problem as selecting a subset of a large raw\nunlabeled dataset to match a desired target distribution, given some unlabeled\ntarget samples. Due to the large scale and dimensionality of the raw text data,\nexisting methods use simple heuristics to select data that are similar to a\nhigh-quality reference corpus (e.g., Wikipedia), or leverage experts to\nmanually curate data. Instead, we extend the classic importance resampling\napproach used in low-dimensions for LM data selection. Crucially, we work in a\nreduced feature space to make importance weight estimation tractable over the\nspace of text. To determine an appropriate feature space, we first show that KL\nreduction, a data metric that measures the proximity between selected data and\nthe target in a feature space, has high correlation with average accuracy on 8\ndownstream tasks (r=0.89) when computed with simple n-gram features. From this\nobservation, we present Data Selection with Importance Resampling (DSIR), an\nefficient and scalable algorithm that estimates importance weights in a reduced\nfeature space (e.g., n-gram features in our instantiation) and selects data\nwith importance resampling according to these weights. When training\ngeneral-domain models (target is Wikipedia + books), DSIR improves over random\nselection and heuristic filtering baselines by 2--2.5% on the GLUE benchmark.\nWhen performing continued pretraining towards a specific domain, DSIR performs\ncomparably to expert curated data across 8 target distributions.\n","authors":["Sang Michael Xie","Shibani Santurkar","Tengyu Ma","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.03169v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03162v1","updated":"2023-02-06T23:42:03Z","published":"2023-02-06T23:42:03Z","title":"Protecting Language Generation Models via Invisible Watermarking","summary":"  Language generation models have been an increasingly powerful enabler for\nmany applications. Many such models offer free or affordable API access, which\nmakes them potentially vulnerable to model extraction attacks through\ndistillation. To protect intellectual property (IP) and ensure fair use of\nthese models, various techniques such as lexical watermarking and synonym\nreplacement have been proposed. However, these methods can be nullified by\nobvious countermeasures such as \"synonym randomization\". To address this issue,\nwe propose GINSEW, a novel method to protect text generation models from being\nstolen through distillation. The key idea of our method is to inject secret\nsignals into the probability vector of the decoding steps for each target\ntoken. We can then detect the secret message by probing a suspect model to tell\nif it is distilled from the protected one. Experimental results show that\nGINSEW can effectively identify instances of IP infringement with minimal\nimpact on the generation quality of protected APIs. Our method demonstrates an\nabsolute improvement of 19 to 29 points on mean average precision (mAP) in\ndetecting suspects compared to previous methods against watermark removal\nattacks.\n","authors":["Xuandong Zhao","Yu-Xiang Wang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2302.03162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.02728v4","updated":"2023-02-06T23:38:35Z","published":"2021-03-03T22:34:01Z","title":"Morality, Machines and the Interpretation Problem: A Value-based,\n  Wittgensteinian Approach to Building Moral Agents","summary":"  We present what we call the Interpretation Problem, whereby any rule in\nsymbolic form is open to infinite interpretation in ways that we might\ndisapprove of and argue that any attempt to build morality into machines is\nsubject to it. We show how the Interpretation Problem in Artificial\nIntelligence is an illustration of Wittgenstein's general claim that no rule\ncan contain the criteria for its own application, and that the risks created by\nthis problem escalate in proportion to the degree to which to machine is\ncausally connected to the world, in what we call the Law of Interpretative\nExposure. Using game theory, we attempt to define the structure of normative\nspaces and argue that any rule-following within a normative space is guided by\nvalues that are external to that space and which cannot themselves be\nrepresented as rules. In light of this, we categorise the types of mistakes an\nartificial moral agent could make into Mistakes of Intention and Instrumental\nMistakes, and we propose ways of building morality into machines by getting\nthem to interpret the rules we give in accordance with these external values,\nthrough explicit moral reasoning, the Show, not Tell paradigm, the adjustment\nof causal power and structure of the agent, and relational values, with the\nultimate aim that the machine develop a virtuous character and that the impact\nof the Interpretation Problem is minimised.\n","authors":["Cosmin Badea","Gregory Artus"],"pdf_url":"https://arxiv.org/pdf/2103.02728v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03147v1","updated":"2023-02-06T22:53:13Z","published":"2023-02-06T22:53:13Z","title":"It's about Time: Rethinking Evaluation on Rumor Detection Benchmarks\n  using Chronological Splits","summary":"  New events emerge over time influencing the topics of rumors in social media.\nCurrent rumor detection benchmarks use random splits as training, development\nand test sets which typically results in topical overlaps. Consequently, models\ntrained on random splits may not perform well on rumor classification on\npreviously unseen topics due to the temporal concept drift. In this paper, we\nprovide a re-evaluation of classification models on four popular rumor\ndetection benchmarks considering chronological instead of random splits. Our\nexperimental results show that the use of random splits can significantly\noverestimate predictive performance across all datasets and models. Therefore,\nwe suggest that rumor detection models should always be evaluated using\nchronological splits for minimizing topical overlaps.\n","authors":["Yida Mu","Kalina Bontcheva","Nikolaos Aletras"],"pdf_url":"https://arxiv.org/pdf/2302.03147v1.pdf","comment":"Accepted at EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2302.03145v1","updated":"2023-02-06T22:41:51Z","published":"2023-02-06T22:41:51Z","title":"Techniques to Improve Neural Math Word Problem Solvers","summary":"  Developing automatic Math Word Problem (MWP) solvers is a challenging task\nthat demands the ability of understanding and mathematical reasoning over the\nnatural language. Recent neural-based approaches mainly encode the problem text\nusing a language model and decode a mathematical expression over quantities and\noperators iteratively. Note the problem text of a MWP consists of a context\npart and a question part, a recent work finds these neural solvers may only\nperform shallow pattern matching between the context text and the golden\nexpression, where question text is not well used. Meanwhile, existing decoding\nprocesses fail to enforce the mathematical laws into the design, where the\nrepresentations for mathematical equivalent expressions are different. To\naddress these two issues, we propose a new encoder-decoder architecture that\nfully leverages the question text and preserves step-wise commutative law.\nBesides generating quantity embeddings, our encoder further encodes the\nquestion text and uses it to guide the decoding process. At each step, our\ndecoder uses Deep Sets to compute expression representations so that these\nembeddings are invariant under any permutation of quantities. Experiments on\nfour established benchmarks demonstrate that our framework outperforms\nstate-of-the-art neural MWP solvers, showing the effectiveness of our\ntechniques. We also conduct a detailed analysis of the results to show the\nlimitations of our approach and further discuss the potential future work. Code\nis available at https://github.com/sophistz/Question-Aware-Deductive-MWP.\n","authors":["Youyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03126v1","updated":"2023-02-06T21:24:02Z","published":"2023-02-06T21:24:02Z","title":"Context-Gloss Augmentation for Improving Arabic Target Sense\n  Verification","summary":"  Arabic language lacks semantic datasets and sense inventories. The most\ncommon semantically-labeled dataset for Arabic is the ArabGlossBERT, a\nrelatively small dataset that consists of 167K context-gloss pairs (about 60K\npositive and 107K negative pairs), collected from Arabic dictionaries. This\npaper presents an enrichment to the ArabGlossBERT dataset, by augmenting it\nusing (Arabic-English-Arabic) machine back-translation. Augmentation increased\nthe dataset size to 352K pairs (149K positive and 203K negative pairs). We\nmeasure the impact of augmentation using different data configurations to\nfine-tune BERT on target sense verification (TSV) task. Overall, the accuracy\nranges between 78% to 84% for different data configurations. Although our\napproach performed at par with the baseline, we did observe some improvements\nfor some POS tags in some experiments. Furthermore, our fine-tuned models are\ntrained on a larger dataset covering larger vocabulary and contexts. We provide\nan in-depth analysis of the accuracy for each part-of-speech (POS).\n","authors":["Sanad Malaysha","Mustafa Jarrar","Mohammed Khalilia"],"pdf_url":"https://arxiv.org/pdf/2302.03126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03106v1","updated":"2023-02-06T20:13:11Z","published":"2023-02-06T20:13:11Z","title":"Efficient and Flexible Topic Modeling using Pretrained Embeddings and\n  Bag of Sentences","summary":"  Pre-trained language models have led to a new state-of-the-art in many NLP\ntasks. However, for topic modeling, statistical generative models such as LDA\nare still prevalent, which do not easily allow incorporating contextual word\nvectors. They might yield topics that do not align very well with human\njudgment. In this work, we propose a novel topic modeling and inference\nalgorithm. We suggest a bag of sentences (BoS) approach using sentences as the\nunit of analysis. We leverage pre-trained sentence embeddings by combining\ngenerative process models with clustering. We derive a fast inference algorithm\nbased on expectation maximization, hard assignments, and an annealing process.\nOur evaluation shows that our method yields state-of-the art results with\nrelatively little computational demands. Our methods is more flexible compared\nto prior works leveraging word embeddings, since it provides the possibility to\ncustomize topic-document distributions using priors. Code is at\n\\url{https://github.com/JohnTailor/BertSenClu}.\n","authors":["Johannes Schneider"],"pdf_url":"https://arxiv.org/pdf/2302.03106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03488v1","updated":"2023-02-06T18:40:04Z","published":"2023-02-06T18:40:04Z","title":"APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model\n  for Noisy Labels and Long-tailed Learning","summary":"  Practical natural language processing (NLP) tasks are commonly long-tailed\nwith noisy labels. Those problems challenge the generalization and robustness\nof complex models such as Deep Neural Networks (DNNs). Some commonly used\nresampling techniques, such as oversampling or undersampling, could easily lead\nto overfitting. It is growing popular to learn the data weights leveraging a\nsmall amount of metadata. Besides, recent studies have shown the advantages of\nself-supervised pre-training, particularly to the under-represented data. In\nthis work, we propose a general framework to handle the problem of both\nlong-tail and noisy labels. The model is adapted to the domain of problems in a\ncontrastive learning manner. The re-weighting module is a feed-forward network\nthat learns explicit weighting functions and adapts weights according to\nmetadata. The framework further adapts weights of terms in the loss function\nthrough a combination of the polynomial expansion of cross-entropy loss and\nfocal loss. Our extensive experiments show that the proposed framework\nconsistently outperforms baseline methods. Lastly, our sensitive analysis\nemphasizes the capability of the proposed framework to handle the long-tailed\nproblem and mitigate the negative impact of noisy labels.\n","authors":["Sunyi Chi","Bo Dong","Yiming Xu","Zhenyu Shi","Zheng Du"],"pdf_url":"https://arxiv.org/pdf/2302.03488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03494v1","updated":"2023-02-06T04:21:59Z","published":"2023-02-06T04:21:59Z","title":"A Categorical Archive of ChatGPT Failures","summary":"  Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Ten categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n","authors":["Ali Borji"],"pdf_url":"https://arxiv.org/pdf/2302.03494v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.03027v1","updated":"2023-02-06T18:59:51Z","published":"2023-02-06T18:59:51Z","title":"Zero-shot Image-to-Image Translation","summary":"  Large-scale text-to-image generative models have shown their remarkable\nability to synthesize diverse and high-quality images. However, it is still\nchallenging to directly apply these models for editing real images for two\nreasons. First, it is hard for users to come up with a perfect text prompt that\naccurately describes every visual detail in the input image. Second, while\nexisting models can introduce desirable changes in certain regions, they often\ndramatically alter the input content and introduce unexpected changes in\nunwanted regions. In this work, we propose pix2pix-zero, an image-to-image\ntranslation method that can preserve the content of the original image without\nmanual prompting. We first automatically discover editing directions that\nreflect desired edits in the text embedding space. To preserve the general\ncontent structure after editing, we further propose cross-attention guidance,\nwhich aims to retain the cross-attention maps of the input image throughout the\ndiffusion process. In addition, our method does not need additional training\nfor these edits and can directly use the existing pre-trained text-to-image\ndiffusion model. We conduct extensive experiments and show that our method\noutperforms existing and concurrent works for both real and synthetic image\nediting.\n","authors":["Gaurav Parmar","Krishna Kumar Singh","Richard Zhang","Yijun Li","Jingwan Lu","Jun-Yan Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.03027v1.pdf","comment":"website: https://pix2pixzero.github.io/"},{"id":"http://arxiv.org/abs/2302.03024v1","updated":"2023-02-06T18:59:17Z","published":"2023-02-06T18:59:17Z","title":"AIM: Adapting Image Models for Efficient Video Action Recognition","summary":"  Recent vision transformer based video models mostly follow the ``image\npre-training then finetuning\" paradigm and have achieved great success on\nmultiple video benchmarks. However, full finetuning such a video model could be\ncomputationally expensive and unnecessary, given the pre-trained image\ntransformer models have demonstrated exceptional transferability. In this work,\nwe propose a novel method to Adapt pre-trained Image Models (AIM) for efficient\nvideo understanding. By freezing the pre-trained image model and adding a few\nlightweight Adapters, we introduce spatial adaptation, temporal adaptation and\njoint adaptation to gradually equip an image model with spatiotemporal\nreasoning capability. We show that our proposed AIM can achieve competitive or\neven better performance than prior arts with substantially fewer tunable\nparameters on four video action recognition benchmarks. Thanks to its\nsimplicity, our method is also generally applicable to different image\npre-trained models, which has the potential to leverage more powerful image\nfoundation models in the future. The project webpage is\n\\url{https://adapt-image-models.github.io/}.\n","authors":["Taojiannan Yang","Yi Zhu","Yusheng Xie","Aston Zhang","Chen Chen","Mu Li"],"pdf_url":"https://arxiv.org/pdf/2302.03024v1.pdf","comment":"Accepted to ICLR 2023. Project webpage is at\n  https://adapt-image-models.github.io/"},{"id":"http://arxiv.org/abs/2302.03023v1","updated":"2023-02-06T18:58:38Z","published":"2023-02-06T18:58:38Z","title":"V1T: large-scale mouse V1 response prediction using a Vision Transformer","summary":"  Accurate predictive models of the visual cortex neural response to natural\nvisual stimuli remain a challenge in computational neuroscience. In this work,\nwe introduce V1T, a novel Vision Transformer based architecture that learns a\nshared visual and behavioral representation across animals. We evaluate our\nmodel on two large datasets recorded from mouse primary visual cortex and\noutperform previous convolution-based models by more than 12.7% in prediction\nperformance. Moreover, we show that the attention weights learned by the\nTransformer correlate with the population receptive fields. Our model thus sets\na new benchmark for neural response prediction and captures characteristic\nfeatures of the visual cortex.\n","authors":["Bryan M. Li","Isabel M. Cornacchia","Nathalie L. Rochefort","Arno Onken"],"pdf_url":"https://arxiv.org/pdf/2302.03023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03022v1","updated":"2023-02-06T18:57:30Z","published":"2023-02-06T18:57:30Z","title":"SurgT: Soft-Tissue Tracking for Robotic Surgery, Benchmark and Challenge","summary":"  This paper introduces the SurgT MICCAI 2022 challenge and its first results.\nThere were two purposes for the creation of this challenge: (1) the\nestablishment of the first standardised benchmark for the research community to\nassess soft-tissue trackers; and (2) to encourage the development of\nunsupervised deep learning methods, given the lack of annotated data in\nsurgery. A dataset of 157 stereo endoscopic videos from 20 clinical cases,\nalong with stereo camera calibration parameters, are provided. The participants\nwere tasked with the development of algorithms to track a bounding box on each\nstereo endoscopic video. At the end of the challenge, the developed methods\nwere assessed on a previously hidden test subset. This assessment uses\nbenchmarking metrics that were purposely developed for this challenge and are\nnow available online. The teams were ranked according to their Expected Average\nOverlap (EAO) score, which is a weighted average of Intersection over Union\n(IoU) scores. The top team achieved an EAO score of 0.583 in the test subset.\nTracking soft-tissue using unsupervised algorithms was found to be achievable.\nThe dataset and benchmarking tool have been successfully created and made\npublicly available online. This challenge is expected to contribute to the\ndevelopment of autonomous robotic surgery, and other digital surgical\ntechnologies.\n","authors":["Joao Cartucho","Alistair Weld","Samyakh Tukra","Haozheng Xu","Hiroki Matsuzaki","Taiyo Ishikawa","Minjun Kwon","Yongeun Jang","Kwang-Ju Kim","Gwang Lee","Bizhe Bai","Lueder Kahrs","Lars Boecking","Simeon Allmendinger","Leopold Muller","Yitong Zhang","Yueming Jin","Bano Sophia","Francisco Vasconcelos","Wolfgang Reiter","Jonas Hajek","Bruno Silva","Lukas R. Buschle","Estevao Lima","Joao L. Vilaca","Sandro Queiros","Stamatia Giannarou"],"pdf_url":"https://arxiv.org/pdf/2302.03022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03020v1","updated":"2023-02-06T18:57:14Z","published":"2023-02-06T18:57:14Z","title":"RLSbench: Domain Adaptation Under Relaxed Label Shift","summary":"  Despite the emergence of principled methods for domain adaptation under label\nshift, the sensitivity of these methods for minor shifts in the class\nconditional distributions remains precariously under explored. Meanwhile,\npopular deep domain adaptation heuristics tend to falter when faced with shifts\nin label proportions. While several papers attempt to adapt these heuristics to\naccommodate shifts in label proportions, inconsistencies in evaluation\ncriteria, datasets, and baselines, make it hard to assess the state of the art.\nIn this paper, we introduce RLSbench, a large-scale relaxed label shift\nbenchmark, consisting of >500 distribution shift pairs that draw on 14 datasets\nacross vision, tabular, and language modalities and compose them with varying\nlabel proportions. First, we evaluate 13 popular domain adaptation methods,\ndemonstrating more widespread failures under label proportion shifts than were\npreviously known. Next, we develop an effective two-step meta-algorithm that is\ncompatible with most deep domain adaptation heuristics: (i) pseudo-balance the\ndata at each epoch; and (ii) adjust the final classifier with (an estimate of)\ntarget label distribution. The meta-algorithm improves existing domain\nadaptation heuristics often by 2--10\\% accuracy points under extreme label\nproportion shifts and has little (i.e., <0.5\\%) effect when label proportions\ndo not shift. We hope that these findings and the availability of RLSbench will\nencourage researchers to rigorously evaluate proposed methods in relaxed label\nshift settings. Code is publicly available at\nhttps://github.com/acmi-lab/RLSbench.\n","authors":["Saurabh Garg","Nick Erickson","James Sharpnack","Alex Smola","Sivaraman Balakrishnan","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2302.03020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03018v1","updated":"2023-02-06T18:56:39Z","published":"2023-02-06T18:56:39Z","title":"DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative\n  Diffusion Models","summary":"  Magnetic resonance imaging (MRI) is a common and life-saving medical imaging\ntechnique. However, acquiring high signal-to-noise ratio MRI scans requires\nlong scan times, resulting in increased costs and patient discomfort, and\ndecreased throughput. Thus, there is great interest in denoising MRI scans,\nespecially for the subtype of diffusion MRI scans that are severely\nSNR-limited. While most prior MRI denoising methods are supervised in nature,\nacquiring supervised training datasets for the multitude of anatomies, MRI\nscanners, and scan parameters proves impractical. Here, we propose Denoising\nDiffusion Models for Denoising Diffusion MRI (DDM$^2$), a self-supervised\ndenoising method for MRI denoising using diffusion denoising generative models.\nOur three-stage framework integrates statistic-based denoising theory into\ndiffusion models and performs denoising through conditional generation. During\ninference, we represent input noisy measurements as a sample from an\nintermediate posterior distribution within the diffusion Markov chain. We\nconduct experiments on 4 real-world in-vivo diffusion MRI datasets and show\nthat our DDM$^2$ demonstrates superior denoising performances ascertained with\nclinically-relevant visual qualitative and quantitative metrics.\n","authors":["Tiange Xiang","Mahmut Yurt","Ali B Syed","Kawin Setsompop","Akshay Chaudhari"],"pdf_url":"https://arxiv.org/pdf/2302.03018v1.pdf","comment":"To appear in ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03014v1","updated":"2023-02-06T18:54:14Z","published":"2023-02-06T18:54:14Z","title":"Detection and Localization of Melanoma Skin Cancer in Histopathological\n  Whole Slide Images","summary":"  Melanoma diagnosed and treated in its early stages can increase the survival\nrate. A projected increase in skin cancer incidents and a dearth of\ndermatopathologists have emphasized the need for computational pathology\n(CPATH) systems. CPATH systems with deep learning (DL) models have the\npotential to identify the presence of melanoma by exploiting underlying\nmorphological and cellular features. This paper proposes a DL method to detect\nmelanoma and distinguish between normal skin and benign/malignant melanocytic\nlesions in Whole Slide Images (WSI). Our method detects lesions with high\naccuracy and localizes them on a WSI to identify potential regions of interest\nfor pathologists. Interestingly, our DL method relies on using a single CNN\nnetwork to create localization maps first and use them to perform slide-level\npredictions to determine patients who have melanoma. Our best model provides\nfavorable patch-wise classification results with a 0.992 F1 score and 0.99\nsensitivity on unseen data.\n","authors":["Neel Kanwal","Roger Amundsen","Helga Hardardottir","Emiel A. M. Janssen","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2302.03014v1.pdf","comment":"Submitted to EUSIPCO 23"},{"id":"http://arxiv.org/abs/2302.03011v1","updated":"2023-02-06T18:50:23Z","published":"2023-02-06T18:50:23Z","title":"Structure and Content-Guided Video Synthesis with Diffusion Models","summary":"  Text-guided generative diffusion models unlock powerful image creation and\nediting tools. While these have been extended to video generation, current\napproaches that edit the content of existing footage while retaining structure\nrequire expensive re-training for every input or rely on error-prone\npropagation of image edits across frames. In this work, we present a structure\nand content-guided video diffusion model that edits videos based on visual or\ntextual descriptions of the desired output. Conflicts between user-provided\ncontent edits and structure representations occur due to insufficient\ndisentanglement between the two aspects. As a solution, we show that training\non monocular depth estimates with varying levels of detail provides control\nover structure and content fidelity. Our model is trained jointly on images and\nvideos which also exposes explicit control of temporal consistency through a\nnovel guidance method. Our experiments demonstrate a wide variety of successes;\nfine-grained control over output characteristics, customization based on a few\nreference images, and a strong user preference towards results by our model.\n","authors":["Patrick Esser","Johnathan Chiu","Parmida Atighehchian","Jonathan Granskog","Anastasis Germanidis"],"pdf_url":"https://arxiv.org/pdf/2302.03011v1.pdf","comment":"Project page at https://research.runwayml.com/gen1"},{"id":"http://arxiv.org/abs/2302.03003v1","updated":"2023-02-06T18:39:40Z","published":"2023-02-06T18:39:40Z","title":"OTRE: Where Optimal Transport Guided Unpaired Image-to-Image Translation\n  Meets Regularization by Enhancing","summary":"  Non-mydriatic retinal color fundus photography (CFP) is widely available due\nto the advantage of not requiring pupillary dilation, however, is prone to poor\nquality due to operators, systemic imperfections, or patient-related causes.\nOptimal retinal image quality is mandated for accurate medical diagnoses and\nautomated analyses. Herein, we leveraged the \\emph{Optimal Transport (OT)}\ntheory to propose an unpaired image-to-image translation scheme for mapping\nlow-quality retinal CFPs to high-quality counterparts. Furthermore, to improve\nthe flexibility, robustness, and applicability of our image enhancement\npipeline in the clinical practice, we generalized a state-of-the-art\nmodel-based image reconstruction method, regularization by denoising, by\nplugging in priors learned by our OT-guided image-to-image translation network.\nWe named it as \\emph{regularization by enhancing (RE)}. We validated the\nintegrated framework, OTRE, on three publicly available retinal image datasets\nby assessing the quality after enhancement and their performance on various\ndownstream tasks, including diabetic retinopathy grading, vessel segmentation,\nand diabetic lesion segmentation. The experimental results demonstrated the\nsuperiority of our proposed framework over some state-of-the-art unsupervised\ncompetitors and a state-of-the-art supervised method.\n","authors":["Wenhui Zhu","Peijie Qiu","Oana M. Dumitrascu","Jacob Jacob","Mohammad Farazi","Zhangsihao Yang","Keshav Nandakumar","Yalin Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03003v1.pdf","comment":"Accepted as a conference paper to The 28th biennial international\n  conference on Information Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2302.03004v1","updated":"2023-02-06T18:39:40Z","published":"2023-02-06T18:39:40Z","title":"Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class\n  Incremental Learning","summary":"  Few-shot class-incremental learning (FSCIL) has been a challenging problem as\nonly a few training samples are accessible for each novel class in the new\nsessions. Finetuning the backbone or adjusting the classifier prototypes\ntrained in the prior sessions would inevitably cause a misalignment between the\nfeature and classifier of old classes, which explains the well-known\ncatastrophic forgetting problem. In this paper, we deal with this misalignment\ndilemma in FSCIL inspired by the recently discovered phenomenon named neural\ncollapse, which reveals that the last-layer features of the same class will\ncollapse into a vertex, and the vertices of all classes are aligned with the\nclassifier prototypes, which are formed as a simplex equiangular tight frame\n(ETF). It corresponds to an optimal geometric structure for classification due\nto the maximized Fisher Discriminant Ratio. We propose a neural collapse\ninspired framework for FSCIL. A group of classifier prototypes are pre-assigned\nas a simplex ETF for the whole label space, including the base session and all\nthe incremental sessions. During training, the classifier prototypes are not\nlearnable, and we adopt a novel loss function that drives the features into\ntheir corresponding prototypes. Theoretical analysis shows that our method\nholds the neural collapse optimality and does not break the feature-classifier\nalignment in an incremental fashion. Experiments on the miniImageNet, CUB-200,\nand CIFAR-100 datasets demonstrate that our proposed framework outperforms the\nstate-of-the-art performances. Code address:\nhttps://github.com/NeuralCollapseApplications/FSCIL\n","authors":["Yibo Yang","Haobo Yuan","Xiangtai Li","Zhouchen Lin","Philip Torr","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.03004v1.pdf","comment":"ICLR 2023 (Notable-top-25%)"},{"id":"http://arxiv.org/abs/2302.02991v1","updated":"2023-02-06T18:29:30Z","published":"2023-02-06T18:29:30Z","title":"Optimal Transport Guided Unsupervised Learning for Enhancing low-quality\n  Retinal Images","summary":"  Real-world non-mydriatic retinal fundus photography is prone to artifacts,\nimperfections and low-quality when certain ocular or systemic co-morbidities\nexist. Artifacts may result in inaccuracy or ambiguity in clinical diagnoses.\nIn this paper, we proposed a simple but effective end-to-end framework for\nenhancing poor-quality retinal fundus images. Leveraging the optimal transport\ntheory, we proposed an unpaired image-to-image translation scheme for\ntransporting low-quality images to their high-quality counterparts. We\ntheoretically proved that a Generative Adversarial Networks (GAN) model with a\ngenerator and discriminator is sufficient for this task. Furthermore, to\nmitigate the inconsistency of information between the low-quality images and\ntheir enhancements, an information consistency mechanism was proposed to\nmaximally maintain structural consistency (optical discs, blood vessels,\nlesions) between the source and enhanced domains. Extensive experiments were\nconducted on the EyeQ dataset to demonstrate the superiority of our proposed\nmethod perceptually and quantitatively.\n","authors":["Wenhui Zhu","Peijie Qiu","Mohammad Farazi","Keshav Nandakumar","Oana M. Dumitrascu","Yalin Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02991v1.pdf","comment":"Accepted as a conference paper to 20th IEEE International Symposium\n  on Biomedical Imaging(ISBI 2023)"},{"id":"http://arxiv.org/abs/2302.02979v1","updated":"2023-02-06T18:10:08Z","published":"2023-02-06T18:10:08Z","title":"Learning disentangled representations for explainable chest X-ray\n  classification using Dirichlet VAEs","summary":"  This study explores the use of the Dirichlet Variational Autoencoder (DirVAE)\nfor learning disentangled latent representations of chest X-ray (CXR) images.\nOur working hypothesis is that distributional sparsity, as facilitated by the\nDirichlet prior, will encourage disentangled feature learning for the complex\ntask of multi-label classification of CXR images. The DirVAE is trained using\nCXR images from the CheXpert database, and the predictive capacity of\nmulti-modal latent representations learned by DirVAE models is investigated\nthrough implementation of an auxiliary multi-label classification task, with a\nview to enforce separation of latent factors according to class-specific\nfeatures. The predictive performance and explainability of the latent space\nlearned using the DirVAE were quantitatively and qualitatively assessed,\nrespectively, and compared with a standard Gaussian prior-VAE (GVAE). We\nintroduce a new approach for explainable multi-label classification in which we\nconduct gradient-guided latent traversals for each class of interest. Study\nfindings indicate that the DirVAE is able to disentangle latent factors into\nclass-specific visual features, a property not afforded by the GVAE, and\nachieve a marginal increase in predictive performance relative to GVAE. We\ngenerate visual examples to show that our explainability method, when applied\nto the trained DirVAE, is able to highlight regions in CXR images that are\nclinically relevant to the class(es) of interest and additionally, can identify\ncases where classification relies on spurious feature correlations.\n","authors":["Rachael Harkness","Alejandro F Frangi","Kieran Zucker","Nishant Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2302.02979v1.pdf","comment":"13 pages, 8 figures, to be published in SPIE Medical Imaging 2023"},{"id":"http://arxiv.org/abs/2302.02976v1","updated":"2023-02-06T18:08:33Z","published":"2023-02-06T18:08:33Z","title":"ConvoWaste: An Automatic Waste Segregation Machine Using Deep Learning","summary":"  Nowadays, proper urban waste management is one of the biggest concerns for\nmaintaining a green and clean environment. An automatic waste segregation\nsystem can be a viable solution to improve the sustainability of the country\nand boost the circular economy. This paper proposes a machine to segregate\nwaste into different parts with the help of a smart object detection algorithm\nusing ConvoWaste in the field of deep convolutional neural networks (DCNN) and\nimage processing techniques. In this paper, deep learning and image processing\ntechniques are applied to precisely classify the waste, and the detected waste\nis placed inside the corresponding bins with the help of a servo motor-based\nsystem. This machine has the provision to notify the responsible authority\nregarding the waste level of the bins and the time to trash out the bins filled\nwith garbage by using the ultrasonic sensors placed in each bin and the\ndual-band GSM-based communication technology. The entire system is controlled\nremotely through an Android app in order to dump the separated waste in the\ndesired place thanks to its automation properties. The use of this system can\naid in the process of recycling resources that were initially destined to\nbecome waste, utilizing natural resources, and turning these resources back\ninto usable products. Thus, the system helps fulfill the criteria of a circular\neconomy through resource optimization and extraction. Finally, the system is\ndesigned to provide services at a low cost while maintaining a high level of\naccuracy in terms of technological advancement in the field of artificial\nintelligence (AI). We have gotten 98% accuracy for our ConvoWaste deep learning\nmodel.\n","authors":["Md. Shahariar Nafiz","Shuvra Smaran Das","Md. Kishor Morol","Abdullah Al Juabir","Dip Nandi"],"pdf_url":"https://arxiv.org/pdf/2302.02976v1.pdf","comment":"Accepted at ICREST 2023"},{"id":"http://arxiv.org/abs/2302.00633v2","updated":"2023-02-06T17:56:38Z","published":"2023-02-01T17:52:40Z","title":"Deep Dependency Networks for Multi-Label Classification","summary":"  We propose a simple approach which combines the strengths of probabilistic\ngraphical models and deep learning architectures for solving the multi-label\nclassification task, focusing specifically on image and video data. First, we\nshow that the performance of previous approaches that combine Markov Random\nFields with neural networks can be modestly improved by leveraging more\npowerful methods such as iterative join graph propagation, integer linear\nprogramming, and $\\ell_1$ regularization-based structure learning. Then we\npropose a new modeling framework called deep dependency networks, which\naugments a dependency network, a model that is easy to train and learns more\naccurate dependencies but is limited to Gibbs sampling for inference, to the\noutput layer of a neural network. We show that despite its simplicity, jointly\nlearning this new architecture yields significant improvements in performance\nover the baseline neural network. In particular, our experimental evaluation on\nthree video activity classification datasets: Charades, Textually Annotated\nCooking Scenes (TACoS), and Wetlab, and three multi-label image classification\ndatasets: MS-COCO, PASCAL VOC, and NUS-WIDE show that deep dependency networks\nare almost always superior to pure neural architectures that do not use\ndependency networks.\n","authors":["Shivvrat Arya","Yu Xiang","Vibhav Gogate"],"pdf_url":"https://arxiv.org/pdf/2302.00633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04746v4","updated":"2023-02-06T17:40:07Z","published":"2023-01-11T22:55:05Z","title":"Switchable Lightweight Anti-symmetric Processing (SLAP) with CNN\n  Outspeeds Data Augmentation by Smaller Sample -- Application in Gomoku\n  Reinforcement Learning","summary":"  To replace data augmentation, this paper proposed a method called SLAP to\nintensify experience to speed up machine learning and reduce the sample size.\nSLAP is a model-independent protocol/function to produce the same output given\ndifferent transformation variants. SLAP improved the convergence speed of\nconvolutional neural network learning by 83% in the experiments with Gomoku\ngame states, with only one eighth of the sample size compared with data\naugmentation. In reinforcement learning for Gomoku, using AlphaGo\nZero/AlphaZero algorithm with data augmentation as baseline, SLAP reduced the\nnumber of training samples by a factor of 8 and achieved similar winning rate\nagainst the same evaluator, but it was not yet evident that it could speed up\nreinforcement learning. The benefits should at least apply to domains that are\ninvariant to symmetry or certain transformations. As future work, SLAP may aid\nmore explainable learning and transfer learning for domains that are not\ninvariant to symmetry, as a small step towards artificial general intelligence.\n","authors":["Chi-Hang Suen","Eduardo Alonso"],"pdf_url":"https://arxiv.org/pdf/2301.04746v4.pdf","comment":"Add co-author and enrich discussion; 6 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.02940v1","updated":"2023-02-06T17:14:59Z","published":"2023-02-06T17:14:59Z","title":"Integrating Eye-Gaze Data into CXR DL Approaches: A Preliminary study","summary":"  This paper proposes a novel multimodal DL architecture incorporating medical\nimages and eye-tracking data for abnormality detection in chest x-rays. Our\nresults show that applying eye gaze data directly into DL architectures does\nnot show superior predictive performance in abnormality detection chest X-rays.\nThese results support other works in the literature and suggest that\nhuman-generated data, such as eye gaze, needs a more thorough investigation\nbefore being applied to DL architectures.\n","authors":["André Luís","Chihcheng Hsieh","Isabel Blanco Nobre","Sandra Costa Sousa","Anderson Maciel","Catarina Moreira","Joaquim Jorge"],"pdf_url":"https://arxiv.org/pdf/2302.02940v1.pdf","comment":"A version of this paper has been accepted for presentation at the 2nd\n  XR Health workshop - XR Technologies for Healthcare and Wellbeing\n  https://ieeevr.org/2023/contribute/workshoppapers/#XRHealth"},{"id":"http://arxiv.org/abs/2302.02936v1","updated":"2023-02-06T17:11:09Z","published":"2023-02-06T17:11:09Z","title":"Private GANs, Revisited","summary":"  We show that the canonical approach for training differentially private GANs\n-- updating the discriminator with differentially private stochastic gradient\ndescent (DPSGD) -- can yield significantly improved results after modifications\nto training. Existing instantiations of this approach neglect to consider how\nadding noise only to discriminator updates disrupts the careful balance between\nthe generator and discriminator necessary for successful GAN training. We show\nthat a simple fix -- taking more discriminator steps between generator steps --\nrestores parity and improves results. Additionally, with the goal of restoring\nparity between the generator and discriminator, we experiment with other\nmodifications to improve discriminator training and see further improvements in\ngeneration quality. Our results demonstrate that on standard benchmarks, DPSGD\noutperforms all alternative GAN privatization schemes.\n","authors":["Alex Bie","Gautam Kamath","Guojun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02928v1","updated":"2023-02-06T17:05:50Z","published":"2023-02-06T17:05:50Z","title":"Generating Evidential BEV Maps in Continuous Driving Space","summary":"  Safety is critical for autonomous driving, and one aspect of improving safety\nis to accurately capture the uncertainties of the perception system, especially\nknowing the unknown. Different from only providing deterministic or\nprobabilistic results, e.g., probabilistic object detection, that only provide\npartial information for the perception scenario, we propose a complete\nprobabilistic model named GevBEV. It interprets the 2D driving space as a\nprobabilistic Bird's Eye View (BEV) map with point-based spatial Gaussian\ndistributions, from which one can draw evidence as the parameters for the\ncategorical Dirichlet distribution of any new sample point in the continuous\ndriving space. The experimental results show that GevBEV not only provides more\nreliable uncertainty quantification but also outperforms the previous works on\nthe benchmark OPV2V of BEV map interpretation for cooperative perception. A\ncritical factor in cooperative perception is the data transmission size through\nthe communication channels. GevBEV helps reduce communication overhead by\nselecting only the most important information to share from the learned\nuncertainty, reducing the average information communicated by 80% with a slight\nperformance drop.\n","authors":["Yunshuang Yuan","Hao Cheng","Michael Ying Yang","Monika Sester"],"pdf_url":"https://arxiv.org/pdf/2302.02928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12558v6","updated":"2023-02-06T17:03:03Z","published":"2022-01-29T10:54:57Z","title":"The KFIoU Loss for Rotated Object Detection","summary":"  Differing from the well-developed horizontal object detection area whereby\nthe computing-friendly IoU based loss is readily adopted and well fits with the\ndetection metrics. In contrast, rotation detectors often involve a more\ncomplicated loss based on SkewIoU which is unfriendly to gradient-based\ntraining. In this paper, we propose an effective approximate SkewIoU loss based\non Gaussian modeling and Gaussian product, which mainly consists of two items.\nThe first term is a scale-insensitive center point loss, which is used to\nquickly narrow the distance between the center points of the two bounding\nboxes. In the distance-independent second term, the product of the Gaussian\ndistributions is adopted to inherently mimic the mechanism of SkewIoU by its\ndefinition, and show its alignment with the SkewIoU loss at trend-level within\na certain distance (i.e. within 9 pixels). This is in contrast to recent\nGaussian modeling based rotation detectors e.g. GWD loss and KLD loss that\ninvolve a human-specified distribution distance metric which require additional\nhyperparameter tuning that vary across datasets and detectors. The resulting\nnew loss called KFIoU loss is easier to implement and works better compared\nwith exact SkewIoU loss, thanks to its full differentiability and ability to\nhandle the non-overlapping cases. We further extend our technique to the 3-D\ncase which also suffers from the same issues as 2-D. Extensive results on\nvarious public datasets (2-D/3-D, aerial/text/face images) with different base\ndetectors show the effectiveness of our approach.\n","authors":["Xue Yang","Yue Zhou","Gefan Zhang","Jirui Yang","Wentao Wang","Junchi Yan","Xiaopeng Zhang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2201.12558v6.pdf","comment":"18 pages, 6 figures, 8 tables, accepted by ICLR 2023, TensorFlow\n  code: https://github.com/yangxue0827/RotationDetection, PyTorch code:\n  https://github.com/open-mmlab/mmrotate, Jittor code:\n  https://github.com/Jittor/JDet"},{"id":"http://arxiv.org/abs/2302.01660v2","updated":"2023-02-06T16:46:38Z","published":"2023-02-03T11:17:59Z","title":"The Learnable Typewriter: A Generative Approach to Text Line Analysis","summary":"  We present a generative document-specific approach to character analysis and\nrecognition in text lines. Our main idea is to build on unsupervised\nmulti-object segmentation methods and in particular those that reconstruct\nimages based on a limited amount of visual elements, called sprites. Our\napproach can learn a large number of different characters and leverage\nline-level annotations when available. Our contribution is twofold. First, we\nprovide the first adaptation and evaluation of a deep unsupervised multi-object\nsegmentation approach for text line analysis. Since these methods have mainly\nbeen evaluated on synthetic data in a completely unsupervised setting,\ndemonstrating that they can be adapted and quantitatively evaluated on real\ntext images and that they can be trained using weak supervision are significant\nprogresses. Second, we demonstrate the potential of our method for new\napplications, more specifically in the field of paleography, which studies the\nhistory and variations of handwriting, and for cipher analysis. We evaluate our\napproach on three very different datasets: a printed volume of the Google1000\ndataset, the Copiale cipher and historical handwritten charters from the 12th\nand early 13th century.\n","authors":["Ioannis Siglidis","Nicolas Gonthier","Julien Gaubil","Tom Monnier","Mathieu Aubry"],"pdf_url":"https://arxiv.org/pdf/2302.01660v2.pdf","comment":"For the code and a quick-overview visit the project webpage at\n  http://imagine.enpc.fr/~siglidii/learnable-typewriter"},{"id":"http://arxiv.org/abs/2103.11135v3","updated":"2023-02-06T16:34:27Z","published":"2021-03-20T08:39:41Z","title":"High Resolution Face Editing with Masked GAN Latent Code Optimization","summary":"  Face editing represents a popular research topic within the computer vision\nand image processing communities. While significant progress has been made\nrecently in this area, existing solutions: (i) are still largely focused on\nlow-resolution images, (ii) often generate editing results with visual\nartefacts, or (iii) lack fine-grained control and alter multiple (entangled)\nattributes at once, when trying to generate the desired facial semantics. In\nthis paper, we aim to address these issues though a novel attribute editing\napproach called MaskFaceGAN that focuses on local attribute editing. The\nproposed approach is based on an optimization procedure that directly optimizes\nthe latent code of a pre-trained (state-of-the-art) Generative Adversarial\nNetwork (i.e., StyleGAN2) with respect to several constraints that ensure: (i)\npreservation of relevant image content, (ii) generation of the targeted facial\nattributes, and (iii) spatially--selective treatment of local image areas. The\nconstraints are enforced with the help of an (differentiable) attribute\nclassifier and face parser that provide the necessary reference information for\nthe optimization procedure. MaskFaceGAN is evaluated in extensive experiments\non the CelebA-HQ, Helen and SiblingsDB-HQf datasets and in comparison with\nseveral state-of-the-art techniques from the literature, i.e., StarGAN, AttGAN,\nSTGAN, and two versions of InterFaceGAN. Our experimental results show that the\nproposed approach is able to edit face images with respect to several local\nfacial attributes with unprecedented image quality and at high-resolutions\n(1024x1024), while exhibiting considerably less problems with attribute\nentanglement than competing solutions. The source code is made freely available\nfrom: https://github.com/MartinPernus/MaskFaceGAN.\n","authors":["Martin Pernuš","Vitomir Štruc","Simon Dobrišek"],"pdf_url":"https://arxiv.org/pdf/2103.11135v3.pdf","comment":"Final ArXiv version. The paper has been accepted for publication in\n  IEEE Transactions on Image Processing journal and will be published in 2023"},{"id":"http://arxiv.org/abs/2302.02908v1","updated":"2023-02-06T16:24:41Z","published":"2023-02-06T16:24:41Z","title":"LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale\n  Image-Text Retrieval","summary":"  Image-text retrieval (ITR) is a task to retrieve the relevant images/texts,\ngiven the query from another modality. The conventional dense retrieval\nparadigm relies on encoding images and texts into dense representations using\ndual-stream encoders, however, it faces challenges with low retrieval speed in\nlarge-scale retrieval scenarios. In this work, we propose the lexicon-weighting\nparadigm, where sparse representations in vocabulary space are learned for\nimages and texts to take advantage of the bag-of-words models and efficient\ninverted indexes, resulting in significantly reduced retrieval latency. A\ncrucial gap arises from the continuous nature of image data, and the\nrequirement for a sparse vocabulary space representation. To bridge this gap,\nwe introduce a novel pre-training framework, Lexicon-Bottlenecked\nLanguage-Image Pre-Training (LexLIP), that learns importance-aware lexicon\nrepresentations. This framework features lexicon-bottlenecked modules between\nthe dual-stream encoders and weakened text decoders, allowing for constructing\ncontinuous bag-of-words bottlenecks to learn lexicon-importance distributions.\nUpon pre-training with same-scale data, our LexLIP achieves state-of-the-art\nperformance on two benchmark ITR datasets, MSCOCO and Flickr30k. Furthermore,\nin large-scale retrieval scenarios, LexLIP outperforms CLIP with a 5.5 ~ 221.3X\nfaster retrieval speed and 13.2 ~ 48.8X less index storage memory.\n","authors":["Ziyang luo","Pu Zhao","Can Xu","Xiubo Geng","Tao Shen","Chongyang Tao","Jing Ma","Qingwen lin","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.02908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02907v1","updated":"2023-02-06T16:23:24Z","published":"2023-02-06T16:23:24Z","title":"GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks","summary":"  While leveraging additional training data is well established to improve\nadversarial robustness, it incurs the unavoidable cost of data collection and\nthe heavy computation to train models. To mitigate the costs, we propose\n\\textit{Guided Adversarial Training } (GAT), a novel adversarial training\ntechnique that exploits auxiliary tasks under a limited set of training data.\nOur approach extends single-task models into multi-task models during the\nmin-max optimization of adversarial training, and drives the loss optimization\nwith a regularization of the gradient curvature across multiple tasks. GAT\nleverages two types of auxiliary tasks: self-supervised tasks, where the labels\nare generated automatically, and domain-knowledge tasks, where human experts\nprovide additional labels. Experimentally, under limited data, GAT increases\nthe robust accuracy on CIFAR-10 up to four times (from 11% to 42% robust\naccuracy) and the robust AUC of CheXpert medical imaging dataset from 50\\% to\n83\\%. On the full CIFAR-10 dataset, GAT outperforms eight state-of-the-art\nadversarial training strategies.\n  Our large study across five datasets and six tasks demonstrates that task\naugmentation is an efficient alternative to data augmentation, and can be key\nto achieving both clean and robust performances.\n","authors":["Salah Ghamizi","Jingfeng Zhang","Maxime Cordy","Mike Papadakis","Masashi Sugiyama","Yves Le Traon"],"pdf_url":"https://arxiv.org/pdf/2302.02907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02887v1","updated":"2023-02-06T15:53:34Z","published":"2023-02-06T15:53:34Z","title":"Neural Document Unwarping using Coupled Grids","summary":"  Restoring the original, flat appearance of a printed document from casual\nphotographs of bent and wrinkled pages is a common everyday problem. In this\npaper we propose a novel method for grid-based single-image document unwarping.\nOur method performs geometric distortion correction via a deep fully\nconvolutional neural network that learns to predict the 3D grid mesh of the\ndocument and the corresponding 2D unwarping grid in a multi-task fashion,\nimplicitly encoding the coupling between the shape of a 3D object and its 2D\nimage. We additionally create and publish our own dataset, called UVDoc, which\ncombines pseudo-photorealistic document images with ground truth grid-based\nphysical 3D and unwarping information, allowing unwarping models to train on\ndata that is more realistic in appearance than the commonly used synthetic\nDoc3D dataset, whilst also being more physically accurate. Our dataset is\nlabeled with all the information necessary to train our unwarping network,\nwithout having to engineer separate loss functions that can deal with the lack\nof ground-truth typically found in document in the wild datasets. We include a\nthorough evaluation that demonstrates that our dual-task unwarping network\ntrained on a mix of synthetic and pseudo-photorealistic images achieves\nstate-of-the-art performance on the DocUNet benchmark dataset. Our code,\nresults and UVDoc dataset will be made publicly available upon publication.\n","authors":["Floor Verhoeven","Tanguy Magne","Olga Sorkine-Hornung"],"pdf_url":"https://arxiv.org/pdf/2302.02887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02884v1","updated":"2023-02-06T15:52:03Z","published":"2023-02-06T15:52:03Z","title":"Intra-operative Brain Tumor Detection with Deep Learning-Optimized\n  Hyperspectral Imaging","summary":"  Surgery for gliomas (intrinsic brain tumors), especially when low-grade, is\nchallenging due to the infiltrative nature of the lesion. Currently, no\nreal-time, intra-operative, label-free and wide-field tool is available to\nassist and guide the surgeon to find the relevant demarcations for these\ntumors. While marker-based methods exist for the high-grade glioma case, there\nis no convenient solution available for the low-grade case; thus, marker-free\noptical techniques represent an attractive option. Although RGB imaging is a\nstandard tool in surgical microscopes, it does not contain sufficient\ninformation for tissue differentiation. We leverage the richer information from\nhyperspectral imaging (HSI), acquired with a snapscan camera in the 468-787 nm\nrange, coupled to a surgical microscope, to build a deep-learning-based\ndiagnostic tool for cancer resection with potential for intra-operative\nguidance. However, the main limitation of the HSI snapscan camera is the image\nacquisition time, limiting its widespread deployment in the operation theater.\nHere, we investigate the effect of HSI channel reduction and pre-selection to\nscope the design space for the development of cheaper and faster sensors.\nNeural networks are used to identify the most important spectral channels for\ntumor tissue differentiation, optimizing the trade-off between the number of\nchannels and precision to enable real-time intra-surgical application. We\nevaluate the performance of our method on a clinical dataset that was acquired\nduring surgery on five patients. By demonstrating the possibility to\nefficiently detect low-grade glioma, these results can lead to better cancer\nresection demarcations, potentially improving treatment effectiveness and\npatient outcome.\n","authors":["Tommaso Giannantonio","Anna Alperovich","Piercosimo Semeraro","Manfredo Atzori","Xiaohan Zhang","Christoph Hauger","Alexander Freytag","Siri Luthman","Roeland Vandebriel","Murali Jayapala","Lien Solie","Steven de Vleeschouwer"],"pdf_url":"https://arxiv.org/pdf/2302.02884v1.pdf","comment":"SPIE Photonics West 2023 conference Optical Biopsy XXI: Toward\n  Real-Time Spectroscopic Imaging and Diagnosis. 18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2210.16081v2","updated":"2023-02-06T15:42:14Z","published":"2022-10-28T11:58:22Z","title":"Object Segmentation of Cluttered Airborne LiDAR Point Clouds","summary":"  Airborne topographic LiDAR is an active remote sensing technology that emits\nnear-infrared light to map objects on the Earth's surface. Derived products of\nLiDAR are suitable to service a wide range of applications because of their\nrich three-dimensional spatial information and their capacity to obtain\nmultiple returns. However, processing point cloud data still requires a\nsignificant effort in manual editing. Certain human-made objects are difficult\nto detect because of their variety of shapes, irregularly-distributed point\nclouds, and low number of class samples. In this work, we propose an efficient\nend-to-end deep learning framework to automatize the detection and segmentation\nof objects defined by an arbitrary number of LiDAR points surrounded by\nclutter. Our method is based on a light version of PointNet that achieves good\nperformance on both object recognition and segmentation tasks. The results are\ntested against manually delineated power transmission towers and show promising\naccuracy.\n","authors":["Mariona Caros","Ariadna Just","Santi Segui","Jordi Vitria"],"pdf_url":"https://arxiv.org/pdf/2210.16081v2.pdf","comment":"proceedings of the 24th International Conference of the Catalan\n  Association for Artificial Intelligence (CCIA 2022)"},{"id":"http://arxiv.org/abs/2302.02871v1","updated":"2023-02-06T15:38:21Z","published":"2023-02-06T15:38:21Z","title":"Top-Down Beats Bottom-Up in 3D Instance Segmentation","summary":"  Most 3D instance segmentation methods exploit a bottom-up strategy, typically\nincluding resource-exhaustive post-processing. For point grouping, bottom-up\nmethods rely on prior assumptions about the objects in the form of\nhyperparameters, which are domain-specific and need to be carefully tuned. On\nthe contrary, we address 3D instance segmentation with a TD3D: top-down, fully\ndata-driven, simple approach trained in an end-to-end manner. With its\nstraightforward fully-convolutional pipeline, it performs surprisingly well on\nthe standard benchmarks: ScanNet v2, its extension ScanNet200, and S3DIS.\nBesides, our method is much faster on inference than the current\nstate-of-the-art grouping-based approaches. Code is available at\nhttps://github.com/SamsungLabs/td3d .\n","authors":["Maksim Kolodiazhnyi","Danila Rukhovich","Anna Vorontsova","Anton Konushin"],"pdf_url":"https://arxiv.org/pdf/2302.02871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00048v2","updated":"2023-02-06T15:33:18Z","published":"2022-05-31T18:28:39Z","title":"PandA: Unsupervised Learning of Parts and Appearances in the Feature\n  Maps of GANs","summary":"  Recent advances in the understanding of Generative Adversarial Networks\n(GANs) have led to remarkable progress in visual editing and synthesis tasks,\ncapitalizing on the rich semantics that are embedded in the latent spaces of\npre-trained GANs. However, existing methods are often tailored to specific GAN\narchitectures and are limited to either discovering global semantic directions\nthat do not facilitate localized control, or require some form of supervision\nthrough manually provided regions or segmentation masks. In this light, we\npresent an architecture-agnostic approach that jointly discovers factors\nrepresenting spatial parts and their appearances in an entirely unsupervised\nfashion. These factors are obtained by applying a semi-nonnegative tensor\nfactorization on the feature maps, which in turn enables context-aware local\nimage editing with pixel-level control. In addition, we show that the\ndiscovered appearance factors correspond to saliency maps that localize\nconcepts of interest, without using any labels. Experiments on a wide range of\nGAN architectures and datasets show that, in comparison to the state of the\nart, our method is far more efficient in terms of training time and, most\nimportantly, provides much more accurate localized control. Our code is\navailable at: https://github.com/james-oldfield/PandA.\n","authors":["James Oldfield","Christos Tzelepis","Yannis Panagakis","Mihalis A. Nicolaou","Ioannis Patras"],"pdf_url":"https://arxiv.org/pdf/2206.00048v2.pdf","comment":"Accepted at ICLR 2023. Code available at:\n  https://github.com/james-oldfield/PandA"},{"id":"http://arxiv.org/abs/2302.02858v1","updated":"2023-02-06T15:25:50Z","published":"2023-02-06T15:25:50Z","title":"TR3D: Towards Real-Time Indoor 3D Object Detection","summary":"  Recently, sparse 3D convolutions have changed 3D object detection. Performing\non par with the voting-based approaches, 3D CNNs are memory-efficient and scale\nto large scenes better. However, there is still room for improvement. With a\nconscious, practice-oriented approach to problem-solving, we analyze the\nperformance of such methods and localize the weaknesses. Applying modifications\nthat resolve the found issues one by one, we end up with TR3D: a fast\nfully-convolutional 3D object detection model trained end-to-end, that achieves\nstate-of-the-art results on the standard benchmarks, ScanNet v2, SUN RGB-D, and\nS3DIS. Moreover, to take advantage of both point cloud and RGB inputs, we\nintroduce an early fusion of 2D and 3D features. We employ our fusion module to\nmake conventional 3D object detection methods multimodal and demonstrate an\nimpressive boost in performance. Our model with early feature fusion, which we\nrefer to as TR3D+FF, outperforms existing 3D object detection approaches on the\nSUN RGB-D dataset. Overall, besides being accurate, both TR3D and TR3D+FF\nmodels are lightweight, memory-efficient, and fast, thereby marking another\nmilestone on the way toward real-time 3D object detection. Code is available at\nhttps://github.com/SamsungLabs/tr3d .\n","authors":["Danila Rukhovich","Anna Vorontsova","Anton Konushin"],"pdf_url":"https://arxiv.org/pdf/2302.02858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02849v1","updated":"2023-02-06T15:14:58Z","published":"2023-02-06T15:14:58Z","title":"An Unsupervised Framework for Joint MRI Super Resolution and Gibbs\n  Artifact Removal","summary":"  The k-space data generated from magnetic resonance imaging (MRI) is only a\nfinite sampling of underlying signals. Therefore, MRI images often suffer from\nlow spatial resolution and Gibbs ringing artifacts. Previous studies tackled\nthese two problems separately, where super resolution methods tend to enhance\nGibbs artifacts, whereas Gibbs ringing removal methods tend to blur the images.\nIt is also a challenge that high resolution ground truth is hard to obtain in\nclinical MRI. In this paper, we propose an unsupervised learning framework for\nboth MRI super resolution and Gibbs artifacts removal without using high\nresolution ground truth. Furthermore, we propose regularization methods to\nimprove the model's generalizability across out-of-distribution MRI images. We\nevaluated our proposed methods with other state-of-the-art methods on eight MRI\ndatasets with various contrasts and anatomical structures. Our method not only\nachieves the best SR performance but also significantly reduces the Gibbs\nartifacts. Our method also demonstrates good generalizability across different\ndatasets, which is beneficial to clinical applications where training data are\nusually scarce and biased.\n","authors":["Yikang Liu","Eric Z. Chen","Xiao Chen","Terrence Chen","Shanhui Sun"],"pdf_url":"https://arxiv.org/pdf/2302.02849v1.pdf","comment":"Accepted by the 28th biennial international conference on Information\n  Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/1701.08435v3","updated":"2023-02-06T14:49:05Z","published":"2017-01-29T21:39:05Z","title":"Transformation-Based Models of Video Sequences","summary":"  In this work we propose a simple unsupervised approach for next frame\nprediction in video. Instead of directly predicting the pixels in a frame given\npast frames, we predict the transformations needed for generating the next\nframe in a sequence, given the transformations of the past frames. This leads\nto sharper results, while using a smaller prediction model. In order to enable\na fair comparison between different video frame prediction models, we also\npropose a new evaluation protocol. We use generated frames as input to a\nclassifier trained with ground truth sequences. This criterion guarantees that\nmodels scoring high are those producing sequences which preserve discriminative\nfeatures, as opposed to merely penalizing any deviation, plausible or not, from\nthe ground truth. Our proposed approach compares favourably against more\nsophisticated ones on the UCF-101 data set, while also being more efficient in\nterms of the number of parameters and computational cost.\n","authors":["Joost van Amersfoort","Anitha Kannan","Marc'Aurelio Ranzato","Arthur Szlam","Du Tran","Soumith Chintala"],"pdf_url":"https://arxiv.org/pdf/1701.08435v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02814v1","updated":"2023-02-06T14:38:09Z","published":"2023-02-06T14:38:09Z","title":"MixFormer: End-to-End Tracking with Iterative Mixed Attention","summary":"  Visual object tracking often employs a multi-stage pipeline of feature\nextraction, target information integration, and bounding box estimation. To\nsimplify this pipeline and unify the process of feature extraction and target\ninformation integration, in this paper, we present a compact tracking\nframework, termed as MixFormer, built upon transformers. Our core design is to\nutilize the flexibility of attention operations, and propose a Mixed Attention\nModule (MAM) for simultaneous feature extraction and target information\nintegration. This synchronous modeling scheme allows to extract target-specific\ndiscriminative features and perform extensive communication between target and\nsearch area. Based on MAM, we build our MixFormer trackers simply by stacking\nmultiple MAMs and placing a localization head on top. Specifically, we\ninstantiate two types of MixFormer trackers, a hierarchical tracker MixCvT, and\na non-hierarchical tracker MixViT. For these two trackers, we investigate a\nseries of pre-training methods and uncover the different behaviors between\nsupervised pre-training and self-supervised pre-training in our MixFormer\ntrackers. We also extend the masked pre-training to our MixFormer trackers and\ndesign the competitive TrackMAE pre-training technique. Finally, to handle\nmultiple target templates during online tracking, we devise an asymmetric\nattention scheme in MAM to reduce computational cost, and propose an effective\nscore prediction module to select high-quality templates. Our MixFormer\ntrackers set a new state-of-the-art performance on seven tracking benchmarks,\nincluding LaSOT, TrackingNet, VOT2020, GOT-10k, OTB100 and UAV123. In\nparticular, our MixViT-L achieves AUC score of 73.3% on LaSOT, 86.1% on\nTrackingNet, EAO of 0.584 on VOT2020, and AO of 75.7% on GOT-10k. Code and\ntrained models will be made available at https://github.com/MCG-NJU/MixFormer.\n","authors":["Yutao Cui","Cheng Jiang","Gangshan Wu","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02814v1.pdf","comment":"Extended version of the paper arXiv:2203.11082 presented at CVPR\n  2022. In particular, the extented MixViT-L achieves AUC score of 73.3% on\n  LaSOT. Besides, we design a new TrackMAE pre-training method for tracking"},{"id":"http://arxiv.org/abs/2208.11945v2","updated":"2023-02-06T14:36:58Z","published":"2022-08-25T09:02:32Z","title":"Efficient Adaptive Activation Rounding for Post-Training Quantization","summary":"  Post-training quantization (PTQ) attracts increasing attention due to its\nconvenience in deploying quantized neural networks. Rounding is the primary\nsource of quantization error, for which previous works adopt the\nrounding-to-nearest scheme with a constant border of 0.5. This work\ndemonstrates that optimizing rounding schemes can improve model accuracy. By\nreplacing the constant border with a simple border function, we can obtain the\nminimal error for multiplying two numbers and eliminate the bias of its\nexpected value, which further benefits model accuracy. Based on this insight,\nwe approximate the border function to make the incurred overhead negligible. We\nalso jointly optimize propagated errors and global errors. We finally propose\nour AQuant framework, which can learn the border function automatically.\nExtensive experiments show that AQuant achieves noticeable improvements\ncompared with state-of-the-art works and pushes the accuracy of ResNet-18 up to\n60.31% under the 2-bit weight and activation post-training quantization.\n","authors":["Zhengyi Li","Cong Guo","Zhanda Zhu","Yangjie Zhou","Yuxian Qiu","Xiaotian Gao","Jingwen Leng","Minyi Guo"],"pdf_url":"https://arxiv.org/pdf/2208.11945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02804v1","updated":"2023-02-06T14:28:49Z","published":"2023-02-06T14:28:49Z","title":"Stop overkilling simple tasks with black-box models and use transparent\n  models instead","summary":"  In recent years, the employment of deep learning methods has led to several\nsignificant breakthroughs in artificial intelligence. Different from\ntraditional machine learning models, deep learning-based approaches are able to\nextract features autonomously from raw data. This allows for bypassing the\nfeature engineering process, which is generally considered to be both\nerror-prone and tedious. Moreover, deep learning strategies often outperform\ntraditional models in terms of accuracy.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2302.02804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.02340v2","updated":"2023-02-06T14:15:47Z","published":"2021-12-04T13:59:52Z","title":"Scanpath Prediction on Information Visualisations","summary":"  We propose Unified Model of Saliency and Scanpaths (UMSS) -- a model that\nlearns to predict visual saliency and scanpaths (i.e. sequences of eye\nfixations) on information visualisations. Although scanpaths provide rich\ninformation about the importance of different visualisation elements during the\nvisual exploration process, prior work has been limited to predicting\naggregated attention statistics, such as visual saliency. We present in-depth\nanalyses of gaze behaviour for different information visualisation elements\n(e.g. Title, Label, Data) on the popular MASSVIS dataset. We show that while,\noverall, gaze patterns are surprisingly consistent across visualisations and\nviewers, there are also structural differences in gaze dynamics for different\nelements. Informed by our analyses, UMSS first predicts multi-duration\nelement-level saliency maps, then probabilistically samples scanpaths from\nthem. Extensive experiments on MASSVIS show that our method consistently\noutperforms state-of-the-art methods with respect to several, widely used\nscanpath and saliency evaluation metrics. Our method achieves a relative\nimprovement in sequence score of 11.5% for scanpath prediction, and a relative\nimprovement in Pearson correlation coefficient of up to 23.6% for saliency\nprediction. These results are auspicious and point towards richer user models\nand simulations of visual attention on visualisations without the need for any\neye tracking equipment.\n","authors":["Yao Wang","Mihai Bâce","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2112.02340v2.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.02790v1","updated":"2023-02-06T14:07:13Z","published":"2023-02-06T14:07:13Z","title":"Perception Datasets for Anomaly Detection in Autonomous Driving: A\n  Survey","summary":"  Deep neural networks (DNN) which are employed in perception systems for\nautonomous driving require a huge amount of data to train on, as they must\nreliably achieve high performance in all kinds of situations. However, these\nDNN are usually restricted to a closed set of semantic classes available in\ntheir training data, and are therefore unreliable when confronted with\npreviously unseen instances. Thus, multiple perception datasets have been\ncreated for the evaluation of anomaly detection methods, which can be\ncategorized into three groups: real anomalies in real-world, synthetic\nanomalies augmented into real-world and completely synthetic scenes. This\nsurvey provides a structured and, to the best of our knowledge, complete\noverview and comparison of perception datasets for anomaly detection in\nautonomous driving. Each chapter provides information about tasks and ground\ntruth, context information, and licenses. Additionally, we discuss current\nweaknesses and gaps in existing datasets to underline the importance of\ndeveloping further data.\n","authors":["Daniel Bogdoll","Svenja Uhlemeyer","Kamil Kowol","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2302.02790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05981v3","updated":"2023-02-06T13:11:44Z","published":"2022-06-13T09:04:32Z","title":"Efficient Human-in-the-loop System for Guiding DNNs Attention","summary":"  Attention guidance is an approach to addressing dataset bias in deep\nlearning, where the model relies on incorrect features to make decisions.\nFocusing on image classification tasks, we propose an efficient\nhuman-in-the-loop system to interactively direct the attention of classifiers\nto the regions specified by users, thereby reducing the influence of\nco-occurrence bias and improving the transferability and interpretability of a\nDNN. Previous approaches for attention guidance require the preparation of\npixel-level annotations and are not designed as interactive systems. We present\na new interactive method to allow users to annotate images with simple clicks,\nand study a novel active learning strategy to significantly reduce the number\nof annotations. We conducted both a numerical evaluation and a user study to\nevaluate the proposed system on multiple datasets. Compared to the existing\nnon-active-learning approach which usually relies on huge amounts of\npolygon-based segmentation masks to fine-tune or train the DNNs, our system can\nsave lots of labor and money and obtain a fine-tuned network that works better\neven when the dataset is biased. The experiment results indicate that the\nproposed system is efficient, reasonable, and reliable.\n","authors":["Yi He","Xi Yang","Chia-Ming Chang","Haoran Xie","Takeo Igarashi"],"pdf_url":"https://arxiv.org/pdf/2206.05981v3.pdf","comment":"13 pages, 11 figures, proceeding of ACM IUI 2023, video\n  https://youtu.be/2MD-z6vXKJ4"},{"id":"http://arxiv.org/abs/2302.02755v1","updated":"2023-02-06T13:05:55Z","published":"2023-02-06T13:05:55Z","title":"Fine-Grained Action Detection with RGB and Pose Information using Two\n  Stream Convolutional Networks","summary":"  As participants of the MediaEval 2022 Sport Task, we propose a two-stream\nnetwork approach for the classification and detection of table tennis strokes.\nEach stream is a succession of 3D Convolutional Neural Network (CNN) blocks\nusing attention mechanisms. Each stream processes different 4D inputs. Our\nmethod utilizes raw RGB data and pose information computed from MMPose toolbox.\nThe pose information is treated as an image by applying the pose either on a\nblack background or on the original RGB frame it has been computed from. Best\nperformance is obtained by feeding raw RGB data to one stream, Pose + RGB\n(PRGB) information to the other stream and applying late fusion on the\nfeatures. The approaches were evaluated on the provided TTStroke-21 data sets.\nWe can report an improvement in stroke classification, reaching 87.3% of\naccuracy, while the detection does not outperform the baseline but still\nreaches an IoU of 0.349 and mAP of 0.110.\n","authors":["Leonard Hacker","Finn Bartels","Pierre-Etienne Martin"],"pdf_url":"https://arxiv.org/pdf/2302.02755v1.pdf","comment":"Working note paper of the sport task of MediaEval 2022 in Bergen,\n  Norway, 12-13 Jan 2023"},{"id":"http://arxiv.org/abs/2302.02752v1","updated":"2023-02-06T12:58:01Z","published":"2023-02-06T12:58:01Z","title":"Baseline Method for the Sport Task of MediaEval 2022 with 3D CNNs using\n  Attention Mechanisms","summary":"  This paper presents the baseline method proposed for the Sports Video task\npart of the MediaEval 2022 benchmark. This task proposes two subtasks: stroke\nclassification from trimmed videos, and stroke detection from untrimmed videos.\nThis baseline addresses both subtasks. We propose two types of 3D-CNN\narchitectures to solve the two subtasks. Both 3D-CNNs use Spatio-temporal\nconvolutions and attention mechanisms. The architectures and the training\nprocess are tailored to solve the addressed subtask. This baseline method is\nshared publicly online to help the participants in their investigation and\nalleviate eventually some aspects of the task such as video processing,\ntraining method, evaluation and submission routine. The baseline method reaches\n86.4% of accuracy with our v2 model for the classification subtask. For the\ndetection subtask, the baseline reaches a mAP of 0.131 and IoU of 0.515 with\nour v1 model.\n","authors":["Pierre-Etienne Martin"],"pdf_url":"https://arxiv.org/pdf/2302.02752v1.pdf","comment":"Baseline paper for the sport Task of MediaEval 2022"},{"id":"http://arxiv.org/abs/2302.02744v1","updated":"2023-02-06T12:39:40Z","published":"2023-02-06T12:39:40Z","title":"AMD-HookNet for Glacier Front Segmentation","summary":"  Knowledge on changes in glacier calving front positions is important for\nassessing the status of glaciers. Remote sensing imagery provides the ideal\ndatabase for monitoring calving front positions, however, it is not feasible to\nperform this task manually for all calving glaciers globally due to\ntime-constraints. Deep learning-based methods have shown great potential for\nglacier calving front delineation from optical and radar satellite imagery. The\ncalving front is represented as a single thin line between the ocean and the\nglacier, which makes the task vulnerable to inaccurate predictions. The limited\navailability of annotated glacier imagery leads to a lack of data diversity\n(not all possible combinations of different weather conditions, terminus\nshapes, sensors, etc. are present in the data), which exacerbates the\ndifficulty of accurate segmentation. In this paper, we propose\nAttention-Multi-hooking-Deep-supervision HookNet (AMD-HookNet), a novel glacier\ncalving front segmentation framework for synthetic aperture radar (SAR) images.\nThe proposed method aims to enhance the feature representation capability\nthrough multiple information interactions between low-resolution and\nhigh-resolution inputs based on a two-branch U-Net. The attention mechanism,\nintegrated into the two branch U-Net, aims to interact between the\ncorresponding coarse and fine-grained feature maps. This allows the network to\nautomatically adjust feature relationships, resulting in accurate\npixel-classification predictions. Extensive experiments and comparisons on the\nchallenging glacier segmentation benchmark dataset CaFFe show that our\nAMD-HookNet achieves a mean distance error of 438 m to the ground truth\noutperforming the current state of the art by 42%, which validates its\neffectiveness.\n","authors":["Fei Wu","Nora Gourmelon","Thorsten Seehaus","Jianlin Zhang","Matthias Braun","Andreas Maier","Vincent Christlein"],"pdf_url":"https://arxiv.org/pdf/2302.02744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06742v4","updated":"2023-02-06T12:08:34Z","published":"2022-10-13T05:12:45Z","title":"H2RBox: Horizontal Box Annotation is All You Need for Oriented Object\n  Detection","summary":"  Oriented object detection emerges in many applications from aerial images to\nautonomous driving, while many existing detection benchmarks are annotated with\nhorizontal bounding box only which is also less costive than fine-grained\nrotated box, leading to a gap between the readily available training corpus and\nthe rising demand for oriented object detection. This paper proposes a simple\nyet effective oriented object detection approach called H2RBox merely using\nhorizontal box annotation for weakly-supervised training, which closes the\nabove gap and shows competitive performance even against those trained with\nrotated boxes. The cores of our method are weakly- and self-supervised\nlearning, which predicts the angle of the object by learning the consistency of\ntwo different views. To our best knowledge, H2RBox is the first horizontal box\nannotation-based oriented object detector. Compared to an alternative i.e.\nhorizontal box-supervised instance segmentation with our post adaption to\noriented object detection, our approach is not susceptible to the prediction\nquality of mask and can perform more robustly in complex scenes containing a\nlarge number of dense objects and outliers. Experimental results show that\nH2RBox has significant performance and speed advantages over horizontal\nbox-supervised instance segmentation methods, as well as lower memory\nrequirements. While compared to rotated box-supervised oriented object\ndetectors, our method shows very close performance and speed. The source code\nis available at PyTorch-based\n\\href{https://github.com/yangxue0827/h2rbox-mmrotate}{MMRotate} and\nJittor-based \\href{https://github.com/yangxue0827/h2rbox-jittor}{JDet}.\n","authors":["Xue Yang","Gefan Zhang","Wentong Li","Xuehui Wang","Yue Zhou","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2210.06742v4.pdf","comment":"15 pages, 6 figures, 7 tables, accepted by ICLR 2023, the source code\n  is available at https://github.com/yangxue0827/h2rbox-mmrotate and\n  https://github.com/yangxue0827/h2rbox-jittor"},{"id":"http://arxiv.org/abs/2212.14441v2","updated":"2023-02-06T11:36:39Z","published":"2022-12-29T19:32:20Z","title":"Fruit Ripeness Classification: a Survey","summary":"  Fruit is a key crop in worldwide agriculture feeding millions of people. The\nstandard supply chain of fruit products involves quality checks to guarantee\nfreshness, taste, and, most of all, safety. An important factor that determines\nfruit quality is its stage of ripening. This is usually manually classified by\nexperts in the field, which makes it a labor-intensive and error-prone process.\nThus, there is an arising need for automation in the process of fruit ripeness\nclassification. Many automatic methods have been proposed that employ a variety\nof feature descriptors for the food item to be graded. Machine learning and\ndeep learning techniques dominate the top-performing methods. Furthermore, deep\nlearning can operate on raw data and thus relieve the users from having to\ncompute complex engineered features, which are often crop-specific. In this\nsurvey, we review the latest methods proposed in the literature to automatize\nfruit ripeness classification, highlighting the most common feature descriptors\nthey operate on.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2212.14441v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14447v3","updated":"2023-02-06T11:36:10Z","published":"2022-12-29T20:05:26Z","title":"A Theoretical Framework for AI Models Explainability","summary":"  EXplainable Artificial Intelligence (XAI) is a vibrant research topic in the\nartificial intelligence community, with growing interest across methods and\ndomains. Much has been written about the subject, yet XAI still lacks shared\nterminology and a framework capable of providing structural soundness to\nexplanations. In our work, we address these issues by proposing a novel\ndefinition of explanation that is a synthesis of what can be found in the\nliterature. We recognize that explanations are not atomic but the combination\nof evidence stemming from the model and its input-output mapping, and the human\ninterpretation of this evidence. Furthermore, we fit explanations into the\nproperties of faithfulness (i.e., the explanation being a true description of\nthe model's inner workings and decision-making process) and plausibility (i.e.,\nhow much the explanation looks convincing to the user). Using our proposed\ntheoretical framework simplifies how these properties are operationalized and\nit provides new insight into common explanation methods that we analyze as case\nstudies.\n","authors":["Matteo Rizzo","Alberto Veneri","Andrea Albarelli","Claudio Lucchese","Cristina Conati"],"pdf_url":"https://arxiv.org/pdf/2212.14447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01201v3","updated":"2023-02-06T11:21:44Z","published":"2022-11-02T15:23:16Z","title":"Human alignment of neural network representations","summary":"  Today's computer vision models achieve human or near-human level performance\nacross a wide variety of vision tasks. However, their architectures, data, and\nlearning algorithms differ in numerous ways from those that give rise to human\nvision. In this paper, we investigate the factors that affect the alignment\nbetween the representations learned by neural networks and human mental\nrepresentations inferred from behavioral responses. We find that model scale\nand architecture have essentially no effect on the alignment with human\nbehavioral responses, whereas the training dataset and objective function both\nhave a much larger impact. These findings are consistent across three datasets\nof human similarity judgments collected using two different tasks. Linear\ntransformations of neural network representations learned from behavioral\nresponses from one dataset substantially improve alignment with human\nsimilarity judgments on the other two datasets. In addition, we find that some\nhuman concepts such as food and animals are well-represented by neural networks\nwhereas others such as royal or sports-related objects are not. Overall,\nalthough models trained on larger, more diverse datasets achieve better\nalignment with humans than models trained on ImageNet alone, our results\nindicate that scaling alone is unlikely to be sufficient to train neural\nnetworks with conceptual representations that match those used by humans.\n","authors":["Lukas Muttenthaler","Jonas Dippel","Lorenz Linhardt","Robert A. Vandermeulen","Simon Kornblith"],"pdf_url":"https://arxiv.org/pdf/2211.01201v3.pdf","comment":"Accepted for publication at ICLR 2023"},{"id":"http://arxiv.org/abs/2301.09489v2","updated":"2023-02-06T11:13:03Z","published":"2023-01-23T15:32:27Z","title":"Contracting Skeletal Kinematic Embeddings for Anomaly Detection","summary":"  Detecting the anomaly of human behavior is paramount to timely recognizing\nendangering situations, such as street fights or elderly falls. However,\nanomaly detection is complex, since anomalous events are rare and because it is\nan open set recognition task, i.e., what is anomalous at inference has not been\nobserved at training. We propose COSKAD, a novel model which encodes skeletal\nhuman motion by an efficient graph convolutional network and learns to COntract\nSKeletal kinematic embeddings onto a latent hypersphere of minimum volume for\nAnomaly Detection. We propose and analyze three latent space designs for\nCOSKAD: the commonly-adopted Euclidean, and the new spherical-radial and\nhyperbolic volumes. All three variants outperform the state-of-the-art,\nincluding video-based techniques, on the ShangaiTechCampus, the Avenue, and on\nthe most recent UBnormal dataset, for which we contribute novel skeleton\nannotations and the selection of human-related videos. The source code and\ndataset will be released upon acceptance.\n","authors":["Alessandro Flaborea","Guido D'Amely","Stefano D'Arrigo","Marco Aurelio Sterpa","Alessio Sampieri","Fabio Galasso"],"pdf_url":"https://arxiv.org/pdf/2301.09489v2.pdf","comment":"Submitted to Patter Recognition Journal"},{"id":"http://arxiv.org/abs/2205.15242v3","updated":"2023-02-06T11:06:56Z","published":"2022-05-30T16:55:59Z","title":"Re-parameterizing Your Optimizers rather than Architectures","summary":"  The well-designed structures in neural networks reflect the prior knowledge\nincorporated into the models. However, though different models have various\npriors, we are used to training them with model-agnostic optimizers such as\nSGD. In this paper, we propose to incorporate model-specific prior knowledge\ninto optimizers by modifying the gradients according to a set of model-specific\nhyper-parameters. Such a methodology is referred to as Gradient\nRe-parameterization, and the optimizers are named RepOptimizers. For the\nextreme simplicity of model structure, we focus on a VGG-style plain model and\nshowcase that such a simple model trained with a RepOptimizer, which is\nreferred to as RepOpt-VGG, performs on par with or better than the recent\nwell-designed models. From a practical perspective, RepOpt-VGG is a favorable\nbase model because of its simple structure, high inference speed and training\nefficiency. Compared to Structural Re-parameterization, which adds priors into\nmodels via constructing extra training-time structures, RepOptimizers require\nno extra forward/backward computations and solve the problem of quantization.\nWe hope to spark further research beyond the realms of model structure design.\nCode and models \\url{https://github.com/DingXiaoH/RepOptimizers}.\n","authors":["Xiaohan Ding","Honghao Chen","Xiangyu Zhang","Kaiqi Huang","Jungong Han","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2205.15242v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.02693v1","updated":"2023-02-06T10:51:21Z","published":"2023-02-06T10:51:21Z","title":"PatchDCT: Patch Refinement for High Quality Instance Segmentation","summary":"  High-quality instance segmentation has shown emerging importance in computer\nvision. Without any refinement, DCT-Mask directly generates high-resolution\nmasks by compressed vectors. To further refine masks obtained by compressed\nvectors, we propose for the first time a compressed vector based multi-stage\nrefinement framework. However, the vanilla combination does not bring\nsignificant gains, because changes in some elements of the DCT vector will\naffect the prediction of the entire mask. Thus, we propose a simple and novel\nmethod named PatchDCT, which separates the mask decoded from a DCT vector into\nseveral patches and refines each patch by the designed classifier and\nregressor. Specifically, the classifier is used to distinguish mixed patches\nfrom all patches, and to correct previously mispredicted foreground and\nbackground patches. In contrast, the regressor is used for DCT vector\nprediction of mixed patches, further refining the segmentation quality at\nboundary locations. Experiments on COCO show that our method achieves 2.0%,\n3.2%, 4.5% AP and 3.4%, 5.3%, 7.0% Boundary AP improvements over Mask-RCNN on\nCOCO, LVIS, and Cityscapes, respectively. It also surpasses DCT-Mask by 0.7%,\n1.1%, 1.3% AP and 0.9%, 1.7%, 4.2% Boundary AP on COCO, LVIS and Cityscapes.\nBesides, the performance of PatchDCT is also competitive with other\nstate-of-the-art methods.\n","authors":["Qinrou Wen","Jirui Yang","Xue Yang","Kewei Liang"],"pdf_url":"https://arxiv.org/pdf/2302.02693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01676v2","updated":"2023-02-06T10:44:21Z","published":"2023-02-03T11:56:38Z","title":"Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction","summary":"  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n","authors":["Davide Costa","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2302.01676v2.pdf","comment":"Accepted paper at The ACM Web Conference 2023, April 30--May 04,\n  2023, Austin, Texas, USA"},{"id":"http://arxiv.org/abs/2302.02688v1","updated":"2023-02-06T10:41:57Z","published":"2023-02-06T10:41:57Z","title":"HyperSLICE: HyperBand optimised Spiral for Low-latency Interactive\n  Cardiac Examination","summary":"  BACKGROUND: Interactive cardiac magnetic resonance imaging is used for fast\nscan planning and MR guided interventions. However, the requirement for\nreal-time acquisition and near real-time visualization constrains the\nachievable spatio-temporal resolution.\n  PURPOSE: To improve interactive imaging resolution through optimization of\nundersampled spiral sampling and leveraging of deep learning for low-latency\nreconstruction (deep artifact suppression).\n  POPULATION: Deep artefact suppression training data consisted of 692\nbreath-held CINEs. The developed interactive sequence was tested prospectively\nin 12 patients (10 for image evaluation, 2 during catheterization).\n  ASSESSMENT: In simulated data, NRMSE, pSNR and SSIM of radial, uniform spiral\nand optimized spiral sampling were compared. In the prospective study, the\noptimized spiral interactive sequence was compared to conventional Cartesian\nreal-time, and breath-hold cine imaging in terms quantitative and qualitative\nimage metrics.\n  RESULTS: The NRMSE, pSNR and SSIM were all statistically significantly higher\nin simulations of optimized spiral compared to radial and uniform spiral\nsampling, particularly after scan plan changes (SSIM: 0.71 vs 0.45 and 0.43).\nProspectively, HyperSLICE proposed a higher spatial and temporal resolution\nthan conventional Cartesian real-time imaging. The pipeline was demonstrated in\npatients during catheter pull back showing sufficiently fast reconstruction for\ninteractive imaging.\n  DATA CONCLUSION: HyperSLICE enables higher spatial and temporal interactive\nimaging. Optimizing the spiral sampling enabled better overall image quality\nand better handling of image transitions compared to radial and uniform spiral\ntrajectories.\n","authors":["Dr. Olivier Jaubert","Dr. Javier Montalt-Tordera","Dr. Daniel Knight","Pr. Simon Arridge","Dr. Jennifer Steeden","Pr. Vivek Muthurangu"],"pdf_url":"https://arxiv.org/pdf/2302.02688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.11808v4","updated":"2023-02-06T10:12:28Z","published":"2022-01-27T21:10:20Z","title":"LAP: An Attention-Based Module for Faithful Interpretation and Knowledge\n  Injection in Convolutional Neural Networks","summary":"  Despite the state-of-the-art performance of deep convolutional neural\nnetworks, they are susceptible to bias and malfunction in unseen situations.\nThe complex computation behind their reasoning is not sufficiently\nhuman-understandable to develop trust. External explainer methods have tried to\ninterpret the network decisions in a human-understandable way, but they are\naccused of fallacies due to their assumptions and simplifications. On the other\nside, the inherent self-interpretability of models, while being more robust to\nthe mentioned fallacies, cannot be applied to the already trained models. In\nthis work, we propose a new attention-based pooling layer, called Local\nAttention Pooling (LAP), that accomplishes self-interpretability and the\npossibility for knowledge injection while improving the model's performance.\nMoreover, several weakly-supervised knowledge injection methodologies are\nprovided to enhance the process of training. We verified our claims by\nevaluating several LAP-extended models on three different datasets, including\nImagenet. The proposed framework offers more valid human-understandable and\nmore faithful-to-the-model interpretations than the commonly used white-box\nexplainer methods.\n","authors":["Rassa Ghavami Modegh","Ahmad Salimi","Alireza Dizaji","Hamid R. Rabiee"],"pdf_url":"https://arxiv.org/pdf/2201.11808v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01327v2","updated":"2023-02-06T09:53:56Z","published":"2023-02-02T18:56:25Z","title":"Dual PatchNorm","summary":"  We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms),\nbefore and after the patch embedding layer in Vision Transformers. We\ndemonstrate that Dual PatchNorm outperforms the result of exhaustive search for\nalternative LayerNorm placement strategies in the Transformer block itself. In\nour experiments, incorporating this trivial modification, often leads to\nimproved accuracy over well-tuned Vision Transformers and never hurts.\n","authors":["Manoj Kumar","Mostafa Dehghani","Neil Houlsby"],"pdf_url":"https://arxiv.org/pdf/2302.01327v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02651v1","updated":"2023-02-06T09:47:46Z","published":"2023-02-06T09:47:46Z","title":"1st Place Solution for PSG competition with ECCV'22 SenseHuman Workshop","summary":"  Panoptic Scene Graph (PSG) generation aims to generate scene graph\nrepresentations based on panoptic segmentation instead of rigid bounding boxes.\nExisting PSG methods utilize one-stage paradigm which simultaneously generates\nscene graphs and predicts semantic segmentation masks or two-stage paradigm\nthat first adopt an off-the-shelf panoptic segmentor, then pairwise\nrelationship prediction between these predicted objects. One-stage approach\ndespite having a simplified training paradigm, its segmentation results are\nusually under-satisfactory, while two-stage approach lacks global context and\nleads to low performance on relation prediction. To bridge this gap, in this\npaper, we propose GRNet, a Global Relation Network in two-stage paradigm, where\nthe pre-extracted local object features and their corresponding masks are fed\ninto a transformer with class embeddings. To handle relation ambiguity and\npredicate classification bias caused by long-tailed distribution, we formulate\nrelation prediction in the second stage as a multi-class classification task\nwith soft label. We conduct comprehensive experiments on OpenPSG dataset and\nachieve the state-of-art performance on the leadboard. We also show the\neffectiveness of our soft label strategy for long-tailed classes in ablation\nstudies. Our code has been released in https://github.com/wangqixun/mfpsg.\n","authors":["Qixun Wang","Xiaofeng Guo","Haofan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02651v1.pdf","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2302.02641v1","updated":"2023-02-06T09:22:58Z","published":"2023-02-06T09:22:58Z","title":"Approximation of radiative transfer for surface spectral features","summary":"  Remote sensing hyperspectral and more generally spectral instruments are\ncommon tools to decipher surface features in Earth and Planetary science. While\nlinear mixture is the most common approximation for compounds detection\n(mineral, water, ice, etc...), the transfer of light in surface and atmospheric\nmedium are highly non-linear. The exact simulation of non-linearities can be\nestimated at very high numerical cost. Here I propose a very simple non-linear\nform (that includes the regular linear area mixture) of radiative transfer to\napproximate surface spectral feature. I demonstrate that this analytical form\nis able to approximate the grain size and intimate mixture dependence of\nsurface features. In addition, the same analytical form can approximate the\neffect of Martian mineral aerosols. Unfortunately, Earth aerosols are more\ncomplex (water droplet, water ice, soot,...) and are not expected to follow the\nsame trend.\n","authors":["Frédéric Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.02641v1.pdf","comment":"4 pages, 3 figures, submitted 21st october 2022 to IEEE Geoscience\n  and Remote Sensing Letters"},{"id":"http://arxiv.org/abs/2302.01162v2","updated":"2023-02-06T09:21:58Z","published":"2023-02-02T15:37:46Z","title":"Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using\n  Pixel-aligned Reconstruction Priors","summary":"  Fast generation of high-quality 3D digital humans is important to a vast\nnumber of applications ranging from entertainment to professional concerns.\nRecent advances in differentiable rendering have enabled the training of 3D\ngenerative models without requiring 3D ground truths. However, the quality of\nthe generated 3D humans still has much room to improve in terms of both\nfidelity and diversity. In this paper, we present Get3DHuman, a novel 3D human\nframework that can significantly boost the realism and diversity of the\ngenerated outcomes by only using a limited budget of 3D ground-truth data. Our\nkey observation is that the 3D generator can profit from human-related priors\nlearned through 2D human generators and 3D reconstructors. Specifically, we\nbridge the latent space of Get3DHuman with that of StyleGAN-Human via a\nspecially-designed prior network, where the input latent code is mapped to the\nshape and texture feature volumes spanned by the pixel-aligned 3D\nreconstructor. The outcomes of the prior network are then leveraged as the\nsupervisory signals for the main generator network. To ensure effective\ntraining, we further propose three tailored losses applied to the generated\nfeature volumes and the intermediate feature maps. Extensive experiments\ndemonstrate that Get3DHuman greatly outperforms the other state-of-the-art\napproaches and can support a wide range of applications including shape\ninterpolation, shape re-texturing, and single-view reconstruction through\nlatent inversion.\n","authors":["Zhangyang Xiong","Di Kang","Derong Jin","Weikai Chen","Linchao Bao","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2302.01162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15307v2","updated":"2023-02-06T08:43:09Z","published":"2022-11-28T13:41:14Z","title":"Tuning-free Plug-and-Play Hyperspectral Image Deconvolution with Deep\n  Priors","summary":"  Deconvolution is a widely used strategy to mitigate the blurring and noisy\ndegradation of hyperspectral images~(HSI) generated by the acquisition devices.\nThis issue is usually addressed by solving an ill-posed inverse problem. While\ninvestigating proper image priors can enhance the deconvolution performance, it\nis not trivial to handcraft a powerful regularizer and to set the\nregularization parameters. To address these issues, in this paper we introduce\na tuning-free Plug-and-Play (PnP) algorithm for HSI deconvolution.\nSpecifically, we use the alternating direction method of multipliers (ADMM) to\ndecompose the optimization problem into two iterative sub-problems. A flexible\nblind 3D denoising network (B3DDN) is designed to learn deep priors and to\nsolve the denoising sub-problem with different noise levels. A measure of 3D\nresidual whiteness is then investigated to adjust the penalty parameters when\nsolving the quadratic sub-problems, as well as a stopping criterion.\nExperimental results on both simulated and real-world data with ground-truth\ndemonstrate the superiority of the proposed method.\n","authors":["Xiuheng Wang","Jie Chen","Cédric Richard"],"pdf_url":"https://arxiv.org/pdf/2211.15307v2.pdf","comment":"IEEE Trans. Geosci. Remote sens., to be published. Manuscript\n  submitted Jun. 30, 2022; revised Oct. 25, 2022, and Dec. 06, 2022; and\n  accepted Feb. 02, 2023"},{"id":"http://arxiv.org/abs/2302.02622v1","updated":"2023-02-06T08:41:07Z","published":"2023-02-06T08:41:07Z","title":"Uncertainty Calibration and its Application to Object Detection","summary":"  Image-based environment perception is an important component especially for\ndriver assistance systems or autonomous driving. In this scope, modern neuronal\nnetworks are used to identify multiple objects as well as the according\nposition and size information within a single frame. The performance of such an\nobject detection model is important for the overall performance of the whole\nsystem. However, a detection model might also predict these objects under a\ncertain degree of uncertainty. [...]\n  In this work, we examine the semantic uncertainty (which object type?) as\nwell as the spatial uncertainty (where is the object and how large is it?). We\nevaluate if the predicted uncertainties of an object detection model match with\nthe observed error that is achieved on real-world data. In the first part of\nthis work, we introduce the definition for confidence calibration of the\nsemantic uncertainty in the context of object detection, instance segmentation,\nand semantic segmentation. We integrate additional position information in our\nexaminations to evaluate the effect of the object's position on the semantic\ncalibration properties. Besides measuring calibration, it is also possible to\nperform a post-hoc recalibration of semantic uncertainty that might have turned\nout to be miscalibrated. [...]\n  The second part of this work deals with the spatial uncertainty obtained by a\nprobabilistic detection model. [...] We review and extend common calibration\nmethods so that it is possible to obtain parametric uncertainty distributions\nfor the position information in a more flexible way.\n  In the last part, we demonstrate a possible use-case for our derived\ncalibration methods in the context of object tracking. [...] We integrate our\npreviously proposed calibration techniques and demonstrate the usefulness of\nsemantic and spatial uncertainty calibration in a subsequent process. [...]\n","authors":["Fabian Küppers"],"pdf_url":"https://arxiv.org/pdf/2302.02622v1.pdf","comment":"PhD thesis at University of Wuppertal, cite by: 'Fabian K\\\"uppers.\n  \"Uncertainty Calibration and its Application to Object Detection.\" PhD\n  Thesis, University of Wuppertal, January 2023'"},{"id":"http://arxiv.org/abs/2302.02619v1","updated":"2023-02-06T08:39:27Z","published":"2023-02-06T08:39:27Z","title":"COVID-19 Infection Analysis Framework using Novel Boosted CNNs and\n  Radiological Images","summary":"  COVID-19 is a new pathogen that first appeared in the human population at the\nend of 2019, and it can lead to novel variants of pneumonia after infection.\nCOVID-19 is a rapidly spreading infectious disease that infects humans faster.\nTherefore, efficient diagnostic systems may accurately identify infected\npatients and thus help control their spread. In this regard, a new two-stage\nanalysis framework is developed to analyze minute irregularities of COVID-19\ninfection. A novel detection Convolutional Neural Network (CNN), STM-BRNet, is\ndeveloped that incorporates the Split-Transform-Merge (STM) block and channel\nboosting (CB) to identify COVID-19 infected CT slices in the first stage. Each\nSTM block extracts boundary and region-smoothing-specific features for COVID-19\ninfection detection. Moreover, the various boosted channels are obtained by\nintroducing the new CB and Transfer Learning (TL) concept in STM blocks to\ncapture small illumination and texture variations of COVID-19-specific images.\nThe COVID-19 CTs are provided with new SA-CB-BRSeg segmentation CNN for\ndelineating infection in images in the second stage. SA-CB-BRSeg methodically\nutilized smoothening and heterogeneous operations in the encoder and decoder to\ncapture simultaneously COVID-19 specific patterns that are region homogeneity,\ntexture variation, and boundaries. Additionally, the new CB concept is\nintroduced in the decoder of SA-CB-BRSeg by combining additional channels using\nTL to learn the low contrast region. The proposed STM-BRNet and SA-CB-BRSeg\nyield considerable achievement in accuracy: 98.01 %, Recall: 98.12%, F-score:\n98.11%, and Dice Similarity: 96.396%, IOU: 98.845 % for the COVID-19 infectious\nregion, respectively. The proposed two-stage framework significantly increased\nperformance compared to single-phase and other reported systems and reduced the\nburden on the radiologists.\n","authors":["Saddam Hussain Khan"],"pdf_url":"https://arxiv.org/pdf/2302.02619v1.pdf","comment":"26 Pages, 11 Figures, 6 Tables. arXiv admin note: text overlap with\n  arXiv:2209.10963"},{"id":"http://arxiv.org/abs/2210.14358v2","updated":"2023-02-06T08:25:47Z","published":"2022-10-25T21:54:26Z","title":"Multi-Domain Long-Tailed Learning by Augmenting Disentangled\n  Representations","summary":"  There is an inescapable long-tailed class-imbalance issue in many real-world\nclassification problems. Existing long-tailed classification methods focus on\nthe single-domain setting, where all examples are drawn from the same\ndistribution. However, real-world scenarios often involve multiple domains with\ndistinct imbalanced class distributions. We study this multi-domain long-tailed\nlearning problem and aim to produce a model that generalizes well across all\nclasses and domains. Towards that goal, we introduce TALLY, which produces\ninvariant predictors by balanced augmenting hidden representations over domains\nand classes. Built upon a proposed selective balanced sampling strategy, TALLY\nachieves this by mixing the semantic representation of one example with the\ndomain-associated nuisances of another, producing a new representation for use\nas data augmentation. To improve the disentanglement of semantic\nrepresentations, TALLY further utilizes a domain-invariant class prototype that\naverages out domain-specific effects. We evaluate TALLY on four long-tailed\nvariants of classical domain generalization benchmarks and two real-world\nimbalanced multi-domain datasets. The results indicate that TALLY consistently\noutperforms other state-of-the-art methods in both subpopulation shift and\ndomain shift.\n","authors":["Xinyu Yang","Huaxiu Yao","Allan Zhou","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2210.14358v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02615v1","updated":"2023-02-06T08:24:41Z","published":"2023-02-06T08:24:41Z","title":"Rethinking Out-of-distribution (OOD) Detection: Masked Image Modeling is\n  All You Need","summary":"  The core of out-of-distribution (OOD) detection is to learn the\nin-distribution (ID) representation, which is distinguishable from OOD samples.\nPrevious work applied recognition-based methods to learn the ID features, which\ntend to learn shortcuts instead of comprehensive representations. In this work,\nwe find surprisingly that simply using reconstruction-based methods could boost\nthe performance of OOD detection significantly. We deeply explore the main\ncontributors of OOD detection and find that reconstruction-based pretext tasks\nhave the potential to provide a generally applicable and efficacious prior,\nwhich benefits the model in learning intrinsic data distributions of the ID\ndataset. Specifically, we take Masked Image Modeling as a pretext task for our\nOOD detection framework (MOOD). Without bells and whistles, MOOD outperforms\nprevious SOTA of one-class OOD detection by 5.7%, multi-class OOD detection by\n3.0%, and near-distribution OOD detection by 2.1%. It even defeats the\n10-shot-per-class outlier exposure OOD detection, although we do not include\nany OOD samples for our detection\n","authors":["Jingyao Li","Pengguang Chen","Shaozuo Yu","Zexin He","Shu Liu","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2302.02615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.14172v2","updated":"2023-02-06T08:06:54Z","published":"2022-07-28T15:34:29Z","title":"Semantic-Aligned Matching for Enhanced DETR Convergence and Multi-Scale\n  Feature Fusion","summary":"  The recently proposed DEtection TRansformer (DETR) has established a fully\nend-to-end paradigm for object detection. However, DETR suffers from slow\ntraining convergence, which hinders its applicability to various detection\ntasks. We observe that DETR's slow convergence is largely attributed to the\ndifficulty in matching object queries to relevant regions due to the unaligned\nsemantics between object queries and encoded image features. With this\nobservation, we design Semantic-Aligned-Matching DETR++ (SAM-DETR++) to\naccelerate DETR's convergence and improve detection performance. The core of\nSAM-DETR++ is a plug-and-play module that projects object queries and encoded\nimage features into the same feature embedding space, where each object query\ncan be easily matched to relevant regions with similar semantics. Besides,\nSAM-DETR++ searches for multiple representative keypoints and exploits their\nfeatures for semantic-aligned matching with enhanced representation capacity.\nFurthermore, SAM-DETR++ can effectively fuse multi-scale features in a\ncoarse-to-fine manner on the basis of the designed semantic-aligned matching.\nExtensive experiments show that the proposed SAM-DETR++ achieves superior\nconvergence speed and competitive detection accuracy. Additionally, as a\nplug-and-play method, SAM-DETR++ can complement existing DETR convergence\nsolutions with even better performance, achieving 44.8% AP with merely 12\ntraining epochs and 49.1% AP with 50 training epochs on COCO val2017 with\nResNet-50. Codes are available at https://github.com/ZhangGongjie/SAM-DETR .\n","authors":["Gongjie Zhang","Zhipeng Luo","Jiaxing Huang","Shijian Lu","Eric P. Xing"],"pdf_url":"https://arxiv.org/pdf/2207.14172v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12935v3","updated":"2023-02-06T07:52:20Z","published":"2023-01-30T14:32:47Z","title":"ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion\n  Probabilistic Models","summary":"  Though denoising diffusion probabilistic models (DDPMs) have achieved\nremarkable generation results, the low sampling efficiency of DDPMs still\nlimits further applications. Since DDPMs can be formulated as diffusion\nordinary differential equations (ODEs), various fast sampling methods can be\nderived from solving diffusion ODEs. However, we notice that previous sampling\nmethods with fixed analytical form are not robust with the error in the noise\nestimated from pretrained diffusion models. In this work, we construct an\nerror-robust Adams solver (ERA-Solver), which utilizes the implicit Adams\nnumerical method that consists of a predictor and a corrector. Different from\nthe traditional predictor based on explicit Adams methods, we leverage a\nLagrange interpolation function as the predictor, which is further enhanced\nwith an error-robust strategy to adaptively select the Lagrange bases with\nlower error in the estimated noise. Experiments on Cifar10, LSUN-Church, and\nLSUN-Bedroom datasets demonstrate that our proposed ERA-Solver achieves 5.14,\n9.42, and 9.69 Fenchel Inception Distance (FID) for image generation, with only\n10 network evaluations.\n","authors":["Shengmeng Li","Luping Liu","Zenghao Chai","Runnan Li","Xu Tan"],"pdf_url":"https://arxiv.org/pdf/2301.12935v3.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.02598v1","updated":"2023-02-06T07:21:03Z","published":"2023-02-06T07:21:03Z","title":"Cluster-aware Contrastive Learning for Unsupervised Out-of-distribution\n  Detection","summary":"  Unsupervised out-of-distribution (OOD) Detection aims to separate the samples\nfalling outside the distribution of training data without label information.\nAmong numerous branches, contrastive learning has shown its excellent\ncapability of learning discriminative representation in OOD detection. However,\nfor its limited vision, merely focusing on instance-level relationship between\naugmented samples, it lacks attention to the relationship between samples with\nsame semantics. Based on the classic contrastive learning, we propose\nCluster-aware Contrastive Learning (CCL) framework for unsupervised OOD\ndetection, which considers both instance-level and semantic-level information.\nSpecifically, we study a cooperation strategy of clustering and contrastive\nlearning to effectively extract the latent semantics and design a cluster-aware\ncontrastive loss function to enhance OOD discriminative ability. The loss\nfunction can simultaneously pay attention to the global and local relationships\nby treating both the cluster centers and the samples belonging to the same\ncluster as positive samples. We conducted sufficient experiments to verify the\neffectiveness of our framework and the model achieves significant improvement\non various image benchmarks.\n","authors":["Menglong Chen","Xingtai Gui","Shicai Fan"],"pdf_url":"https://arxiv.org/pdf/2302.02598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.09959v4","updated":"2023-02-06T04:38:57Z","published":"2022-06-20T18:42:44Z","title":"Global Context Vision Transformers","summary":"  We propose global context vision transformer (GC ViT), a novel architecture\nthat enhances parameter and compute utilization for computer vision tasks. The\ncore of the novel model are global context self-attention modules, joint with\nstandard local self-attention, to effectively yet efficiently model both long\nand short-range spatial interactions, as an alternative to complex operations\nsuch as an attention masks or local windows shifting. While the local\nself-attention modules are responsible for modeling short-range information,\nthe global query tokens are shared across all global self-attention modules to\ninteract with local key and values. In addition, we address the lack of\ninductive bias in ViTs and improve the modeling of inter-channel dependencies\nby proposing a novel downsampler which leverages a parameter-efficient fused\ninverted residual block. The proposed GC ViT achieves new state-of-the-art\nperformance across image classification, object detection and semantic\nsegmentation tasks. On ImageNet-1K dataset for classification, GC ViT models\nwith 51M, 90M and 201M parameters achieve 84.3%, 84.9% and 85.6% Top-1\naccuracy, respectively, surpassing comparably-sized prior art such as CNN-based\nConvNeXt and ViT-based Swin Transformer. Pre-trained GC ViT backbones in\ndownstream tasks of object detection, instance segmentation, and semantic\nsegmentation on MS COCO and ADE20K datasets outperform prior work consistently,\nsometimes by large margins.\n","authors":["Ali Hatamizadeh","Hongxu Yin","Jan Kautz","Pavlo Molchanov"],"pdf_url":"https://arxiv.org/pdf/2206.09959v4.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2211.01567v2","updated":"2023-02-06T04:32:17Z","published":"2022-11-03T03:12:52Z","title":"Galaxy Image Deconvolution for Weak Gravitational Lensing with Unrolled\n  Plug-and-Play ADMM","summary":"  Removing optical and atmospheric blur from galaxy images significantly\nimproves galaxy shape measurements for weak gravitational lensing and galaxy\nevolution studies. This ill-posed linear inverse problem is usually solved with\ndeconvolution algorithms enhanced by regularisation priors or deep learning. We\nintroduce a so-called \"physics-based deep learning\" approach to the Point\nSpread Function (PSF) deconvolution problem in galaxy surveys. We apply\nalgorithm unrolling and the Plug-and-Play technique to the Alternating\nDirection Method of Multipliers (ADMM), in which a neural network learns\nappropriate hyperparameters and denoising priors from simulated galaxy images.\nWe characterise the time-performance trade-off of several methods for galaxies\nof differing brightness levels as well as our method's robustness to systematic\nPSF errors and ablations. We show an improvement in reduced shear ellipticity\nerror of 38.6% (SNR=20)/45.0% (SNR=200) compared to classic methods and 7.4%\n(SNR=20)/33.2% (SNR=200) compared to modern methods.\n","authors":["Tianao Li","Emma Alexander"],"pdf_url":"https://arxiv.org/pdf/2211.01567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02553v1","updated":"2023-02-06T04:11:52Z","published":"2023-02-06T04:11:52Z","title":"A Correction-Based Dynamic Enhancement Framework towards Underwater\n  Detection","summary":"  To assist underwater object detection for better performance, image\nenhancement technology is often used as a pre-processing step. However, most of\nthe existing enhancement methods tend to pursue the visual quality of an image,\ninstead of providing effective help for detection tasks. In fact, image\nenhancement algorithms should be optimized with the goal of utility\nimprovement. In this paper, to adapt to the underwater detection tasks, we\nproposed a lightweight dynamic enhancement algorithm using a contribution\ndictionary to guide low-level corrections. Dynamic solutions are designed to\ncapture differences in detection preferences. In addition, it can also balance\nthe inconsistency between the contribution of correction operations and their\ntime complexity. Experimental results in real underwater object detection tasks\nshow the superiority of our proposed method in both generalization and\nreal-time performance.\n","authors":["Yanling Qiu","Qianxue Feng","Boqin Cai","Hongan Wei","Weiling Chen"],"pdf_url":"https://arxiv.org/pdf/2302.02553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07253v3","updated":"2023-02-06T04:06:44Z","published":"2022-07-15T01:59:14Z","title":"Single Shot Self-Reliant Scene Text Spotter by Decoupled yet\n  Collaborative Detection and Recognition","summary":"  Typical text spotters follow the two-stage spotting paradigm which detects\nthe boundary for a text instance first and then performs text recognition\nwithin the detected regions. Despite the remarkable progress of such spotting\nparadigm, an important limitation is that the performance of text recognition\ndepends heavily on the precision of text detection, resulting in the potential\nerror propagation from detection to recognition. In this work, we propose the\nsingle shot Self-Reliant Scene Text Spotter v2 (SRSTS v2), which circumvents\nthis limitation by decoupling recognition from detection while optimizing two\ntasks collaboratively. Specifically, our SRSTS v2 samples representative\nfeature points around each potential text instance, and conducts both text\ndetection and recognition in parallel guided by these sampled points. Thus, the\ntext recognition is no longer dependent on detection, thereby alleviating the\nerror propagation from detection to recognition. Moreover, the sampling module\nis learned under the supervision from both detection and recognition, which\nallows for the collaborative optimization and mutual enhancement between two\ntasks. Benefiting from such sampling-driven concurrent spotting framework, our\napproach is able to recognize the text instances correctly even if the precise\ntext boundaries are challenging to detect. Extensive experiments on four\nbenchmarks demonstrate that our method compares favorably to state-of-the-art\nspotters.\n","authors":["Jingjing Wu","Pengyuan Lyu","Guangming Lu","Chengquan Zhang","Kun Yao","Wenjie Pei"],"pdf_url":"https://arxiv.org/pdf/2207.07253v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02551v1","updated":"2023-02-06T03:59:15Z","published":"2023-02-06T03:59:15Z","title":"CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets","summary":"  Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot\nclassification through their ability generate embeddings for each class based\non their (natural language) names. Prior work has focused on improving the\naccuracy of these models through prompt engineering or by incorporating a small\namount of labeled downstream data (via finetuning). However, there has been\nlittle focus on improving the richness of the class names themselves, which can\npose issues when class labels are coarsely-defined and uninformative. We\npropose Classification with Hierarchical Label Sets (or CHiLS), an alternative\nstrategy for zero-shot classification specifically designed for datasets with\nimplicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each\nclass, produce a set of subclasses, using either existing label hierarchies or\nby querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though\nthese subclasses were the labels of interest; (iii) map the predicted subclass\nback to its parent to produce the final prediction. Across numerous datasets\nwith underlying hierarchical structure, CHiLS leads to improved accuracy in\nsituations both with and without ground-truth hierarchical information. CHiLS\nis simple to implement within existing CLIP pipelines and requires no\nadditional training cost. Code is available at:\nhttps://github.com/acmi-lab/CHILS.\n","authors":["Zachary Novack","Saurabh Garg","Julian McAuley","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2302.02551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02550v1","updated":"2023-02-06T03:55:35Z","published":"2023-02-06T03:55:35Z","title":"Domain Re-Modulation for Few-Shot Generative Domain Adaptation","summary":"  In this study, we investigate the task of few-shot Generative Domain\nAdaptation (GDA), which involves transferring a pre-trained generator from one\ndomain to a new domain using one or a few reference images. Building upon\nprevious research that has focused on Target-domain Consistency, Large\nDiversity, and Cross-domain Consistency, we conclude two additional desired\nproperties for GDA: Memory and Domain Association. To meet these properties, we\nproposed a novel method Domain Re-Modulation (DoRM). Specifically, DoRM freezes\nthe source generator and employs additional mapping and affine modules (M&A\nmodule) to capture the attributes of the target domain, resulting in a linearly\ncombinable domain shift in style space. This allows for high-fidelity\nmulti-domain and hybrid-domain generation by integrating multiple M&A modules\nin a single generator. DoRM is lightweight and easy to implement. Extensive\nexperiments demonstrated the superior performance of DoRM on both one-shot and\n10-shot GDA, both quantitatively and qualitatively. Additionally, for the first\ntime, multi-domain and hybrid-domain generation can be achieved with a minimal\nstorage cost by using a single model. The code will be available at\nhttps://github.com/wuyi2020/DoRM.\n","authors":["Yi Wu","Ziqiang Li","Chaoyue Wang","Heliang Zheng","Shanshan Zhao","Bin Li","Dacheng Ta"],"pdf_url":"https://arxiv.org/pdf/2302.02550v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2209.06994v2","updated":"2023-02-06T03:47:36Z","published":"2022-09-15T01:48:08Z","title":"PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on\n  Transformer","summary":"  Lane detection is one of the fundamental modules in self-driving. In this\npaper we employ a transformer-only method for lane detection, thus it could\nbenefit from the blooming development of fully vision transformer and achieve\nthe state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks,\nby fine-tuning the weight fully pre-trained on large datasets. More\nimportantly, this paper proposes a novel and general framework called\nPriorLane, which is used to enhance the segmentation performance of the fully\nvision transformer by introducing the low-cost local prior knowledge.\nSpecifically, PriorLane utilizes an encoder-only transformer to fuse the\nfeature extracted by a pre-trained segmentation model with prior knowledge\nembeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted\nto enhance the fusion performance by aligning the knowledge embedding.\nExtensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA\nlane detection methods by a 2.82% mIoU when prior knowledge is employed.\n","authors":["Qibo Qiu","Haiming Gao","Wei Hua","Gang Huang","Xiaofei He"],"pdf_url":"https://arxiv.org/pdf/2209.06994v2.pdf","comment":"Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2302.02535v1","updated":"2023-02-06T02:13:51Z","published":"2023-02-06T02:13:51Z","title":"PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement\n  and Pose Restoration","summary":"  Recent interest in point cloud analysis has led rapid progress in designing\ndeep learning methods for 3D models. However, state-of-the-art models are not\nrobust to rotations, which remains an unknown prior to real applications and\nharms the model performance. In this work, we introduce a novel Patch-wise\nRotation-invariant network (PaRot), which achieves rotation invariance via\nfeature disentanglement and produces consistent predictions for samples with\narbitrary rotations. Specifically, we design a siamese training module which\ndisentangles rotation invariance and equivariance from patches defined over\ndifferent scales, e.g., the local geometry and global shape, via a pair of\nrotations. However, our disentangled invariant feature loses the intrinsic pose\ninformation of each patch. To solve this problem, we propose a\nrotation-invariant geometric relation to restore the relative pose with\nequivariant information for patches defined over different scales. Utilising\nthe pose information, we propose a hierarchical module which implements\nintra-scale and inter-scale feature aggregation for 3D shape learning.\nMoreover, we introduce a pose-aware feature propagation process with the\nrotation-invariant relative pose information embedded. Experiments show that\nour disentanglement module extracts high-quality rotation-robust features and\nthe proposed lightweight model achieves competitive results in rotated 3D\nobject classification and part segmentation tasks. Our project page is released\nat: https://patchrot.github.io/.\n","authors":["Dingxin Zhang","Jianhui Yu","Chaoyi Zhang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2302.02535v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.02524v1","updated":"2023-02-06T01:44:45Z","published":"2023-02-06T01:44:45Z","title":"Novel Fundus Image Preprocessing for Retcam Images to Improve Deep\n  Learning Classification of Retinopathy of Prematurity","summary":"  Retinopathy of Prematurity (ROP) is a potentially blinding eye disorder\nbecause of damage to the eye's retina which can affect babies born prematurely.\nScreening of ROP is essential for early detection and treatment. This is a\nlaborious and manual process which requires trained physician performing\ndilated ophthalmological examination which can be subjective resulting in lower\ndiagnosis success for clinically significant disease. Automated diagnostic\nmethods can assist ophthalmologists increase diagnosis accuracy using deep\nlearning. Several research groups have highlighted various approaches. This\npaper proposes the use of new novel fundus preprocessing methods using\npretrained transfer learning frameworks to create hybrid models to give higher\ndiagnosis accuracy. The evaluations show that these novel methods in comparison\nto traditional imaging processing contribute to higher accuracy in classifying\nPlus disease, Stages of ROP and Zones. We achieve accuracy of 97.65% for Plus\ndisease, 89.44% for Stage, 90.24% for Zones\n","authors":["Sajid Rahim","Kourosh Sabri","Anna Ells","Alan Wassyng","Mark Lawford","Linyang Chu","Wenbo He"],"pdf_url":"https://arxiv.org/pdf/2302.02524v1.pdf","comment":"10 pages, 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2302.02521v1","updated":"2023-02-06T01:28:52Z","published":"2023-02-06T01:28:52Z","title":"Exploiting Partial Common Information Microstructure for Multi-Modal\n  Brain Tumor Segmentation","summary":"  Learning with multiple modalities is crucial for automated brain tumor\nsegmentation from magnetic resonance imaging data. Explicitly optimizing the\ncommon information shared among all modalities (e.g., by maximizing the total\ncorrelation) has been shown to achieve better feature representations and thus\nenhance the segmentation performance. However, existing approaches are\noblivious to partial common information shared by subsets of the modalities. In\nthis paper, we show that identifying such partial common information can\nsignificantly boost the discriminative power of image segmentation models. In\nparticular, we introduce a novel concept of partial common information mask\n(PCI-mask) to provide a fine-grained characterization of what partial common\ninformation is shared by which subsets of the modalities. By solving a masked\ncorrelation maximization and simultaneously learning an optimal PCI-mask, we\nidentify the latent microstructure of partial common information and leverage\nit in a self-attention module to selectively weight different feature\nrepresentations in multi-modal data. We implement our proposed framework on the\nstandard U-Net. Our experimental results on the Multi-modal Brain Tumor\nSegmentation Challenge (BraTS) datasets consistently outperform those of\nstate-of-the-art segmentation baselines, with validation Dice similarity\ncoefficients of 0.920, 0.897, 0.837 for the whole tumor, tumor core, and\nenhancing tumor on BraTS-2020.\n","authors":["Yongsheng Mei","Tian Lan","Guru Venkataramani"],"pdf_url":"https://arxiv.org/pdf/2302.02521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14286v2","updated":"2023-02-06T01:15:04Z","published":"2022-11-25T18:41:44Z","title":"CHIMLE: Conditional Hierarchical IMLE for Multimodal Conditional Image\n  Synthesis","summary":"  A persistent challenge in conditional image synthesis has been to generate\ndiverse output images from the same input image despite only one output image\nbeing observed per input image. GAN-based methods are prone to mode collapse,\nwhich leads to low diversity. To get around this, we leverage Implicit Maximum\nLikelihood Estimation (IMLE) which can overcome mode collapse fundamentally.\nIMLE uses the same generator as GANs but trains it with a different,\nnon-adversarial objective which ensures each observed image has a generated\nsample nearby. Unfortunately, to generate high-fidelity images, prior\nIMLE-based methods require a large number of samples, which is expensive. In\nthis paper, we propose a new method to get around this limitation, which we dub\nConditional Hierarchical IMLE (CHIMLE), which can generate high-fidelity images\nwithout requiring many samples. We show CHIMLE significantly outperforms the\nprior best IMLE, GAN and diffusion-based methods in terms of image fidelity and\nmode coverage across four tasks, namely night-to-day, 16x single image\nsuper-resolution, image colourization and image decompression. Quantitatively,\nour method improves Fr\\'echet Inception Distance (FID) by 36.9% on average\ncompared to the prior best IMLE-based method, and by 27.5% on average compared\nto the best non-IMLE-based general-purpose methods.\n","authors":["Shichong Peng","Alireza Moazeni","Ke Li"],"pdf_url":"https://arxiv.org/pdf/2211.14286v2.pdf","comment":"More results and code are available on the project website at\n  https://niopeng.github.io/CHIMLE/"},{"id":"http://arxiv.org/abs/2302.02519v1","updated":"2023-02-06T01:13:13Z","published":"2023-02-06T01:13:13Z","title":"RDFNet: Regional Dynamic FISTA-Net for Spectral Snapshot Compressive\n  Imaging","summary":"  Deep convolutional neural networks have recently shown promising results in\ncompressive spectral reconstruction. Previous methods, however, usually adopt a\nsingle mapping function for sparse representation. Considering that different\nregions have distinct characteristics, it is desirable to apply various mapping\nfunctions to adjust different regions' transformations dynamically. With this\nin mind, we first introduce a regional dynamic way of using Fast Iterative\nShrinkage-Thresholding Algorithm (FISTA) to exploit regional characteristics\nand derive dynamic sparse representations. Then, we propose to unfold the\nprocess into a hierarchical dynamic deep network, dubbed RDFNet. The network\ncomprises multiple regional dynamic blocks and corresponding pixel-wise\nadaptive soft-thresholding modules, respectively in charge of region-based\ndynamic mapping and pixel-wise soft-thresholding selection. The regional\ndynamic block guides the network to adjust the transformation domain for\ndifferent regions. Equipped with the adaptive soft-thresholding, our proposed\nregional dynamic architecture can also learn appropriate shrinkage scale in a\npixel-wise manner.\n  Extensive experiments on both simulated and real data demonstrate that our\nmethod outperforms prior state-of-the-arts.\n","authors":["Shiyun Zhou","Tingfa Xu","Shaocong Dong","Jianan Li"],"pdf_url":"https://arxiv.org/pdf/2302.02519v1.pdf","comment":"IEEE Transactions on Computational Imaging"},{"id":"http://arxiv.org/abs/2302.02515v1","updated":"2023-02-06T01:01:00Z","published":"2023-02-06T01:01:00Z","title":"Deep Learning for Time Series Classification and Extrinsic Regression: A\n  Current Survey","summary":"  Time Series Classification and Extrinsic Regression are important and\nchallenging machine learning tasks. Deep learning has revolutionized natural\nlanguage processing and computer vision and holds great promise in other fields\nsuch as time series analysis where the relevant features must often be\nabstracted from the raw data but are not known a priori. This paper surveys the\ncurrent state of the art in the fast-moving field of deep learning for time\nseries classification and extrinsic regression. We review different network\narchitectures and training methods used for these tasks and discuss the\nchallenges and opportunities when applying deep learning to time series data.\nWe also summarize two critical applications of time series classification and\nextrinsic regression, human activity recognition and satellite earth\nobservation.\n","authors":["Navid Mohammadi Foumani","Lynn Miller","Chang Wei Tan","Geoffrey I. Webb","Germain Forestier","Mahsa Salehi"],"pdf_url":"https://arxiv.org/pdf/2302.02515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12047v2","updated":"2023-02-06T00:55:06Z","published":"2022-11-22T06:42:41Z","title":"Convolutional Neural Generative Coding: Scaling Predictive Coding to\n  Natural Images","summary":"  In this work, we develop convolutional neural generative coding (Conv-NGC), a\ngeneralization of predictive coding to the case of\nconvolution/deconvolution-based computation. Specifically, we concretely\nimplement a flexible neurobiologically-motivated algorithm that progressively\nrefines latent state feature maps in order to dynamically form a more accurate\ninternal representation/reconstruction model of natural images. The performance\nof the resulting sensory processing system is evaluated on complex datasets\nsuch as Color-MNIST, CIFAR-10, and Street House View Numbers (SVHN). We study\nthe effectiveness of our brain-inspired model on the tasks of reconstruction\nand image denoising and find that it is competitive with convolutional\nauto-encoding systems trained by backpropagation of errors and outperforms them\nwith respect to out-of-distribution reconstruction (including the full 90k\nCINIC-10 test set).\n","authors":["Alexander Ororbia","Ankur Mali"],"pdf_url":"https://arxiv.org/pdf/2211.12047v2.pdf","comment":"Revisions/updates, expanded appendix"},{"id":"http://arxiv.org/abs/2110.03260v2","updated":"2023-02-06T00:10:14Z","published":"2021-10-07T08:31:23Z","title":"An Uncertainty-aware Loss Function for Training Neural Networks with\n  Calibrated Predictions","summary":"  Uncertainty quantification of machine learning and deep learning methods\nplays an important role in enhancing trust to the obtained result. In recent\nyears, a numerous number of uncertainty quantification methods have been\nintroduced. Monte Carlo dropout (MC-Dropout) is one of the most well-known\ntechniques to quantify uncertainty in deep learning methods. In this study, we\npropose two new loss functions by combining cross entropy with Expected\nCalibration Error (ECE) and Predictive Entropy (PE). The obtained results\nclearly show that the new proposed loss functions lead to having a calibrated\nMC-Dropout method. Our results confirmed the great impact of the new hybrid\nloss functions for minimising the overlap between the distributions of\nuncertainty estimates for correct and incorrect predictions without sacrificing\nthe model's overall performance.\n","authors":["Afshar Shamsi","Hamzeh Asgharnezhad","AmirReza Tajally","Saeid Nahavandi","Henry Leung"],"pdf_url":"https://arxiv.org/pdf/2110.03260v2.pdf","comment":"11 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2206.14502v2","updated":"2023-02-06T23:56:02Z","published":"2022-06-29T09:44:33Z","title":"RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and\n  Out Distribution Robustness","summary":"  We show that the effectiveness of the well celebrated Mixup [Zhang et al.,\n2018] can be further improved if instead of using it as the sole learning\nobjective, it is utilized as an additional regularizer to the standard\ncross-entropy loss. This simple change not only provides much improved accuracy\nbut also significantly improves the quality of the predictive uncertainty\nestimation of Mixup in most cases under various forms of covariate shifts and\nout-of-distribution detection experiments. In fact, we observe that Mixup\nyields much degraded performance on detecting out-of-distribution samples\npossibly, as we show empirically, because of its tendency to learn models that\nexhibit high-entropy throughout; making it difficult to differentiate\nin-distribution samples from out-distribution ones. To show the efficacy of our\napproach (RegMixup), we provide thorough analyses and experiments on vision\ndatasets (ImageNet & CIFAR-10/100) and compare it with a suite of recent\napproaches for reliable uncertainty estimation.\n","authors":["Francesco Pinto","Harry Yang","Ser-Nam Lim","Philip H. S. Torr","Puneet K. Dokania"],"pdf_url":"https://arxiv.org/pdf/2206.14502v2.pdf","comment":"22 pages, 18 figures"},{"id":"http://arxiv.org/abs/2302.03156v1","updated":"2023-02-06T23:30:51Z","published":"2023-02-06T23:30:51Z","title":"Novel Building Detection and Location Intelligence Collection in Aerial\n  Satellite Imagery","summary":"  Building structures detection and information about these buildings in aerial\nimages is an important solution for city planning and management, land use\nanalysis. It can be the center piece to answer important questions such as\nplanning evacuation routes in case of an earthquake, flood management, etc.\nThese applications rely on being able to accurately retrieve up-to-date\ninformation. Being able to accurately detect buildings in a bounding box\ncentered on a specific latitude-longitude value can help greatly. The key\nchallenge is to be able to detect buildings which can be commercial,\nindustrial, hut settlements, or skyscrapers. Once we are able to detect such\nbuildings, our goal will be to cluster and categorize similar types of\nbuildings together.\n","authors":["Sandeep Singh","Christian Wiles","Ahmed Bilal"],"pdf_url":"https://arxiv.org/pdf/2302.03156v1.pdf","comment":"9 pages(5 main pages, 4 auxiliary pages)"},{"id":"http://arxiv.org/abs/2302.03130v1","updated":"2023-02-06T21:35:44Z","published":"2023-02-06T21:35:44Z","title":"Spatial Functa: Scaling Functa to ImageNet Classification and Generation","summary":"  Neural fields, also known as implicit neural representations, have emerged as\na powerful means to represent complex signals of various modalities. Based on\nthis Dupont et al. (2022) introduce a framework that views neural fields as\ndata, termed *functa*, and proposes to do deep learning directly on this\ndataset of neural fields. In this work, we show that the proposed framework\nfaces limitations when scaling up to even moderately complex datasets such as\nCIFAR-10. We then propose *spatial functa*, which overcome these limitations by\nusing spatially arranged latent representations of neural fields, thereby\nallowing us to scale up the approach to ImageNet-1k at 256x256 resolution. We\ndemonstrate competitive performance to Vision Transformers (Steiner et al.,\n2022) on classification and Latent Diffusion (Rombach et al., 2022) on image\ngeneration respectively.\n","authors":["Matthias Bauer","Emilien Dupont","Andy Brock","Dan Rosenbaum","Jonathan Schwarz","Hyunjik Kim"],"pdf_url":"https://arxiv.org/pdf/2302.03130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03128v1","updated":"2023-02-06T21:30:08Z","published":"2023-02-06T21:30:08Z","title":"Cooperverse: A Mobile-Edge-Cloud Framework for Universal Cooperative\n  Perception with Mixed Connectivity and Automation","summary":"  Cooperative perception (CP) is attracting increasing attention and is\nregarded as the core foundation to support cooperative driving automation, a\npotential key solution to addressing the safety, mobility, and sustainability\nissues of contemporary transportation systems. However, current research on CP\nis still at the beginning stages where a systematic problem formulation of CP\nis still missing, acting as the essential guideline of the system design of a\nCP system under real-world situations. In this paper, we formulate a universal\nCP system into an optimization problem and a mobile-edge-cloud framework called\nCooperverse. This system addresses CP in a mixed connectivity and automation\nenvironment. A Dynamic Feature Sharing (DFS) methodology is introduced to\nsupport this CP system under certain constraints and a Random Priority\nFiltering (RPF) method is proposed to conduct DFS with high performance.\nExperiments have been conducted based on a high-fidelity CP platform, and the\nresults show that the Cooperverse framework is effective for dynamic node\nengagement and the proposed DFS methodology can improve system CP performance\nby 14.5% and the RPF method can reduce the communication cost for mobile nodes\nby 90% with only 1.7% drop for average precision.\n","authors":["Zhengwei Bai","Guoyuan Wu","Matthew J. Barth","Yongkang Liu","Emrah Akin Sisbot","Kentaro Oguchi"],"pdf_url":"https://arxiv.org/pdf/2302.03128v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2205.07030v2","updated":"2023-02-06T21:06:15Z","published":"2022-05-14T10:17:34Z","title":"Realistic Defocus Blur for Multiplane Computer-Generated Holography","summary":"  This paper introduces a new multiplane CGH computation method to reconstruct\nartefact-free high-quality holograms with natural-looking defocus blur. Our\nmethod introduces a new targeting scheme and a new loss function. While the\ntargeting scheme accounts for defocused parts of the scene at each depth plane,\nthe new loss function analyzes focused and defocused parts separately in\nreconstructed images. Our method support phase-only CGH calculations using\nvarious iterative (e.g., Gerchberg-Saxton, Gradient Descent) and non-iterative\n(e.g., Double Phase) CGH techniques. We achieve our best image quality using a\nmodified gradient descent-based optimization recipe where we introduce a\nconstraint inspired by the double phase method. We validate our method\nexperimentally using our proof-of-concept holographic display, comparing\nvarious algorithms, including multi-depth scenes with sparse and dense\ncontents.\n","authors":["Koray Kavaklı","Yuta Itoh","Hakan Urey","Kaan Akşit"],"pdf_url":"https://arxiv.org/pdf/2205.07030v2.pdf","comment":"16 pages in total, first 9 pages are for the manuscript, remaining\n  pages are for supplementary. For more visit:\n  https://complightlab.com/publications/realistic_defocus_cgh For our codebase\n  visit https://github.com/complight/realistic_defocus"},{"id":"http://arxiv.org/abs/2302.03120v1","updated":"2023-02-06T20:59:02Z","published":"2023-02-06T20:59:02Z","title":"Studying Therapy Effects and Disease Outcomes in Silico using Artificial\n  Counterfactual Tissue Samples","summary":"  Understanding the interactions of different cell types inside the immune\ntumor microenvironment (iTME) is crucial for the development of immunotherapy\ntreatments as well as for predicting their outcomes. Highly multiplexed tissue\nimaging (HMTI) technologies offer a tool which can capture cell properties of\ntissue samples by measuring expression of various proteins and storing them in\nseparate image channels. HMTI technologies can be used to gain insights into\nthe iTME and in particular how the iTME differs for different patient outcome\ngroups of interest (e.g., treatment responders vs. non-responders).\nUnderstanding the systematic differences in the iTME of different patient\noutcome groups is crucial for developing better treatments and personalising\nexisting treatments. However, such analyses are inherently limited by the fact\nthat any two tissue samples vary due to a large number of factors unrelated to\nthe outcome. Here, we present CF-HistoGAN, a machine learning framework that\nemploys generative adversarial networks (GANs) to create artificial\ncounterfactual tissue samples that resemble the original tissue samples as\nclosely as possible but capture the characteristics of a different patient\noutcome group. Specifically, we learn to \"translate\" HMTI samples from one\npatient group to create artificial paired samples. We show that this approach\nallows to directly study the effects of different patient outcomes on the iTMEs\nof individual tissue samples. We demonstrate that CF-HistoGAN can be employed\nas an explorative tool for understanding iTME effects on the pixel level.\nMoreover, we show that our method can be used to identify statistically\nsignificant differences in the expression of different proteins between patient\ngroups with greater sensitivity compared to conventional approaches.\n","authors":["Martin Paulikat","Christian M. Schürch","Christian F. Baumgartner"],"pdf_url":"https://arxiv.org/pdf/2302.03120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.09929v2","updated":"2023-02-06T20:57:03Z","published":"2022-01-24T19:37:04Z","title":"Euclidean and Affine Curve Reconstruction","summary":"  We consider practical aspects of reconstructing planar curves with prescribed\nEuclidean or affine curvatures. These curvatures are invariant under the\nspecial Euclidean group and the equi-affine groups, respectively, and play an\nimportant role in computer vision and shape analysis. We discuss and implement\nalgorithms for such reconstruction, and give estimates on how close\nreconstructed curves are relative to the closeness of their curvatures in\nappropriate metrics. Several illustrative examples are provided.\n","authors":["Jose Agudelo","Brooke Dippold","Ian Klein","Alex Kokot","Eric Geiger","Irina Kogan"],"pdf_url":"https://arxiv.org/pdf/2201.09929v2.pdf","comment":"This paper is a result of an REU project conducted at the North\n  Carolina State University in the Summer and Fall 2020. This version, with\n  improved quality of presentation and figures, is accepted to \"Involve\"\n  https://msp.org/involve/about/journal/about.html"},{"id":"http://arxiv.org/abs/2302.03114v1","updated":"2023-02-06T20:33:16Z","published":"2023-02-06T20:33:16Z","title":"From CAD models to soft point cloud labels: An automatic annotation\n  pipeline for cheaply supervised 3D semantic segmentation","summary":"  We propose a fully automatic annotation scheme which takes a raw 3D point\ncloud with a set of fitted CAD models as input, and outputs convincing\npoint-wise labels which can be used as cheap training data for point cloud\nsegmentation. Compared to manual annotations, we show that our automatic labels\nare accurate while drastically reducing the annotation time, and eliminating\nthe need for manual intervention or dataset-specific parameters. Our labeling\npipeline outputs semantic classes and soft point-wise object scores which can\neither be binarized into standard one-hot-encoded labels, thresholded into weak\nlabels with ambiguous points left unlabeled, or used directly as soft labels\nduring training. We evaluate the label quality and segmentation performance of\nPointNet++ on a dataset of real industrial point clouds and Scan2CAD, a public\ndataset of indoor scenes. Our results indicate that reducing supervision in\nareas which are more difficult to label automatically is beneficial, compared\nto the conventional approach of naively assigning a hard \"best guess\" label to\nevery point.\n","authors":["Galadrielle Humblot-Renaux","Simon Buus Jensen","Andreas Møgelmose"],"pdf_url":"https://arxiv.org/pdf/2302.03114v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2302.03084v1","updated":"2023-02-06T19:40:04Z","published":"2023-02-06T19:40:04Z","title":"Pic2Word: Mapping Pictures to Words for Zero-shot Composed Image\n  Retrieval","summary":"  In Composed Image Retrieval (CIR), a user combines a query image with text to\ndescribe their intended target. Existing methods rely on supervised learning of\nCIR models using labeled triplets consisting of the query image, text\nspecification, and the target image. Labeling such triplets is expensive and\nhinders broad applicability of CIR. In this work, we propose to study an\nimportant task, Zero-Shot Composed Image Retrieval (ZS-CIR), whose goal is to\nbuild a CIR model without requiring labeled triplets for training. To this end,\nwe propose a novel method, called Pic2Word, that requires only weakly labeled\nimage-caption pairs and unlabeled image datasets to train. Unlike existing\nsupervised CIR models, our model trained on weakly labeled or unlabeled\ndatasets shows strong generalization across diverse ZS-CIR tasks, e.g.,\nattribute editing, object composition, and domain conversion. Our approach\noutperforms several supervised CIR methods on the common CIR benchmark, CIRR\nand Fashion-IQ. Code will be made publicly available at\nhttps://github.com/google-research/composed_image_retrieval.\n","authors":["Kuniaki Saito","Kihyuk Sohn","Xiang Zhang","Chun-Liang Li","Chen-Yu Lee","Kate Saenko","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2302.03084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.07085v4","updated":"2023-02-06T19:21:18Z","published":"2021-06-13T20:32:24Z","title":"Survey: Image Mixing and Deleting for Data Augmentation","summary":"  Neural networks are prone to overfitting and memorizing data patterns. To\navoid over-fitting and enhance their generalization and performance, various\nmethods have been suggested in the literature, including dropout,\nregularization, label smoothing, etc. One such method is augmentation which\nintroduces different types of corruption in the data to prevent the model from\noverfitting and to memorize patterns present in the data. A sub-area of data\naugmentation is image mixing and deleting. This specific type of augmentation\neither deletes image regions or mixes two images to hide or make particular\ncharacteristics of images confusing for the network, forcing it to emphasize\nthe overall structure of the object in an image. Models trained with this\napproach have proven to perform and generalize well compared to those trained\nwithout image mixing or deleting. An added benefit that comes with this method\nof training is robustness against image corruption. Due to its low\ncomputational cost and recent success, researchers have proposed many image\nmixing and deleting techniques. We furnish an in-depth survey of image mixing\nand deleting techniques and provide categorization via their most\ndistinguishing features. We initiate our discussion with some fundamental\nrelevant concepts. Next, we present essentials, such as each category's\nstrengths and limitations, describing their working mechanism, basic\nformulations, and applications. We also discuss the general challenges and\nrecommend possible future research directions for image mixing and deleting\ndata augmentation techniques. Datasets and codes for evaluation are publicly\navailable here.\n","authors":["Humza Naveed","Saeed Anwar","Munawar Hayat","Kashif Javed","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2106.07085v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03064v1","updated":"2023-02-06T19:02:44Z","published":"2023-02-06T19:02:44Z","title":"Investigating Pulse-Echo Sound Speed Estimation in Breast Ultrasound\n  with Deep Learning","summary":"  Ultrasound is an adjunct tool to mammography that can quickly and safely aid\nphysicians with diagnosing breast abnormalities. Clinical ultrasound often\nassumes a constant sound speed to form B-mode images for diagnosis. However,\nthe various types of breast tissue, such as glandular, fat, and lesions, differ\nin sound speed. These differences can degrade the image reconstruction process.\nAlternatively, sound speed can be a powerful tool for identifying disease. To\nthis end, we propose a deep-learning approach for sound speed estimation from\nin-phase and quadrature ultrasound signals. First, we develop a large-scale\nsimulated ultrasound dataset that generates quasi-realistic breast tissue by\nmodeling breast gland, skin, and lesions with varying echogenicity and sound\nspeed. We developed a fully convolutional neural network architecture trained\non a simulated dataset to produce an estimated sound speed map from inputting\nthree complex-value in-phase and quadrature ultrasound images formed from\nplane-wave transmissions at separate angles. Furthermore, thermal noise\naugmentation is used during model optimization to enhance generalizability to\nreal ultrasound data. We evaluate the model on simulated, phantom, and in-vivo\nbreast ultrasound data, demonstrating its ability to accurately estimate sound\nspeeds consistent with previously reported values in the literature. Our\nsimulated dataset and model will be publicly available to provide a step\ntowards accurate and generalizable sound speed estimation for pulse-echo\nultrasound imaging.\n","authors":["Walter A. Simson","Magdalini Paschali","Vasiliki Sideri-Lampretsa","Nassir Navab","Jeremy J. Dahl"],"pdf_url":"https://arxiv.org/pdf/2302.03064v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.02908v1","updated":"2023-02-06T16:24:41Z","published":"2023-02-06T16:24:41Z","title":"LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale\n  Image-Text Retrieval","summary":"  Image-text retrieval (ITR) is a task to retrieve the relevant images/texts,\ngiven the query from another modality. The conventional dense retrieval\nparadigm relies on encoding images and texts into dense representations using\ndual-stream encoders, however, it faces challenges with low retrieval speed in\nlarge-scale retrieval scenarios. In this work, we propose the lexicon-weighting\nparadigm, where sparse representations in vocabulary space are learned for\nimages and texts to take advantage of the bag-of-words models and efficient\ninverted indexes, resulting in significantly reduced retrieval latency. A\ncrucial gap arises from the continuous nature of image data, and the\nrequirement for a sparse vocabulary space representation. To bridge this gap,\nwe introduce a novel pre-training framework, Lexicon-Bottlenecked\nLanguage-Image Pre-Training (LexLIP), that learns importance-aware lexicon\nrepresentations. This framework features lexicon-bottlenecked modules between\nthe dual-stream encoders and weakened text decoders, allowing for constructing\ncontinuous bag-of-words bottlenecks to learn lexicon-importance distributions.\nUpon pre-training with same-scale data, our LexLIP achieves state-of-the-art\nperformance on two benchmark ITR datasets, MSCOCO and Flickr30k. Furthermore,\nin large-scale retrieval scenarios, LexLIP outperforms CLIP with a 5.5 ~ 221.3X\nfaster retrieval speed and 13.2 ~ 48.8X less index storage memory.\n","authors":["Ziyang luo","Pu Zhao","Can Xu","Xiubo Geng","Tao Shen","Chongyang Tao","Jing Ma","Qingwen lin","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.02908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05575v3","updated":"2023-02-06T15:54:51Z","published":"2022-01-14T17:35:16Z","title":"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph\n  Embeddings","summary":"  Previous knowledge graph embedding approaches usually map entities to\nrepresentations and utilize score functions to predict the target entities, yet\nthey typically struggle to reason rare or emerging unseen entities. In this\npaper, we propose kNN-KGE, a new knowledge graph embedding approach with\npre-trained language models, by linearly interpolating its entity distribution\nwith k-nearest neighbors. We compute the nearest neighbors based on the\ndistance in the entity embedding space from the knowledge store. Our approach\ncan allow rare or emerging entities to be memorized explicitly rather than\nimplicitly in model parameters. Experimental results demonstrate that our\napproach can improve inductive and transductive link prediction results and\nyield better performance for low-resource settings with only a few triples,\nwhich might be easier to reason via explicit memory. Code is available at\nhttps://github.com/zjunlp/KNN-KG.\n","authors":["Ningyu Zhang","Xin Xie","Xiang Chen","Yongheng Wang","Xu Cheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2201.05575v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.01680v2","updated":"2023-02-06T13:02:12Z","published":"2023-02-03T12:02:54Z","title":"Two-Stage Constrained Actor-Critic for Short Video Recommendation","summary":"  The wide popularity of short videos on social media poses new opportunities\nand challenges to optimize recommender systems on the video-sharing platforms.\nUsers sequentially interact with the system and provide complex and\nmulti-faceted responses, including watch time and various types of interactions\nwith multiple videos. One the one hand, the platforms aims at optimizing the\nusers' cumulative watch time (main goal) in long term, which can be effectively\noptimized by Reinforcement Learning. On the other hand, the platforms also\nneeds to satisfy the constraint of accommodating the responses of multiple user\ninteractions (auxiliary goals) such like, follow, share etc. In this paper, we\nformulate the problem of short video recommendation as a Constrained Markov\nDecision Process (CMDP). We find that traditional constrained reinforcement\nlearning algorithms can not work well in this setting. We propose a novel\ntwo-stage constrained actor-critic method: At stage one, we learn individual\npolicies to optimize each auxiliary signal. At stage two, we learn a policy to\n(i) optimize the main signal and (ii) stay close to policies learned at the\nfirst stage, which effectively guarantees the performance of this main policy\non the auxiliaries. Through extensive offline evaluations, we demonstrate\neffectiveness of our method over alternatives in both optimizing the main goal\nas well as balancing the others. We further show the advantage of our method in\nlive experiments of short video recommendations, where it significantly\noutperforms other baselines in terms of both watch time and interactions. Our\napproach has been fully launched in the production system to optimize user\nexperiences on the platform.\n","authors":["Qingpeng Cai","Zhenghai Xue","Chi Zhang","Wanqi Xue","Shuchang Liu","Ruohan Zhan","Xueliang Wang","Tianyou Zuo","Wentao Xie","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01680v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.13248"},{"id":"http://arxiv.org/abs/2302.02657v1","updated":"2023-02-06T09:52:12Z","published":"2023-02-06T09:52:12Z","title":"Divide and Conquer: Towards Better Embedding-based Retrieval for\n  Recommender Systems From a Multi-task Perspective","summary":"  Embedding-based retrieval (EBR) methods are widely used in modern recommender\nsystems thanks to its simplicity and effectiveness. However, along the journey\nof deploying and iterating on EBR in production, we still identify some\nfundamental issues in existing methods. First, when dealing with large corpus\nof candidate items, EBR models often have difficulties in balancing the\nperformance on distinguishing highly relevant items (positives) from both\nirrelevant ones (easy negatives) and from somewhat related yet not competitive\nones (hard negatives). Also, we have little control in the diversity and\nfairness of the retrieval results because of the ``greedy'' nature of nearest\nvector search. These issues compromise the performance of EBR methods in\nlarge-scale industrial scenarios. This paper introduces a simple and\nproven-in-production solution to overcome these issues. The proposed solution\ntakes a divide-and-conquer approach: the whole set of candidate items are\ndivided into multiple clusters and we run EBR to retrieve relevant candidates\nfrom each cluster in parallel; top candidates from each cluster are then\ncombined by some controllable merging strategies. This approach allows our EBR\nmodels to only concentrate on discriminating positives from mostly hard\nnegatives. It also enables further improvement from a multi-tasking learning\n(MTL) perspective: retrieval problems within each cluster can be regarded as\nindividual tasks; inspired by recent successes in prompting and prefix-tuning,\nwe propose an efficient task adaption technique further boosting the retrieval\nperformance within each cluster with negligible overheads.\n","authors":["Yuan Zhang","Xue Dong","Weijie Ding","Biao Li","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.02657v1.pdf","comment":"To appear in WWW'23 (Industry Track)"},{"id":"http://arxiv.org/abs/2302.02636v1","updated":"2023-02-06T09:15:39Z","published":"2023-02-06T09:15:39Z","title":"Hybrid Contrastive Constraints for Multi-Scenario Ad Ranking","summary":"  Multi-scenario ad ranking aims at leveraging the data from multiple domains\nor channels for training a unified ranking model to improve the performance at\neach individual scenario. Although the research on this task has made important\nprogress, it still lacks the consideration of cross-scenario relations, thus\nleading to limitation in learning capability and difficulty in interrelation\nmodeling. In this paper, we propose a Hybrid Contrastive Constrained approach\n(HC^2) for multi-scenario ad ranking. To enhance the modeling of data\ninterrelation, we elaborately design a hybrid contrastive learning approach to\ncapture commonalities and differences among multiple scenarios. The core of our\napproach consists of two elaborated contrastive losses, namely generalized and\nindividual contrastive loss, which aim at capturing common knowledge and\nscenario-specific knowledge, respectively. To adapt contrastive learning to the\ncomplex multi-scenario setting, we propose a series of important improvements.\nFor generalized contrastive loss, we enhance contrastive learning by extending\nthe contrastive samples (label-aware and diffusion noise enhanced contrastive\nsamples) and reweighting the contrastive samples (reciprocal similarity\nweighting). For individual contrastive loss, we use the strategies of\ndropout-based augmentation and {cross-scenario encoding} for generating\nmeaningful positive and negative contrastive samples, respectively. Extensive\nexperiments on both offline evaluation and online test have demonstrated the\neffectiveness of the proposed HC$^2$ by comparing it with a number of\ncompetitive baselines.\n","authors":["Shanlei Mu","Penghui Wei","Wayne Xin Zhao","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.02636v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2301.10405v2","updated":"2023-02-06T09:10:32Z","published":"2023-01-25T04:45:06Z","title":"Editing Language Model-based Knowledge Graph Embeddings","summary":"  Recently decades have witnessed the empirical success of framing Knowledge\nGraph (KG) embeddings via language models. However, language model-based KG\nembeddings are usually deployed as static artifacts, which are challenging to\nmodify without re-training after deployment. To address this issue, we propose\na new task of editing language model-based KG embeddings in this paper. The\nproposed task aims to enable data-efficient and fast updates to KG embeddings\nwithout damaging the performance of the rest. We build four new datasets:\nE-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge\nediting baselines demonstrating the limited ability of previous models to\nhandle the proposed challenging task. We further propose a simple yet strong\nbaseline dubbed KGEditor, which utilizes additional parametric layers of the\nhyper network to edit/add facts. Comprehensive experimental results demonstrate\nthat KGEditor can perform better when updating specific facts while not\naffecting the rest with low training resources. Code and datasets will be\navailable in https://github.com/zjunlp/PromptKG/tree/main/deltaKG.\n","authors":["Siyuan Cheng","Ningyu Zhang","Bozhong Tian","Zelin Dai","Feiyu Xiong","Wei Guo","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2301.10405v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/KGE_Editing/"},{"id":"http://arxiv.org/abs/2302.02592v1","updated":"2023-02-06T07:00:20Z","published":"2023-02-06T07:00:20Z","title":"RLTP: Reinforcement Learning to Pace for Delayed Impression Modeling in\n  Preloaded Ads","summary":"  To increase brand awareness, many advertisers conclude contracts with\nadvertising platforms to purchase traffic and then deliver advertisements to\ntarget audiences. In a whole delivery period, advertisers usually desire a\ncertain impression count for the ads, and they also expect that the delivery\nperformance is as good as possible (e.g., obtaining high click-through rate).\nAdvertising platforms employ pacing algorithms to satisfy the demands via\nadjusting the selection probabilities to traffic requests in real-time.\nHowever, the delivery procedure is also affected by the strategies from\npublishers, which cannot be controlled by advertising platforms. Preloading is\na widely used strategy for many types of ads (e.g., video ads) to make sure\nthat the response time for displaying after a traffic request is legitimate,\nwhich results in delayed impression phenomenon. Traditional pacing algorithms\ncannot handle the preloading nature well because they rely on immediate\nfeedback signals, and may fail to guarantee the demands from advertisers.\n  In this paper, we focus on a new research problem of impression pacing for\npreloaded ads, and propose a Reinforcement Learning To Pace framework RLTP. It\nlearns a pacing agent that sequentially produces selection probabilities in the\nwhole delivery period. To jointly optimize the two objectives of impression\ncount and delivery performance, RLTP employs tailored reward estimator to\nsatisfy the guaranteed impression count, penalize the over-delivery and\nmaximize the traffic value. Experiments on large-scale industrial datasets\nverify that RLTP outperforms baseline pacing algorithms by a large margin. We\nhave deployed the RLTP framework online to our advertising platform, and\nresults show that it achieves significant uplift to core metrics including\ndelivery completion rate and click-through rate.\n","authors":["Penghui Wei","Yongqiang Chen","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.02592v1.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2302.02579v1","updated":"2023-02-06T06:19:05Z","published":"2023-02-06T06:19:05Z","title":"Recommender Systems: A Primer","summary":"  Personalized recommendations have become a common feature of modern online\nservices, including most major e-commerce sites, media platforms and social\nnetworks. Today, due to their high practical relevance, research in the area of\nrecommender systems is flourishing more than ever. However, with the new\napplication scenarios of recommender systems that we observe today, constantly\nnew challenges arise as well, both in terms of algorithmic requirements and\nwith respect to the evaluation of such systems. In this paper, we first provide\nan overview of the traditional formulation of the recommendation problem. We\nthen review the classical algorithmic paradigms for item retrieval and ranking\nand elaborate how such systems can be evaluated. Afterwards, we discuss a\nnumber of recent developments in recommender systems research, including\nresearch on session-based recommendation, biases in recommender systems, and\nquestions regarding the impact and value of recommender systems in practice.\n","authors":["Pablo Castells","Dietmar Jannach"],"pdf_url":"https://arxiv.org/pdf/2302.02579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03136v1","updated":"2023-02-06T21:49:03Z","published":"2023-02-06T21:49:03Z","title":"Learned Accelerator Framework for Angular-Distance-Based\n  High-Dimensional DBSCAN","summary":"  Density-based clustering is a commonly used tool in data science. Today many\ndata science works are utilizing high-dimensional neural embeddings. However,\ntraditional density-based clustering techniques like DBSCAN have a degraded\nperformance on high-dimensional data. In this paper, we propose LAF, a generic\nlearned accelerator framework to speed up the original DBSCAN and the\nsampling-based variants of DBSCAN on high-dimensional data with angular\ndistance metric. This framework consists of a learned cardinality estimator and\na post-processing module. The cardinality estimator can fast predict whether a\ndata point is core or not to skip unnecessary range queries, while the\npost-processing module detects the false negative predictions and merges the\nfalsely separated clusters. The evaluation shows our LAF-enhanced DBSCAN method\noutperforms the state-of-the-art efficient DBSCAN variants on both efficiency\nand quality.\n","authors":["Yifan Wang","Daisy Zhe Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03136v1.pdf","comment":"Accepted by EDBT 2023"},{"id":"http://arxiv.org/abs/2302.03487v1","updated":"2023-02-06T09:17:52Z","published":"2023-02-06T09:17:52Z","title":"PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework\n  in E-commerce","summary":"  Re-ranking draws increased attention on both academics and industries, which\nrearranges the ranking list by modeling the mutual influence among items to\nbetter meet users' demands. Many existing re-ranking methods directly take the\ninitial ranking list as input, and generate the optimal permutation through a\nwell-designed context-wise model, which brings the evaluation-before-reranking\nproblem. Meanwhile, evaluating all candidate permutations brings unacceptable\ncomputational costs in practice. Thus, to better balance efficiency and\neffectiveness, online systems usually use a two-stage architecture which uses\nsome heuristic methods such as beam-search to generate a suitable amount of\ncandidate permutations firstly, which are then fed into the evaluation model to\nget the optimal permutation. However, existing methods in both stages can be\nimproved through the following aspects. As for generation stage, heuristic\nmethods only use point-wise prediction scores and lack an effective judgment.\nAs for evaluation stage, most existing context-wise evaluation models only\nconsider the item context and lack more fine-grained feature context modeling.\nThis paper presents a novel end-to-end re-ranking framework named PIER to\ntackle the above challenges which still follows the two-stage architecture and\ncontains two mainly modules named FPSM and OCPM. We apply SimHash in FPSM to\nselect top-K candidates from the full permutation based on user's\npermutation-level interest in an efficient way. Then we design a novel\nomnidirectional attention mechanism in OCPM to capture the context information\nin the permutation. Finally, we jointly train these two modules end-to-end by\nintroducing a comparative learning loss. Offline experiment results demonstrate\nthat PIER outperforms baseline models on both public and industrial datasets,\nand we have successfully deployed PIER on Meituan food delivery platform.\n","authors":["Xiaowen Shi","Fan Yang","Ze Wang","Xiaoxu Wu","Muzhi Guan","Guogang Liao","Yongkang Wang","Xingxing Wang","Dong Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03487v1.pdf","comment":"9 pages, 3 figures"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.03027v1","updated":"2023-02-06T18:59:51Z","published":"2023-02-06T18:59:51Z","title":"Zero-shot Image-to-Image Translation","summary":"  Large-scale text-to-image generative models have shown their remarkable\nability to synthesize diverse and high-quality images. However, it is still\nchallenging to directly apply these models for editing real images for two\nreasons. First, it is hard for users to come up with a perfect text prompt that\naccurately describes every visual detail in the input image. Second, while\nexisting models can introduce desirable changes in certain regions, they often\ndramatically alter the input content and introduce unexpected changes in\nunwanted regions. In this work, we propose pix2pix-zero, an image-to-image\ntranslation method that can preserve the content of the original image without\nmanual prompting. We first automatically discover editing directions that\nreflect desired edits in the text embedding space. To preserve the general\ncontent structure after editing, we further propose cross-attention guidance,\nwhich aims to retain the cross-attention maps of the input image throughout the\ndiffusion process. In addition, our method does not need additional training\nfor these edits and can directly use the existing pre-trained text-to-image\ndiffusion model. We conduct extensive experiments and show that our method\noutperforms existing and concurrent works for both real and synthetic image\nediting.\n","authors":["Gaurav Parmar","Krishna Kumar Singh","Richard Zhang","Yijun Li","Jingwan Lu","Jun-Yan Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.03027v1.pdf","comment":"website: https://pix2pixzero.github.io/"},{"id":"http://arxiv.org/abs/2302.03026v1","updated":"2023-02-06T18:59:25Z","published":"2023-02-06T18:59:25Z","title":"Sampling-Based Accuracy Testing of Posterior Estimators for General\n  Inference","summary":"  Parameter inference, i.e. inferring the posterior distribution of the\nparameters of a statistical model given some data, is a central problem to many\nscientific disciplines. Posterior inference with generative models is an\nalternative to methods such as Markov Chain Monte Carlo, both for\nlikelihood-based and simulation-based inference. However, assessing the\naccuracy of posteriors encoded in generative models is not straightforward. In\nthis paper, we introduce `distance to random point' (DRP) coverage testing as a\nmethod to estimate coverage probabilities of generative posterior estimators.\n  Our method differs from previously-existing coverage-based methods, which\nrequire posterior evaluations. We prove that our approach is necessary and\nsufficient to show that a posterior estimator is optimal. We demonstrate the\nmethod on a variety of synthetic examples, and show that DRP can be used to\ntest the results of posterior inference analyses in high-dimensional spaces. We\nalso show that our method can detect non-optimal inferences in cases where\nexisting methods fail.\n","authors":["Pablo Lemos","Adam Coogan","Yashar Hezaveh","Laurence Perreault-Levasseur"],"pdf_url":"https://arxiv.org/pdf/2302.03026v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2302.03025v1","updated":"2023-02-06T18:59:20Z","published":"2023-02-06T18:59:20Z","title":"A Toy Model of Universality: Reverse Engineering How Networks Learn\n  Group Operations","summary":"  Universality is a key hypothesis in mechanistic interpretability -- that\ndifferent models learn similar features and circuits when trained on similar\ntasks. In this work, we study the universality hypothesis by examining how\nsmall neural networks learn to implement group composition. We present a novel\nalgorithm by which neural networks may implement composition for any finite\ngroup via mathematical representation theory. We then show that networks\nconsistently learn this algorithm by reverse engineering model logits and\nweights, and confirm our understanding using ablations. By studying networks of\ndiffering architectures trained on various groups, we find mixed evidence for\nuniversality: using our algorithm, we can completely characterize the family of\ncircuits and features that networks learn on this task, but for a given network\nthe precise circuits learned -- as well as the order they develop -- are\narbitrary.\n","authors":["Bilal Chughtai","Lawrence Chan","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2302.03025v1.pdf","comment":"9 page main body, 1 page references, 12 page appendix"},{"id":"http://arxiv.org/abs/2302.03023v1","updated":"2023-02-06T18:58:38Z","published":"2023-02-06T18:58:38Z","title":"V1T: large-scale mouse V1 response prediction using a Vision Transformer","summary":"  Accurate predictive models of the visual cortex neural response to natural\nvisual stimuli remain a challenge in computational neuroscience. In this work,\nwe introduce V1T, a novel Vision Transformer based architecture that learns a\nshared visual and behavioral representation across animals. We evaluate our\nmodel on two large datasets recorded from mouse primary visual cortex and\noutperform previous convolution-based models by more than 12.7% in prediction\nperformance. Moreover, we show that the attention weights learned by the\nTransformer correlate with the population receptive fields. Our model thus sets\na new benchmark for neural response prediction and captures characteristic\nfeatures of the visual cortex.\n","authors":["Bryan M. Li","Isabel M. Cornacchia","Nathalie L. Rochefort","Arno Onken"],"pdf_url":"https://arxiv.org/pdf/2302.03023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03020v1","updated":"2023-02-06T18:57:14Z","published":"2023-02-06T18:57:14Z","title":"RLSbench: Domain Adaptation Under Relaxed Label Shift","summary":"  Despite the emergence of principled methods for domain adaptation under label\nshift, the sensitivity of these methods for minor shifts in the class\nconditional distributions remains precariously under explored. Meanwhile,\npopular deep domain adaptation heuristics tend to falter when faced with shifts\nin label proportions. While several papers attempt to adapt these heuristics to\naccommodate shifts in label proportions, inconsistencies in evaluation\ncriteria, datasets, and baselines, make it hard to assess the state of the art.\nIn this paper, we introduce RLSbench, a large-scale relaxed label shift\nbenchmark, consisting of >500 distribution shift pairs that draw on 14 datasets\nacross vision, tabular, and language modalities and compose them with varying\nlabel proportions. First, we evaluate 13 popular domain adaptation methods,\ndemonstrating more widespread failures under label proportion shifts than were\npreviously known. Next, we develop an effective two-step meta-algorithm that is\ncompatible with most deep domain adaptation heuristics: (i) pseudo-balance the\ndata at each epoch; and (ii) adjust the final classifier with (an estimate of)\ntarget label distribution. The meta-algorithm improves existing domain\nadaptation heuristics often by 2--10\\% accuracy points under extreme label\nproportion shifts and has little (i.e., <0.5\\%) effect when label proportions\ndo not shift. We hope that these findings and the availability of RLSbench will\nencourage researchers to rigorously evaluate proposed methods in relaxed label\nshift settings. Code is publicly available at\nhttps://github.com/acmi-lab/RLSbench.\n","authors":["Saurabh Garg","Nick Erickson","James Sharpnack","Alex Smola","Sivaraman Balakrishnan","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2302.03020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12328v2","updated":"2023-02-06T18:56:53Z","published":"2022-11-19T14:00:50Z","title":"A survey on knowledge-enhanced multimodal learning","summary":"  Multimodal learning has been a field of increasing interest, aiming to\ncombine various modalities in a single joint representation. Especially in the\narea of visiolinguistic (VL) learning multiple models and techniques have been\ndeveloped, targeting a variety of tasks that involve images and text. VL models\nhave reached unprecedented performances by extending the idea of Transformers,\nso that both modalities can learn from each other. Massive pre-training\nprocedures enable VL models to acquire a certain level of real-world\nunderstanding, although many gaps can be identified: the limited comprehension\nof commonsense, factual, temporal and other everyday knowledge aspects\nquestions the extendability of VL tasks. Knowledge graphs and other knowledge\nsources can fill those gaps by explicitly providing missing information,\nunlocking novel capabilities of VL models. In the same time, knowledge graphs\nenhance explainability, fairness and validity of decision making, issues of\noutermost importance for such complex implementations. The current survey aims\nto unify the fields of VL representation learning and knowledge graphs, and\nprovides a taxonomy and analysis of knowledge-enhanced VL models.\n","authors":["Maria Lymperaiou","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2211.12328v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03015v1","updated":"2023-02-06T18:54:58Z","published":"2023-02-06T18:54:58Z","title":"Exploring and Exploiting Decision Boundary Dynamics for Adversarial\n  Robustness","summary":"  The robustness of a deep classifier can be characterized by its margins: the\ndecision boundary's distances to natural data points. However, it is unclear\nwhether existing robust training methods effectively increase the margin for\neach vulnerable point during training. To understand this, we propose a\ncontinuous-time framework for quantifying the relative speed of the decision\nboundary with respect to each individual point. Through visualizing the moving\nspeed of the decision boundary under Adversarial Training, one of the most\neffective robust training algorithms, a surprising moving-behavior is revealed:\nthe decision boundary moves away from some vulnerable points but simultaneously\nmoves closer to others, decreasing their margins. To alleviate these\nconflicting dynamics of the decision boundary, we propose Dynamics-aware Robust\nTraining (DyART), which encourages the decision boundary to engage in movement\nthat prioritizes increasing smaller margins. In contrast to prior works, DyART\ndirectly operates on the margins rather than their indirect approximations,\nallowing for more targeted and effective robustness improvement. Experiments on\nthe CIFAR-10 and Tiny-ImageNet datasets verify that DyART alleviates the\nconflicting dynamics of the decision boundary and obtains improved robustness\nunder various perturbation sizes compared to the state-of-the-art defenses. Our\ncode is available at\nhttps://github.com/Yuancheng-Xu/Dynamics-Aware-Robust-Training.\n","authors":["Yuancheng Xu","Yanchao Sun","Micah Goldblum","Tom Goldstein","Furong Huang"],"pdf_url":"https://arxiv.org/pdf/2302.03015v1.pdf","comment":"Published at International Conference on Learning Representations\n  (ICLR) 2023"},{"id":"http://arxiv.org/abs/2302.03014v1","updated":"2023-02-06T18:54:14Z","published":"2023-02-06T18:54:14Z","title":"Detection and Localization of Melanoma Skin Cancer in Histopathological\n  Whole Slide Images","summary":"  Melanoma diagnosed and treated in its early stages can increase the survival\nrate. A projected increase in skin cancer incidents and a dearth of\ndermatopathologists have emphasized the need for computational pathology\n(CPATH) systems. CPATH systems with deep learning (DL) models have the\npotential to identify the presence of melanoma by exploiting underlying\nmorphological and cellular features. This paper proposes a DL method to detect\nmelanoma and distinguish between normal skin and benign/malignant melanocytic\nlesions in Whole Slide Images (WSI). Our method detects lesions with high\naccuracy and localizes them on a WSI to identify potential regions of interest\nfor pathologists. Interestingly, our DL method relies on using a single CNN\nnetwork to create localization maps first and use them to perform slide-level\npredictions to determine patients who have melanoma. Our best model provides\nfavorable patch-wise classification results with a 0.992 F1 score and 0.99\nsensitivity on unseen data.\n","authors":["Neel Kanwal","Roger Amundsen","Helga Hardardottir","Emiel A. M. Janssen","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2302.03014v1.pdf","comment":"Submitted to EUSIPCO 23"},{"id":"http://arxiv.org/abs/2302.03008v1","updated":"2023-02-06T18:43:10Z","published":"2023-02-06T18:43:10Z","title":"LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease\n  Assessment from Fundus Images","summary":"  Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the\nleading cause of dementia. Early diagnosis is critical for patients to benefit\nfrom potential intervention and treatment. The retina has been hypothesized as\na diagnostic site for AD detection owing to its anatomical connection with the\nbrain. Developed AI models for this purpose have yet to provide a rational\nexplanation about the decision and neither infer the stage of disease's\nprogression. Along this direction, we propose a novel model-agnostic\nexplainable-AI framework, called Granular Neuron-level Explainer (LAVA), an\ninterpretation prototype that probes into intermediate layers of the\nConvolutional Neural Network (CNN) models to assess the AD continuum directly\nfrom the retinal imaging without longitudinal or clinical evaluation. This\nmethod is applied to validate the retinal vasculature as a biomarker and\ndiagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank\ncognitive tests and vascular morphological features suggest LAVA shows strong\npromise and effectiveness in identifying AD stages across the progression\ncontinuum.\n","authors":["Nooshin Yousefzadeh","Charlie Tran","Adolfo Ramirez-Zamora","Jinghua Chen","Ruogu Fang","My T. Thai"],"pdf_url":"https://arxiv.org/pdf/2302.03008v1.pdf","comment":"27 pages, 11 figures"},{"id":"http://arxiv.org/abs/2106.14045v3","updated":"2023-02-06T18:42:06Z","published":"2021-06-26T15:28:38Z","title":"The mbsts package: Multivariate Bayesian Structural Time Series Models\n  in R","summary":"  The multivariate Bayesian structural time series (MBSTS) model is a general\nmachine learning model that deals with inference and prediction for multiple\ncorrelated time series, where one also has the choice of using a different\ncandidate pool of contemporaneous predictors for each target series. The MBSTS\nmodel has wide applications and is ideal for feature selection, time series\nforecasting, nowcasting, inferring causal impact, and others. This paper\ndemonstrates how to use the R package mbsts for MBSTS modeling, establishing a\nbridge between user-friendly and developer-friendly functions in the package\nand the corresponding methodology. Object-oriented functions in the package are\nexplained in the way that enables users to flexibly add or deduct some\ncomponents, as well as to simplify or complicate some settings.\n","authors":["Ning Ning","Jinwen Qiu"],"pdf_url":"https://arxiv.org/pdf/2106.14045v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03004v1","updated":"2023-02-06T18:39:40Z","published":"2023-02-06T18:39:40Z","title":"Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class\n  Incremental Learning","summary":"  Few-shot class-incremental learning (FSCIL) has been a challenging problem as\nonly a few training samples are accessible for each novel class in the new\nsessions. Finetuning the backbone or adjusting the classifier prototypes\ntrained in the prior sessions would inevitably cause a misalignment between the\nfeature and classifier of old classes, which explains the well-known\ncatastrophic forgetting problem. In this paper, we deal with this misalignment\ndilemma in FSCIL inspired by the recently discovered phenomenon named neural\ncollapse, which reveals that the last-layer features of the same class will\ncollapse into a vertex, and the vertices of all classes are aligned with the\nclassifier prototypes, which are formed as a simplex equiangular tight frame\n(ETF). It corresponds to an optimal geometric structure for classification due\nto the maximized Fisher Discriminant Ratio. We propose a neural collapse\ninspired framework for FSCIL. A group of classifier prototypes are pre-assigned\nas a simplex ETF for the whole label space, including the base session and all\nthe incremental sessions. During training, the classifier prototypes are not\nlearnable, and we adopt a novel loss function that drives the features into\ntheir corresponding prototypes. Theoretical analysis shows that our method\nholds the neural collapse optimality and does not break the feature-classifier\nalignment in an incremental fashion. Experiments on the miniImageNet, CUB-200,\nand CIFAR-100 datasets demonstrate that our proposed framework outperforms the\nstate-of-the-art performances. Code address:\nhttps://github.com/NeuralCollapseApplications/FSCIL\n","authors":["Yibo Yang","Haobo Yuan","Xiangtai Li","Zhouchen Lin","Philip Torr","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.03004v1.pdf","comment":"ICLR 2023 (Notable-top-25%)"},{"id":"http://arxiv.org/abs/2302.01425v2","updated":"2023-02-06T18:34:36Z","published":"2023-02-02T21:32:13Z","title":"Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective","summary":"  The top-k operator returns a k-sparse vector, where the non-zero values\ncorrespond to the k largest values of the input. Unfortunately, because it is a\ndiscontinuous function, it is difficult to incorporate in neural networks\ntrained end-to-end with backpropagation. Recent works have considered\ndifferentiable relaxations, based either on regularization or perturbation\ntechniques. However, to date, no approach is fully differentiable and sparse.\nIn this paper, we propose new differentiable and sparse top-k operators. We\nview the top-k operator as a linear program over the permutahedron, the convex\nhull of permutations. We then introduce a p-norm regularization term to smooth\nout the operator, and show that its computation can be reduced to isotonic\noptimization. Our framework is significantly more general than the existing one\nand allows for example to express top-k operators that select values in\nmagnitude. On the algorithmic side, in addition to pool adjacent violator (PAV)\nalgorithms, we propose a new GPU/TPU-friendly Dykstra algorithm to solve\nisotonic optimization problems. We successfully use our operators to prune\nweights in neural networks, to fine-tune vision transformers, and as a router\nin sparse mixture of experts.\n","authors":["Michael E. Sander","Joan Puigcerver","Josip Djolonga","Gabriel Peyré","Mathieu Blondel"],"pdf_url":"https://arxiv.org/pdf/2302.01425v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2302.02988v1","updated":"2023-02-06T18:27:11Z","published":"2023-02-06T18:27:11Z","title":"Asymptotically Minimax Optimal Fixed-Budget Best Arm Identification for\n  Expected Simple Regret Minimization","summary":"  We investigate fixed-budget best arm identification (BAI) for expected simple\nregret minimization. In each round of an adaptive experiment, a decision maker\ndraws one of multiple treatment arms based on past observations and\nsubsequently observes the outcomes of the chosen arm. After the experiment, the\ndecision maker recommends a treatment arm with the highest projected outcome.\nWe evaluate this decision in terms of the expected simple regret, a difference\nbetween the expected outcomes of the best and recommended treatment arms. Due\nto the inherent uncertainty, we evaluate the regret using the minimax\ncriterion. For distributions with fixed variances (location-shift models), such\nas Gaussian distributions, we derive asymptotic lower bounds for the worst-case\nexpected simple regret. Then, we show that the Random Sampling (RS)-Augmented\nInverse Probability Weighting (AIPW) strategy proposed by Kato et al. (2022) is\nasymptotically minimax optimal in the sense that the leading factor of its\nworst-case expected simple regret asymptotically matches our derived worst-case\nlower bound. Our result indicates that, for location-shift models, the optimal\nRS-AIPW strategy draws treatment arms with varying probabilities based on their\nvariances. This result contrasts with the results of Bubeck et al. (2011),\nwhich shows that drawing each treatment arm with an equal ratio is minimax\noptimal in a bounded outcome setting.\n","authors":["Masahiro Kato","Masaaki Imaizumi","Takuya Ishihara","Toru Kitagawa"],"pdf_url":"https://arxiv.org/pdf/2302.02988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00674v2","updated":"2023-02-06T18:21:56Z","published":"2023-02-01T18:59:36Z","title":"Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary\n  Data","summary":"  Few-shot learning involves learning an effective model from only a few\nlabeled datapoints. The use of a small training set makes it difficult to avoid\noverfitting but also makes few-shot learning applicable to many important\nreal-world settings. In this work, we focus on Few-shot Learning with Auxiliary\nData (FLAD), a training paradigm that assumes access to auxiliary data during\nfew-shot learning in hopes of improving generalization. Introducing auxiliary\ndata during few-shot learning leads to essential design choices where\nhand-designed heuristics can lead to sub-optimal performance. In this work, we\nfocus on automated sampling strategies for FLAD and relate them to the\nexplore-exploit dilemma that is central in multi-armed bandit settings. Based\non this connection we propose two algorithms -- EXP3-FLAD and UCB1-FLAD -- and\ncompare them with methods that either explore or exploit, finding that the\ncombination of exploration and exploitation is crucial. Using our proposed\nalgorithms to train T5 yields a 9% absolute improvement over the explicitly\nmulti-task pre-trained T0 model across 11 datasets.\n","authors":["Alon Albalak","Colin Raffel","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.00674v2.pdf","comment":"19 pages, 7 figures, code available at\n  https://github.com/alon-albalak/FLAD"},{"id":"http://arxiv.org/abs/2302.02984v1","updated":"2023-02-06T18:19:25Z","published":"2023-02-06T18:19:25Z","title":"Robust Subtask Learning for Compositional Generalization","summary":"  Compositional reinforcement learning is a promising approach for training\npolicies to perform complex long-horizon tasks. Typically, a high-level task is\ndecomposed into a sequence of subtasks and a separate policy is trained to\nperform each subtask. In this paper, we focus on the problem of training\nsubtask policies in a way that they can be used to perform any task; here, a\ntask is given by a sequence of subtasks. We aim to maximize the worst-case\nperformance over all tasks as opposed to the average-case performance. We\nformulate the problem as a two agent zero-sum game in which the adversary picks\nthe sequence of subtasks. We propose two RL algorithms to solve this game: one\nis an adaptation of existing multi-agent RL algorithms to our setting and the\nother is an asynchronous version which enables parallel training of subtask\npolicies. We evaluate our approach on two multi-task environments with\ncontinuous states and actions and demonstrate that our algorithms outperform\nstate-of-the-art baselines.\n","authors":["Kishor Jothimurugan","Steve Hsu","Osbert Bastani","Rajeev Alur"],"pdf_url":"https://arxiv.org/pdf/2302.02984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02979v1","updated":"2023-02-06T18:10:08Z","published":"2023-02-06T18:10:08Z","title":"Learning disentangled representations for explainable chest X-ray\n  classification using Dirichlet VAEs","summary":"  This study explores the use of the Dirichlet Variational Autoencoder (DirVAE)\nfor learning disentangled latent representations of chest X-ray (CXR) images.\nOur working hypothesis is that distributional sparsity, as facilitated by the\nDirichlet prior, will encourage disentangled feature learning for the complex\ntask of multi-label classification of CXR images. The DirVAE is trained using\nCXR images from the CheXpert database, and the predictive capacity of\nmulti-modal latent representations learned by DirVAE models is investigated\nthrough implementation of an auxiliary multi-label classification task, with a\nview to enforce separation of latent factors according to class-specific\nfeatures. The predictive performance and explainability of the latent space\nlearned using the DirVAE were quantitatively and qualitatively assessed,\nrespectively, and compared with a standard Gaussian prior-VAE (GVAE). We\nintroduce a new approach for explainable multi-label classification in which we\nconduct gradient-guided latent traversals for each class of interest. Study\nfindings indicate that the DirVAE is able to disentangle latent factors into\nclass-specific visual features, a property not afforded by the GVAE, and\nachieve a marginal increase in predictive performance relative to GVAE. We\ngenerate visual examples to show that our explainability method, when applied\nto the trained DirVAE, is able to highlight regions in CXR images that are\nclinically relevant to the class(es) of interest and additionally, can identify\ncases where classification relies on spurious feature correlations.\n","authors":["Rachael Harkness","Alejandro F Frangi","Kieran Zucker","Nishant Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2302.02979v1.pdf","comment":"13 pages, 8 figures, to be published in SPIE Medical Imaging 2023"},{"id":"http://arxiv.org/abs/2302.02978v1","updated":"2023-02-06T18:09:06Z","published":"2023-02-06T18:09:06Z","title":"MuG: A Multimodal Classification Benchmark on Game Data with Tabular,\n  Textual, and Visual Fields","summary":"  Multimodal learning has attracted the interest of the machine learning\ncommunity due to its great potential in a variety of applications. To help\nachieve this potential, we propose a multimodal benchmark MuG with eight\ndatasets allowing researchers to test the multimodal perceptron capabilities of\ntheir models. These datasets are collected from four different genres of games\nthat cover tabular, textual, and visual modalities. We conduct multi-aspect\ndata analysis to provide insights into the benchmark, including label balance\nratios, percentages of missing features, distributions of data within each\nmodality, and the correlations between labels and input modalities. We further\npresent experimental results obtained by several state-of-the-art unimodal\nclassifiers and multimodal classifiers, which demonstrate the challenging and\nmultimodal-dependent properties of the benchmark. MuG is released at\nhttps://github.com/lujiaying/MUG-Bench with the data, documents, tutorials, and\nimplemented baselines. Extensions of MuG are welcomed to facilitate the\nprogress of research in multimodal learning problems.\n","authors":["Jiaying Lu","Yongchen Qian","Shifan Zhao","Yuanzhe Xi","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2302.02978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03052v3","updated":"2023-02-06T18:08:02Z","published":"2022-10-06T16:57:23Z","title":"ByteTransformer: A High-Performance Transformer Boosted for\n  Variable-Length Inputs","summary":"  Transformers have become keystone models in natural language processing over\nthe past decade. They have achieved great popularity in deep learning\napplications, but the increasing sizes of the parameter spaces required by\ntransformer models generate a commensurate need to accelerate performance.\nNatural language processing problems are also routinely faced with\nvariable-length sequences, as word counts commonly vary among sentences.\nExisting deep learning frameworks pad variable-length sequences to a maximal\nlength, which adds significant memory and computational overhead. In this\npaper, we present ByteTransformer, a high-performance transformer boosted for\nvariable-length inputs. We propose a padding-free algorithm that liberates the\nentire transformer from redundant computations on zero padded tokens. In\naddition to algorithmic-level optimization, we provide architecture-aware\noptimizations for transformer functional modules, especially the\nperformance-critical algorithm Multi-Head Attention (MHA). Experimental results\non an NVIDIA A100 GPU with variable-length sequence inputs validate that our\nfused MHA outperforms PyTorch by 6.13x. The end-to-end performance of\nByteTransformer for a forward BERT transformer surpasses state-of-the-art\ntransformer frameworks, such as PyTorch JIT, TensorFlow XLA, Tencent\nTurboTransformer, Microsoft DeepSpeed-Inference and NVIDIA FasterTransformer,\nby 87\\%, 131\\%, 138\\%, 74\\% and 55\\%, respectively. We also demonstrate the\ngeneral applicability of our optimization methods to other BERT-like models,\nincluding ALBERT, DistilBERT, and DeBERTa.\n","authors":["Yujia Zhai","Chengquan Jiang","Leyuan Wang","Xiaoying Jia","Shang Zhang","Zizhong Chen","Xin Liu","Yibo Zhu"],"pdf_url":"https://arxiv.org/pdf/2210.03052v3.pdf","comment":"Accepted at IPDPS 2023"},{"id":"http://arxiv.org/abs/2302.02972v1","updated":"2023-02-06T18:02:07Z","published":"2023-02-06T18:02:07Z","title":"Concrete Safety for ML Problems: System Safety for ML Development and\n  Assessment","summary":"  Many stakeholders struggle to make reliances on ML-driven systems due to the\nrisk of harm these systems may cause. Concerns of trustworthiness, unintended\nsocial harms, and unacceptable social and ethical violations undermine the\npromise of ML advancements. Moreover, such risks in complex ML-driven systems\npresent a special challenge as they are often difficult to foresee, arising\nover periods of time, across populations, and at scale. These risks often arise\nnot from poor ML development decisions or low performance directly but rather\nemerge through the interactions amongst ML development choices, the context of\nmodel use, environmental factors, and the effects of a model on its target.\nSystems safety engineering is an established discipline with a proven track\nrecord of identifying and managing risks even in high-complexity sociotechnical\nsystems. In this work, we apply a state-of-the-art systems safety approach to\nconcrete applications of ML with notable social and ethical risks to\ndemonstrate a systematic means for meeting the assurance requirements needed to\nargue for safe and trustworthy ML in sociotechnical systems.\n","authors":["Edgar W. Jatho","Logan O. Mailloux","Eugene D. Williams","Patrick McClure","Joshua A. Kroll"],"pdf_url":"https://arxiv.org/pdf/2302.02972v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2211.04602"},{"id":"http://arxiv.org/abs/2302.02971v1","updated":"2023-02-06T18:01:38Z","published":"2023-02-06T18:01:38Z","title":"U-Clip: On-Average Unbiased Stochastic Gradient Clipping","summary":"  U-Clip is a simple amendment to gradient clipping that can be applied to any\niterative gradient optimization algorithm. Like regular clipping, U-Clip\ninvolves using gradients that are clipped to a prescribed size (e.g. with\ncomponent wise or norm based clipping) but instead of discarding the clipped\nportion of the gradient, U-Clip maintains a buffer of these values that is\nadded to the gradients on the next iteration (before clipping). We show that\nthe cumulative bias of the U-Clip updates is bounded by a constant. This\nimplies that the clipped updates are unbiased on average. Convergence follows\nvia a lemma that guarantees convergence with updates $u_i$ as long as\n$\\sum_{i=1}^t (u_i - g_i) = o(t)$ where $g_i$ are the gradients. Extensive\nexperimental exploration is performed on CIFAR10 with further validation given\non ImageNet.\n","authors":["Bryn Elesedy","Marcus Hutter"],"pdf_url":"https://arxiv.org/pdf/2302.02971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00633v2","updated":"2023-02-06T17:56:38Z","published":"2023-02-01T17:52:40Z","title":"Deep Dependency Networks for Multi-Label Classification","summary":"  We propose a simple approach which combines the strengths of probabilistic\ngraphical models and deep learning architectures for solving the multi-label\nclassification task, focusing specifically on image and video data. First, we\nshow that the performance of previous approaches that combine Markov Random\nFields with neural networks can be modestly improved by leveraging more\npowerful methods such as iterative join graph propagation, integer linear\nprogramming, and $\\ell_1$ regularization-based structure learning. Then we\npropose a new modeling framework called deep dependency networks, which\naugments a dependency network, a model that is easy to train and learns more\naccurate dependencies but is limited to Gibbs sampling for inference, to the\noutput layer of a neural network. We show that despite its simplicity, jointly\nlearning this new architecture yields significant improvements in performance\nover the baseline neural network. In particular, our experimental evaluation on\nthree video activity classification datasets: Charades, Textually Annotated\nCooking Scenes (TACoS), and Wetlab, and three multi-label image classification\ndatasets: MS-COCO, PASCAL VOC, and NUS-WIDE show that deep dependency networks\nare almost always superior to pure neural architectures that do not use\ndependency networks.\n","authors":["Shivvrat Arya","Yu Xiang","Vibhav Gogate"],"pdf_url":"https://arxiv.org/pdf/2302.00633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04746v4","updated":"2023-02-06T17:40:07Z","published":"2023-01-11T22:55:05Z","title":"Switchable Lightweight Anti-symmetric Processing (SLAP) with CNN\n  Outspeeds Data Augmentation by Smaller Sample -- Application in Gomoku\n  Reinforcement Learning","summary":"  To replace data augmentation, this paper proposed a method called SLAP to\nintensify experience to speed up machine learning and reduce the sample size.\nSLAP is a model-independent protocol/function to produce the same output given\ndifferent transformation variants. SLAP improved the convergence speed of\nconvolutional neural network learning by 83% in the experiments with Gomoku\ngame states, with only one eighth of the sample size compared with data\naugmentation. In reinforcement learning for Gomoku, using AlphaGo\nZero/AlphaZero algorithm with data augmentation as baseline, SLAP reduced the\nnumber of training samples by a factor of 8 and achieved similar winning rate\nagainst the same evaluator, but it was not yet evident that it could speed up\nreinforcement learning. The benefits should at least apply to domains that are\ninvariant to symmetry or certain transformations. As future work, SLAP may aid\nmore explainable learning and transfer learning for domains that are not\ninvariant to symmetry, as a small step towards artificial general intelligence.\n","authors":["Chi-Hang Suen","Eduardo Alonso"],"pdf_url":"https://arxiv.org/pdf/2301.04746v4.pdf","comment":"Add co-author and enrich discussion; 6 pages, 8 figures"},{"id":"http://arxiv.org/abs/2211.03128v2","updated":"2023-02-06T17:32:02Z","published":"2022-11-06T14:08:43Z","title":"Confidence-Ranked Reconstruction of Census Microdata from Published\n  Statistics","summary":"  A reconstruction attack on a private dataset $D$ takes as input some publicly\naccessible information about the dataset and produces a list of candidate\nelements of $D$. We introduce a new class of data reconstruction attacks based\non randomized methods for non-convex optimization. We empirically demonstrate\nthat our attacks can not only reconstruct full rows of $D$ from aggregate query\nstatistics $Q(D)\\in \\mathbb{R}^m$, but can do so in a way that reliably ranks\nreconstructed rows by their odds of appearing in the private data, providing a\nsignature that could be used for prioritizing reconstructed rows for further\nactions such as identify theft or hate crime. We also design a sequence of\nbaselines for evaluating reconstruction attacks. Our attacks significantly\noutperform those that are based only on access to a public distribution or\npopulation from which the private dataset $D$ was sampled, demonstrating that\nthey are exploiting information in the aggregate statistics $Q(D)$, and not\nsimply the overall structure of the distribution. In other words, the queries\n$Q(D)$ are permitting reconstruction of elements of this dataset, not the\ndistribution from which $D$ was drawn. These findings are established both on\n2010 U.S. decennial Census data and queries and Census-derived American\nCommunity Survey datasets. Taken together, our methods and experiments\nillustrate the risks in releasing numerically precise aggregate statistics of a\nlarge dataset, and provide further motivation for the careful application of\nprovably private techniques such as differential privacy.\n","authors":["Travis Dick","Cynthia Dwork","Michael Kearns","Terrance Liu","Aaron Roth","Giuseppe Vietri","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2211.03128v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02949v1","updated":"2023-02-06T17:30:33Z","published":"2023-02-06T17:30:33Z","title":"Adaptive Parameterization of Deep Learning Models for Federated Learning","summary":"  Federated Learning offers a way to train deep neural networks in a\ndistributed fashion. While this addresses limitations related to distributed\ndata, it incurs a communication overhead as the model parameters or gradients\nneed to be exchanged regularly during training. This can be an issue with large\nscale distribution of learning asks and negate the benefit of the respective\nresource distribution. In this paper, we we propose to utilise parallel\nAdapters for Federated Learning. Using various datasets, we show that Adapters\ncan be applied with different Federated Learning techniques. We highlight that\nour approach can achieve similar inference performance compared to training the\nfull model while reducing the communication overhead drastically. We further\nexplore the applicability of Adapters in cross-silo and cross-device settings,\nas well as different non-IID data distributions.\n","authors":["Morten From Elvebakken","Alexandros Iosifidis","Lukas Esterle"],"pdf_url":"https://arxiv.org/pdf/2302.02949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02947v1","updated":"2023-02-06T17:30:22Z","published":"2023-02-06T17:30:22Z","title":"GPS++: Reviving the Art of Message Passing for Molecular Property\n  Prediction","summary":"  We present GPS++, a hybrid Message Passing Neural Network / Graph Transformer\nmodel for molecular property prediction. Our model integrates a well-tuned\nlocal message passing component and biased global attention with other key\nideas from prior literature to achieve state-of-the-art results on large-scale\nmolecular dataset PCQM4Mv2. Through a thorough ablation study we highlight the\nimpact of individual components and, contrary to expectations set by recent\ntrends, find that nearly all of the model's performance can be maintained\nwithout any use of global self-attention. We also show that our approach is\nsignificantly more accurate than prior art when 3D positional information is\nnot available.\n","authors":["Dominic Masters","Josef Dean","Kerstin Klaser","Zhiyi Li","Sam Maddrell-Mander","Adam Sanders","Hatem Helal","Deniz Beker","Andrew Fitzgibbon","Shenyang Huang","Ladislav Rampášek","Dominique Beaini"],"pdf_url":"https://arxiv.org/pdf/2302.02947v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2212.02229"},{"id":"http://arxiv.org/abs/2302.02948v1","updated":"2023-02-06T17:30:22Z","published":"2023-02-06T17:30:22Z","title":"Efficient Online Reinforcement Learning with Offline Data","summary":"  Sample efficiency and exploration remain major challenges in online\nreinforcement learning (RL). A powerful approach that can be applied to address\nthese issues is the inclusion of offline data, such as prior trajectories from\na human expert or a sub-optimal exploration policy. Previous methods have\nrelied on extensive modifications and additional complexity to ensure the\neffective use of this data. Instead, we ask: can we simply apply existing\noff-policy methods to leverage offline data when learning online? In this work,\nwe demonstrate that the answer is yes; however, a set of minimal but important\nchanges to existing off-policy RL algorithms are required to achieve reliable\nperformance. We extensively ablate these design choices, demonstrating the key\nfactors that most affect performance, and arrive at a set of recommendations\nthat practitioners can readily apply, whether their data comprise a small\nnumber of expert demonstrations or large volumes of sub-optimal trajectories.\nWe see that correct application of these simple recommendations can provide a\n$\\mathbf{2.5\\times}$ improvement over existing approaches across a diverse set\nof competitive benchmarks, with no additional computational overhead.\n","authors":["Philip J. Ball","Laura Smith","Ilya Kostrikov","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2302.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02941v1","updated":"2023-02-06T17:16:42Z","published":"2023-02-06T17:16:42Z","title":"On Over-Squashing in Message Passing Neural Networks: The Impact of\n  Width, Depth, and Topology","summary":"  Message Passing Neural Networks (MPNNs) are instances of Graph Neural\nNetworks that leverage the graph to send messages over the edges. This\ninductive bias leads to a phenomenon known as over-squashing, where a node\nfeature is insensitive to information contained at distant nodes. Despite\nrecent methods introduced to mitigate this issue, an understanding of the\ncauses for over-squashing and of possible solutions are lacking. In this\ntheoretical work, we prove that: (i) Neural network width can mitigate\nover-squashing, but at the cost of making the whole network more sensitive;\n(ii) Conversely, depth cannot help mitigate over-squashing: increasing the\nnumber of layers leads to over-squashing being dominated by vanishing\ngradients; (iii) The graph topology plays the greatest role, since\nover-squashing occurs between nodes at high commute (access) time. Our analysis\nprovides a unified framework to study different recent methods introduced to\ncope with over-squashing and serves as a justification for a class of methods\nthat fall under `graph rewiring'.\n","authors":["Francesco Di Giovanni","Lorenzo Giusti","Federico Barbero","Giulia Luise","Pietro Lio'","Michael Bronstein"],"pdf_url":"https://arxiv.org/pdf/2302.02941v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2302.02936v1","updated":"2023-02-06T17:11:09Z","published":"2023-02-06T17:11:09Z","title":"Private GANs, Revisited","summary":"  We show that the canonical approach for training differentially private GANs\n-- updating the discriminator with differentially private stochastic gradient\ndescent (DPSGD) -- can yield significantly improved results after modifications\nto training. Existing instantiations of this approach neglect to consider how\nadding noise only to discriminator updates disrupts the careful balance between\nthe generator and discriminator necessary for successful GAN training. We show\nthat a simple fix -- taking more discriminator steps between generator steps --\nrestores parity and improves results. Additionally, with the goal of restoring\nparity between the generator and discriminator, we experiment with other\nmodifications to improve discriminator training and see further improvements in\ngeneration quality. Our results demonstrate that on standard benchmarks, DPSGD\noutperforms all alternative GAN privatization schemes.\n","authors":["Alex Bie","Gautam Kamath","Guojun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02931v1","updated":"2023-02-06T17:07:16Z","published":"2023-02-06T17:07:16Z","title":"Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group\n  Shifts","summary":"  Training machine learning models robust to distribution shifts is critical\nfor real-world applications. Some robust training algorithms (e.g., Group DRO)\nspecialize to group shifts and require group information on all training\npoints. Other methods (e.g., CVaR DRO) that do not need group annotations can\nbe overly conservative, since they naively upweight high loss points which may\nform a contrived set that does not correspond to any meaningful group in the\nreal world (e.g., when the high loss points are randomly mislabeled training\npoints). In this work, we address limitations in prior approaches by assuming a\nmore nuanced form of group shift: conditioned on the label, we assume that the\ntrue group function (indicator over group) is simple. For example, we may\nexpect that group shifts occur along low bitrate features (e.g., image\nbackground, lighting). Thus, we aim to learn a model that maintains high\naccuracy on simple group functions realized by these low bitrate features, that\nneed not spend valuable model capacity achieving high accuracy on contrived\ngroups of examples. Based on this, we consider the two-player game formulation\nof DRO where the adversary's capacity is bitrate-constrained. Our resulting\npractical algorithm, Bitrate-Constrained DRO (BR-DRO), does not require group\ninformation on training samples yet matches the performance of Group DRO on\ndatasets that have training group annotations and that of CVaR DRO on\nlong-tailed distributions. Our theoretical analysis reveals that in some\nsettings BR-DRO objective can provably yield statistically efficient and less\nconservative solutions than unconstrained CVaR DRO.\n","authors":["Amrith Setlur","Don Dennis","Benjamin Eysenbach","Aditi Raghunathan","Chelsea Finn","Virginia Smith","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2302.02931v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12558v6","updated":"2023-02-06T17:03:03Z","published":"2022-01-29T10:54:57Z","title":"The KFIoU Loss for Rotated Object Detection","summary":"  Differing from the well-developed horizontal object detection area whereby\nthe computing-friendly IoU based loss is readily adopted and well fits with the\ndetection metrics. In contrast, rotation detectors often involve a more\ncomplicated loss based on SkewIoU which is unfriendly to gradient-based\ntraining. In this paper, we propose an effective approximate SkewIoU loss based\non Gaussian modeling and Gaussian product, which mainly consists of two items.\nThe first term is a scale-insensitive center point loss, which is used to\nquickly narrow the distance between the center points of the two bounding\nboxes. In the distance-independent second term, the product of the Gaussian\ndistributions is adopted to inherently mimic the mechanism of SkewIoU by its\ndefinition, and show its alignment with the SkewIoU loss at trend-level within\na certain distance (i.e. within 9 pixels). This is in contrast to recent\nGaussian modeling based rotation detectors e.g. GWD loss and KLD loss that\ninvolve a human-specified distribution distance metric which require additional\nhyperparameter tuning that vary across datasets and detectors. The resulting\nnew loss called KFIoU loss is easier to implement and works better compared\nwith exact SkewIoU loss, thanks to its full differentiability and ability to\nhandle the non-overlapping cases. We further extend our technique to the 3-D\ncase which also suffers from the same issues as 2-D. Extensive results on\nvarious public datasets (2-D/3-D, aerial/text/face images) with different base\ndetectors show the effectiveness of our approach.\n","authors":["Xue Yang","Yue Zhou","Gefan Zhang","Jirui Yang","Wentao Wang","Junchi Yan","Xiaopeng Zhang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2201.12558v6.pdf","comment":"18 pages, 6 figures, 8 tables, accepted by ICLR 2023, TensorFlow\n  code: https://github.com/yangxue0827/RotationDetection, PyTorch code:\n  https://github.com/open-mmlab/mmrotate, Jittor code:\n  https://github.com/Jittor/JDet"},{"id":"http://arxiv.org/abs/2302.02926v1","updated":"2023-02-06T16:59:25Z","published":"2023-02-06T16:59:25Z","title":"Curriculum Graph Machine Learning: A Survey","summary":"  Graph machine learning has been extensively studied in both academia and\nindustry. However, in the literature, most existing graph machine learning\nmodels are designed to conduct training with data samples in a random order,\nwhich may suffer from suboptimal performance due to ignoring the importance of\ndifferent graph data samples and their training orders for the model\noptimization status. To tackle this critical problem, curriculum graph machine\nlearning (Graph CL), which integrates the strength of graph machine learning\nand curriculum learning, arises and attracts an increasing amount of attention\nfrom the research community. Therefore, in this paper, we comprehensively\noverview approaches on Graph CL and present a detailed survey of recent\nadvances in this direction. Specifically, we first discuss the key challenges\nof Graph CL and provide its formal problem definition. Then, we categorize and\nsummarize existing methods into three classes based on three kinds of graph\nmachine learning tasks, i.e., node-level, link-level, and graph-level tasks.\nFinally, we share our thoughts on future research directions. To the best of\nour knowledge, this paper is the first survey for curriculum graph machine\nlearning.\n","authors":["Haoyang Li","Xin Wang","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.02926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01851v2","updated":"2023-02-06T16:58:32Z","published":"2023-02-03T16:53:32Z","title":"Unsupervised hierarchical clustering using the learning dynamics of RBMs","summary":"  Datasets in the real world are often complex and to some degree hierarchical,\nwith groups and sub-groups of data sharing common characteristics at different\nlevels of abstraction. Understanding and uncovering the hidden structure of\nthese datasets is an important task that has many practical applications. To\naddress this challenge, we present a new and general method for building\nrelational data trees by exploiting the learning dynamics of the Restricted\nBoltzmann Machine (RBM). Our method is based on the mean-field approach,\nderived from the Plefka expansion, and developed in the context of disordered\nsystems. It is designed to be easily interpretable. We tested our method in an\nartificially created hierarchical dataset and on three different real-world\ndatasets (images of digits, mutations in the human genome, and a homologous\nfamily of proteins). The method is able to automatically identify the\nhierarchical structure of the data. This could be useful in the study of\nhomologous protein sequences, where the relationships between proteins are\ncritical for understanding their function and evolution.\n","authors":["Aurélien Decelle","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2302.01851v2.pdf","comment":"33 pages, 17 figures"},{"id":"http://arxiv.org/abs/2302.02924v1","updated":"2023-02-06T16:56:53Z","published":"2023-02-06T16:56:53Z","title":"Dropout Injection at Test Time for Post Hoc Uncertainty Quantification\n  in Neural Networks","summary":"  Among Bayesian methods, Monte-Carlo dropout provides principled tools for\nevaluating the epistemic uncertainty of neural networks. Its popularity\nrecently led to seminal works that proposed activating the dropout layers only\nduring inference for evaluating uncertainty. This approach, which we call\ndropout injection, provides clear benefits over its traditional counterpart\n(which we call embedded dropout) since it allows one to obtain a post hoc\nuncertainty measure for any existing network previously trained without\ndropout, avoiding an additional, time-consuming training process.\nUnfortunately, no previous work compared injected and embedded dropout;\ntherefore, we provide the first thorough investigation, focusing on regression\nproblems. The main contribution of our work is to provide guidelines on the\neffective use of injected dropout so that it can be a practical alternative to\nthe current use of embedded dropout. In particular, we show that its\neffectiveness strongly relies on a suitable scaling of the corresponding\nuncertainty measure, and we discuss the trade-off between negative\nlog-likelihood and calibration error as a function of the scale factor.\nExperimental results on UCI data sets and crowd counting benchmarks support our\nclaim that dropout injection can effectively behave as a competitive post hoc\nuncertainty quantification technique.\n","authors":["Emanuele Ledda","Giorgio Fumera","Fabio Roli"],"pdf_url":"https://arxiv.org/pdf/2302.02924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02923v1","updated":"2023-02-06T16:55:37Z","published":"2023-02-06T16:55:37Z","title":"In Search of Insights, Not Magic Bullets: Towards Demystification of the\n  Model Selection Dilemma in Heterogeneous Treatment Effect Estimation","summary":"  Personalized treatment effect estimates are often of interest in high-stakes\napplications -- thus, before deploying a model estimating such effects in\npractice, one needs to be sure that the best candidate from the ever-growing\nmachine learning toolbox for this task was chosen. Unfortunately, due to the\nabsence of counterfactual information in practice, it is usually not possible\nto rely on standard validation metrics for doing so, leading to a well-known\nmodel selection dilemma in the treatment effect estimation literature. While\nsome solutions have recently been investigated, systematic understanding of the\nstrengths and weaknesses of different model selection criteria is still\nlacking. In this paper, instead of attempting to declare a global `winner', we\ntherefore empirically investigate success- and failure modes of different\nselection criteria. We highlight that there is a complex interplay between\nselection strategies, candidate estimators and the DGP used for testing, and\nprovide interesting insights into the relative (dis)advantages of different\ncriteria alongside desiderata for the design of further illuminating empirical\nstudies in this context.\n","authors":["Alicia Curth","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2302.02923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02922v1","updated":"2023-02-06T16:54:20Z","published":"2023-02-06T16:54:20Z","title":"Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural\n  Networks","summary":"  Due to the significant computational challenge of training large-scale graph\nneural networks (GNNs), various sparse learning techniques have been exploited\nto reduce memory and storage costs. Examples include \\textit{graph\nsparsification} that samples a subgraph to reduce the amount of data\naggregation and \\textit{model sparsification} that prunes the neural network to\nreduce the number of trainable weights. Despite the empirical successes in\nreducing the training cost while maintaining the test accuracy, the theoretical\ngeneralization analysis of sparse learning for GNNs remains elusive. To the\nbest of our knowledge, this paper provides the first theoretical\ncharacterization of joint edge-model sparse learning from the perspective of\nsample complexity and convergence rate in achieving zero generalization error.\nIt proves analytically that both sampling important nodes and pruning neurons\nwith the lowest-magnitude can reduce the sample complexity and improve\nconvergence without compromising the test accuracy. Although the analysis is\ncentered on two-layer GNNs with structural constraints on data, the insights\nare applicable to more general setups and justified by both synthetic and\npractical citation datasets.\n","authors":["Shuai Zhang","Meng Wang","Pin-Yu Chen","Sijia Liu","Songtao Lu","Miao Liu"],"pdf_url":"https://arxiv.org/pdf/2302.02922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02921v1","updated":"2023-02-06T16:52:15Z","published":"2023-02-06T16:52:15Z","title":"Holistic Deep-Reinforcement-Learning-based Training of Autonomous\n  Navigation Systems","summary":"  In recent years, Deep Reinforcement Learning emerged as a promising approach\nfor autonomous navigation of ground vehicles and has been utilized in various\nareas of navigation such as cruise control, lane changing, or obstacle\navoidance. However, most research works either focus on providing an end-to-end\nsolution training the whole system using Deep Reinforcement Learning or focus\non one specific aspect such as local motion planning. This however, comes along\nwith a number of problems such as catastrophic forgetfulness, inefficient\nnavigation behavior, and non-optimal synchronization between different entities\nof the navigation stack. In this paper, we propose a holistic Deep\nReinforcement Learning training approach in which the training procedure is\ninvolving all entities of the navigation stack. This should enhance the\nsynchronization between- and understanding of all entities of the navigation\nstack and as a result, improve navigational performance. We trained several\nagents with a number of different observation spaces to study the impact of\ndifferent input on the navigation behavior of the agent. In profound\nevaluations against multiple learning-based and classic model-based navigation\napproaches, our proposed agent could outperform the baselines in terms of\nefficiency and safety attaining shorter path lengths, less roundabout paths,\nand less collisions.\n","authors":["Linh Kästner","Marvin Meusel","Teham Bhuiyan","Jens Lambrecht"],"pdf_url":"https://arxiv.org/pdf/2302.02921v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2209.12651v3","updated":"2023-02-06T16:47:52Z","published":"2022-09-26T12:53:23Z","title":"Learning Variational Models with Unrolling and Bilevel Optimization","summary":"  In this paper we consider the problem learning of variational models in the\ncontext of supervised learning via risk minimization. Our goal is to provide a\ndeeper understanding of the two approaches of learning of variational models\nvia bilevel optimization and via algorithm unrolling. The former considers the\nvariational model as a lower level optimization problem below the risk\nminimization problem, while the latter replaces the lower level optimization\nproblem by an algorithm that solves said problem approximately. Both approaches\nare used in practice, but, unrolling is much simpler from a computational point\nof view. To analyze and compare the two approaches, we consider a simple toy\nmodel, and compute all risks and the respective estimators explicitly. We show\nthat unrolling can be better than the bilevel optimization approach, but also\nthat the performance of unrolling can depend significantly on further\nparameters, sometimes in unexpected ways: While the stepsize of the unrolled\nalgorithm matters a lot, the number of unrolled iterations only matters if the\nnumber is even or odd, and these two cases are notably different.\n","authors":["Christoph Brauer","Niklas Breustedt","Timo de Wolff","Dirk A. Lorenz"],"pdf_url":"https://arxiv.org/pdf/2209.12651v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02914v1","updated":"2023-02-06T16:38:43Z","published":"2023-02-06T16:38:43Z","title":"Energy-based Out-of-Distribution Detection for Graph Neural Networks","summary":"  Learning on graphs, where instance nodes are inter-connected, has become one\nof the central problems for deep learning, as relational structures are\npervasive and induce data inter-dependence which hinders trivial adaptation of\nexisting approaches that assume inputs to be i.i.d.~sampled. However, current\nmodels mostly focus on improving testing performance of in-distribution data\nand largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing\nsamples that may cause negative outcome if the prediction is overconfident on\nthem. In this paper, we investigate the under-explored problem, OOD detection\non graph-structured data, and identify a provably effective OOD discriminator\nbased on an energy function directly extracted from graph neural networks\ntrained with standard classification loss. This paves a way for a simple,\npowerful and efficient OOD detection model for GNN-based learning on graphs,\nwhich we call GNNSafe. It also has nice theoretical properties that guarantee\nan overall distinguishable margin between the detection scores for\nin-distribution and OOD samples, which, more critically, can be further\nstrengthened by a learning-free energy belief propagation scheme. For\ncomprehensive evaluation, we introduce new benchmark settings that evaluate the\nmodel for detecting OOD data from both synthetic and real distribution shifts\n(cross-domain graph shifts and temporal graph shifts). The results show that\nGNNSafe achieves up to $17.0\\%$ AUROC improvement over state-of-the-arts and it\ncould serve as simple yet strong baselines in such an under-developed area.\n","authors":["Qitian Wu","Yiting Chen","Chenxiao Yang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2302.02914v1.pdf","comment":"Accepted by International Conference on Learning Representations\n  (ICLR 2023)"},{"id":"http://arxiv.org/abs/2211.09403v3","updated":"2023-02-06T16:38:04Z","published":"2022-11-17T08:24:13Z","title":"Learning Mixtures of Markov Chains and MDPs","summary":"  We present an algorithm for learning mixtures of Markov chains and Markov\ndecision processes (MDPs) from short unlabeled trajectories. Specifically, our\nmethod handles mixtures of Markov chains with optional control input by going\nthrough a multi-step process, involving (1) a subspace estimation step, (2)\nspectral clustering of trajectories using \"pairwise distance estimators,\" along\nwith refinement using the EM algorithm, (3) a model estimation step, and (4) a\nclassification step for predicting labels of new trajectories. We provide\nend-to-end performance guarantees, where we only explicitly require the length\nof trajectories to be linear in the number of states and the number of\ntrajectories to be linear in a mixing time parameter. Experimental results\nsupport these guarantees, where we attain 96.6% average accuracy on a mixture\nof two MDPs in gridworld, outperforming the EM algorithm with random\ninitialization (73.2% average accuracy).\n","authors":["Chinmaya Kausik","Kevin Tan","Ambuj Tewari"],"pdf_url":"https://arxiv.org/pdf/2211.09403v3.pdf","comment":"51 pages (13 page paper, 38 page appendix). Paper restructured and\n  refined, corrections made to proofs, experiments added"},{"id":"http://arxiv.org/abs/2206.01730v2","updated":"2023-02-06T16:34:38Z","published":"2022-06-01T08:43:35Z","title":"On the complexity of nonsmooth automatic differentiation","summary":"  Using the notion of conservative gradient, we provide a simple model to\nestimate the computational costs of the backward and forward modes of\nalgorithmic differentiation for a wide class of nonsmooth programs. The\noverhead complexity of the backward mode turns out to be independent of the\ndimension when using programs with locally Lipschitz semi-algebraic or\ndefinable elementary functions. This considerably extends Baur-Strassen's\nsmooth cheap gradient principle. We illustrate our results by establishing fast\nbackpropagation results of conservative gradients through feedforward neural\nnetworks with standard activation and loss functions. Nonsmooth\nbackpropagation's cheapness contrasts with concurrent forward approaches, which\nhave, to this day, dimensional-dependent worst-case overhead estimates. We\nprovide further results suggesting the superiority of backward propagation of\nconservative gradients. Indeed, we relate the complexity of computing a large\nnumber of directional derivatives to that of matrix multiplication, and we show\nthat finding two subgradients in the Clarke subdifferential of a function is an\nNP-hard problem.\n","authors":["Jérôme Bolte","Ryan Boustany","Edouard Pauwels","Béatrice Pesquet-Popescu"],"pdf_url":"https://arxiv.org/pdf/2206.01730v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02913v1","updated":"2023-02-06T16:34:16Z","published":"2023-02-06T16:34:16Z","title":"Beyond Statistical Similarity: Rethinking Metrics for Deep Generative\n  Models in Engineering Design","summary":"  Deep generative models, such as Variational Autoencoders (VAEs), Generative\nAdversarial Networks (GANs), Diffusion Models, and Transformers, have shown\ngreat promise in a variety of applications, including image and speech\nsynthesis, natural language processing, and drug discovery. However, when\napplied to engineering design problems, evaluating the performance of these\nmodels can be challenging, as traditional statistical metrics based on\nlikelihood may not fully capture the requirements of engineering applications.\nThis paper doubles as a review and a practical guide to evaluation metrics for\ndeep generative models (DGMs) in engineering design. We first summarize\nwell-accepted `classic' evaluation metrics for deep generative models grounded\nin machine learning theory and typical computer science applications. Using\ncase studies, we then highlight why these metrics seldom translate well to\ndesign problems but see frequent use due to the lack of established\nalternatives. Next, we curate a set of design-specific metrics which have been\nproposed across different research communities and can be used for evaluating\ndeep generative models. These metrics focus on unique requirements in design\nand engineering, such as constraint satisfaction, functional performance,\nnovelty, and conditioning. We structure our review and discussion as a set of\npractical selection criteria and usage guidelines. Throughout our discussion,\nwe apply the metrics to models trained on simple 2-dimensional example\nproblems. Finally, to illustrate the selection process and classic usage of the\npresented metrics, we evaluate three deep generative models on a multifaceted\nbicycle frame design problem considering performance target achievement, design\nnovelty, and geometric constraints. We publicly release the code for the\ndatasets, models, and metrics used throughout the paper at\ndecode.mit.edu/projects/metrics/.\n","authors":["Lyle Regenwetter","Akash Srivastava","Dan Gutfreund","Faez Ahmed"],"pdf_url":"https://arxiv.org/pdf/2302.02913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02910v1","updated":"2023-02-06T16:29:50Z","published":"2023-02-06T16:29:50Z","title":"An Empirical Analysis of Fairness Notions under Differential Privacy","summary":"  Recent works have shown that selecting an optimal model architecture suited\nto the differential privacy setting is necessary to achieve the best possible\nutility for a given privacy budget using differentially private stochastic\ngradient descent (DP-SGD)(Tramer and Boneh 2020; Cheng et al. 2022). In light\nof these findings, we empirically analyse how different fairness notions,\nbelonging to distinct classes of statistical fairness criteria (independence,\nseparation and sufficiency), are impacted when one selects a model architecture\nsuitable for DP-SGD, optimized for utility. Using standard datasets from ML\nfairness literature, we show using a rigorous experimental protocol, that by\nselecting the optimal model architecture for DP-SGD, the differences across\ngroups concerning the relevant fairness metrics (demographic parity, equalized\nodds and predictive parity) more often decrease or are negligibly impacted,\ncompared to the non-private baseline, for which optimal model architecture has\nalso been selected to maximize utility. These findings challenge the\nunderstanding that differential privacy will necessarily exacerbate unfairness\nin deep learning models trained on biased datasets.\n","authors":["Anderson Santana de Oliveira","Caelin Kaplan","Khawla Mallat","Tanmay Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2302.02910v1.pdf","comment":"Accepted for oral presentation at the The Fourth AAAI Workshop on\n  Privacy-Preserving Artificial Intelligence (PPAI-23)\n  https://aaai-ppai23.github.io/#accepted_papers"},{"id":"http://arxiv.org/abs/2302.02909v1","updated":"2023-02-06T16:26:29Z","published":"2023-02-06T16:26:29Z","title":"Spectral Augmentations for Graph Contrastive Learning","summary":"  Contrastive learning has emerged as a premier method for learning\nrepresentations with or without supervision. Recent studies have shown its\nutility in graph representation learning for pre-training. Despite successes,\nthe understanding of how to design effective graph augmentations that can\ncapture structural properties common to many different types of downstream\ngraphs remains incomplete. We propose a set of well-motivated graph\ntransformation operations derived via graph spectral analysis to provide a bank\nof candidates when constructing augmentations for a graph contrastive\nobjective, enabling contrastive learning to capture useful structural\nrepresentation from pre-training graph datasets. We first present a spectral\ngraph cropping augmentation that involves filtering nodes by applying\nthresholds to the eigenvalues of the leading Laplacian eigenvectors. Our second\nnovel augmentation reorders the graph frequency components in a structural\nLaplacian-derived position graph embedding. Further, we introduce a method that\nleads to improved views of local subgraphs by performing alignment via global\nrandom walk embeddings. Our experimental results indicate consistent\nimprovements in out-of-domain graph data transfer compared to state-of-the-art\ngraph contrastive learning methods, shedding light on how to design a graph\nlearner that is able to learn structural properties common to diverse graph\ntypes.\n","authors":["Amur Ghose","Yingxue Zhang","Jianye Hao","Mark Coates"],"pdf_url":"https://arxiv.org/pdf/2302.02909v1.pdf","comment":"To appear in AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.02907v1","updated":"2023-02-06T16:23:24Z","published":"2023-02-06T16:23:24Z","title":"GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks","summary":"  While leveraging additional training data is well established to improve\nadversarial robustness, it incurs the unavoidable cost of data collection and\nthe heavy computation to train models. To mitigate the costs, we propose\n\\textit{Guided Adversarial Training } (GAT), a novel adversarial training\ntechnique that exploits auxiliary tasks under a limited set of training data.\nOur approach extends single-task models into multi-task models during the\nmin-max optimization of adversarial training, and drives the loss optimization\nwith a regularization of the gradient curvature across multiple tasks. GAT\nleverages two types of auxiliary tasks: self-supervised tasks, where the labels\nare generated automatically, and domain-knowledge tasks, where human experts\nprovide additional labels. Experimentally, under limited data, GAT increases\nthe robust accuracy on CIFAR-10 up to four times (from 11% to 42% robust\naccuracy) and the robust AUC of CheXpert medical imaging dataset from 50\\% to\n83\\%. On the full CIFAR-10 dataset, GAT outperforms eight state-of-the-art\nadversarial training strategies.\n  Our large study across five datasets and six tasks demonstrates that task\naugmentation is an efficient alternative to data augmentation, and can be key\nto achieving both clean and robust performances.\n","authors":["Salah Ghamizi","Jingfeng Zhang","Maxime Cordy","Mike Papadakis","Masashi Sugiyama","Yves Le Traon"],"pdf_url":"https://arxiv.org/pdf/2302.02907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00511v2","updated":"2023-02-06T16:23:04Z","published":"2023-02-01T15:33:51Z","title":"Iterative Deepening Hyperband","summary":"  Hyperparameter optimization (HPO) is concerned with the automated search for\nthe most appropriate hyperparameter configuration (HPC) of a parameterized\nmachine learning algorithm. A state-of-the-art HPO method is Hyperband, which,\nhowever, has its own parameters that influence its performance. One of these\nparameters, the maximal budget, is especially problematic: If chosen too small,\nthe budget needs to be increased in hindsight and, as Hyperband is not\nincremental by design, the entire algorithm must be re-run. This is not only\ncostly but also comes with a loss of valuable knowledge already accumulated. In\nthis paper, we propose incremental variants of Hyperband that eliminate these\ndrawbacks, and show that these variants satisfy theoretical guarantees\nqualitatively similar to those for the original Hyperband with the \"right\"\nbudget. Moreover, we demonstrate their practical utility in experiments with\nbenchmark data sets.\n","authors":["Jasmin Brandt","Marcel Wever","Dimitrios Iliadis","Viktor Bengs","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2302.00511v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13496v4","updated":"2023-02-06T16:21:35Z","published":"2022-05-26T17:10:28Z","title":"Censored Quantile Regression Neural Networks for Distribution-Free\n  Survival Analysis","summary":"  This paper considers doing quantile regression on censored data using neural\nnetworks (NNs). This adds to the survival analysis toolkit by allowing direct\nprediction of the target variable, along with a distribution-free\ncharacterisation of uncertainty, using a flexible function approximator. We\nbegin by showing how an algorithm popular in linear models can be applied to\nNNs. However, the resulting procedure is inefficient, requiring sequential\noptimisation of an individual NN at each desired quantile. Our major\ncontribution is a novel algorithm that simultaneously optimises a grid of\nquantiles output by a single NN. To offer theoretical insight into our\nalgorithm, we show firstly that it can be interpreted as a form of\nexpectation-maximisation, and secondly that it exhibits a desirable\n`self-correcting' property. Experimentally, the algorithm produces quantiles\nthat are better calibrated than existing methods on 10 out of 12 real datasets.\n","authors":["Tim Pearce","Jong-Hyeon Jeong","Yichen Jia","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2205.13496v4.pdf","comment":"Published in NeurIPS 2022"},{"id":"http://arxiv.org/abs/2302.02904v1","updated":"2023-02-06T16:18:48Z","published":"2023-02-06T16:18:48Z","title":"Rethinking Gauss-Newton for learning over-parameterized models","summary":"  Compared to gradient descent, Gauss-Newton's method (GN) and variants are\nknown to converge faster to local optima at the expense of a higher\ncomputational cost per iteration. Still, GN is not widely used for optimizing\ndeep neural networks despite a constant effort to reduce their higher\ncomputational cost. In this work, we propose to take a step back and re-think\nthe properties of GN in light of recent advances in the dynamics of gradient\nflows of over-parameterized models and the implicit bias they induce. We first\nprove a fast global convergence result for the continuous-time limit of the\ngeneralized GN in the over-parameterized regime. We then show empirically that\nGN exhibits both a kernel regime where it generalizes as well as gradient\nflows, and a feature learning regime where GN induces an implicit bias for\nselecting global solutions that systematically under-performs those found by a\ngradient flow. Importantly, we observed this phenomenon even with enough\ncomputational budget to perform exact GN steps over the total training\nobjective. This study suggests the need to go beyond improving the\ncomputational cost of GN for over-parametrized models towards designing new\nmethods that can trade off optimization speed and the quality of their implicit\nbias.\n","authors":["Michael Arbel"],"pdf_url":"https://arxiv.org/pdf/2302.02904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02900v1","updated":"2023-02-06T16:09:27Z","published":"2023-02-06T16:09:27Z","title":"Controllable Lexical Simplification for English","summary":"  Fine-tuning Transformer-based approaches have recently shown exciting results\non sentence simplification task. However, so far, no research has applied\nsimilar approaches to the Lexical Simplification (LS) task. In this paper, we\npresent ConLS, a Controllable Lexical Simplification system fine-tuned with T5\n(a Transformer-based model pre-trained with a BERT-style approach and several\nother tasks). The evaluation results on three datasets (LexMTurk, BenchLS, and\nNNSeval) have shown that our model performs comparable to LSBert (the current\nstate-of-the-art) and even outperforms it in some cases. We also conducted a\ndetailed comparison on the effectiveness of control tokens to give a clear view\nof how each token contributes to the model.\n","authors":["Kim Cheng Sheang","Daniel Ferrés","Horacio Saggion"],"pdf_url":"https://arxiv.org/pdf/2302.02900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02898v1","updated":"2023-02-06T16:06:07Z","published":"2023-02-06T16:06:07Z","title":"Arena-Web -- A Web-based Development and Benchmarking Platform for\n  Autonomous Navigation Approaches","summary":"  In recent years, mobile robot navigation approaches have become increasingly\nimportant due to various application areas ranging from healthcare to warehouse\nlogistics. In particular, Deep Reinforcement Learning approaches have gained\npopularity for robot navigation but are not easily accessible to non-experts\nand complex to develop. In recent years, efforts have been made to make these\nsophisticated approaches accessible to a wider audience. In this paper, we\npresent Arena-Web, a web-based development and evaluation suite for developing,\ntraining, and testing DRL-based navigation planners for various robotic\nplatforms and scenarios. The interface is designed to be intuitive and engaging\nto appeal to non-experts and make the technology accessible to a wider\naudience. With Arena-Web and its interface, training and developing Deep\nReinforcement Learning agents is simplified and made easy without a single line\nof code. The web-app is free to use and openly available under the link stated\nin the supplementary materials.\n","authors":["Linh Kästner","Reyk Carstens","Christopher Liebig","Volodymyr Shcherbyna","Lena Nahrworld","Subhin Lee","Jens Lambrecht"],"pdf_url":"https://arxiv.org/pdf/2302.02898v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.02896v1","updated":"2023-02-06T16:03:38Z","published":"2023-02-06T16:03:38Z","title":"Label Assisted Autoencoder for Anomaly Detection in Power Generation\n  Plants","summary":"  One of the critical factors that drive the economic development of a country\nand guarantee the sustainability of its industries is the constant availability\nof electricity. This is usually provided by the national electric grid.\nHowever, in developing countries where companies are emerging on a constant\nbasis including telecommunication industries, those are still experiencing a\nnon-stable electricity supply. Therefore, they have to rely on generators to\nguarantee their full functionality. Those generators depend on fuel to function\nand the rate of consumption gets usually high, if not monitored properly.\nMonitoring operation is usually carried out by a (non-expert) human. In some\ncases, this could be a tedious process, as some companies have reported an\nexaggerated high consumption rate. This work proposes a label assisted\nautoencoder for anomaly detection in the fuel consumed by power generating\nplants. In addition to the autoencoder model, we added a labelling assistance\nmodule that checks if an observation is labelled, the label is used to check\nthe veracity of the corresponding anomaly classification given a threshold. A\nconsensus is then reached on whether training should stop or whether the\nthreshold should be updated or the training should continue with the search for\nhyper-parameters. Results show that the proposed model is highly efficient for\nreading anomalies with a detection accuracy of $97.20\\%$ which outperforms the\nexisting model of $96.1\\%$ accuracy trained on the same dataset. In addition,\nthe proposed model is able to classify the anomalies according to their degree\nof severity.\n","authors":["Marcellin Atemkeng","Victor Osanyindoro","Rockefeller Rockefeller","Sisipho Hamlomo","Jecinta Mulongo","Theophilus Ansah-Narh","Franklin Tchakounte","Arnaud Nguembang Fadja"],"pdf_url":"https://arxiv.org/pdf/2302.02896v1.pdf","comment":"Submitted to Journal"},{"id":"http://arxiv.org/abs/2301.11857v2","updated":"2023-02-06T15:59:53Z","published":"2023-01-27T17:05:29Z","title":"Policy-Value Alignment and Robustness in Search-based Multi-Agent\n  Learning","summary":"  Large-scale AI systems that combine search and learning have reached\nsuper-human levels of performance in game-playing, but have also been shown to\nfail in surprising ways. The brittleness of such models limits their efficacy\nand trustworthiness in real-world deployments. In this work, we systematically\nstudy one such algorithm, AlphaZero, and identify two phenomena related to the\nnature of exploration. First, we find evidence of policy-value misalignment --\nfor many states, AlphaZero's policy and value predictions contradict each\nother, revealing a tension between accurate move-selection and value estimation\nin AlphaZero's objective. Further, we find inconsistency within AlphaZero's\nvalue function, which causes it to generalize poorly, despite its policy\nplaying an optimal strategy. From these insights we derive VISA-VIS: a novel\nmethod that improves policy-value alignment and value robustness in AlphaZero.\nExperimentally, we show that our method reduces policy-value misalignment by up\nto 76%, reduces value generalization error by up to 50%, and reduces average\nvalue error by up to 55%.\n","authors":["Niko A. Grupen","Michael Hanlon","Alexis Hao","Daniel D. Lee","Bart Selman"],"pdf_url":"https://arxiv.org/pdf/2301.11857v2.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2201.05575v3","updated":"2023-02-06T15:54:51Z","published":"2022-01-14T17:35:16Z","title":"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph\n  Embeddings","summary":"  Previous knowledge graph embedding approaches usually map entities to\nrepresentations and utilize score functions to predict the target entities, yet\nthey typically struggle to reason rare or emerging unseen entities. In this\npaper, we propose kNN-KGE, a new knowledge graph embedding approach with\npre-trained language models, by linearly interpolating its entity distribution\nwith k-nearest neighbors. We compute the nearest neighbors based on the\ndistance in the entity embedding space from the knowledge store. Our approach\ncan allow rare or emerging entities to be memorized explicitly rather than\nimplicitly in model parameters. Experimental results demonstrate that our\napproach can improve inductive and transductive link prediction results and\nyield better performance for low-resource settings with only a few triples,\nwhich might be easier to reason via explicit memory. Code is available at\nhttps://github.com/zjunlp/KNN-KG.\n","authors":["Ningyu Zhang","Xin Xie","Xiang Chen","Yongheng Wang","Xu Cheng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2201.05575v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.02888v1","updated":"2023-02-06T15:53:51Z","published":"2023-02-06T15:53:51Z","title":"Findings of the TSAR-2022 Shared Task on Multilingual Lexical\n  Simplification","summary":"  We report findings of the TSAR-2022 shared task on multilingual lexical\nsimplification, organized as part of the Workshop on Text Simplification,\nAccessibility, and Readability TSAR-2022 held in conjunction with EMNLP 2022.\nThe task called the Natural Language Processing research community to\ncontribute with methods to advance the state of the art in multilingual lexical\nsimplification for English, Portuguese, and Spanish. A total of 14 teams\nsubmitted the results of their lexical simplification systems for the provided\ntest data. Results of the shared task indicate new benchmarks in Lexical\nSimplification with English lexical simplification quantitative results\nnoticeably higher than those obtained for Spanish and (Brazilian) Portuguese.\n","authors":["Horacio Saggion","Sanja Štajner","Daniel Ferrés","Kim Cheng Sheang","Matthew Shardlow","Kai North","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2302.02888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10481v2","updated":"2023-02-06T15:53:12Z","published":"2023-01-25T09:30:32Z","title":"FewShotTextGCN: K-hop neighborhood regularization for few-shot learning\n  on graphs","summary":"  We present FewShotTextGCN, a novel method designed to effectively utilize the\nproperties of word-document graphs for improved learning in low-resource\nsettings. We introduce K-hop Neighbourhood Regularization, a regularizer for\nheterogeneous graphs, and show that it stabilizes and improves learning when\nonly a few training samples are available. We furthermore propose a\nsimplification in the graph-construction method, which results in a graph that\nis $\\sim$7 times less dense and yields better performance in little-resource\nsettings while performing on par with the state of the art in high-resource\nsettings. Finally, we introduce a new variant of Adaptive Pseudo-Labeling\ntailored for word-document graphs. When using as little as 20 samples for\ntraining, we outperform a strong TextGCN baseline with 17% in absolute accuracy\non average over eight languages. We demonstrate that our method can be applied\nto document classification without any language model pretraining on a wide\nrange of typologically diverse languages while performing on par with large\npretrained language models.\n","authors":["Niels van der Heijden","Ekaterina Shutova","Helen Yannakoudakis"],"pdf_url":"https://arxiv.org/pdf/2301.10481v2.pdf","comment":"8 pages, 4 figures, EACL 2023"},{"id":"http://arxiv.org/abs/2302.02884v1","updated":"2023-02-06T15:52:03Z","published":"2023-02-06T15:52:03Z","title":"Intra-operative Brain Tumor Detection with Deep Learning-Optimized\n  Hyperspectral Imaging","summary":"  Surgery for gliomas (intrinsic brain tumors), especially when low-grade, is\nchallenging due to the infiltrative nature of the lesion. Currently, no\nreal-time, intra-operative, label-free and wide-field tool is available to\nassist and guide the surgeon to find the relevant demarcations for these\ntumors. While marker-based methods exist for the high-grade glioma case, there\nis no convenient solution available for the low-grade case; thus, marker-free\noptical techniques represent an attractive option. Although RGB imaging is a\nstandard tool in surgical microscopes, it does not contain sufficient\ninformation for tissue differentiation. We leverage the richer information from\nhyperspectral imaging (HSI), acquired with a snapscan camera in the 468-787 nm\nrange, coupled to a surgical microscope, to build a deep-learning-based\ndiagnostic tool for cancer resection with potential for intra-operative\nguidance. However, the main limitation of the HSI snapscan camera is the image\nacquisition time, limiting its widespread deployment in the operation theater.\nHere, we investigate the effect of HSI channel reduction and pre-selection to\nscope the design space for the development of cheaper and faster sensors.\nNeural networks are used to identify the most important spectral channels for\ntumor tissue differentiation, optimizing the trade-off between the number of\nchannels and precision to enable real-time intra-surgical application. We\nevaluate the performance of our method on a clinical dataset that was acquired\nduring surgery on five patients. By demonstrating the possibility to\nefficiently detect low-grade glioma, these results can lead to better cancer\nresection demarcations, potentially improving treatment effectiveness and\npatient outcome.\n","authors":["Tommaso Giannantonio","Anna Alperovich","Piercosimo Semeraro","Manfredo Atzori","Xiaohan Zhang","Christoph Hauger","Alexander Freytag","Siri Luthman","Roeland Vandebriel","Murali Jayapala","Lien Solie","Steven de Vleeschouwer"],"pdf_url":"https://arxiv.org/pdf/2302.02884v1.pdf","comment":"SPIE Photonics West 2023 conference Optical Biopsy XXI: Toward\n  Real-Time Spectroscopic Imaging and Diagnosis. 18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2302.02876v1","updated":"2023-02-06T15:43:48Z","published":"2023-02-06T15:43:48Z","title":"Variational Information Pursuit for Interpretable Predictions","summary":"  There is a growing interest in the machine learning community in developing\npredictive algorithms that are \"interpretable by design\". Towards this end,\nrecent work proposes to make interpretable decisions by sequentially asking\ninterpretable queries about data until a prediction can be made with high\nconfidence based on the answers obtained (the history). To promote short\nquery-answer chains, a greedy procedure called Information Pursuit (IP) is\nused, which adaptively chooses queries in order of information gain. Generative\nmodels are employed to learn the distribution of query-answers and labels,\nwhich is in turn used to estimate the most informative query. However, learning\nand inference with a full generative model of the data is often intractable for\ncomplex tasks. In this work, we propose Variational Information Pursuit (V-IP),\na variational characterization of IP which bypasses the need for learning\ngenerative models. V-IP is based on finding a query selection strategy and a\nclassifier that minimizes the expected cross-entropy between true and predicted\nlabels. We then demonstrate that the IP strategy is the optimal solution to\nthis problem. Therefore, instead of learning generative models, we can use our\noptimal strategy to directly pick the most informative query given any history.\nWe then develop a practical algorithm by defining a finite-dimensional\nparameterization of our strategy and classifier using deep networks and train\nthem end-to-end using our objective. Empirically, V-IP is 10-100x faster than\nIP on different Vision and NLP tasks with competitive performance. Moreover,\nV-IP finds much shorter query chains when compared to reinforcement learning\nwhich is typically used in sequential-decision-making problems. Finally, we\ndemonstrate the utility of V-IP on challenging tasks like medical diagnosis\nwhere the performance is far superior to the generative modelling approach.\n","authors":["Aditya Chattopadhyay","Kwan Ho Ryan Chan","Benjamin D. Haeffele","Donald Geman","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2302.02876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13570v5","updated":"2023-02-06T15:38:47Z","published":"2022-09-27T17:46:15Z","title":"Hierarchical Sliced Wasserstein Distance","summary":"  Sliced Wasserstein (SW) distance has been widely used in different\napplication scenarios since it can be scaled to a large number of supports\nwithout suffering from the curse of dimensionality. The value of sliced\nWasserstein distance is the average of transportation cost between\none-dimensional representations (projections) of original measures that are\nobtained by Radon Transform (RT). Despite its efficiency in the number of\nsupports, estimating the sliced Wasserstein requires a relatively large number\nof projections in high-dimensional settings. Therefore, for applications where\nthe number of supports is relatively small compared with the dimension, e.g.,\nseveral deep learning applications where the mini-batch approaches are\nutilized, the complexities from matrix multiplication of Radon Transform become\nthe main computational bottleneck. To address this issue, we propose to derive\nprojections by linearly and randomly combining a smaller number of projections\nwhich are named bottleneck projections. We explain the usage of these\nprojections by introducing Hierarchical Radon Transform (HRT) which is\nconstructed by applying Radon Transform variants recursively. We then formulate\nthe approach into a new metric between measures, named Hierarchical Sliced\nWasserstein (HSW) distance. By proving the injectivity of HRT, we derive the\nmetricity of HSW. Moreover, we investigate the theoretical properties of HSW\nincluding its connection to SW variants and its computational and sample\ncomplexities. Finally, we compare the computational cost and generative quality\nof HSW with the conventional SW on the task of deep generative modeling using\nvarious benchmark datasets including CIFAR10, CelebA, and Tiny ImageNet.\n","authors":["Khai Nguyen","Tongzheng Ren","Huy Nguyen","Litu Rout","Tan Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2209.13570v5.pdf","comment":"Accepted to ICLR 2023, 29 pages, 8 figures, 3 tables,"},{"id":"http://arxiv.org/abs/2206.00048v2","updated":"2023-02-06T15:33:18Z","published":"2022-05-31T18:28:39Z","title":"PandA: Unsupervised Learning of Parts and Appearances in the Feature\n  Maps of GANs","summary":"  Recent advances in the understanding of Generative Adversarial Networks\n(GANs) have led to remarkable progress in visual editing and synthesis tasks,\ncapitalizing on the rich semantics that are embedded in the latent spaces of\npre-trained GANs. However, existing methods are often tailored to specific GAN\narchitectures and are limited to either discovering global semantic directions\nthat do not facilitate localized control, or require some form of supervision\nthrough manually provided regions or segmentation masks. In this light, we\npresent an architecture-agnostic approach that jointly discovers factors\nrepresenting spatial parts and their appearances in an entirely unsupervised\nfashion. These factors are obtained by applying a semi-nonnegative tensor\nfactorization on the feature maps, which in turn enables context-aware local\nimage editing with pixel-level control. In addition, we show that the\ndiscovered appearance factors correspond to saliency maps that localize\nconcepts of interest, without using any labels. Experiments on a wide range of\nGAN architectures and datasets show that, in comparison to the state of the\nart, our method is far more efficient in terms of training time and, most\nimportantly, provides much more accurate localized control. Our code is\navailable at: https://github.com/james-oldfield/PandA.\n","authors":["James Oldfield","Christos Tzelepis","Yannis Panagakis","Mihalis A. Nicolaou","Ioannis Patras"],"pdf_url":"https://arxiv.org/pdf/2206.00048v2.pdf","comment":"Accepted at ICLR 2023. Code available at:\n  https://github.com/james-oldfield/PandA"},{"id":"http://arxiv.org/abs/2302.02865v1","updated":"2023-02-06T15:30:08Z","published":"2023-02-06T15:30:08Z","title":"Probabilistic Contrastive Learning Recovers the Correct Aleatoric\n  Uncertainty of Ambiguous Inputs","summary":"  Contrastively trained encoders have recently been proven to invert the\ndata-generating process: they encode each input, e.g., an image, into the true\nlatent vector that generated the image (Zimmermann et al., 2021). However,\nreal-world observations often have inherent ambiguities. For instance, images\nmay be blurred or only show a 2D view of a 3D object, so multiple latents could\nhave generated them. This makes the true posterior for the latent vector\nprobabilistic with heteroscedastic uncertainty. In this setup, we extend the\ncommon InfoNCE objective and encoders to predict latent distributions instead\nof points. We prove that these distributions recover the correct posteriors of\nthe data-generating process, including its level of aleatoric uncertainty, up\nto a rotation of the latent space. In addition to providing calibrated\nuncertainty estimates, these posteriors allow the computation of credible\nintervals in image retrieval. They comprise images with the same latent as a\ngiven query, subject to its uncertainty.\n","authors":["Michael Kirchhof","Enkelejda Kasneci","Seong Joon Oh"],"pdf_url":"https://arxiv.org/pdf/2302.02865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02860v1","updated":"2023-02-06T15:26:41Z","published":"2023-02-06T15:26:41Z","title":"Solving Maxwell's Equation in 2D with Neural Networks with Local\n  Converging Inputs","summary":"  In this paper we apply neural networks with local converging inputs (NNLCI),\noriginally introduced in [arXiv:2109.09316], to solve the two dimensional\nMaxwell's equation around perfect electric conductors (PECs). The input to the\nnetworks consist of local patches of low cost numerical solutions to the\nequation computed on two coarse grids, and the output is a more accurate\nsolution at the center of the local patch. We apply the recently developed\nsecond order finite difference method [arXiv:2209.00740] to generate the input\nand training data which captures the scattering of electromagnetic waves off of\na PEC at a given terminal time. The advantage of NNLCI is that once trained it\noffers an efficient alternative to costly high-resolution conventional\nnumerical methods; our numerical experiments indicate the computational\ncomplexity saving by a factor of $8^3$ in terms of the number of\nspatial-temporal grid points. In contrast with existing research work on\napplying neural networks to directly solve PDEs, our method takes advantage of\nthe local domain of dependence of the Maxwell's equation in the input solution\npatches, and is therefore simpler, yet still robust. We demonstrate that we can\ntrain our neural network on some PECs to predict accurate solutions to\ndifferent PECs with quite different geometries from any of the training\nexamples.\n","authors":["Harris Cobb","Hwi Lee","Yingjie Liu"],"pdf_url":"https://arxiv.org/pdf/2302.02860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09479v2","updated":"2023-02-06T15:24:37Z","published":"2023-01-23T15:22:42Z","title":"Modality-Agnostic Variational Compression of Implicit Neural\n  Representations","summary":"  We introduce a modality-agnostic neural compression algorithm based on a\nfunctional view of data and parameterised as an Implicit Neural Representation\n(INR). Bridging the gap between latent coding and sparsity, we obtain compact\nlatent representations non-linearly mapped to a soft gating mechanism. This\nallows the specialisation of a shared INR network to each data item through\nsubnetwork selection. After obtaining a dataset of such latent representations,\nwe directly optimise the rate/distortion trade-off in a modality-agnostic space\nusing neural compression. Variational Compression of Implicit Neural\nRepresentations (VC-INR) shows improved performance given the same\nrepresentational capacity pre quantisation while also outperforming previous\nquantisation schemes used for other INR techniques. Our experiments demonstrate\nstrong results over a large set of diverse modalities using the same algorithm\nwithout any modality-specific inductive biases. We show results on images,\nclimate data, 3D shapes and scenes as well as audio and video, introducing\nVC-INR as the first INR-based method to outperform codecs as well-known and\ndiverse as JPEG 2000, MP3 and AVC/HEVC on their respective modalities.\n","authors":["Jonathan Richard Schwarz","Jihoon Tack","Yee Whye Teh","Jaeho Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2301.09479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02854v1","updated":"2023-02-06T15:22:52Z","published":"2023-02-06T15:22:52Z","title":"NA-SODINN: a deep learning algorithm for exoplanet image detection based\n  on residual noise regimes","summary":"  Supervised machine learning was recently introduced in high-contrast imaging\n(HCI) through the SODINN algorithm, a convolutional neural network designed for\nexoplanet detection in angular differential imaging (ADI) data sets. The\nbenchmarking of HCI algorithms within the Exoplanet Imaging Data Challenge\n(EIDC) showed that (i) SODINN can produce a high number of false positives in\nthe final detection maps, and (ii) algorithms processing images in a more local\nmanner perform better. This work aims to improve the SODINN detection\nperformance by introducing new local processing approaches and adapting its\nlearning process accordingly. We propose NA-SODINN, a new deep learning\narchitecture that better captures image noise correlations by training an\nindependent SODINN model per noise regime over the processed frame. The\nidentification of these noise regimes is based on a novel technique, named\nPCA-pmaps, which allows to estimate the distance from the star in the image\nfrom which background noise starts to dominate over residual speckle noise.\nNA-SODINN is also fed with local discriminators, such as S/N curves, which\ncomplement spatio-temporal feature maps when training the model.Our new\napproach is tested against its predecessor, as well as two SODINN-based hybrid\nmodels and a more standard annular-PCA approach, through local ROC analysis of\nADI sequences from VLT/SPHERE and Keck/NIRC-2 instruments. Results show that\nNA-SODINN enhances SODINN in both the sensitivity and specificity, especially\nin the speckle-dominated noise regime. NA-SODINN is also benchmarked against\nthe complete set of submitted detection algorithms in EIDC, in which we show\nthat its final detection score matches or outperforms the most powerful\ndetection algorithms, reaching a performance similar to that of the Regime\nSwitching Model algorithm.\n","authors":["Carles Cantero","Olivier Absil","Carl-Henrik Dahlqvist","Marc Van Droogenbroeck"],"pdf_url":"https://arxiv.org/pdf/2302.02854v1.pdf","comment":"Submitted to A&A journal.Comments on the submitted version are\n  welcome"},{"id":"http://arxiv.org/abs/2302.02849v1","updated":"2023-02-06T15:14:58Z","published":"2023-02-06T15:14:58Z","title":"An Unsupervised Framework for Joint MRI Super Resolution and Gibbs\n  Artifact Removal","summary":"  The k-space data generated from magnetic resonance imaging (MRI) is only a\nfinite sampling of underlying signals. Therefore, MRI images often suffer from\nlow spatial resolution and Gibbs ringing artifacts. Previous studies tackled\nthese two problems separately, where super resolution methods tend to enhance\nGibbs artifacts, whereas Gibbs ringing removal methods tend to blur the images.\nIt is also a challenge that high resolution ground truth is hard to obtain in\nclinical MRI. In this paper, we propose an unsupervised learning framework for\nboth MRI super resolution and Gibbs artifacts removal without using high\nresolution ground truth. Furthermore, we propose regularization methods to\nimprove the model's generalizability across out-of-distribution MRI images. We\nevaluated our proposed methods with other state-of-the-art methods on eight MRI\ndatasets with various contrasts and anatomical structures. Our method not only\nachieves the best SR performance but also significantly reduces the Gibbs\nartifacts. Our method also demonstrates good generalizability across different\ndatasets, which is beneficial to clinical applications where training data are\nusually scarce and biased.\n","authors":["Yikang Liu","Eric Z. Chen","Xiao Chen","Terrence Chen","Shanhui Sun"],"pdf_url":"https://arxiv.org/pdf/2302.02849v1.pdf","comment":"Accepted by the 28th biennial international conference on Information\n  Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2302.02845v1","updated":"2023-02-06T15:09:34Z","published":"2023-02-06T15:09:34Z","title":"Audio Representation Learning by Distilling Video as Privileged\n  Information","summary":"  Deep audio representation learning using multi-modal audio-visual data often\nleads to a better performance compared to uni-modal approaches. However, in\nreal-world scenarios both modalities are not always available at the time of\ninference, leading to performance degradation by models trained for multi-modal\ninference. In this work, we propose a novel approach for deep audio\nrepresentation learning using audio-visual data when the video modality is\nabsent at inference. For this purpose, we adopt teacher-student knowledge\ndistillation under the framework of learning using privileged information\n(LUPI). While the previous methods proposed for LUPI use soft-labels generated\nby the teacher, in our proposed method we use embeddings learned by the teacher\nto train the student network. We integrate our method in two different\nsettings: sequential data where the features are divided into multiple segments\nthroughout time, and non-sequential data where the entire features are treated\nas one whole segment. In the non-sequential setting both the teacher and\nstudent networks are comprised of an encoder component and a task header. We\nuse the embeddings produced by the encoder component of the teacher to train\nthe encoder of the student, while the task header of the student is trained\nusing ground-truth labels. In the sequential setting, the networks have an\nadditional aggregation component that is placed between the encoder and task\nheader. We use two sets of embeddings produced by the encoder and aggregation\ncomponent of the teacher to train the student. Similar to the non-sequential\nsetting, the task header of the student network is trained using ground-truth\nlabels. We test our framework on two different audio-visual tasks, namely\nspeaker recognition and speech emotion recognition and show considerable\nimprovements over sole audio-based recognition as well as prior works that use\nLUPI.\n","authors":["Amirhossein Hajavi","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2302.02845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00895v2","updated":"2023-02-06T14:56:11Z","published":"2022-09-30T10:55:40Z","title":"On Best-Arm Identification with a Fixed Budget in Non-Parametric\n  Multi-Armed Bandits","summary":"  We lay the foundations of a non-parametric theory of best-arm identification\nin multi-armed bandits with a fixed budget T. We consider general, possibly\nnon-parametric, models D for distributions over the arms; an overarching\nexample is the model D = P(0,1) of all probability distributions over [0,1]. We\npropose upper bounds on the average log-probability of misidentifying the\noptimal arm based on information-theoretic quantities that correspond to infima\nover Kullback-Leibler divergences between some distributions in D and a given\ndistribution. This is made possible by a refined analysis of the\nsuccessive-rejects strategy of Audibert, Bubeck, and Munos (2010). We finally\nprovide lower bounds on the same average log-probability, also in terms of the\nsame new information-theoretic quantities; these lower bounds are larger when\nthe (natural) assumptions on the considered strategies are stronger. All these\nnew upper and lower bounds generalize existing bounds based, e.g., on gaps\nbetween distributions.\n","authors":["Antoine Barrier","Aurélien Garivier","Gilles Stoltz"],"pdf_url":"https://arxiv.org/pdf/2210.00895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02834v1","updated":"2023-02-06T14:52:56Z","published":"2023-02-06T14:52:56Z","title":"Uncertainty estimation for time series forecasting via Gaussian process\n  regression surrogates","summary":"  Machine learning models are widely used to solve real-world problems in\nscience and industry. To build robust models, we should quantify the\nuncertainty of the model's predictions on new data. This study proposes a new\nmethod for uncertainty estimation based on the surrogate Gaussian process\nmodel. Our method can equip any base model with an accurate uncertainty\nestimate produced by a separate surrogate. Compared to other approaches, the\nestimate remains computationally effective with training only one additional\nmodel and doesn't rely on data-specific assumptions. The only requirement is\nthe availability of the base model as a black box, which is typical.\nExperiments for challenging time-series forecasting data show that surrogate\nmodel-based methods provide more accurate confidence intervals than\nbootstrap-based methods in both medium and small-data regimes and different\nfamilies of base models, including linear regression, ARIMA, and gradient\nboosting.\n","authors":["Leonid Erlygin","Vladimir Zholobov","Valeriia Baklanova","Evgeny Sokolovskiy","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2302.02834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1701.08435v3","updated":"2023-02-06T14:49:05Z","published":"2017-01-29T21:39:05Z","title":"Transformation-Based Models of Video Sequences","summary":"  In this work we propose a simple unsupervised approach for next frame\nprediction in video. Instead of directly predicting the pixels in a frame given\npast frames, we predict the transformations needed for generating the next\nframe in a sequence, given the transformations of the past frames. This leads\nto sharper results, while using a smaller prediction model. In order to enable\na fair comparison between different video frame prediction models, we also\npropose a new evaluation protocol. We use generated frames as input to a\nclassifier trained with ground truth sequences. This criterion guarantees that\nmodels scoring high are those producing sequences which preserve discriminative\nfeatures, as opposed to merely penalizing any deviation, plausible or not, from\nthe ground truth. Our proposed approach compares favourably against more\nsophisticated ones on the UCF-101 data set, while also being more efficient in\nterms of the number of parameters and computational cost.\n","authors":["Joost van Amersfoort","Anitha Kannan","Marc'Aurelio Ranzato","Arthur Szlam","Du Tran","Soumith Chintala"],"pdf_url":"https://arxiv.org/pdf/1701.08435v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02829v1","updated":"2023-02-06T14:46:51Z","published":"2023-02-06T14:46:51Z","title":"Collective Robustness Certificates: Exploiting Interdependence in Graph\n  Neural Networks","summary":"  In tasks like node classification, image segmentation, and named-entity\nrecognition we have a classifier that simultaneously outputs multiple\npredictions (a vector of labels) based on a single input, i.e. a single graph,\nimage, or document respectively. Existing adversarial robustness certificates\nconsider each prediction independently and are thus overly pessimistic for such\ntasks. They implicitly assume that an adversary can use different perturbed\ninputs to attack different predictions, ignoring the fact that we have a single\nshared input. We propose the first collective robustness certificate which\ncomputes the number of predictions that are simultaneously guaranteed to remain\nstable under perturbation, i.e. cannot be attacked. We focus on Graph Neural\nNetworks and leverage their locality property - perturbations only affect the\npredictions in a close neighborhood - to fuse multiple single-node certificates\ninto a drastically stronger collective certificate. For example, on the\nCiteseer dataset our collective certificate for node classification increases\nthe average number of certifiable feature perturbations from $7$ to $351$.\n","authors":["Jan Schuchardt","Aleksandar Bojchevski","Johannes Gasteiger","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2302.02829v1.pdf","comment":"Accepted at ICLR 2021 (https://openreview.net/forum?id=ULQdiUTHe3y).\n  Uploaded to arxiv to fix Google Scholar indexing"},{"id":"http://arxiv.org/abs/2209.14734v3","updated":"2023-02-06T14:38:00Z","published":"2022-09-29T12:55:03Z","title":"DiGress: Discrete Denoising diffusion for graph generation","summary":"  This work introduces DiGress, a discrete denoising diffusion model for\ngenerating graphs with categorical node and edge attributes. Our model utilizes\na discrete diffusion process that progressively edits graphs with noise,\nthrough the process of adding or removing edges and changing the categories. A\ngraph transformer network is trained to revert this process, simplifying the\nproblem of distribution learning over graphs into a sequence of node and edge\nclassification tasks. We further improve sample quality by introducing a\nMarkovian noise model that preserves the marginal distribution of node and edge\ntypes during diffusion, and by incorporating auxiliary graph-theoretic\nfeatures. A procedure for conditioning the generation on graph-level features\nis also proposed. DiGress achieves state-of-the-art performance on molecular\nand non-molecular datasets, with up to 3x validity improvement on a planar\ngraph dataset. It is also the first model to scale to the large GuacaMol\ndataset containing 1.3M drug-like molecules without the use of\nmolecule-specific representations.\n","authors":["Clement Vignac","Igor Krawczuk","Antoine Siraudin","Bohan Wang","Volkan Cevher","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2209.14734v3.pdf","comment":"22 pages. Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2208.11945v2","updated":"2023-02-06T14:36:58Z","published":"2022-08-25T09:02:32Z","title":"Efficient Adaptive Activation Rounding for Post-Training Quantization","summary":"  Post-training quantization (PTQ) attracts increasing attention due to its\nconvenience in deploying quantized neural networks. Rounding is the primary\nsource of quantization error, for which previous works adopt the\nrounding-to-nearest scheme with a constant border of 0.5. This work\ndemonstrates that optimizing rounding schemes can improve model accuracy. By\nreplacing the constant border with a simple border function, we can obtain the\nminimal error for multiplying two numbers and eliminate the bias of its\nexpected value, which further benefits model accuracy. Based on this insight,\nwe approximate the border function to make the incurred overhead negligible. We\nalso jointly optimize propagated errors and global errors. We finally propose\nour AQuant framework, which can learn the border function automatically.\nExtensive experiments show that AQuant achieves noticeable improvements\ncompared with state-of-the-art works and pushes the accuracy of ResNet-18 up to\n60.31% under the 2-bit weight and activation post-training quantization.\n","authors":["Zhengyi Li","Cong Guo","Zhanda Zhu","Yangjie Zhou","Yuxian Qiu","Xiaotian Gao","Jingwen Leng","Minyi Guo"],"pdf_url":"https://arxiv.org/pdf/2208.11945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02813v1","updated":"2023-02-06T14:36:33Z","published":"2023-02-06T14:36:33Z","title":"Migration Reframed? A multilingual analysis on the stance shift in\n  Europe during the Ukrainian crisis","summary":"  The war in Ukraine seems to have positively changed the attitude toward the\ncritical societal topic of migration in Europe -- at least towards refugees\nfrom Ukraine. We investigate whether this impression is substantiated by how\nthe topic is reflected in online news and social media, thus linking the\nrepresentation of the issue on the Web to its perception in society. For this\npurpose, we combine and adapt leading-edge automatic text processing for a\nnovel multilingual stance detection approach. Starting from 5.5M Twitter posts\npublished by 565 European news outlets in one year, beginning September 2021,\nplus replies, we perform a multilingual analysis of migration-related media\ncoverage and associated social media interaction for Europe and selected\nEuropean countries.\n  The results of our analysis show that there is actually a reframing of the\ndiscussion illustrated by the terminology change, e.g., from \"migrant\" to\n\"refugee\", often even accentuated with phrases such as \"real refugees\".\nHowever, concerning a stance shift in public perception, the picture is more\ndiverse than expected. All analyzed cases show a noticeable temporal stance\nshift around the start of the war in Ukraine. Still, there are apparent\nnational differences in the size and stability of this shift.\n","authors":["Sergej Wildemann","Claudia Niederée","Erick Elejalde"],"pdf_url":"https://arxiv.org/pdf/2302.02813v1.pdf","comment":"To be published in The Web Conference 2023"},{"id":"http://arxiv.org/abs/2302.02807v1","updated":"2023-02-06T14:31:51Z","published":"2023-02-06T14:31:51Z","title":"Federated Survival Forests","summary":"  Survival analysis is a subfield of statistics concerned with modeling the\noccurrence time of a particular event of interest for a population. Survival\nanalysis found widespread applications in healthcare, engineering, and social\nsciences. However, real-world applications involve survival datasets that are\ndistributed, incomplete, censored, and confidential. In this context, federated\nlearning can tremendously improve the performance of survival analysis\napplications. Federated learning provides a set of privacy-preserving\ntechniques to jointly train machine learning models on multiple datasets\nwithout compromising user privacy, leading to a better generalization\nperformance. Despite the widespread development of federated learning in recent\nAI research, only a few studies focus on federated survival analysis. In this\nwork, we present a novel federated algorithm for survival analysis based on one\nof the most successful survival models, the random survival forest. We call the\nproposed method Federated Survival Forest (FedSurF). With a single\ncommunication round, FedSurF obtains a discriminative power comparable to\ndeep-learning-based federated models trained over hundreds of federated\niterations. Moreover, FedSurF retains all the advantages of random forests,\nnamely low computational cost and natural handling of missing values and\nincomplete datasets. These advantages are especially desirable in real-world\nfederated environments with multiple small datasets stored on devices with low\ncomputational capabilities. Numerical experiments compare FedSurF with\nstate-of-the-art survival models in federated networks, showing how FedSurF\noutperforms deep-learning-based federated algorithms in realistic environments\nwith non-identically distributed data.\n","authors":["Alberto Archetti","Matteo Matteucci"],"pdf_url":"https://arxiv.org/pdf/2302.02807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02804v1","updated":"2023-02-06T14:28:49Z","published":"2023-02-06T14:28:49Z","title":"Stop overkilling simple tasks with black-box models and use transparent\n  models instead","summary":"  In recent years, the employment of deep learning methods has led to several\nsignificant breakthroughs in artificial intelligence. Different from\ntraditional machine learning models, deep learning-based approaches are able to\nextract features autonomously from raw data. This allows for bypassing the\nfeature engineering process, which is generally considered to be both\nerror-prone and tedious. Moreover, deep learning strategies often outperform\ntraditional models in terms of accuracy.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2302.02804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02792v1","updated":"2023-02-06T14:10:53Z","published":"2023-02-06T14:10:53Z","title":"Dealing With Non-stationarity in Decentralized Cooperative Multi-Agent\n  Deep Reinforcement Learning via Multi-Timescale Learning","summary":"  Decentralized cooperative multi-agent deep reinforcement learning (MARL) can\nbe a versatile learning framework, particularly in scenarios where centralized\ntraining is either not possible or not practical. One of the key challenges in\ndecentralized deep MARL is the non-stationarity of the learning environment\nwhen multiple agents are learning concurrently. A commonly used and efficient\nscheme for decentralized MARL is independent learning in which agents\nconcurrently update their policies independent of each other. We first show\nthat independent learning does not always converge, while sequential learning\nwhere agents update their policies one after another in a sequence is\nguaranteed to converge to an agent-by-agent optimal solution. In sequential\nlearning, when one agent updates its policy, all other agent's policies are\nkept fixed, alleviating the challenge of non-stationarity due to concurrent\nupdates in other agents' policies. However, it can be slow because only one\nagent is learning at any time. Therefore it might also not always be practical.\nIn this work, we propose a decentralized cooperative MARL algorithm based on\nmulti-timescale learning. In multi-timescale learning, all agents learn\nconcurrently, but at different learning rates. In our proposed method, when one\nagent updates its policy, other agents are allowed to update their policies as\nwell, but at a slower rate. This speeds up sequential learning, while also\nminimizing non-stationarity caused by other agents updating concurrently.\nMulti-timescale learning outperforms state-of-the-art decentralized learning\nmethods on a set of challenging multi-agent cooperative tasks in the epymarl\n(papoudakis2020) benchmark. This can be seen as a first step towards more\ngeneral decentralized cooperative deep MARL methods based on multi-timescale\nlearning.\n","authors":["Hadi Nekoei","Akilesh Badrinaaraayanan","Amit Sinha","Mohammad Amini","Janarthanan Rajendran","Aditya Mahajan","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2302.02792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02788v1","updated":"2023-02-06T14:03:33Z","published":"2023-02-06T14:03:33Z","title":"A Strong Baseline for Batch Imitation Learning","summary":"  Imitation of expert behaviour is a highly desirable and safe approach to the\nproblem of sequential decision making. We provide an easy-to-implement, novel\nalgorithm for imitation learning under a strict data paradigm, in which the\nagent must learn solely from data collected a priori. This paradigm allows our\nalgorithm to be used for environments in which safety or cost are of critical\nconcern. Our algorithm requires no additional hyper-parameter tuning beyond any\nstandard batch reinforcement learning (RL) algorithm, making it an ideal\nbaseline for such data-strict regimes. Furthermore, we provide formal sample\ncomplexity guarantees for the algorithm in finite Markov Decision Problems. In\ndoing so, we formally demonstrate an unproven claim from Kearns & Singh (1998).\nOn the empirical side, our contribution is twofold. First, we develop a\npractical, robust and principled evaluation protocol for offline RL methods,\nmaking use of only the dataset provided for model selection. This stands in\ncontrast to the vast majority of previous works in offline RL, which tune\nhyperparameters on the evaluation environment, limiting the practical\napplicability when deployed in new, cost-critical environments. As such, we\nestablish precedent for the development and fair evaluation of offline RL\nalgorithms. Second, we evaluate our own algorithm on challenging continuous\ncontrol benchmarks, demonstrating its practical applicability and\ncompetitiveness with state-of-the-art performance, despite being a simpler\nalgorithm.\n","authors":["Matthew Smith","Lucas Maystre","Zhenwen Dai","Kamil Ciosek"],"pdf_url":"https://arxiv.org/pdf/2302.02788v1.pdf","comment":"28 pages (10 main, 18 appendix), 4 figures"},{"id":"http://arxiv.org/abs/2302.02787v1","updated":"2023-02-06T14:02:28Z","published":"2023-02-06T14:02:28Z","title":"Generative models for two-ground-truth partitions in networks","summary":"  A myriad of approaches have been proposed to characterise the mesoscale\nstructure of networks - most often as a partition based on patterns variously\ncalled communities, blocks, or clusters. Clearly, distinct methods designed to\ndetect different types of patterns may provide a variety of answers to the\nnetwork's mesoscale structure. Yet, even multiple runs of a given method can\nsometimes yield diverse and conflicting results, yielding entire landscapes of\npartitions which potentially include multiple (locally optimal) mesoscale\nexplanations of the network. Such ambiguity motivates a closer look at the\nability of these methods to find multiple qualitatively different 'ground\ntruth' partitions in a network. Here, we propose a generative model which\nallows for two distinct partitions to be built into the mesoscale structure of\na single benchmark network. We demonstrate a use case of the benchmark model by\nexploring the power of stochastic block models (SBMs) to detect coexisting\nbi-community and core-periphery structures of different strengths. We find that\nthe ability to detect the two partitions individually varies considerably by\nSBM variant and that coexistence of both partitions is recovered only in a very\nlimited number of cases. Our findings suggest that in most instances only one -\nin some way dominating - structure can be detected, even in the presence of\nother partitions in the generated network. They underline the need for\nconsidering entire landscapes of partitions when different competing\nexplanations exist and motivate future research to advance partition\ncoexistence detection methods. Our model also contributes to the field of\nbenchmark networks more generally by enabling further exploration of the\nability of new and existing methods to detect ambiguity in mesoscale structure\nof networks.\n","authors":["Lena Mangold","Camille Roth"],"pdf_url":"https://arxiv.org/pdf/2302.02787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07874v3","updated":"2023-02-06T13:57:57Z","published":"2022-07-16T08:21:55Z","title":"Model-Aware Contrastive Learning: Towards Escaping the Dilemmas","summary":"  Contrastive learning (CL) continuously achieves significant breakthroughs\nacross multiple domains. However, the most common InfoNCE based methods suffer\nfrom some existing dilemmas, e.g., uniformity-tolerance dilemma (UTD) and the\ngradient reduction. It has been identified that UTD can lead to unexpected\nperformance degradation. We argue that the fixity of temperature is to blame\nfor UTD. To tackle this challenge, we enrich the CL loss family by presenting a\nModel-Aware Contrastive Learning (MACL) strategy, whose temperature is adaptive\nto the magnitude of alignment that reflects the basic confidence of the\ninstance discrimination task, then enables CL loss to adjust the penalty\nstrength for hard negatives adaptively. Regarding another dilemma, the gradient\nreduction issue, we derive the limits of an involved gradient scaling factor,\nwhich allows us to explain from a unified perspective why some recent\napproaches are effective with fewer negative samples, and summarily present a\ngradient reweighting to escape this dilemma. Extensive remarkable empirical\nresults in vision, sentence, and graph modality validate our approach's general\nimprovement for representation learning and downstream tasks.\n","authors":["Zizheng Huang","Haoxing Chen","Ziqi Wen","Chao Zhang","Huaxiong Li","Bo Wang","Chunlin Chen"],"pdf_url":"https://arxiv.org/pdf/2207.07874v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.01128v2","updated":"2023-02-06T13:57:34Z","published":"2021-06-02T12:50:56Z","title":"Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and\n  Costs","summary":"  The ability to align points across two related yet incomparable point clouds\n(e.g. living in different spaces) plays an important role in machine learning.\nThe Gromov-Wasserstein (GW) framework provides an increasingly popular answer\nto such problems, by seeking a low-distortion, geometry-preserving assignment\nbetween these points. As a non-convex, quadratic generalization of optimal\ntransport (OT), GW is NP-hard. While practitioners often resort to solving GW\napproximately as a nested sequence of entropy-regularized OT problems, the\ncubic complexity (in the number $n$ of samples) of that approach is a\nroadblock. We show in this work how a recent variant of the OT problem that\nrestricts the set of admissible couplings to those having a low-rank\nfactorization is remarkably well suited to the resolution of GW: when applied\nto GW, we show that this approach is not only able to compute a stationary\npoint of the GW problem in time $O(n^2)$, but also uniquely positioned to\nbenefit from the knowledge that the initial cost matrices are low-rank, to\nyield a linear time $O(n)$ GW approximation. Our approach yields similar\nresults, yet orders of magnitude faster computation than the SoTA entropic GW\napproaches, on both simulated and real data.\n","authors":["Meyer Scetbon","Gabriel Peyré","Marco Cuturi"],"pdf_url":"https://arxiv.org/pdf/2106.01128v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02780v1","updated":"2023-02-06T13:50:57Z","published":"2023-02-06T13:50:57Z","title":"Coherence and Diversity through Noise: Self-Supervised Paraphrase\n  Generation via Structure-Aware Denoising","summary":"  In this paper, we propose SCANING, an unsupervised framework for paraphrasing\nvia controlled noise injection. We focus on the novel task of paraphrasing\nalgebraic word problems having practical applications in online pedagogy as a\nmeans to reduce plagiarism as well as ensure understanding on the part of the\nstudent instead of rote memorization. This task is more complex than\nparaphrasing general-domain corpora due to the difficulty in preserving\ncritical information for solution consistency of the paraphrased word problem,\nmanaging the increased length of the text and ensuring diversity in the\ngenerated paraphrase. Existing approaches fail to demonstrate adequate\nperformance on at least one, if not all, of these facets, necessitating the\nneed for a more comprehensive solution. To this end, we model the noising\nsearch space as a composition of contextual and syntactic aspects and sample\nnoising functions consisting of either one or both aspects. This allows for\nlearning a denoising function that operates over both aspects and produces\nsemantically equivalent and syntactically diverse outputs through grounded\nnoise injection. The denoising function serves as a foundation for learning a\nparaphrasing function which operates solely in the input-paraphrase space\nwithout carrying any direct dependency on noise. We demonstrate SCANING\nconsiderably improves performance in terms of both semantic preservation and\nproducing diverse paraphrases through extensive automated and manual evaluation\nacross 4 datasets.\n","authors":["Rishabh Gupta","Venktesh V.","Mukesh Mohania","Vikram Goyal"],"pdf_url":"https://arxiv.org/pdf/2302.02780v1.pdf","comment":"12 pages (main}; 22 pages in total"},{"id":"http://arxiv.org/abs/2302.02774v1","updated":"2023-02-06T13:42:14Z","published":"2023-02-06T13:42:14Z","title":"The SSL Interplay: Augmentations, Inductive Bias, and Generalization","summary":"  Self-supervised learning (SSL) has emerged as a powerful framework to learn\nrepresentations from raw data without supervision. Yet in practice, engineers\nface issues such as instability in tuning optimizers and collapse of\nrepresentations during training. Such challenges motivate the need for a theory\nto shed light on the complex interplay between the choice of data augmentation,\nnetwork architecture, and training algorithm. We study such an interplay with a\nprecise analysis of generalization performance on both pretraining and\ndownstream tasks in a theory friendly setup, and highlight several insights for\nSSL practitioners that arise from our theory.\n","authors":["Vivien Cabannes","Bobak T. Kiani","Randall Balestriero","Yann LeCun","Alberto Bietti"],"pdf_url":"https://arxiv.org/pdf/2302.02774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15081v5","updated":"2023-02-06T13:38:19Z","published":"2022-11-28T05:54:24Z","title":"Flip Initial Features: Generalization of Neural Networks Under Sparse\n  Features for Semi-supervised Node Classification","summary":"  Graph neural networks (GNNs) have been widely used under semi-supervised\nsettings. Prior studies have mainly focused on finding appropriate graph\nfilters (e.g., aggregation schemes) to generalize well for both homophilic and\nheterophilic graphs. Even though these approaches are essential and effective,\nthey still suffer from the sparsity in initial node features inherent in the\nbag-of-words representation. Common in semi-supervised learning where the\ntraining samples often fail to cover the entire dimensions of graph filters\n(hyperplanes), this can precipitate over-fitting of specific dimensions in the\nfirst projection matrix. To deal with this problem, we suggest a simple and\nnovel strategy; create additional space by flipping the initial features and\nhyperplane simultaneously. Training in both the original and in the flip space\ncan provide precise updates of learnable parameters. To the best of our\nknowledge, this is the first attempt that effectively moderates the overfitting\nproblem in GNN. Extensive experiments on real-world datasets demonstrate that\nthe proposed technique improves the node classification accuracy up to 40.2 %\n","authors":["Yoonhyuk Choi","Jiho Choi","Taewook Ko","Chong-Kwon Kim"],"pdf_url":"https://arxiv.org/pdf/2211.15081v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.09159v5","updated":"2023-02-06T13:33:53Z","published":"2021-03-16T15:56:57Z","title":"Learning to Shape Rewards using a Game of Two Partners","summary":"  Reward shaping (RS) is a powerful method in reinforcement learning (RL) for\novercoming the problem of sparse or uninformative rewards. However, RS\ntypically relies on manually engineered shaping-reward functions whose\nconstruction is time-consuming and error-prone. It also requires domain\nknowledge which runs contrary to the goal of autonomous learning. We introduce\nReinforcement Learning Optimising Shaping Algorithm (ROSA), an automated reward\nshaping framework in which the shaping-reward function is constructed in a\nMarkov game between two agents. A reward-shaping agent (Shaper) uses switching\ncontrols to determine which states to add shaping rewards for more efficient\nlearning while the other agent (Controller) learns the optimal policy for the\ntask using these shaped rewards. We prove that ROSA, which adopts existing RL\nalgorithms, learns to construct a shaping-reward function that is beneficial to\nthe task thus ensuring efficient convergence to high performance policies. We\ndemonstrate ROSA's properties in three didactic experiments and show its\nsuperior performance against state-of-the-art RS algorithms in challenging\nsparse reward environments.\n","authors":["David Mguni","Taher Jafferjee","Jianhong Wang","Nicolas Perez-Nieves","Tianpei Yang","Matthew Taylor","Wenbin Song","Feifei Tong","Hui Chen","Jiangcheng Zhu","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2103.09159v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02766v1","updated":"2023-02-06T13:24:48Z","published":"2023-02-06T13:24:48Z","title":"Generalization Bounds with Data-dependent Fractal Dimensions","summary":"  Providing generalization guarantees for modern neural networks has been a\ncrucial task in statistical learning. Recently, several studies have attempted\nto analyze the generalization error in such settings by using tools from\nfractal geometry. While these works have successfully introduced new\nmathematical tools to apprehend generalization, they heavily rely on a\nLipschitz continuity assumption, which in general does not hold for neural\nnetworks and might make the bounds vacuous. In this work, we address this issue\nand prove fractal geometry-based generalization bounds without requiring any\nLipschitz assumption. To achieve this goal, we build up on a classical covering\nargument in learning theory and introduce a data-dependent fractal dimension.\nDespite introducing a significant amount of technical complications, this new\nnotion lets us control the generalization error (over either fixed or random\nhypothesis spaces) along with certain mutual information (MI) terms. To provide\na clearer interpretation to the newly introduced MI terms, as a next step, we\nintroduce a notion of \"geometric stability\" and link our bounds to the prior\nart. Finally, we make a rigorous connection between the proposed data-dependent\ndimension and topological data analysis tools, which then enables us to compute\nthe dimension in a numerically efficient way. We support our theory with\nexperiments conducted on various settings.\n","authors":["Benjamin Dupuis","George Deligiannidis","Umut Şimşekli"],"pdf_url":"https://arxiv.org/pdf/2302.02766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05981v3","updated":"2023-02-06T13:11:44Z","published":"2022-06-13T09:04:32Z","title":"Efficient Human-in-the-loop System for Guiding DNNs Attention","summary":"  Attention guidance is an approach to addressing dataset bias in deep\nlearning, where the model relies on incorrect features to make decisions.\nFocusing on image classification tasks, we propose an efficient\nhuman-in-the-loop system to interactively direct the attention of classifiers\nto the regions specified by users, thereby reducing the influence of\nco-occurrence bias and improving the transferability and interpretability of a\nDNN. Previous approaches for attention guidance require the preparation of\npixel-level annotations and are not designed as interactive systems. We present\na new interactive method to allow users to annotate images with simple clicks,\nand study a novel active learning strategy to significantly reduce the number\nof annotations. We conducted both a numerical evaluation and a user study to\nevaluate the proposed system on multiple datasets. Compared to the existing\nnon-active-learning approach which usually relies on huge amounts of\npolygon-based segmentation masks to fine-tune or train the DNNs, our system can\nsave lots of labor and money and obtain a fine-tuned network that works better\neven when the dataset is biased. The experiment results indicate that the\nproposed system is efficient, reasonable, and reliable.\n","authors":["Yi He","Xi Yang","Chia-Ming Chang","Haoran Xie","Takeo Igarashi"],"pdf_url":"https://arxiv.org/pdf/2206.05981v3.pdf","comment":"13 pages, 11 figures, proceeding of ACM IUI 2023, video\n  https://youtu.be/2MD-z6vXKJ4"},{"id":"http://arxiv.org/abs/2302.02755v1","updated":"2023-02-06T13:05:55Z","published":"2023-02-06T13:05:55Z","title":"Fine-Grained Action Detection with RGB and Pose Information using Two\n  Stream Convolutional Networks","summary":"  As participants of the MediaEval 2022 Sport Task, we propose a two-stream\nnetwork approach for the classification and detection of table tennis strokes.\nEach stream is a succession of 3D Convolutional Neural Network (CNN) blocks\nusing attention mechanisms. Each stream processes different 4D inputs. Our\nmethod utilizes raw RGB data and pose information computed from MMPose toolbox.\nThe pose information is treated as an image by applying the pose either on a\nblack background or on the original RGB frame it has been computed from. Best\nperformance is obtained by feeding raw RGB data to one stream, Pose + RGB\n(PRGB) information to the other stream and applying late fusion on the\nfeatures. The approaches were evaluated on the provided TTStroke-21 data sets.\nWe can report an improvement in stroke classification, reaching 87.3% of\naccuracy, while the detection does not outperform the baseline but still\nreaches an IoU of 0.349 and mAP of 0.110.\n","authors":["Leonard Hacker","Finn Bartels","Pierre-Etienne Martin"],"pdf_url":"https://arxiv.org/pdf/2302.02755v1.pdf","comment":"Working note paper of the sport task of MediaEval 2022 in Bergen,\n  Norway, 12-13 Jan 2023"},{"id":"http://arxiv.org/abs/2302.01680v2","updated":"2023-02-06T13:02:12Z","published":"2023-02-03T12:02:54Z","title":"Two-Stage Constrained Actor-Critic for Short Video Recommendation","summary":"  The wide popularity of short videos on social media poses new opportunities\nand challenges to optimize recommender systems on the video-sharing platforms.\nUsers sequentially interact with the system and provide complex and\nmulti-faceted responses, including watch time and various types of interactions\nwith multiple videos. One the one hand, the platforms aims at optimizing the\nusers' cumulative watch time (main goal) in long term, which can be effectively\noptimized by Reinforcement Learning. On the other hand, the platforms also\nneeds to satisfy the constraint of accommodating the responses of multiple user\ninteractions (auxiliary goals) such like, follow, share etc. In this paper, we\nformulate the problem of short video recommendation as a Constrained Markov\nDecision Process (CMDP). We find that traditional constrained reinforcement\nlearning algorithms can not work well in this setting. We propose a novel\ntwo-stage constrained actor-critic method: At stage one, we learn individual\npolicies to optimize each auxiliary signal. At stage two, we learn a policy to\n(i) optimize the main signal and (ii) stay close to policies learned at the\nfirst stage, which effectively guarantees the performance of this main policy\non the auxiliaries. Through extensive offline evaluations, we demonstrate\neffectiveness of our method over alternatives in both optimizing the main goal\nas well as balancing the others. We further show the advantage of our method in\nlive experiments of short video recommendations, where it significantly\noutperforms other baselines in terms of both watch time and interactions. Our\napproach has been fully launched in the production system to optimize user\nexperiences on the platform.\n","authors":["Qingpeng Cai","Zhenghai Xue","Chi Zhang","Wanqi Xue","Shuchang Liu","Ruohan Zhan","Xueliang Wang","Tianyou Zuo","Wentao Xie","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01680v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.13248"},{"id":"http://arxiv.org/abs/2302.02752v1","updated":"2023-02-06T12:58:01Z","published":"2023-02-06T12:58:01Z","title":"Baseline Method for the Sport Task of MediaEval 2022 with 3D CNNs using\n  Attention Mechanisms","summary":"  This paper presents the baseline method proposed for the Sports Video task\npart of the MediaEval 2022 benchmark. This task proposes two subtasks: stroke\nclassification from trimmed videos, and stroke detection from untrimmed videos.\nThis baseline addresses both subtasks. We propose two types of 3D-CNN\narchitectures to solve the two subtasks. Both 3D-CNNs use Spatio-temporal\nconvolutions and attention mechanisms. The architectures and the training\nprocess are tailored to solve the addressed subtask. This baseline method is\nshared publicly online to help the participants in their investigation and\nalleviate eventually some aspects of the task such as video processing,\ntraining method, evaluation and submission routine. The baseline method reaches\n86.4% of accuracy with our v2 model for the classification subtask. For the\ndetection subtask, the baseline reaches a mAP of 0.131 and IoU of 0.515 with\nour v1 model.\n","authors":["Pierre-Etienne Martin"],"pdf_url":"https://arxiv.org/pdf/2302.02752v1.pdf","comment":"Baseline paper for the sport Task of MediaEval 2022"},{"id":"http://arxiv.org/abs/2302.02738v1","updated":"2023-02-06T12:28:35Z","published":"2023-02-06T12:28:35Z","title":"INCREASE: Inductive Graph Representation Learning for Spatio-Temporal\n  Kriging","summary":"  Spatio-temporal kriging is an important problem in web and social\napplications, such as Web or Internet of Things, where things (e.g., sensors)\nconnected into a web often come with spatial and temporal properties. It aims\nto infer knowledge for (the things at) unobserved locations using the data from\n(the things at) observed locations during a given time period of interest. This\nproblem essentially requires \\emph{inductive learning}. Once trained, the model\nshould be able to perform kriging for different locations including newly given\nones, without retraining. However, it is challenging to perform accurate\nkriging results because of the heterogeneous spatial relations and diverse\ntemporal patterns. In this paper, we propose a novel inductive graph\nrepresentation learning model for spatio-temporal kriging. We first encode\nheterogeneous spatial relations between the unobserved and observed locations\nby their spatial proximity, functional similarity, and transition probability.\nBased on each relation, we accurately aggregate the information of most\ncorrelated observed locations to produce inductive representations for the\nunobserved locations, by jointly modeling their similarities and differences.\nThen, we design relation-aware gated recurrent unit (GRU) networks to\nadaptively capture the temporal correlations in the generated sequence\nrepresentations for each relation. Finally, we propose a multi-relation\nattention mechanism to dynamically fuse the complex spatio-temporal information\nat different time steps from multiple relations to compute the kriging output.\nExperimental results on three real-world datasets show that our proposed model\noutperforms state-of-the-art methods consistently, and the advantage is more\nsignificant when there are fewer observed locations. Our code is available at\nhttps://github.com/zhengchuanpan/INCREASE.\n","authors":["Chuanpan Zheng","Xiaoliang Fan","Cheng Wang","Jianzhong Qi","Chaochao Chen","Longbiao Chen"],"pdf_url":"https://arxiv.org/pdf/2302.02738v1.pdf","comment":"WWW 2023 paper"},{"id":"http://arxiv.org/abs/2211.10976v3","updated":"2023-02-06T12:26:54Z","published":"2022-11-20T13:12:33Z","title":"Federated deep transfer learning for EEG decoding using multiple BCI\n  tasks","summary":"  Deep learning has been successful in BCI decoding. However, it is very\ndata-hungry and requires pooling data from multiple sources. EEG data from\nvarious sources decrease the decoding performance due to negative transfer.\nRecently, transfer learning for EEG decoding has been suggested as a remedy and\nbecome subject to recent BCI competitions (e.g. BEETL), but there are two\ncomplications in combining data from many subjects. First, privacy is not\nprotected as highly personal brain data needs to be shared (and copied across\nincreasingly tight information governance boundaries). Moreover, BCI data are\ncollected from different sources and are often based on different BCI tasks,\nwhich has been thought to limit their reusability. Here, we demonstrate a\nfederated deep transfer learning technique, the Multi-dataset Federated\nSeparate-Common-Separate Network (MF-SCSN) based on our previous work of SCSN,\nwhich integrates privacy-preserving properties into deep transfer learning to\nutilise data sets with different tasks. This framework trains a BCI decoder\nusing different source data sets obtained from different imagery tasks (e.g.\nsome data sets with hands and feet, vs others with single hands and tongue,\netc). Therefore, by introducing privacy-preserving transfer learning\ntechniques, we unlock the reusability and scalability of existing BCI data\nsets. We evaluated our federated transfer learning method on the NeurIPS 2021\nBEETL competition BCI task. The proposed architecture outperformed the baseline\ndecoder by 3%. Moreover, compared with the baseline and other transfer learning\nalgorithms, our method protects the privacy of the brain data from different\ndata centres.\n","authors":["Xiaoxi Wei","A. Aldo Faisal"],"pdf_url":"https://arxiv.org/pdf/2211.10976v3.pdf","comment":"4 pages, 3 figures"},{"id":"http://arxiv.org/abs/2210.04878v2","updated":"2023-02-06T12:26:37Z","published":"2022-10-10T17:50:42Z","title":"Translate First Reorder Later: Leveraging Monotonicity in Semantic\n  Parsing","summary":"  Prior work in semantic parsing has shown that conventional seq2seq models\nfail at compositional generalization tasks. This limitation led to a resurgence\nof methods that model alignments between sentences and their corresponding\nmeaning representations, either implicitly through latent variables or\nexplicitly by taking advantage of alignment annotations. We take the second\ndirection and propose TPOL, a two-step approach that first translates input\nsentences monotonically and then reorders them to obtain the correct output.\nThis is achieved with a modular framework comprising a Translator and a\nReorderer component. We test our approach on two popular semantic parsing\ndatasets. Our experiments show that by means of the monotonic translations,\nTPOL can learn reliable lexico-logical patterns from aligned data,\nsignificantly improving compositional generalization both over conventional\nseq2seq models, as well as over other approaches that exploit gold alignments.\n","authors":["Francesco Cazzaro","Davide Locatelli","Ariadna Quattoni","Xavier Carreras"],"pdf_url":"https://arxiv.org/pdf/2210.04878v2.pdf","comment":"Accepted at Findings of ACL: EACL 2023. 8 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.02731v1","updated":"2023-02-06T12:16:36Z","published":"2023-02-06T12:16:36Z","title":"Root Laplacian Eigenmaps with their application in spectral embedding","summary":"  The root laplacian operator or the square root of Laplacian which can be\nobtained in complete Riemannian manifolds in the Gromov sense has an analog in\ngraph theory as a square root of graph-Laplacian. Some potential applications\nhave been shown in geometric deep learning (spectral clustering) and graph\nsignal processing.\n","authors":["Shouvik Datta Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.02731v1.pdf","comment":"21 pages,4 figures"},{"id":"http://arxiv.org/abs/2301.13819v2","updated":"2023-02-06T12:03:38Z","published":"2023-01-24T19:23:38Z","title":"Causal-Discovery Performance of ChatGPT in the context of Neuropathic\n  Pain Diagnosis","summary":"  ChatGPT has demonstrated exceptional proficiency in natural language\nconversation, e.g., it can answer a wide range of questions while no previous\nlarge language models can. Thus, we would like to push its limit and explore\nits ability to answer causal discovery questions by using a medical benchmark\n(Tu et al. 2019) in causal discovery.\n","authors":["Ruibo Tu","Chao Ma","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02721v1","updated":"2023-02-06T11:57:45Z","published":"2023-02-06T11:57:45Z","title":"Multipath agents for modular multitask ML systems","summary":"  A standard ML model is commonly generated by a single method that specifies\naspects such as architecture, initialization, training data and hyperparameters\nconfiguration. The presented work introduces a novel methodology allowing to\ndefine multiple methods as distinct agents. Agents can collaborate and compete\nto generate and improve ML models for a given tasks. The proposed methodology\nis demonstrated with the generation and extension of a dynamic modular\nmultitask ML system solving more than one hundred image classification tasks.\nDiverse agents can compete to produce the best performing model for a task by\nreusing the modules introduced to the system by competing agents. The presented\nwork focuses on the study of agents capable of: 1) reusing the modules\ngenerated by concurrent agents, 2) activating in parallel multiple modules in a\nfrozen state by connecting them with trainable modules, 3) condition the\nactivation mixture on each data sample by using a trainable router module. We\ndemonstrate that this simple per-sample parallel routing method can boost the\nquality of the combined solutions by training a fraction of the activated\nparameters.\n","authors":["Andrea Gesmundo"],"pdf_url":"https://arxiv.org/pdf/2302.02721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02714v1","updated":"2023-02-06T11:41:14Z","published":"2023-02-06T11:41:14Z","title":"Differentiable Programming of Chemical Reaction Networks","summary":"  We present a differentiable formulation of abstract chemical reaction\nnetworks (CRNs) that can be trained to solve a variety of computational tasks.\nChemical reaction networks are one of the most fundamental computational\nsubstrates used by nature. We study well-mixed single-chamber systems, as well\nas systems with multiple chambers separated by membranes, under mass-action\nkinetics. We demonstrate that differentiable optimisation, combined with proper\nregularisation, can discover non-trivial sparse reaction networks that can\nimplement various sorts of oscillators and other chemical computing devices.\n","authors":["Alexander Mordvintsev","Ettore Randazzo","Eyvind Niklasson"],"pdf_url":"https://arxiv.org/pdf/2302.02714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02713v1","updated":"2023-02-06T11:40:44Z","published":"2023-02-06T11:40:44Z","title":"Flat Seeking Bayesian Neural Networks","summary":"  Bayesian Neural Networks (BNNs) offer a probabilistic interpretation for deep\nlearning models by imposing a prior distribution over model parameters and\ninferencing a posterior distribution based on observed data. The model sampled\nfrom the posterior distribution can be used for providing ensemble predictions\nand quantifying prediction uncertainty. It is well-known that deep learning\nmodels with a lower sharpness have a better generalization ability.\nNonetheless, existing posterior inferences are not aware of sharpness/flatness,\nhence possibly leading to high sharpness for the models sampled from it. In\nthis paper, we develop theories, the Bayesian setting, and the variational\ninference approach for the sharpness-aware posterior. Specifically, the models\nsampled from our sharpness-aware posterior and the optimal approximate\nposterior estimating this sharpness-aware posterior have a better flatness,\nhence possibly possessing a higher generalization ability. We conduct\nexperiments by leveraging the sharpness-aware posterior with the\nstate-of-the-art Bayesian Neural Networks, showing that the flat-seeking\ncounterparts outperform their baselines in all metrics of interest.\n","authors":["Van-Anh Nguyen","Tung-Long Vuong","Hoang Phan","Thanh-Toan Do","Dinh Phung","Trung Le"],"pdf_url":"https://arxiv.org/pdf/2302.02713v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.02711v1","updated":"2023-02-06T11:37:06Z","published":"2023-02-06T11:37:06Z","title":"Network-Aided Intelligent Traffic Steering in 6G ORAN: A Multi-Layer\n  Optimization Framework","summary":"  To enable an intelligent, programmable and multi-vendor radio access network\n(RAN) for 6G networks, considerable efforts have been made in standardization\nand development of open RAN (ORAN). So far, however, the applicability of ORAN\nin controlling and optimizing RAN functions has not been widely investigated.\nIn this paper, we jointly optimize the flow-split distribution, congestion\ncontrol and scheduling (JFCS) to enable an intelligent traffic steering\napplication in ORAN. Combining tools from network utility maximization and\nstochastic optimization, we introduce a multi-layer optimization framework that\nprovides fast convergence, long-term utility-optimality and significant delay\nreduction compared to the state-of-the-art and baseline RAN approaches. Our\nmain contributions are three-fold: i) we propose the novel JFCS framework to\nefficiently and adaptively direct traffic to appropriate radio units; ii) we\ndevelop low-complexity algorithms based on the reinforcement learning, inner\napproximation and bisection search methods to effectively solve the JFCS\nproblem in different time scales; and iii) the rigorous theoretical performance\nresults are analyzed to show that there exists a scaling factor to improve the\ntradeoff between delay and utility-optimization. Collectively, the insights in\nthis work will open the door towards fully automated networks with enhanced\ncontrol and flexibility. Numerical results are provided to demonstrate the\neffectiveness of the proposed algorithms in terms of the convergence rate,\nlong-term utility-optimality and delay reduction.\n","authors":["Van-Dinh Nguyen","Thang X. Vu","Nhan Thanh Nguyen","Dinh C. Nguyen","Markku Juntti","Nguyen Cong Luong","Dinh Thai Hoang","Diep N. Nguyen","Symeon Chatzinotas"],"pdf_url":"https://arxiv.org/pdf/2302.02711v1.pdf","comment":"33 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.14441v2","updated":"2023-02-06T11:36:39Z","published":"2022-12-29T19:32:20Z","title":"Fruit Ripeness Classification: a Survey","summary":"  Fruit is a key crop in worldwide agriculture feeding millions of people. The\nstandard supply chain of fruit products involves quality checks to guarantee\nfreshness, taste, and, most of all, safety. An important factor that determines\nfruit quality is its stage of ripening. This is usually manually classified by\nexperts in the field, which makes it a labor-intensive and error-prone process.\nThus, there is an arising need for automation in the process of fruit ripeness\nclassification. Many automatic methods have been proposed that employ a variety\nof feature descriptors for the food item to be graded. Machine learning and\ndeep learning techniques dominate the top-performing methods. Furthermore, deep\nlearning can operate on raw data and thus relieve the users from having to\ncompute complex engineered features, which are often crop-specific. In this\nsurvey, we review the latest methods proposed in the literature to automatize\nfruit ripeness classification, highlighting the most common feature descriptors\nthey operate on.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2212.14441v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14447v3","updated":"2023-02-06T11:36:10Z","published":"2022-12-29T20:05:26Z","title":"A Theoretical Framework for AI Models Explainability","summary":"  EXplainable Artificial Intelligence (XAI) is a vibrant research topic in the\nartificial intelligence community, with growing interest across methods and\ndomains. Much has been written about the subject, yet XAI still lacks shared\nterminology and a framework capable of providing structural soundness to\nexplanations. In our work, we address these issues by proposing a novel\ndefinition of explanation that is a synthesis of what can be found in the\nliterature. We recognize that explanations are not atomic but the combination\nof evidence stemming from the model and its input-output mapping, and the human\ninterpretation of this evidence. Furthermore, we fit explanations into the\nproperties of faithfulness (i.e., the explanation being a true description of\nthe model's inner workings and decision-making process) and plausibility (i.e.,\nhow much the explanation looks convincing to the user). Using our proposed\ntheoretical framework simplifies how these properties are operationalized and\nit provides new insight into common explanation methods that we analyze as case\nstudies.\n","authors":["Matteo Rizzo","Alberto Veneri","Andrea Albarelli","Claudio Lucchese","Cristina Conati"],"pdf_url":"https://arxiv.org/pdf/2212.14447v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.06093v3","updated":"2023-02-06T11:23:16Z","published":"2021-09-13T16:09:31Z","title":"Direct Advantage Estimation","summary":"  The predominant approach in reinforcement learning is to assign credit to\nactions based on the expected return. However, we show that the return may\ndepend on the policy in a way which could lead to excessive variance in value\nestimation and slow down learning. Instead, we show that the advantage function\ncan be interpreted as causal effects and shares similar properties with causal\nrepresentations. Based on this insight, we propose Direct Advantage Estimation\n(DAE), a novel method that can model the advantage function and estimate it\ndirectly from on-policy data while simultaneously minimizing the variance of\nthe return without requiring the (action-)value function. We also relate our\nmethod to Temporal Difference methods by showing how value functions can be\nseamlessly integrated into DAE. The proposed method is easy to implement and\ncan be readily adapted by modern actor-critic methods. We evaluate DAE\nempirically on three discrete control domains and show that it can outperform\ngeneralized advantage estimation (GAE), a strong baseline for advantage\nestimation, on a majority of the environments when applied to policy\noptimization.\n","authors":["Hsiao-Ru Pan","Nico Gürtler","Alexander Neitz","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2109.06093v3.pdf","comment":"Published at NeurIPS 2022"},{"id":"http://arxiv.org/abs/2211.01201v3","updated":"2023-02-06T11:21:44Z","published":"2022-11-02T15:23:16Z","title":"Human alignment of neural network representations","summary":"  Today's computer vision models achieve human or near-human level performance\nacross a wide variety of vision tasks. However, their architectures, data, and\nlearning algorithms differ in numerous ways from those that give rise to human\nvision. In this paper, we investigate the factors that affect the alignment\nbetween the representations learned by neural networks and human mental\nrepresentations inferred from behavioral responses. We find that model scale\nand architecture have essentially no effect on the alignment with human\nbehavioral responses, whereas the training dataset and objective function both\nhave a much larger impact. These findings are consistent across three datasets\nof human similarity judgments collected using two different tasks. Linear\ntransformations of neural network representations learned from behavioral\nresponses from one dataset substantially improve alignment with human\nsimilarity judgments on the other two datasets. In addition, we find that some\nhuman concepts such as food and animals are well-represented by neural networks\nwhereas others such as royal or sports-related objects are not. Overall,\nalthough models trained on larger, more diverse datasets achieve better\nalignment with humans than models trained on ImageNet alone, our results\nindicate that scaling alone is unlikely to be sufficient to train neural\nnetworks with conceptual representations that match those used by humans.\n","authors":["Lukas Muttenthaler","Jonas Dippel","Lorenz Linhardt","Robert A. Vandermeulen","Simon Kornblith"],"pdf_url":"https://arxiv.org/pdf/2211.01201v3.pdf","comment":"Accepted for publication at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.02706v1","updated":"2023-02-06T11:08:25Z","published":"2023-02-06T11:08:25Z","title":"When the Ground Truth is not True: Modelling Human Biases in Temporal\n  Annotations","summary":"  In supervised learning, low quality annotations lead to poorly performing\nclassification and detection models, while also rendering evaluation\nunreliable. This is particularly apparent on temporal data, where annotation\nquality is affected by multiple factors. For example, in the post-hoc\nself-reporting of daily activities, cognitive biases are one of the most common\ningredients. In particular, reporting the start and duration of an activity\nafter its finalisation may incorporate biases introduced by personal time\nperceptions, as well as the imprecision and lack of granularity due to time\nrounding. Here we propose a method to model human biases on temporal\nannotations and argue for the use of soft labels. Experimental results in\nsynthetic data show that soft labels provide a better approximation of the\nground truth for several metrics. We showcase the method on a real dataset of\ndaily activities.\n","authors":["Taku Yamagata","Emma L. Tonkin","Benjamin Arana Sanchez","Ian Craddock","Miquel Perello Nieto","Raul Santos-Rodriguez","Weisong Yang","Peter Flach"],"pdf_url":"https://arxiv.org/pdf/2302.02706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15242v3","updated":"2023-02-06T11:06:56Z","published":"2022-05-30T16:55:59Z","title":"Re-parameterizing Your Optimizers rather than Architectures","summary":"  The well-designed structures in neural networks reflect the prior knowledge\nincorporated into the models. However, though different models have various\npriors, we are used to training them with model-agnostic optimizers such as\nSGD. In this paper, we propose to incorporate model-specific prior knowledge\ninto optimizers by modifying the gradients according to a set of model-specific\nhyper-parameters. Such a methodology is referred to as Gradient\nRe-parameterization, and the optimizers are named RepOptimizers. For the\nextreme simplicity of model structure, we focus on a VGG-style plain model and\nshowcase that such a simple model trained with a RepOptimizer, which is\nreferred to as RepOpt-VGG, performs on par with or better than the recent\nwell-designed models. From a practical perspective, RepOpt-VGG is a favorable\nbase model because of its simple structure, high inference speed and training\nefficiency. Compared to Structural Re-parameterization, which adds priors into\nmodels via constructing extra training-time structures, RepOptimizers require\nno extra forward/backward computations and solve the problem of quantization.\nWe hope to spark further research beyond the realms of model structure design.\nCode and models \\url{https://github.com/DingXiaoH/RepOptimizers}.\n","authors":["Xiaohan Ding","Honghao Chen","Xiangyu Zhang","Kaiqi Huang","Jungong Han","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2205.15242v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2301.08209v2","updated":"2023-02-06T10:57:44Z","published":"2023-01-19T18:00:51Z","title":"GIPA: A General Information Propagation Algorithm for Graph Learning","summary":"  Graph neural networks (GNNs) have been widely used in graph-structured data\ncomputation, showing promising performance in various applications such as node\nclassification, link prediction, and network recommendation. Existing works\nmainly focus on node-wise correlation when doing weighted aggregation of\nneighboring nodes based on attention, such as dot product by the dense vectors\nof two nodes. This may cause conflicting noise in nodes to be propagated when\ndoing information propagation. To solve this problem, we propose a General\nInformation Propagation Algorithm (GIPA in short), which exploits more\nfine-grained information fusion including bit-wise and feature-wise\ncorrelations based on edge features in their propagation. Specifically, the\nbit-wise correlation calculates the element-wise attention weight through a\nmulti-layer perceptron (MLP) based on the dense representations of two nodes\nand their edge; The feature-wise correlation is based on the one-hot\nrepresentations of node attribute features for feature selection. We evaluate\nthe performance of GIPA on the Open Graph Benchmark proteins (OGBN-proteins for\nshort) dataset and the Alipay dataset of Alibaba. Experimental results reveal\nthat GIPA outperforms the state-of-the-art models in terms of prediction\naccuracy, e.g., GIPA achieves an average ROC-AUC of $0.8901\\pm 0.0011$, which\nis better than that of all the existing methods listed in the OGBN-proteins\nleaderboard.\n","authors":["Houyi Li","Zhihong Chen","Zhao Li","Qinkai Zheng","Peng Zhang","Shuigeng Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.08209v2.pdf","comment":"Accepted by DASFAA2023. arXiv admin note: substantial text overlap\n  with arXiv:2105.06035"},{"id":"http://arxiv.org/abs/2302.01676v2","updated":"2023-02-06T10:44:21Z","published":"2023-02-03T11:56:38Z","title":"Show me your NFT and I tell you how it will perform: Multimodal\n  representation learning for NFT selling price prediction","summary":"  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain\ntechnologies and smart contracts, of unique crypto assets on digital art forms\n(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,\nNFTs have attracted the attention of crypto enthusiasts and investors intent on\nplacing promising investments in this profitable market. However, the NFT\nfinancial performance prediction has not been widely explored to date.\n  In this work, we address the above problem based on the hypothesis that NFT\nimages and their textual descriptions are essential proxies to predict the NFT\nselling prices. To this purpose, we propose MERLIN, a novel multimodal deep\nlearning framework designed to train Transformer-based language and visual\nmodels, along with graph neural network models, on collections of NFTs' images\nand texts. A key aspect in MERLIN is its independence on financial features, as\nit exploits only the primary data a user interested in NFT trading would like\nto deal with, i.e., NFT images and textual descriptions. By learning dense\nrepresentations of such data, a price-category classification task is performed\nby MERLIN models, which can also be tuned according to user preferences in the\ninference phase to mimic different risk-return investment profiles.\nExperimental evaluation on a publicly available dataset has shown that MERLIN\nmodels achieve significant performances according to several financial\nassessment criteria, fostering profitable investments, and also beating\nbaseline machine-learning classifiers based on financial features.\n","authors":["Davide Costa","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2302.01676v2.pdf","comment":"Accepted paper at The ACM Web Conference 2023, April 30--May 04,\n  2023, Austin, Texas, USA"},{"id":"http://arxiv.org/abs/2301.09279v2","updated":"2023-02-06T10:42:47Z","published":"2023-01-23T05:32:42Z","title":"StockEmotions: Discover Investor Emotions for Financial Sentiment\n  Analysis and Multivariate Time Series","summary":"  There has been growing interest in applying NLP techniques in the financial\ndomain, however, resources are extremely limited. This paper introduces\nStockEmotions, a new dataset for detecting emotions in the stock market that\nconsists of 10,000 English comments collected from StockTwits, a financial\nsocial media platform. Inspired by behavioral finance, it proposes 12\nfine-grained emotion classes that span the roller coaster of investor emotion.\nUnlike existing financial sentiment datasets, StockEmotions presents granular\nfeatures such as investor sentiment classes, fine-grained emotions, emojis, and\ntime series data. To demonstrate the usability of the dataset, we perform a\ndataset analysis and conduct experimental downstream tasks. For financial\nsentiment/emotion classification tasks, DistilBERT outperforms other baselines,\nand for multivariate time series forecasting, a Temporal Attention LSTM model\ncombining price index, text, and emotion features achieves the best performance\nthan using a single feature.\n","authors":["Jean Lee","Hoyoul Luis Youn","Josiah Poon","Soyeon Caren Han"],"pdf_url":"https://arxiv.org/pdf/2301.09279v2.pdf","comment":"Preprint - Accepted by the AAAI-23 Bridge Program (AI for Financial\n  Services)"},{"id":"http://arxiv.org/abs/2302.02676v1","updated":"2023-02-06T10:28:16Z","published":"2023-02-06T10:28:16Z","title":"Languages are Rewards: Hindsight Finetuning using Human Feedback","summary":"  Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values.\nExisting works focus on supervised finetuning of pretrained models, based on\ncurated model generations that are preferred by human labelers. Such works have\nachieved remarkable successes in understanding and following instructions\n(e.g., InstructGPT, ChatGPT, etc). However, to date, a key limitation of\nsupervised finetuning is that it cannot learn from negative ratings; models are\nonly trained on positive-rated data, which makes it data inefficient. Because\ncollecting human feedback data is both time consuming and expensive, it is\nvital for the model to learn from all feedback, akin to the remarkable ability\nof humans to learn from diverse feedback. In this work, we propose a novel\ntechnique called Hindsight Finetuning for making language models learn from\ndiverse human feedback. In fact, our idea is motivated by how humans learn from\nhindsight experience. We condition the model on a sequence of model generations\npaired with hindsight feedback, and finetune the model to predict the most\npreferred output. By doing so, models can learn to identify and correct\nnegative attributes or errors. Applying the method to GPT-J, we observe that it\nsignificantly improves results on summarization and dialogue tasks using the\nsame amount of human feedback.\n","authors":["Hao Liu","Carmelo Sferrazza","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02672v1","updated":"2023-02-06T10:21:21Z","published":"2023-02-06T10:21:21Z","title":"Identifiability of latent-variable and structural-equation models: from\n  linear to nonlinear","summary":"  An old problem in multivariate statistics is that linear Gaussian models are\noften unidentifiable, i.e. some parameters cannot be uniquely estimated. In\nfactor analysis, an orthogonal rotation of the factors is unidentifiable, while\nin linear regression, the direction of effect cannot be identified. For such\nlinear models, non-Gaussianity of the (latent) variables has been shown to\nprovide identifiability. In the case of factor analysis, this leads to\nindependent component analysis, while in the case of the direction of effect,\nnon-Gaussian versions of structural equation modelling solve the problem. More\nrecently, we have shown how even general nonparametric nonlinear versions of\nsuch models can be estimated. Non-Gaussianity is not enough in this case, but\nassuming we have time series, or that the distributions are suitably modulated\nby some observed auxiliary variables, the models are identifiable. This paper\nreviews the identifiability theory for the linear and nonlinear cases,\nconsidering both factor analytic models and structural equation models.\n","authors":["Aapo Hyvärinen","Ilyes Khemakhem","Ricardo Monti"],"pdf_url":"https://arxiv.org/pdf/2302.02672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01538v2","updated":"2023-02-06T10:18:03Z","published":"2023-02-03T04:24:49Z","title":"DCM: Deep energy method based on the principle of minimum complementary\n  energy","summary":"  The principle of minimum potential and complementary energy are the most\nimportant variational principles in solid mechanics. The deep energy method\n(DEM), which has received much attention, is based on the principle of minimum\npotential energy and lacks the important form of minimum complementary energy.\nThus, we propose the deep energy method based on the principle of minimum\ncomplementary energy (DCM). The output function of DCM is the stress function\nthat naturally satisfies the equilibrium equation. We extend the proposed DCM\nalgorithm (DCM-P), adding the terms that naturally satisfy the biharmonic\nequation in the Airy stress function. We combine operator learning with\nphysical equations and propose a deep complementary energy operator method\n(DCM-O), including branch net, trunk net, basis net, and particular net. DCM-O\nfirst combines existing high-fidelity numerical results to train DCM-O through\ndata. Then the complementary energy is used to train the branch net and trunk\nnet in DCM-O. To analyze DCM performance, we present the numerical result of\nthe most common stress functions, the Prandtl and Airy stress function. The\nproposed method DCM is used to model the representative mechanical problems\nwith the different types of boundary conditions. We compare DCM with the\nexisting PINNs and DEM algorithms. The result shows the advantage of the\nproposed DCM is suitable for dealing with problems of dominated displacement\nboundary conditions, which is reflected in theory and our numerical\nexperiments. DCM-P and DCM-O improve the accuracy of DCM and the speed of\ncalculation convergence. DCM is an essential supplementary energy form of the\ndeep energy method. We believe that operator learning based on the energy\nmethod can balance data and physical equations well, giving computational\nmechanics broad research prospects.\n","authors":["Yizheng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01538v2.pdf","comment":"46 pages, 23 figures"},{"id":"http://arxiv.org/abs/2302.02670v1","updated":"2023-02-06T10:18:03Z","published":"2023-02-06T10:18:03Z","title":"Random Forests for time-fixed and time-dependent predictors: The\n  DynForest R package","summary":"  The R package DynForest implements random forests for predicting a\ncategorical or a (multiple causes) time-to-event outcome based on time-fixed\nand time-dependent predictors. Through the random forests, the time-dependent\npredictors can be measured with error at subject-specific times, and they can\nbe endogeneous (i.e., impacted by the outcome process). They are modeled\ninternally using flexible linear mixed models (thanks to lcmm package) with\ntime-associations pre-specified by the user. DynForest computes dynamic\npredictions that take into account all the information from time-fixed and\ntime-dependent predictors. DynForest also provides information about the most\npredictive variables using variable importance and minimal depth. Variable\nimportance can also be computed on groups of variables. To display the results,\nseveral functions are available such as summary and plot functions. This paper\naims to guide the user with a step-by-step example of the different functions\nfor fitting random forests within DynForest.\n","authors":["Anthony Devaux","Cécile Proust-Lima","Robin Genuer"],"pdf_url":"https://arxiv.org/pdf/2302.02670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.11808v4","updated":"2023-02-06T10:12:28Z","published":"2022-01-27T21:10:20Z","title":"LAP: An Attention-Based Module for Faithful Interpretation and Knowledge\n  Injection in Convolutional Neural Networks","summary":"  Despite the state-of-the-art performance of deep convolutional neural\nnetworks, they are susceptible to bias and malfunction in unseen situations.\nThe complex computation behind their reasoning is not sufficiently\nhuman-understandable to develop trust. External explainer methods have tried to\ninterpret the network decisions in a human-understandable way, but they are\naccused of fallacies due to their assumptions and simplifications. On the other\nside, the inherent self-interpretability of models, while being more robust to\nthe mentioned fallacies, cannot be applied to the already trained models. In\nthis work, we propose a new attention-based pooling layer, called Local\nAttention Pooling (LAP), that accomplishes self-interpretability and the\npossibility for knowledge injection while improving the model's performance.\nMoreover, several weakly-supervised knowledge injection methodologies are\nprovided to enhance the process of training. We verified our claims by\nevaluating several LAP-extended models on three different datasets, including\nImagenet. The proposed framework offers more valid human-understandable and\nmore faithful-to-the-model interpretations than the commonly used white-box\nexplainer methods.\n","authors":["Rassa Ghavami Modegh","Ahmad Salimi","Alireza Dizaji","Hamid R. Rabiee"],"pdf_url":"https://arxiv.org/pdf/2201.11808v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02667v1","updated":"2023-02-06T10:07:41Z","published":"2023-02-06T10:07:41Z","title":"A Scalable and Efficient Iterative Method for Copying Machine Learning\n  Classifiers","summary":"  Differential replication through copying refers to the process of replicating\nthe decision behavior of a machine learning model using another model that\npossesses enhanced features and attributes. This process is relevant when\nexternal constraints limit the performance of an industrial predictive system.\nUnder such circumstances, copying enables the retention of original prediction\ncapabilities while adapting to new demands. Previous research has focused on\nthe single-pass implementation for copying. This paper introduces a novel\nsequential approach that significantly reduces the amount of computational\nresources needed to train or maintain a copy, leading to reduced maintenance\ncosts for companies using machine learning models in production. The\neffectiveness of the sequential approach is demonstrated through experiments\nwith synthetic and real-world datasets, showing significant reductions in time\nand resources, while maintaining or improving accuracy.\n","authors":["Nahuel Statuto","Irene Unceta","Jordi Nin","Oriol Pujol"],"pdf_url":"https://arxiv.org/pdf/2302.02667v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.14698v4","updated":"2023-02-06T10:01:44Z","published":"2022-08-31T08:47:02Z","title":"Bayesian Optimization-based Combinatorial Assignment","summary":"  We study the combinatorial assignment domain, which includes combinatorial\nauctions and course allocation. The main challenge in this domain is that the\nbundle space grows exponentially in the number of items. To address this,\nseveral papers have recently proposed machine learning-based preference\nelicitation algorithms that aim to elicit only the most important information\nfrom agents. However, the main shortcoming of this prior work is that it does\nnot model a mechanism's uncertainty over values for not yet elicited bundles.\nIn this paper, we address this shortcoming by presenting a Bayesian\noptimization-based combinatorial assignment (BOCA) mechanism. Our key technical\ncontribution is to integrate a method for capturing model uncertainty into an\niterative combinatorial auction mechanism. Concretely, we design a new method\nfor estimating an upper uncertainty bound that can be used to define an\nacquisition function to determine the next query to the agents. This enables\nthe mechanism to properly explore (and not just exploit) the bundle space\nduring its preference elicitation phase. We run computational experiments in\nseveral spectrum auction domains to evaluate BOCA's performance. Our results\nshow that BOCA achieves higher allocative efficiency than state-of-the-art\napproaches.\n","authors":["Jakob Weissteiner","Jakob Heiss","Julien Siems","Sven Seuken"],"pdf_url":"https://arxiv.org/pdf/2208.14698v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02663v1","updated":"2023-02-06T10:01:38Z","published":"2023-02-06T10:01:38Z","title":"Linking data separation, visual separation, and classifier performance\n  using pseudo-labeling by contrastive learning","summary":"  Lacking supervised data is an issue while training deep neural networks\n(DNNs), mainly when considering medical and biological data where supervision\nis expensive. Recently, Embedded Pseudo-Labeling (EPL) addressed this problem\nby using a non-linear projection (t-SNE) from a feature space of the DNN to a\n2D space, followed by semi-supervised label propagation using a\nconnectivity-based method (OPFSemi). We argue that the performance of the final\nclassifier depends on the data separation present in the latent space and\nvisual separation present in the projection. We address this by first proposing\nto use contrastive learning to produce the latent space for EPL by two methods\n(SimCLR and SupCon) and by their combination, and secondly by showing, via an\nextensive set of experiments, the aforementioned correlations between data\nseparation, visual separation, and classifier performance. We demonstrate our\nresults by the classification of five real-world challenging image datasets of\nhuman intestinal parasites with only 1% supervised samples.\n","authors":["Bárbara Caroline Benato","Alexandre Xavier Falcão","Alexandru-Cristian Telea"],"pdf_url":"https://arxiv.org/pdf/2302.02663v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.02662v1","updated":"2023-02-06T10:01:08Z","published":"2023-02-06T10:01:08Z","title":"Grounding Large Language Models in Interactive Environments with Online\n  Reinforcement Learning","summary":"  Recent works successfully leveraged Large Language Models' (LLM) abilities to\ncapture abstract knowledge about world's physics to solve decision-making\nproblems. Yet, the alignment between LLMs' knowledge and the environment can be\nwrong and limit functional competence due to lack of grounding. In this paper,\nwe study an approach to achieve this alignment through functional grounding: we\nconsider an agent using an LLM as a policy that is progressively updated as the\nagent interacts with the environment, leveraging online Reinforcement Learning\nto improve its performance to solve goals. Using an interactive textual\nenvironment designed to study higher-level forms of functional grounding, and a\nset of spatial and navigation tasks, we study several scientific questions: 1)\nCan LLMs boost sample efficiency for online learning of various RL tasks? 2)\nHow can it boost different forms of generalization? 3) What is the impact of\nonline learning? We study these questions by functionally grounding several\nvariants (size, architecture) of FLAN-T5.\n","authors":["Thomas Carta","Clément Romac","Thomas Wolf","Sylvain Lamprier","Olivier Sigaud","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2302.02662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.04850v3","updated":"2023-02-06T10:00:56Z","published":"2021-11-08T22:17:36Z","title":"Dueling RL: Reinforcement Learning with Trajectory Preferences","summary":"  We consider the problem of preference based reinforcement learning (PbRL),\nwhere, unlike traditional reinforcement learning, an agent receives feedback\nonly in terms of a 1 bit (0/1) preference over a trajectory pair instead of\nabsolute rewards for them. The success of the traditional RL framework\ncrucially relies on the underlying agent-reward model, which, however, depends\non how accurately a system designer can express an appropriate reward function\nand often a non-trivial task. The main novelty of our framework is the ability\nto learn from preference-based trajectory feedback that eliminates the need to\nhand-craft numeric reward models. This paper sets up a formal framework for the\nPbRL problem with non-markovian rewards, where the trajectory preferences are\nencoded by a generalized linear model of dimension $d$. Assuming the transition\nmodel is known, we then propose an algorithm with almost optimal regret\nguarantee of $\\tilde {\\mathcal{O}}\\left( SH d \\log (T / \\delta) \\sqrt{T}\n\\right)$. We further, extend the above algorithm to the case of unknown\ntransition dynamics, and provide an algorithm with near optimal regret\nguarantee $\\widetilde{\\mathcal{O}}((\\sqrt{d} + H^2 + |\\mathcal{S}|)\\sqrt{dT}\n+\\sqrt{|\\mathcal{S}||\\mathcal{A}|TH} )$. To the best of our knowledge, our work\nis one of the first to give tight regret guarantees for preference based RL\nproblems with trajectory preferences.\n","authors":["Aldo Pacchiano","Aadirupa Saha","Jonathan Lee"],"pdf_url":"https://arxiv.org/pdf/2111.04850v3.pdf","comment":"Aadirupa Saha and Aldo Pacchiano contributed equally"},{"id":"http://arxiv.org/abs/2302.00981v3","updated":"2023-02-06T10:00:56Z","published":"2023-02-02T10:00:46Z","title":"Predicting Molecule-Target Interaction by Learning Biomedical Network\n  and Molecule Representations","summary":"  The study of molecule-target interaction is quite important for drug\ndiscovery in terms of target identification, hit identification, pathway study,\ndrug-drug interaction, etc. Most existing methodologies utilize either\nbiomedical network information or molecule structural features to predict\npotential interaction link. However, the biomedical network information based\nmethods usually suffer from cold start problem, while structure based methods\noften give limited performance due to the structure/interaction assumption and\ndata quality. To address these issues, we propose a pseudo-siamese Graph Neural\nNetwork method, namely MTINet+, which learns both biomedical network\ntopological and molecule structural/chemical information as representations to\npredict potential interaction of given molecule and target pair. In MTINet+,\n1-hop subgraphs of given molecule and target pair are extracted from known\ninteraction of biomedical network as topological information, meanwhile the\nmolecule structural and chemical attributes are processed as molecule\ninformation. MTINet+ learns these two types of information as embedding\nfeatures for predicting the pair link. In the experiments of different\nmolecule-target interaction tasks, MTINet+ significantly outperforms over the\nstate-of-the-art baselines. In addition, in our designed network sparsity\nexperiments , MTINet+ shows strong robustness against different sparse\nbiomedical networks.\n","authors":["Jinjiang Guo","Jie Li"],"pdf_url":"https://arxiv.org/pdf/2302.00981v3.pdf","comment":"9 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:2102.01649"},{"id":"http://arxiv.org/abs/2302.01327v2","updated":"2023-02-06T09:53:56Z","published":"2023-02-02T18:56:25Z","title":"Dual PatchNorm","summary":"  We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms),\nbefore and after the patch embedding layer in Vision Transformers. We\ndemonstrate that Dual PatchNorm outperforms the result of exhaustive search for\nalternative LayerNorm placement strategies in the Transformer block itself. In\nour experiments, incorporating this trivial modification, often leads to\nimproved accuracy over well-tuned Vision Transformers and never hurts.\n","authors":["Manoj Kumar","Mostafa Dehghani","Neil Houlsby"],"pdf_url":"https://arxiv.org/pdf/2302.01327v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02653v1","updated":"2023-02-06T09:49:58Z","published":"2023-02-06T09:49:58Z","title":"L'explicabilité au service de l'extraction de connaissances :\n  application à des données médicales","summary":"  The use of machine learning has increased dramatically in the last decade.\nThe lack of transparency is now a limiting factor, which the field of\nexplainability wants to address. Furthermore, one of the challenges of data\nmining is to present the statistical relationships of a dataset when they can\nbe highly non-linear. One of the strengths of supervised learning is its\nability to find complex statistical relationships that explainability allows to\nrepresent in an intelligible way. This paper shows that explanations can be\nused to extract knowledge from data and shows how feature selection, data\nsubgroup analysis and selection of highly informative instances benefit from\nexplanations. We then present a complete data processing pipeline using these\nmethods on medical data. -- --\n  L'utilisation de l'apprentissage automatique a connu un bond cette derni\\`ere\nd\\'ecennie. Le manque de transparence est aujourd'hui un frein, que le domaine\nde l'explicabilit\\'e veut r\\'esoudre. Par ailleurs, un des d\\'efis de\nl'exploration de donn\\'ees est de pr\\'esenter les relations statistiques d'un\njeu de donn\\'ees alors que celles-ci peuvent \\^etre hautement non-lin\\'eaires.\nUne des forces de l'apprentissage supervis\\'e est sa capacit\\'e \\`a trouver des\nrelations statistiques complexes que l'explicabilit\\'e permet de repr\\'esenter\nde mani\\`ere intelligible. Ce papier montre que les explications permettent de\nfaire de l'extraction de connaissance sur des donn\\'ees et comment la\ns\\'election de variables, l'analyse de sous-groupes de donn\\'ees et la\ns\\'election d'instances avec un fort pouvoir informatif b\\'en\\'eficient des\nexplications. Nous pr\\'esentons alors un pipeline complet de traitement des\ndonn\\'ees utilisant ces m\\'ethodes pour l'exploration de donn\\'ees m\\'edicales.\n","authors":["Robin Cugny","Emmanuel Doumard","Elodie Escriva","Haomiao Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02653v1.pdf","comment":"6 pages, 3 figures, EXPLAIN'AI Workshop, in French"},{"id":"http://arxiv.org/abs/2302.02650v1","updated":"2023-02-06T09:44:53Z","published":"2023-02-06T09:44:53Z","title":"Tree-Based Learning on Amperometric Time Series Data Demonstrates High\n  Accuracy for Classification","summary":"  Elucidating exocytosis processes provide insights into cellular\nneurotransmission mechanisms, and may have potential in neurodegenerative\ndiseases research. Amperometry is an established electrochemical method for the\ndetection of neurotransmitters released from and stored inside cells. An\nimportant aspect of the amperometry method is the sub-millisecond temporal\nresolution of the current recordings which leads to several hundreds of\ngigabytes of high-quality data. In this study, we present a universal method\nfor the classification with respect to diverse amperometric datasets using\ndata-driven approaches in computational science. We demonstrate a very high\nprediction accuracy (greater than or equal to 95%). This includes an end-to-end\nsystematic machine learning workflow for amperometric time series datasets\nconsisting of pre-processing; feature extraction; model identification;\ntraining and testing; followed by feature importance evaluation - all\nimplemented. We tested the method on heterogeneous amperometric time series\ndatasets generated using different experimental approaches, chemical\nstimulations, electrode types, and varying recording times. We identified a\ncertain overarching set of common features across these datasets which enables\naccurate predictions. Further, we showed that information relevant for the\nclassification of amperometric traces are neither in the spiky segments alone,\nnor can it be retrieved from just the temporal structure of spikes. In fact,\nthe transients between spikes and the trace baselines carry essential\ninformation for a successful classification, thereby strongly demonstrating\nthat an effective feature representation of amperometric time series requires\nthe full time series. To our knowledge, this is one of the first studies that\npropose a scheme for machine learning, and in particular, supervised learning\non full amperometry time series data.\n","authors":["Jeyashree Krishnan","Zeyu Lian","Pieter E. Oomen","Xiulan He","Soodabeh Majdi","Andreas Schuppert","Andrew Ewing"],"pdf_url":"https://arxiv.org/pdf/2302.02650v1.pdf","comment":"56 pages, 11 figures"},{"id":"http://arxiv.org/abs/2302.02636v1","updated":"2023-02-06T09:15:39Z","published":"2023-02-06T09:15:39Z","title":"Hybrid Contrastive Constraints for Multi-Scenario Ad Ranking","summary":"  Multi-scenario ad ranking aims at leveraging the data from multiple domains\nor channels for training a unified ranking model to improve the performance at\neach individual scenario. Although the research on this task has made important\nprogress, it still lacks the consideration of cross-scenario relations, thus\nleading to limitation in learning capability and difficulty in interrelation\nmodeling. In this paper, we propose a Hybrid Contrastive Constrained approach\n(HC^2) for multi-scenario ad ranking. To enhance the modeling of data\ninterrelation, we elaborately design a hybrid contrastive learning approach to\ncapture commonalities and differences among multiple scenarios. The core of our\napproach consists of two elaborated contrastive losses, namely generalized and\nindividual contrastive loss, which aim at capturing common knowledge and\nscenario-specific knowledge, respectively. To adapt contrastive learning to the\ncomplex multi-scenario setting, we propose a series of important improvements.\nFor generalized contrastive loss, we enhance contrastive learning by extending\nthe contrastive samples (label-aware and diffusion noise enhanced contrastive\nsamples) and reweighting the contrastive samples (reciprocal similarity\nweighting). For individual contrastive loss, we use the strategies of\ndropout-based augmentation and {cross-scenario encoding} for generating\nmeaningful positive and negative contrastive samples, respectively. Extensive\nexperiments on both offline evaluation and online test have demonstrated the\neffectiveness of the proposed HC$^2$ by comparing it with a number of\ncompetitive baselines.\n","authors":["Shanlei Mu","Penghui Wei","Wayne Xin Zhao","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.02636v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2210.07295v2","updated":"2023-02-06T09:13:31Z","published":"2022-10-13T18:49:59Z","title":"Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog","summary":"  Traditional systems designed for task oriented dialog utilize knowledge\npresent only in structured knowledge sources to generate responses. However,\nrelevant information required to generate responses may also reside in\nunstructured sources, such as documents. Recent state of the art models such as\nHyKnow and SeKnow aimed at overcoming these challenges make limiting\nassumptions about the knowledge sources. For instance, these systems assume\nthat certain types of information, such as a phone number, is always present in\na structured knowledge base (KB) while information about aspects such as\nentrance ticket prices, would always be available in documents.\n  In this paper, we create a modified version of the MutliWOZ-based dataset\nprepared by SeKnow to demonstrate how current methods have significant\ndegradation in performance when strict assumptions about the source of\ninformation are removed. Then, in line with recent work exploiting pre-trained\nlanguage models, we fine-tune a BART based model using prompts for the tasks of\nquerying knowledge sources, as well as, for response generation, without making\nassumptions about the information present in each knowledge source. Through a\nseries of experiments, we demonstrate that our model is robust to perturbations\nto knowledge modality (source of information), and that it can fuse information\nfrom structured as well as unstructured knowledge to generate responses.\n","authors":["Mayank Mishra","Danish Contractor","Dinesh Raghu"],"pdf_url":"https://arxiv.org/pdf/2210.07295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.03436v4","updated":"2023-02-06T09:11:06Z","published":"2020-12-07T03:34:03Z","title":"Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank\n  Tensor Completion and Tensor Robust Principal Component Analysis","summary":"  The nuclear norm and Schatten-$p$ quasi-norm are popular rank proxies in\nlow-rank matrix recovery. However, computing the nuclear norm or Schatten-$p$\nquasi-norm of a tensor is hard in both theory and practice, hindering their\napplication to low-rank tensor completion (LRTC) and tensor robust principal\ncomponent analysis (TRPCA). In this paper, we propose a new class of tensor\nrank regularizers based on the Euclidean norms of the CP component vectors of a\ntensor and show that these regularizers are monotonic transformations of tensor\nSchatten-$p$ quasi-norm. This connection enables us to minimize the\nSchatten-$p$ quasi-norm in LRTC and TRPCA implicitly via the component vectors.\nThe method scales to big tensors and provides an arbitrarily sharper rank proxy\nfor low-rank tensor recovery compared to the nuclear norm. On the other hand,\nwe study the generalization abilities of LRTC with the Schatten-$p$ quasi-norm\nregularizer and LRTC with the proposed regularizers. The theorems show that a\nrelatively sharper regularizer leads to a tighter error bound, which is\nconsistent with our numerical results. Particularly, we prove that for LRTC\nwith Schatten-$p$ quasi-norm regularizer on $d$-order tensors, $p=1/d$ is\nalways better than any $p>1/d$ in terms of the generalization ability. We also\nprovide a recovery error bound to verify the usefulness of small $p$ in the\nSchatten-$p$ quasi-norm for TRPCA. Numerical results on synthetic data and real\ndata demonstrate the effectiveness of the regularization methods and theorems.\n","authors":["Jicong Fan","Lijun Ding","Chengrun Yang","Zhao Zhang","Madeleine Udell"],"pdf_url":"https://arxiv.org/pdf/2012.03436v4.pdf","comment":"43 pages; published by Transactions on Machine Learning Research,\n  January 2023; https://openreview.net/forum?id=Grhi800jVz"},{"id":"http://arxiv.org/abs/2301.10405v2","updated":"2023-02-06T09:10:32Z","published":"2023-01-25T04:45:06Z","title":"Editing Language Model-based Knowledge Graph Embeddings","summary":"  Recently decades have witnessed the empirical success of framing Knowledge\nGraph (KG) embeddings via language models. However, language model-based KG\nembeddings are usually deployed as static artifacts, which are challenging to\nmodify without re-training after deployment. To address this issue, we propose\na new task of editing language model-based KG embeddings in this paper. The\nproposed task aims to enable data-efficient and fast updates to KG embeddings\nwithout damaging the performance of the rest. We build four new datasets:\nE-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge\nediting baselines demonstrating the limited ability of previous models to\nhandle the proposed challenging task. We further propose a simple yet strong\nbaseline dubbed KGEditor, which utilizes additional parametric layers of the\nhyper network to edit/add facts. Comprehensive experimental results demonstrate\nthat KGEditor can perform better when updating specific facts while not\naffecting the rest with low training resources. Code and datasets will be\navailable in https://github.com/zjunlp/PromptKG/tree/main/deltaKG.\n","authors":["Siyuan Cheng","Ningyu Zhang","Bozhong Tian","Zelin Dai","Feiyu Xiong","Wei Guo","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2301.10405v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/KGE_Editing/"},{"id":"http://arxiv.org/abs/2112.09036v4","updated":"2023-02-06T09:01:51Z","published":"2021-12-16T17:27:29Z","title":"The Dual PC Algorithm and the Role of Gaussianity for Structure Learning\n  of Bayesian Networks","summary":"  Learning the graphical structure of Bayesian networks is key to describing\ndata-generating mechanisms in many complex applications but poses considerable\ncomputational challenges. Observational data can only identify the equivalence\nclass of the directed acyclic graph underlying a Bayesian network model, and a\nvariety of methods exist to tackle the problem. Under certain assumptions, the\npopular PC algorithm can consistently recover the correct equivalence class by\nreverse-engineering the conditional independence (CI) relationships holding in\nthe variable distribution. The dual PC algorithm is a novel scheme to carry out\nthe CI tests within the PC algorithm by leveraging the inverse relationship\nbetween covariance and precision matrices. By exploiting block matrix\ninversions we can simultaneously perform tests on partial correlations of\ncomplementary (or dual) conditioning sets. The multiple CI tests of the dual PC\nalgorithm proceed by first considering marginal and full-order CI relationships\nand progressively moving to central-order ones. Simulation studies show that\nthe dual PC algorithm outperforms the classic PC algorithm both in terms of run\ntime and in recovering the underlying network structure, even in the presence\nof deviations from Gaussianity. Additionally, we show that the dual PC\nalgorithm applies for Gaussian copula models, and demonstrate its performance\nin that setting.\n","authors":["Enrico Giudice","Jack Kuipers","Giusi Moffa"],"pdf_url":"https://arxiv.org/pdf/2112.09036v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02628v1","updated":"2023-02-06T08:57:20Z","published":"2023-02-06T08:57:20Z","title":"Trust, but Verify: Using Self-Supervised Probing to Improve\n  Trustworthiness","summary":"  Trustworthy machine learning is of primary importance to the practical\ndeployment of deep learning models. While state-of-the-art models achieve\nastonishingly good performance in terms of accuracy, recent literature reveals\nthat their predictive confidence scores unfortunately cannot be trusted: e.g.,\nthey are often overconfident when wrong predictions are made, or so even for\nobvious outliers. In this paper, we introduce a new approach of self-supervised\nprobing, which enables us to check and mitigate the overconfidence issue for a\ntrained model, thereby improving its trustworthiness. We provide a simple yet\neffective framework, which can be flexibly applied to existing\ntrustworthiness-related methods in a plug-and-play manner. Extensive\nexperiments on three trustworthiness-related tasks (misclassification\ndetection, calibration and out-of-distribution detection) across various\nbenchmarks verify the effectiveness of our proposed probing framework.\n","authors":["Ailin Deng","Shen Li","Miao Xiong","Zhirui Chen","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2302.02628v1.pdf","comment":"European Conference on Computer Vision 2022"},{"id":"http://arxiv.org/abs/2301.12458v2","updated":"2023-02-06T08:49:21Z","published":"2023-01-29T15:00:43Z","title":"Self-supervised Semi-implicit Graph Variational Auto-encoders with\n  Masking","summary":"  Generative graph self-supervised learning (SSL) aims to learn node\nrepresentations by reconstructing the input graph data. However, most existing\nmethods focus on unsupervised learning tasks only and very few work has shown\nits superiority over the state-of-the-art graph contrastive learning (GCL)\nmodels, especially on the classification task. While a very recent model has\nbeen proposed to bridge the gap, its performance on unsupervised learning tasks\nis still unknown. In this paper, to comprehensively enhance the performance of\ngenerative graph SSL against other GCL models on both unsupervised and\nsupervised learning tasks, we propose the SeeGera model, which is based on the\nfamily of self-supervised variational graph auto-encoder (VGAE). Specifically,\nSeeGera adopts the semi-implicit variational inference framework, a\nhierarchical variational framework, and mainly focuses on feature\nreconstruction and structure/feature masking. On the one hand, SeeGera\nco-embeds both nodes and features in the encoder and reconstructs both links\nand features in the decoder. Since feature embeddings contain rich semantic\ninformation on features, they can be combined with node embeddings to provide\nfine-grained knowledge for feature reconstruction. On the other hand, SeeGera\nadds an additional layer for structure/feature masking to the hierarchical\nvariational framework, which boosts the model generalizability. We conduct\nextensive experiments comparing SeeGera with 9 other state-of-the-art\ncompetitors. Our results show that SeeGera can compare favorably against other\nstate-of-the-art GCL methods in a variety of unsupervised and supervised\nlearning tasks.\n","authors":["Xiang Li","Tiandi Ye","Caihua Shan","Dongsheng Li","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2301.12458v2.pdf","comment":"Accepted by WebConf 2023"},{"id":"http://arxiv.org/abs/2209.15414v2","updated":"2023-02-06T08:45:20Z","published":"2022-09-27T10:03:01Z","title":"Predicting the power grid frequency of European islands","summary":"  Modelling, forecasting and overall understanding of the dynamics of the power\ngrid and its frequency are essential for the safe operation of existing and\nfuture power grids. Much previous research was focused on large continental\nareas, while small systems, such as islands are less well-studied. These\nnatural island systems are ideal testing environments for microgrid proposals\nand artificially islanded grid operation. In the present paper, we utilize\nmeasurements of the power grid frequency obtained in European islands: the\nFaroe Islands, Ireland, the Balearic Islands and Iceland and investigate how\ntheir frequency can be predicted, compared to the Nordic power system, acting\nas a reference. The Balearic islands are found to be particularly deterministic\nand easy to predict in contrast to hard-to-predict Iceland. Furthermore, we\nshow that typically 2-4 weeks of data are needed to improve prediction\nperformance beyond simple benchmarks.\n","authors":["Thorbjørn Lund Onsaker","Heidi S. Nygård","Damià Gomila","Pere Colet","Ralf Mikut","Richard Jumar","Heiko Maass","Uwe Kühnapfel","Veit Hagenmeyer","Benjamin Schäfer"],"pdf_url":"https://arxiv.org/pdf/2209.15414v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2302.02622v1","updated":"2023-02-06T08:41:07Z","published":"2023-02-06T08:41:07Z","title":"Uncertainty Calibration and its Application to Object Detection","summary":"  Image-based environment perception is an important component especially for\ndriver assistance systems or autonomous driving. In this scope, modern neuronal\nnetworks are used to identify multiple objects as well as the according\nposition and size information within a single frame. The performance of such an\nobject detection model is important for the overall performance of the whole\nsystem. However, a detection model might also predict these objects under a\ncertain degree of uncertainty. [...]\n  In this work, we examine the semantic uncertainty (which object type?) as\nwell as the spatial uncertainty (where is the object and how large is it?). We\nevaluate if the predicted uncertainties of an object detection model match with\nthe observed error that is achieved on real-world data. In the first part of\nthis work, we introduce the definition for confidence calibration of the\nsemantic uncertainty in the context of object detection, instance segmentation,\nand semantic segmentation. We integrate additional position information in our\nexaminations to evaluate the effect of the object's position on the semantic\ncalibration properties. Besides measuring calibration, it is also possible to\nperform a post-hoc recalibration of semantic uncertainty that might have turned\nout to be miscalibrated. [...]\n  The second part of this work deals with the spatial uncertainty obtained by a\nprobabilistic detection model. [...] We review and extend common calibration\nmethods so that it is possible to obtain parametric uncertainty distributions\nfor the position information in a more flexible way.\n  In the last part, we demonstrate a possible use-case for our derived\ncalibration methods in the context of object tracking. [...] We integrate our\npreviously proposed calibration techniques and demonstrate the usefulness of\nsemantic and spatial uncertainty calibration in a subsequent process. [...]\n","authors":["Fabian Küppers"],"pdf_url":"https://arxiv.org/pdf/2302.02622v1.pdf","comment":"PhD thesis at University of Wuppertal, cite by: 'Fabian K\\\"uppers.\n  \"Uncertainty Calibration and its Application to Object Detection.\" PhD\n  Thesis, University of Wuppertal, January 2023'"},{"id":"http://arxiv.org/abs/2302.02619v1","updated":"2023-02-06T08:39:27Z","published":"2023-02-06T08:39:27Z","title":"COVID-19 Infection Analysis Framework using Novel Boosted CNNs and\n  Radiological Images","summary":"  COVID-19 is a new pathogen that first appeared in the human population at the\nend of 2019, and it can lead to novel variants of pneumonia after infection.\nCOVID-19 is a rapidly spreading infectious disease that infects humans faster.\nTherefore, efficient diagnostic systems may accurately identify infected\npatients and thus help control their spread. In this regard, a new two-stage\nanalysis framework is developed to analyze minute irregularities of COVID-19\ninfection. A novel detection Convolutional Neural Network (CNN), STM-BRNet, is\ndeveloped that incorporates the Split-Transform-Merge (STM) block and channel\nboosting (CB) to identify COVID-19 infected CT slices in the first stage. Each\nSTM block extracts boundary and region-smoothing-specific features for COVID-19\ninfection detection. Moreover, the various boosted channels are obtained by\nintroducing the new CB and Transfer Learning (TL) concept in STM blocks to\ncapture small illumination and texture variations of COVID-19-specific images.\nThe COVID-19 CTs are provided with new SA-CB-BRSeg segmentation CNN for\ndelineating infection in images in the second stage. SA-CB-BRSeg methodically\nutilized smoothening and heterogeneous operations in the encoder and decoder to\ncapture simultaneously COVID-19 specific patterns that are region homogeneity,\ntexture variation, and boundaries. Additionally, the new CB concept is\nintroduced in the decoder of SA-CB-BRSeg by combining additional channels using\nTL to learn the low contrast region. The proposed STM-BRNet and SA-CB-BRSeg\nyield considerable achievement in accuracy: 98.01 %, Recall: 98.12%, F-score:\n98.11%, and Dice Similarity: 96.396%, IOU: 98.845 % for the COVID-19 infectious\nregion, respectively. The proposed two-stage framework significantly increased\nperformance compared to single-phase and other reported systems and reduced the\nburden on the radiologists.\n","authors":["Saddam Hussain Khan"],"pdf_url":"https://arxiv.org/pdf/2302.02619v1.pdf","comment":"26 Pages, 11 Figures, 6 Tables. arXiv admin note: text overlap with\n  arXiv:2209.10963"},{"id":"http://arxiv.org/abs/2201.11783v3","updated":"2023-02-06T08:34:53Z","published":"2022-01-27T19:51:09Z","title":"Boosting Exploration in Multi-Task Reinforcement Learning using\n  Adversarial Networks","summary":"  Advancements in reinforcement learning (RL) have been remarkable in recent\nyears. However, the limitations of traditional training methods have become\nincreasingly evident, particularly in meta-RL settings where agents face new,\nunseen tasks. Conventional training approaches are susceptible to failure in\nsuch situations as they need more robustness to adversity. Our proposed\nadversarial training regime for Multi-Task Reinforcement Learning (MT-RL)\naddresses the limitations of conventional training methods in RL, especially in\nmeta-RL environments where the agent faces new tasks. The adversarial component\nchallenges the agent, forcing it to improve its decision-making abilities in\ndynamic and unpredictable situations. This component operates without relying\non manual intervention or domain-specific knowledge, making it a highly\nversatile solution. Experiments conducted in multiple MT-RL environments\ndemonstrate that adversarial training leads to better exploration and a deeper\nunderstanding of the environment. The adversarial training regime for MT-RL\npresents a new perspective on training and development for RL agents and is a\nvaluable contribution to the field.\n","authors":["Ramnath Kumar","Tristan Deleu","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2201.11783v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14358v2","updated":"2023-02-06T08:25:47Z","published":"2022-10-25T21:54:26Z","title":"Multi-Domain Long-Tailed Learning by Augmenting Disentangled\n  Representations","summary":"  There is an inescapable long-tailed class-imbalance issue in many real-world\nclassification problems. Existing long-tailed classification methods focus on\nthe single-domain setting, where all examples are drawn from the same\ndistribution. However, real-world scenarios often involve multiple domains with\ndistinct imbalanced class distributions. We study this multi-domain long-tailed\nlearning problem and aim to produce a model that generalizes well across all\nclasses and domains. Towards that goal, we introduce TALLY, which produces\ninvariant predictors by balanced augmenting hidden representations over domains\nand classes. Built upon a proposed selective balanced sampling strategy, TALLY\nachieves this by mixing the semantic representation of one example with the\ndomain-associated nuisances of another, producing a new representation for use\nas data augmentation. To improve the disentanglement of semantic\nrepresentations, TALLY further utilizes a domain-invariant class prototype that\naverages out domain-specific effects. We evaluate TALLY on four long-tailed\nvariants of classical domain generalization benchmarks and two real-world\nimbalanced multi-domain datasets. The results indicate that TALLY consistently\noutperforms other state-of-the-art methods in both subpopulation shift and\ndomain shift.\n","authors":["Xinyu Yang","Huaxiu Yao","Allan Zhou","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2210.14358v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02609v1","updated":"2023-02-06T08:11:16Z","published":"2023-02-06T08:11:16Z","title":"Leveraging Domain Relations for Domain Generalization","summary":"  Distribution shift is a major challenge in machine learning, as models often\nperform poorly during the test stage if the test distribution differs from the\ntraining distribution. In this paper, we focus on domain shifts, which occur\nwhen the model is applied to new domains that are different from the ones it\nwas trained on, and propose a new approach called D^3G. Unlike previous\napproaches that aim to learn a single model that is domain invariant, D^3G\nlearns domain-specific models by leveraging the relations among different\ndomains. Concretely, D^3G learns a set of training-domain-specific functions\nduring the training stage and reweights them based on domain relations during\nthe test stage. These domain relations can be directly derived or learned from\nfixed domain meta-data. Under mild assumptions, we theoretically proved that\nusing domain relations to reweight training-domain-specific functions achieves\nstronger generalization compared to averaging them. Empirically, we evaluated\nthe effectiveness of D^3G using both toy and real-world datasets for tasks such\nas temperature regression, land use classification, and molecule-protein\ninteraction prediction. Our results showed that D^3G consistently outperformed\nstate-of-the-art methods, with an average improvement of 10.6% in performance.\n","authors":["Huaxiu Yao","Xinyu Yang","Xinyi Pan","Shengchao Liu","Pang Wei Koh","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2302.02609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02607v1","updated":"2023-02-06T08:08:34Z","published":"2023-02-06T08:08:34Z","title":"Target-based Surrogates for Stochastic Optimization","summary":"  We consider minimizing functions for which it is expensive to compute the\n(possibly stochastic) gradient. Such functions are prevalent in reinforcement\nlearning, imitation learning and adversarial training. Our target optimization\nframework uses the (expensive) gradient computation to construct surrogate\nfunctions in a target space (e.g. the logits output by a linear model for\nclassification) that can be minimized efficiently. This allows for multiple\nparameter updates to the model, amortizing the cost of gradient computation. In\nthe full-batch setting, we prove that our surrogate is a global upper-bound on\nthe loss, and can be (locally) minimized using a black-box optimization\nalgorithm. We prove that the resulting majorization-minimization algorithm\nensures convergence to a stationary point of the loss. Next, we instantiate our\nframework in the stochastic setting and propose the $SSO$ algorithm, which can\nbe viewed as projected stochastic gradient descent in the target space. This\nconnection enables us to prove theoretical guarantees for $SSO$ when minimizing\nconvex functions. Our framework allows the use of standard stochastic\noptimization algorithms to construct surrogates which can be minimized by any\ndeterministic optimization method. To evaluate our framework, we consider a\nsuite of supervised learning and imitation learning problems. Our experiments\nindicate the benefits of target optimization and the effectiveness of $SSO$.\n","authors":["Jonathan Wilder Lavington","Sharan Vaswani","Reza Babanezhad","Mark Schmidt","Nicolas Le Roux"],"pdf_url":"https://arxiv.org/pdf/2302.02607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.08748v3","updated":"2023-02-06T08:05:39Z","published":"2021-06-16T12:48:55Z","title":"Input Invex Neural Network","summary":"  Connected decision boundaries are useful in several tasks like image\nsegmentation, clustering, alpha-shape or defining a region in nD-space.\nHowever, the machine learning literature lacks methods for generating connected\ndecision boundaries using neural networks. Thresholding an invex function, a\ngeneralization of a convex function, generates such decision boundaries. This\npaper presents two methods for constructing invex functions using neural\nnetworks. The first approach is based on constraining a neural network with\nGradient Clipped-Gradient Penality (GCGP), where we clip and penalise the\ngradients. In contrast, the second one is based on the relationship of the\ninvex function to the composition of invertible and convex functions. We employ\nconnectedness as a basic interpretation method and create connected\nregion-based classifiers. We show that multiple connected set based classifiers\ncan approximate any classification function. In the experiments section, we use\nour methods for classification tasks using an ensemble of 1-vs-all models as\nwell as using a single multiclass model on larger-scale datasets. The\nexperiments show that connected set-based classifiers do not pose any\ndisadvantage over ordinary neural network classifiers, but rather, enhance\ntheir interpretability. We also did an extensive study on the properties of\ninvex function and connected sets for interpretability and network morphism\nwith experiments on simulated and real-world data sets. Our study suggests that\ninvex function is fundamental to understanding and applying locality and\nconnectedness of input space which is useful for various downstream tasks.\n","authors":["Suman Sapkota","Binod Bhattarai"],"pdf_url":"https://arxiv.org/pdf/2106.08748v3.pdf","comment":"42 pages, 23 figures"},{"id":"http://arxiv.org/abs/2301.07067v2","updated":"2023-02-06T08:03:15Z","published":"2023-01-17T18:31:12Z","title":"Transformers as Algorithms: Generalization and Stability in In-context\n  Learning","summary":"  In-context learning (ICL) is a type of prompting where a transformer model\noperates on a sequence of (input, output) examples and performs inference\non-the-fly. In this work, we formalize in-context learning as an algorithm\nlearning problem where a transformer model implicitly constructs a hypothesis\nfunction at inference-time. We first explore the statistical aspects of this\nabstraction through the lens of multitask learning: We obtain generalization\nbounds for ICL when the input prompt is (1) a sequence of i.i.d. (input, label)\npairs or (2) a trajectory arising from a dynamical system. The crux of our\nanalysis is relating the excess risk to the stability of the algorithm\nimplemented by the transformer. We characterize when transformer/attention\narchitecture provably obeys the stability condition and also provide empirical\nverification. For generalization on unseen tasks, we identify an inductive bias\nphenomenon in which the transfer learning risk is governed by the task\ncomplexity and the number of MTL tasks in a highly predictable manner. Finally,\nwe provide numerical evaluations that (1) demonstrate transformers can indeed\nimplement near-optimal algorithms on classical regression problems with i.i.d.\nand dynamic data, (2) provide insights on stability, and (3) verify our\ntheoretical predictions.\n","authors":["Yingcong Li","M. Emrullah Ildiz","Dimitris Papailiopoulos","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2301.07067v2.pdf","comment":"Revised version significantly improves the stability guarantees and\n  provides new experiments"},{"id":"http://arxiv.org/abs/2111.09666v2","updated":"2023-02-06T07:59:33Z","published":"2021-11-18T12:50:53Z","title":"CCSL: A Causal Structure Learning Method from Multiple Unknown\n  Environments","summary":"  Most existing causal structure learning methods assume data collected from\none environment and independent and identically distributed (i.i.d.). In some\ncases, data are collected from different subjects from multiple environments,\nwhich provides more information but might make the data non-identical or\nnon-independent distribution. Some previous efforts try to learn causal\nstructure from this type of data in two independent stages, i.e., first\ndiscovering i.i.d. groups from non-i.i.d. samples, then learning the causal\nstructures from different groups. This straightforward solution ignores the\nintrinsic connections between the two stages, that is both the clustering stage\nand the learning stage should be guided by the same causal mechanism. Towards\nthis end, we propose a unified Causal Cluster Structures Learning (named CCSL)\nmethod for causal discovery from non-i.i.d. data. This method simultaneously\nintegrates the following two tasks: 1) clustering samples of the subjects with\nthe same causal mechanism into different groups; 2) learning causal structures\nfrom the samples within the group. Specifically, for the former, we provide a\nCausality-related Chinese Restaurant Process to cluster samples based on the\nsimilarity of the causal structure; for the latter, we introduce a\nvariational-inference-based approach to learn the causal structures.\nTheoretical results provide identification of the causal model and the\nclustering model under the linear non-Gaussian assumption. Experimental results\non both simulated and real-world data further validate the correctness and\neffectiveness of the proposed method.\n","authors":["Wei Chen","Yunjin Wu","Ruichu Cai","Yueguo Chen","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2111.09666v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02605v1","updated":"2023-02-06T07:57:50Z","published":"2023-02-06T07:57:50Z","title":"Toward Large Kernel Models","summary":"  Recent studies indicate that kernel machines can often perform similarly or\nbetter than deep neural networks (DNNs) on small datasets. The interest in\nkernel machines has been additionally bolstered by the discovery of their\nequivalence to wide neural networks in certain regimes. However, a key feature\nof DNNs is their ability to scale the model size and training data size\nindependently, whereas in traditional kernel machines model size is tied to\ndata size. Because of this coupling, scaling kernel machines to large data has\nbeen computationally challenging. In this paper, we provide a way forward for\nconstructing large-scale general kernel models, which are a generalization of\nkernel machines that decouples the model and data, allowing training on large\ndatasets. Specifically, we introduce EigenPro 3.0, an algorithm based on\nprojected dual preconditioned SGD and show scaling to model and data sizes\nwhich have not been possible with existing kernel methods.\n","authors":["Amirhesam Abedsoltan","Mikhail Belkin","Parthe Pandit"],"pdf_url":"https://arxiv.org/pdf/2302.02605v1.pdf","comment":"Code is available at github.com/EigenPro/EigenPro3"},{"id":"http://arxiv.org/abs/2210.00226v3","updated":"2023-02-06T07:56:05Z","published":"2022-10-01T09:04:17Z","title":"Towards Understanding and Mitigating Dimensional Collapse in\n  Heterogeneous Federated Learning","summary":"  Federated learning aims to train models collaboratively across different\nclients without the sharing of data for privacy considerations. However, one\nmajor challenge for this learning paradigm is the {\\em data heterogeneity}\nproblem, which refers to the discrepancies between the local data distributions\namong various clients. To tackle this problem, we first study how data\nheterogeneity affects the representations of the globally aggregated models.\nInterestingly, we find that heterogeneous data results in the global model\nsuffering from severe {\\em dimensional collapse}, in which representations tend\nto reside in a lower-dimensional space instead of the ambient space. Moreover,\nwe observe a similar phenomenon on models locally trained on each client and\ndeduce that the dimensional collapse on the global model is inherited from\nlocal models. In addition, we theoretically analyze the gradient flow dynamics\nto shed light on how data heterogeneity result in dimensional collapse for\nlocal models. To remedy this problem caused by the data heterogeneity, we\npropose {\\sc FedDecorr}, a novel method that can effectively mitigate\ndimensional collapse in federated learning. Specifically, {\\sc FedDecorr}\napplies a regularization term during local training that encourages different\ndimensions of representations to be uncorrelated. {\\sc FedDecorr}, which is\nimplementation-friendly and computationally-efficient, yields consistent\nimprovements over baselines on standard benchmark datasets. Code:\nhttps://github.com/Yujun-Shi/FedCLS.\n","authors":["Yujun Shi","Jian Liang","Wenqing Zhang","Vincent Y. F. Tan","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2210.00226v3.pdf","comment":"camera ready version of ICLR 2023"},{"id":"http://arxiv.org/abs/2301.12935v3","updated":"2023-02-06T07:52:20Z","published":"2023-01-30T14:32:47Z","title":"ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion\n  Probabilistic Models","summary":"  Though denoising diffusion probabilistic models (DDPMs) have achieved\nremarkable generation results, the low sampling efficiency of DDPMs still\nlimits further applications. Since DDPMs can be formulated as diffusion\nordinary differential equations (ODEs), various fast sampling methods can be\nderived from solving diffusion ODEs. However, we notice that previous sampling\nmethods with fixed analytical form are not robust with the error in the noise\nestimated from pretrained diffusion models. In this work, we construct an\nerror-robust Adams solver (ERA-Solver), which utilizes the implicit Adams\nnumerical method that consists of a predictor and a corrector. Different from\nthe traditional predictor based on explicit Adams methods, we leverage a\nLagrange interpolation function as the predictor, which is further enhanced\nwith an error-robust strategy to adaptively select the Lagrange bases with\nlower error in the estimated noise. Experiments on Cifar10, LSUN-Church, and\nLSUN-Bedroom datasets demonstrate that our proposed ERA-Solver achieves 5.14,\n9.42, and 9.69 Fenchel Inception Distance (FID) for image generation, with only\n10 network evaluations.\n","authors":["Shengmeng Li","Luping Liu","Zenghao Chai","Runnan Li","Xu Tan"],"pdf_url":"https://arxiv.org/pdf/2301.12935v3.pdf","comment":"16 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.02601v1","updated":"2023-02-06T07:45:57Z","published":"2023-02-06T07:45:57Z","title":"Learning Representations of Bi-Level Knowledge Graphs for Reasoning\n  beyond Link Prediction","summary":"  Knowledge graphs represent known facts using triplets. While existing\nknowledge graph embedding methods only consider the connections between\nentities, we propose considering the relationships between triplets. For\nexample, let us consider two triplets $T_1$ and $T_2$ where $T_1$ is\n(Academy_Awards, Nominates, Avatar) and $T_2$ is (Avatar, Wins,\nAcademy_Awards). Given these two base-level triplets, we see that $T_1$ is a\nprerequisite for $T_2$. In this paper, we define a higher-level triplet to\nrepresent a relationship between triplets, e.g., $\\langle T_1$,\nPrerequisiteFor, $T_2\\rangle$ where PrerequisiteFor is a higher-level relation.\nWe define a bi-level knowledge graph that consists of the base-level and the\nhigher-level triplets. We also propose a data augmentation strategy based on\nthe random walks on the bi-level knowledge graph to augment plausible triplets.\nOur model called BiVE learns embeddings by taking into account the structures\nof the base-level and the higher-level triplets, with additional consideration\nof the augmented triplets. We propose two new tasks: triplet prediction and\nconditional link prediction. Given a triplet $T_1$ and a higher-level relation,\nthe triplet prediction predicts a triplet that is likely to be connected to\n$T_1$ by the higher-level relation, e.g., $\\langle T_1$, PrerequisiteFor,\n?$\\rangle$. The conditional link prediction predicts a missing entity in a\ntriplet conditioned on another triplet, e.g., $\\langle T_1$, PrerequisiteFor,\n(Avatar, Wins, ?)$\\rangle$. Experimental results show that BiVE significantly\noutperforms all other methods in the two new tasks and the typical base-level\nlink prediction in real-world bi-level knowledge graphs.\n","authors":["Chanyoung Chung","Joyce Jiyoung Whang"],"pdf_url":"https://arxiv.org/pdf/2302.02601v1.pdf","comment":"14 pages, 3 figures, 15 tables. 37th AAAI Conference on Artificial\n  Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2302.02599v1","updated":"2023-02-06T07:22:49Z","published":"2023-02-06T07:22:49Z","title":"MAP: Memory-aware Automated Intra-op Parallel Training For Foundation\n  Models","summary":"  Recently, large models have achieved the state of the art performances in\nvarious fields. In order to support large model training, we have to use\ndistributed training techniques. However, finding an efficient distributed\nexecution plan not only requires fine-grained model statistics, such as memory\nand computing overhead of each operator but also is a labor-intensive task even\nfor an expert in the field of distributed training. In this paper, we introduce\nMAP, a compiler built upon PyTorch to implement Memory-aware Automated\nParallelization. To profiling operator costs, existing training systems and\nmachine learning pipelines either physically execute with respect to each\noperand or estimate the memory usage with a scaled input tensor, which are\noften time-consuming and misleading. Compared with existing methods, MAP\nprovides an easy-to-use symbolic profiler to generate memory and computing\nstatistics of an arbitrary PyTorch model with trivial time cost, so it will\nboost high productivity for ML developers. In addition, MAP can also seamlessly\nspeed up different static planning tasks on computation graphs for PyTorch, and\nrequires only a few lines of modification to user code to generate a new module\ninstance that has a top-performing distributed execution plan. The source code\nis publicly available at https://github.com/hpcaitech/ColossalAI\n","authors":["Yuliang Liu","Shenggui Li","Jiarui Fang","Yanjun Shao","Boyuan Yao","Yang You"],"pdf_url":"https://arxiv.org/pdf/2302.02599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02597v1","updated":"2023-02-06T07:17:31Z","published":"2023-02-06T07:17:31Z","title":"ProbPNN: Enhancing Deep Probabilistic Forecasting with Statistical\n  Information","summary":"  Probabilistic forecasts are essential for various downstream applications\nsuch as business development, traffic planning, and electrical grid balancing.\nMany of these probabilistic forecasts are performed on time series data that\ncontain calendar-driven periodicities. However, existing probabilistic\nforecasting methods do not explicitly take these periodicities into account.\nTherefore, in the present paper, we introduce a deep learning-based method that\nconsiders these calendar-driven periodicities explicitly. The present paper,\nthus, has a twofold contribution: First, we apply statistical methods that use\ncalendar-driven prior knowledge to create rolling statistics and combine them\nwith neural networks to provide better probabilistic forecasts. Second, we\nbenchmark ProbPNN with state-of-the-art benchmarks by comparing the achieved\nnormalised continuous ranked probability score (nCRPS) and normalised Pinball\nLoss (nPL) on two data sets containing in total more than 1000 time series. The\nresults of the benchmarks show that using statistical forecasting components\nimproves the probabilistic forecast performance and that ProbPNN outperforms\nother deep learning forecasting methods whilst requiring less computation\ncosts.\n","authors":["Benedikt Heidrich","Kaleb Phipps","Oliver Neumann","Marian Turowski","Ralf Mikut","Veit Hagenmeyer"],"pdf_url":"https://arxiv.org/pdf/2302.02597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09100v2","updated":"2023-02-06T07:09:03Z","published":"2022-11-16T18:35:42Z","title":"Global Optimization with Parametric Function Approximation","summary":"  We consider the problem of global optimization with noisy zeroth order\noracles - a well-motivated problem useful for various applications ranging from\nhyper-parameter tuning for deep learning to new material design. Existing work\nrelies on Gaussian processes or other non-parametric family, which suffers from\nthe curse of dimensionality. In this paper, we propose a new algorithm GO-UCB\nthat leverages a parametric family of functions (e.g., neural networks)\ninstead. Under a realizable assumption and a few other mild geometric\nconditions, we show that GO-UCB achieves a cumulative regret of\n$\\tilde{O}(\\sqrt{T})$ where $T$ is the time horizon. At the core of GO-UCB is a\ncarefully designed uncertainty set over parameters based on gradients that\nallows optimistic exploration. Synthetic and real-world experiments illustrate\nGO-UCB works better than Bayesian optimization approaches in high dimensional\ncases, even if the model is misspecified.\n","authors":["Chong Liu","Yu-Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2211.09100v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02596v1","updated":"2023-02-06T07:07:15Z","published":"2023-02-06T07:07:15Z","title":"Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook\n  for Sparse Neural Network Researchers","summary":"  This article does not propose any novel algorithm or new hardware for\nsparsity. Instead, it aims to serve the \"common good\" for the increasingly\nprosperous Sparse Neural Network (SNN) research community. We attempt to\nsummarize some most common confusions in SNNs, that one may come across in\nvarious scenarios such as paper review/rebuttal and talks - many drawn from the\nauthors' own bittersweet experiences! We feel that doing so is meaningful and\ntimely, since the focus of SNN research is notably shifting from traditional\npruning to more diverse and profound forms of sparsity before, during, and\nafter training. The intricate relationships between their scopes, assumptions,\nand approaches lead to misunderstandings, for non-experts or even experts in\nSNNs. In response, we summarize ten Q\\&As of SNNs from many key aspects,\nincluding dense vs. sparse, unstructured sparse vs. structured sparse, pruning\nvs. sparse training, dense-to-sparse training vs. sparse-to-sparse training,\nstatic sparsity vs. dynamic sparsity, before-training/during-training vs.\npost-training sparsity, and many more. We strive to provide proper and\ngenerically applicable answers to clarify those confusions to the best extent\npossible. We hope our summary provides useful general knowledge for people who\nwant to enter and engage with this exciting community; and also provides some\n\"mind of ease\" convenience for SNN researchers to explain their work in the\nright contexts. At the very least (and perhaps as this article's most\ninsignificant target functionality), if you are writing/planning to write a\npaper or rebuttal in the field of SNNs, we hope some of our answers could help\nyou!\n","authors":["Shiwei Liu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02595v1","updated":"2023-02-06T07:03:02Z","published":"2023-02-06T07:03:02Z","title":"Clarifying Trust of Materials Property Predictions using Neural Networks\n  with Distribution-Specific Uncertainty Quantification","summary":"  It is critical that machine learning (ML) model predictions be trustworthy\nfor high-throughput catalyst discovery approaches. Uncertainty quantification\n(UQ) methods allow estimation of the trustworthiness of an ML model, but these\nmethods have not been well explored in the field of heterogeneous catalysis.\nHerein, we investigate different UQ methods applied to a crystal graph\nconvolutional neural network (CGCNN) to predict adsorption energies of\nmolecules on alloys from the Open Catalyst 2020 (OC20) dataset, the largest\nexisting heterogeneous catalyst dataset. We apply three UQ methods to the\nadsorption energy predictions, namely k-fold ensembling, Monte Carlo dropout,\nand evidential regression. The effectiveness of each UQ method is assessed\nbased on accuracy, sharpness, dispersion, calibration, and tightness.\nEvidential regression is demonstrated to be a powerful approach for rapidly\nobtaining tunable, competitively trustworthy UQ estimates for heterogeneous\ncatalysis applications when using neural networks. Recalibration of model\nuncertainties is shown to be essential in practical screening applications of\ncatalysts using uncertainties.\n","authors":["Cameron Gruich","Varun Madhavan","Yixin Wang","Bryan Goldsmith"],"pdf_url":"https://arxiv.org/pdf/2302.02595v1.pdf","comment":"28 pages, 16 figures (8 main text, 8 SI), submitted to Machine\n  Learning: Science & Technology journal (MLST, IOP)"},{"id":"http://arxiv.org/abs/2302.02591v1","updated":"2023-02-06T06:58:17Z","published":"2023-02-06T06:58:17Z","title":"Generative Diffusion Models on Graphs: Methods and Applications","summary":"  Diffusion models, as a novel generative paradigm, have achieved remarkable\nsuccess in various image generation tasks such as image inpainting,\nimage-to-text translation, and video generation. Graph generation is a crucial\ncomputational task on graphs with numerous real-world applications. It aims to\nlearn the distribution of given graphs and then generate new graphs. Given the\ngreat success of diffusion models in image generation, increasing efforts have\nbeen made to leverage these techniques to advance graph generation in recent\nyears. In this paper, we first provide a comprehensive overview of generative\ndiffusion models on graphs, In particular, we review representative algorithms\nfor three variants of graph diffusion models, i.e., Score Matching with\nLangevin Dynamics (SMLD), Denoising Diffusion Probabilistic Model (DDPM), and\nScore-based Generative Model (SGM). Then, we summarize the major applications\nof generative diffusion models on graphs with a specific focus on molecule and\nprotein modeling. Finally, we discuss promising directions in generative\ndiffusion models on graph-structured data.\n","authors":["Wenqi Fan","Chengyi Liu","Yunqing Liu","Jiatong Li","Hang Li","Hui Liu","Jiliang Tang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2302.02591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02589v1","updated":"2023-02-06T06:54:49Z","published":"2023-02-06T06:54:49Z","title":"$z$-SignFedAvg: A Unified Stochastic Sign-based Compression for\n  Federated Learning","summary":"  Federated Learning (FL) is a promising privacy-preserving distributed\nlearning paradigm but suffers from high communication cost when training\nlarge-scale machine learning models. Sign-based methods, such as SignSGD\n\\cite{bernstein2018signsgd}, have been proposed as a biased gradient\ncompression technique for reducing the communication cost. However, sign-based\nalgorithms could diverge under heterogeneous data, which thus motivated the\ndevelopment of advanced techniques, such as the error-feedback method and\nstochastic sign-based compression, to fix this issue. Nevertheless, these\nmethods still suffer from slower convergence rates. Besides, none of them\nallows multiple local SGD updates like FedAvg \\cite{mcmahan2017communication}.\nIn this paper, we propose a novel noisy perturbation scheme with a general\nsymmetric noise distribution for sign-based compression, which not only allows\none to flexibly control the tradeoff between gradient bias and convergence\nperformance, but also provides a unified viewpoint to existing stochastic\nsign-based methods. More importantly, the unified noisy perturbation scheme\nenables the development of the very first sign-based FedAvg algorithm\n($z$-SignFedAvg) to accelerate the convergence. Theoretically, we show that\n$z$-SignFedAvg achieves a faster convergence rate than existing sign-based\nmethods and, under the uniformly distributed noise, can enjoy the same\nconvergence rate as its uncompressed counterpart. Extensive experiments are\nconducted to demonstrate that the $z$-SignFedAvg can achieve competitive\nempirical performance on real datasets and outperforms existing schemes.\n","authors":["Zhiwei Tang","Yanmeng Wang","Tsung-Hui Chang"],"pdf_url":"https://arxiv.org/pdf/2302.02589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03171v4","updated":"2023-02-06T06:08:12Z","published":"2022-06-07T10:42:02Z","title":"Introspective Experience Replay: Look Back When Surprised","summary":"  In reinforcement learning (RL), experience replay-based sampling techniques\nplay a crucial role in promoting convergence by eliminating spurious\ncorrelations. However, widely used methods such as uniform experience replay\n(UER) and prioritized experience replay (PER) have been shown to have\nsub-optimal convergence and high seed sensitivity respectively. To address\nthese issues, we propose a novel approach called IntrospectiveExperience Replay\n(IER) that selectively samples batches of data points prior to surprising\nevents. Our method builds upon the theoretically sound reverse experience\nreplay (RER) technique, which has been shown to reduce bias in the output of\nQ-learning-type algorithms with linear function approximation. However, this\napproach is not always practical or reliable when using neural function\napproximation. Through empirical evaluations, we demonstrate that IER with\nneural function approximation yields reliable and superior performance compared\ntoUER, PER, and hindsight experience replay (HER) across most tasks.\n","authors":["Ramnath Kumar","Dheeraj Nagaraj"],"pdf_url":"https://arxiv.org/pdf/2206.03171v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.00371v2","updated":"2023-02-06T05:42:52Z","published":"2021-07-01T11:15:20Z","title":"Sparse GCA and Thresholded Gradient Descent","summary":"  Generalized correlation analysis (GCA) is concerned with uncovering linear\nrelationships across multiple datasets. It generalizes canonical correlation\nanalysis that is designed for two datasets. We study sparse GCA when there are\npotentially multiple generalized correlation tuples in data and the loading\nmatrix has a small number of nonzero rows. It includes sparse CCA and sparse\nPCA of correlation matrices as special cases. We first formulate sparse GCA as\ngeneralized eigenvalue problems at both population and sample levels via a\ncareful choice of normalization constraints. Based on a Lagrangian form of the\nsample optimization problem, we propose a thresholded gradient descent\nalgorithm for estimating GCA loading vectors and matrices in high dimensions.\nWe derive tight estimation error bounds for estimators generated by the\nalgorithm with proper initialization. We also demonstrate the prowess of the\nalgorithm on a number of synthetic datasets.\n","authors":["Sheng Gao","Zongming Ma"],"pdf_url":"https://arxiv.org/pdf/2107.00371v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02573v1","updated":"2023-02-06T05:33:16Z","published":"2023-02-06T05:33:16Z","title":"Topology-aware Federated Learning in Edge Computing: A Comprehensive\n  Survey","summary":"  The ultra-low latency requirements of 5G/6G applications and privacy\nconstraints call for distributed machine learning systems to be deployed at the\nedge. With its simple yet effective approach, federated learning (FL) is proved\nto be a natural solution for massive user-owned devices in edge computing with\ndistributed and private training data. Most vanilla FL algorithms based on\nFedAvg follow a naive star topology, ignoring the heterogeneity and hierarchy\nof the volatile edge computing architectures and topologies in reality. In this\npaper, we conduct a comprehensive survey on the existing work of optimized FL\nmodels, frameworks, and algorithms with a focus on their network topologies.\nAfter a brief recap of FL and edge computing networks, we introduce various\ntypes of edge network topologies, along with the optimizations under the\naforementioned network topologies. Lastly, we discuss the remaining challenges\nand future works for applying FL in topology-specific edge networks.\n","authors":["Jiajun Wu","Steve Drew","Fan Dong","Zhuangdi Zhu","Jiayu Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.02573v1.pdf","comment":"36 pages, 16 figures, journal submission"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.02755v1","updated":"2023-02-06T13:05:55Z","published":"2023-02-06T13:05:55Z","title":"Fine-Grained Action Detection with RGB and Pose Information using Two\n  Stream Convolutional Networks","summary":"  As participants of the MediaEval 2022 Sport Task, we propose a two-stream\nnetwork approach for the classification and detection of table tennis strokes.\nEach stream is a succession of 3D Convolutional Neural Network (CNN) blocks\nusing attention mechanisms. Each stream processes different 4D inputs. Our\nmethod utilizes raw RGB data and pose information computed from MMPose toolbox.\nThe pose information is treated as an image by applying the pose either on a\nblack background or on the original RGB frame it has been computed from. Best\nperformance is obtained by feeding raw RGB data to one stream, Pose + RGB\n(PRGB) information to the other stream and applying late fusion on the\nfeatures. The approaches were evaluated on the provided TTStroke-21 data sets.\nWe can report an improvement in stroke classification, reaching 87.3% of\naccuracy, while the detection does not outperform the baseline but still\nreaches an IoU of 0.349 and mAP of 0.110.\n","authors":["Leonard Hacker","Finn Bartels","Pierre-Etienne Martin"],"pdf_url":"https://arxiv.org/pdf/2302.02755v1.pdf","comment":"Working note paper of the sport task of MediaEval 2022 in Bergen,\n  Norway, 12-13 Jan 2023"},{"id":"http://arxiv.org/abs/2302.02752v1","updated":"2023-02-06T12:58:01Z","published":"2023-02-06T12:58:01Z","title":"Baseline Method for the Sport Task of MediaEval 2022 with 3D CNNs using\n  Attention Mechanisms","summary":"  This paper presents the baseline method proposed for the Sports Video task\npart of the MediaEval 2022 benchmark. This task proposes two subtasks: stroke\nclassification from trimmed videos, and stroke detection from untrimmed videos.\nThis baseline addresses both subtasks. We propose two types of 3D-CNN\narchitectures to solve the two subtasks. Both 3D-CNNs use Spatio-temporal\nconvolutions and attention mechanisms. The architectures and the training\nprocess are tailored to solve the addressed subtask. This baseline method is\nshared publicly online to help the participants in their investigation and\nalleviate eventually some aspects of the task such as video processing,\ntraining method, evaluation and submission routine. The baseline method reaches\n86.4% of accuracy with our v2 model for the classification subtask. For the\ndetection subtask, the baseline reaches a mAP of 0.131 and IoU of 0.515 with\nour v1 model.\n","authors":["Pierre-Etienne Martin"],"pdf_url":"https://arxiv.org/pdf/2302.02752v1.pdf","comment":"Baseline paper for the sport Task of MediaEval 2022"}]},"2023-02-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2210.00660v2","updated":"2023-02-05T23:51:06Z","published":"2022-10-03T00:28:44Z","title":"A Non-monotonic Self-terminating Language Model","summary":"  Recent large-scale neural autoregressive sequence models have shown\nimpressive performances on a variety of natural language generation tasks.\nHowever, their generated sequences often exhibit degenerate properties such as\nnon-termination, undesirable repetition, and premature termination, when\ngenerated with decoding algorithms such as greedy search, beam search, top-$k$\nsampling, and nucleus sampling. In this paper, we focus on the problem of\nnon-terminating sequences resulting from an incomplete decoding algorithm. We\nfirst define an incomplete probable decoding algorithm which includes greedy\nsearch, top-$k$ sampling, and nucleus sampling, beyond the incomplete decoding\nalgorithm originally put forward by Welleck et al. (2020). We then propose a\nnon-monotonic self-terminating language model, which significantly relaxes the\nconstraint of monotonically increasing termination probability in the\noriginally proposed self-terminating language model by Welleck et al. (2020),\nto address the issue of non-terminating sequences when using incomplete\nprobable decoding algorithms. We prove that our proposed model prevents\nnon-terminating sequences when using not only incomplete probable decoding\nalgorithms but also beam search. We empirically validate our model on sequence\ncompletion tasks with various architectures.\n","authors":["Eugene Choi","Kyunghyun Cho","Cheolhyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2210.00660v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.02500v1","updated":"2023-02-05T22:34:36Z","published":"2023-02-05T22:34:36Z","title":"TempEL: Linking Dynamically Evolving and Newly Emerging Entities","summary":"  In our continuously evolving world, entities change over time and new,\npreviously non-existing or unknown, entities appear. We study how this\nevolutionary scenario impacts the performance on a well established entity\nlinking (EL) task. For that study, we introduce TempEL, an entity linking\ndataset that consists of time-stratified English Wikipedia snapshots from 2013\nto 2022, from which we collect both anchor mentions of entities, and these\ntarget entities' descriptions. By capturing such temporal aspects, our newly\nintroduced TempEL resource contrasts with currently existing entity linking\ndatasets, which are composed of fixed mentions linked to a single static\nversion of a target Knowledge Base (e.g., Wikipedia 2010 for CoNLL-AIDA).\nIndeed, for each of our collected temporal snapshots, TempEL contains links to\nentities that are continual, i.e., occur in all of the years, as well as\ncompletely new entities that appear for the first time at some point. Thus, we\nenable to quantify the performance of current state-of-the-art EL models for:\n(i) entities that are subject to changes over time in their Knowledge Base\ndescriptions as well as their mentions' contexts, and (ii) newly created\nentities that were previously non-existing (e.g., at the time the EL model was\ntrained). Our experimental results show that in terms of temporal performance\ndegradation, (i) continual entities suffer a decrease of up to 3.1% EL\naccuracy, while (ii) for new entities this accuracy drop is up to 17.9%. This\nhighlights the challenge of the introduced TempEL dataset and opens new\nresearch prospects in the area of time-evolving entity disambiguation.\n","authors":["Klim Zaporojets","Lucie-Aimee Kaffee","Johannes Deleu","Thomas Demeester","Chris Develder","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2302.02500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02479v1","updated":"2023-02-05T20:30:48Z","published":"2023-02-05T20:30:48Z","title":"Hatemongers ride on echo chambers to escalate hate speech diffusion","summary":"  Recent years have witnessed a swelling rise of hateful and abusive content\nover online social networks. While detection and moderation of hate speech have\nbeen the early go-to countermeasures, the solution requires a deeper\nexploration of the dynamics of hate generation and propagation. We analyze more\nthan 32 million posts from over 6.8 million users across three popular online\nsocial networks to investigate the interrelations between hateful behavior,\ninformation dissemination, and polarised organization mediated by echo\nchambers. We find that hatemongers play a more crucial role in governing the\nspread of information compared to singled-out hateful content. This observation\nholds for both the growth of information cascades as well as the conglomeration\nof hateful actors. Dissection of the core-wise distribution of these networks\npoints towards the fact that hateful users acquire a more well-connected\nposition in the social network and often flock together to build up information\ncascades. We observe that this cohesion is far from mere organized behavior;\ninstead, in these networks, hatemongers dominate the echo chambers -- groups of\nusers actively align themselves to specific ideological positions. The observed\ndominance of hateful users to inflate information cascades is primarily via\nuser interactions amplified within these echo chambers. We conclude our study\nwith a cautionary note that popularity-based recommendation of content is\nsusceptible to be exploited by hatemongers given their potential to escalate\ncontent popularity via echo-chambered interactions.\n","authors":["Vasu Goel","Dhruv Sahnan","Subhabrata Dutta","Anil Bandhakavi","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2302.02479v1.pdf","comment":"Accepted in PNAS Nexus"},{"id":"http://arxiv.org/abs/2302.02463v1","updated":"2023-02-05T19:15:33Z","published":"2023-02-05T19:15:33Z","title":"Nationality Bias in Text Generation","summary":"  Little attention is placed on analyzing nationality bias in language models,\nespecially when nationality is highly used as a factor in increasing the\nperformance of social NLP models. This paper examines how a text generation\nmodel, GPT-2, accentuates pre-existing societal biases about country-based\ndemonyms. We generate stories using GPT-2 for various nationalities and use\nsensitivity analysis to explore how the number of internet users and the\ncountry's economic status impacts the sentiment of the stories. To reduce the\npropagation of biases through large language models (LLM), we explore the\ndebiasing method of adversarial triggering. Our results show that GPT-2\ndemonstrates significant bias against countries with lower internet users, and\nadversarial triggering effectively reduces the same.\n","authors":["Pranav Narayanan Venkit","Sanjana Gautam","Ruchi Panchanadikar"," Ting-Hao"," Huang","Shomir Wilson"],"pdf_url":"https://arxiv.org/pdf/2302.02463v1.pdf","comment":"EACL 2023 Paper"},{"id":"http://arxiv.org/abs/2301.07695v2","updated":"2023-02-05T19:10:08Z","published":"2023-01-16T05:10:20Z","title":"EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records","summary":"  We present a new text-to-SQL dataset for electronic health records (EHRs).\nThe utterances were collected from 222 hospital staff, including physicians,\nnurses, insurance review and health records teams, and more. To construct the\nQA dataset on structured EHR data, we conducted a poll at a university hospital\nand templatized the responses to create seed questions. Then, we manually\nlinked them to two open-source EHR databases, MIMIC-III and eICU, and included\nthem with various time expressions and held-out unanswerable questions in the\ndataset, which were all collected from the poll. Our dataset poses a unique set\nof challenges: the model needs to 1) generate SQL queries that reflect a wide\nrange of needs in the hospital, including simple retrieval and complex\noperations such as calculating survival rate, 2) understand various time\nexpressions to answer time-sensitive questions in healthcare, and 3)\ndistinguish whether a given question is answerable or unanswerable based on the\nprediction confidence. We believe our dataset, EHRSQL, could serve as a\npractical benchmark to develop and assess QA models on structured EHR data and\ntake one step further towards bridging the gap between text-to-SQL research and\nits real-life deployment in healthcare. EHRSQL is available at\nhttps://github.com/glee4810/EHRSQL.\n","authors":["Gyubok Lee","Hyeonji Hwang","Seongsu Bae","Yeonsu Kwon","Woncheol Shin","Seongjun Yang","Minjoon Seo","Jong-Yeup Kim","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2301.07695v2.pdf","comment":"Published as a conference paper at NeurIPS 2022 (Track on Datasets\n  and Benchmarks)"},{"id":"http://arxiv.org/abs/2209.04862v2","updated":"2023-02-05T18:40:38Z","published":"2022-09-11T13:32:39Z","title":"Adaptive Perturbation-Based Gradient Estimation for Discrete Latent\n  Variable Models","summary":"  The integration of discrete algorithmic components in deep learning\narchitectures has numerous applications. Recently, Implicit Maximum Likelihood\nEstimation (IMLE, Niepert, Minervini, and Franceschi 2021), a class of gradient\nestimators for discrete exponential family distributions, was proposed by\ncombining implicit differentiation through perturbation with the path-wise\ngradient estimator. However, due to the finite difference approximation of the\ngradients, it is especially sensitive to the choice of the finite difference\nstep size, which needs to be specified by the user. In this work, we present\nAdaptive IMLE (AIMLE), the first adaptive gradient estimator for complex\ndiscrete distributions: it adaptively identifies the target distribution for\nIMLE by trading off the density of gradient information with the degree of bias\nin the gradient estimates. We empirically evaluate our estimator on synthetic\nexamples, as well as on Learning to Explain, Discrete Variational\nAuto-Encoders, and Neural Relational Inference tasks. In our experiments, we\nshow that our adaptive gradient estimator can produce faithful estimates while\nrequiring orders of magnitude fewer samples than other gradient estimators.\n","authors":["Pasquale Minervini","Luca Franceschi","Mathias Niepert"],"pdf_url":"https://arxiv.org/pdf/2209.04862v2.pdf","comment":"Proceedings of the Thirty-Seventh AAAI Conference on Artificial\n  Intelligence (AAAI 2023)"},{"id":"http://arxiv.org/abs/2302.02453v1","updated":"2023-02-05T18:35:21Z","published":"2023-02-05T18:35:21Z","title":"FineDeb: A Debiasing Framework for Language Models","summary":"  As language models are increasingly included in human-facing machine learning\ntools, bias against demographic subgroups has gained attention. We propose\nFineDeb, a two-phase debiasing framework for language models that starts with\ncontextual debiasing of embeddings learned by pretrained language models. The\nmodel is then fine-tuned on a language modeling objective. Our results show\nthat FineDeb offers stronger debiasing in comparison to other methods which\noften result in models as biased as the original language model. Our framework\nis generalizable for demographics with multiple classes, and we demonstrate its\neffectiveness through extensive experiments and comparisons with state of the\nart techniques. We release our code and data on GitHub.\n","authors":["Akash Saravanan","Dhruv Mullick","Habibur Rahman","Nidhi Hegde"],"pdf_url":"https://arxiv.org/pdf/2302.02453v1.pdf","comment":"Poster presentation at AAAI 2023: The Workshop on Artificial\n  Intelligence for Social Good 2023 (https://amulyayadav.github.io/AI4SG2023/)"},{"id":"http://arxiv.org/abs/2302.02419v1","updated":"2023-02-05T16:15:46Z","published":"2023-02-05T16:15:46Z","title":"deep learning of segment-level feature representation for speech emotion\n  recognition in conversations","summary":"  Accurately detecting emotions in conversation is a necessary yet challenging\ntask due to the complexity of emotions and dynamics in dialogues. The emotional\nstate of a speaker can be influenced by many different factors, such as\ninterlocutor stimulus, dialogue scene, and topic. In this work, we propose a\nconversational speech emotion recognition method to deal with capturing\nattentive contextual dependency and speaker-sensitive interactions. First, we\nuse a pretrained VGGish model to extract segment-based audio representation in\nindividual utterances. Second, an attentive bi-directional gated recurrent unit\n(GRU) models contextual-sensitive information and explores intra- and\ninter-speaker dependencies jointly in a dynamic manner. The experiments\nconducted on the standard conversational dataset MELD demonstrate the\neffectiveness of the proposed method when compared against state-of the-art\nmethods.\n","authors":["Jiachen Luo","Huy Phan","Joshua Reiss"],"pdf_url":"https://arxiv.org/pdf/2302.02419v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2210.07316v2","updated":"2023-02-05T15:59:49Z","published":"2022-10-13T19:42:08Z","title":"MTEB: Massive Text Embedding Benchmark","summary":"  Text embeddings are commonly evaluated on a small set of datasets from a\nsingle task not covering their possible applications to other tasks. It is\nunclear whether state-of-the-art embeddings on semantic textual similarity\n(STS) can be equally well applied to other tasks like clustering or reranking.\nThis makes progress in the field difficult to track, as various models are\nconstantly being proposed without proper evaluation. To solve this problem, we\nintroduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding\ntasks covering a total of 58 datasets and 112 languages. Through the\nbenchmarking of 33 models on MTEB, we establish the most comprehensive\nbenchmark of text embeddings to date. We find that no particular text embedding\nmethod dominates across all tasks. This suggests that the field has yet to\nconverge on a universal text embedding method and scale it up sufficiently to\nprovide state-of-the-art results on all embedding tasks. MTEB comes with\nopen-source code and a public leaderboard at\nhttps://github.com/embeddings-benchmark/mteb.\n","authors":["Niklas Muennighoff","Nouamane Tazi","Loïc Magne","Nils Reimers"],"pdf_url":"https://arxiv.org/pdf/2210.07316v2.pdf","comment":"24 pages, 14 tables, 6 figures"},{"id":"http://arxiv.org/abs/2301.12596v2","updated":"2023-02-05T15:30:42Z","published":"2023-01-30T00:53:50Z","title":"Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with\n  Unsupervised Text Pretraining","summary":"  While neural text-to-speech (TTS) has achieved human-like natural synthetic\nspeech, multilingual TTS systems are limited to resource-rich languages due to\nthe need for paired text and studio-quality audio data. This paper proposes a\nmethod for zero-shot multilingual TTS using text-only data for the target\nlanguage. The use of text-only data allows the development of TTS systems for\nlow-resource languages for which only textual resources are available, making\nTTS accessible to thousands of languages. Inspired by the strong cross-lingual\ntransferability of multilingual language models, our framework first performs\nmasked language model pretraining with multilingual text-only data. Then we\ntrain this model with a paired data in a supervised manner, while freezing a\nlanguage-aware embedding layer. This allows inference even for languages not\nincluded in the paired data but present in the text-only data. Evaluation\nresults demonstrate highly intelligible zero-shot TTS with a character error\nrate of less than 12% for an unseen language. All experiments were conducted\nusing public datasets and the implementation will be made available for\nreproducibility.\n","authors":["Takaaki Saeki","Soumi Maiti","Xinjian Li","Shinji Watanabe","Shinnosuke Takamichi","Hiroshi Saruwatari"],"pdf_url":"https://arxiv.org/pdf/2301.12596v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02291v1","updated":"2023-02-05T03:58:45Z","published":"2023-02-05T03:58:45Z","title":"A Semantic Approach to Negation Detection and Word Disambiguation with\n  Natural Language Processing","summary":"  This study aims to demonstrate the methods for detecting negations in a\nsentence by uniquely evaluating the lexical structure of the text via word\nsense disambiguation. Additionally, the proposed method examined all the unique\nfeatures of the related expressions within a text to resolve the contextual\nusage of the sentence and the effect of negation on sentiment analysis. The\napplication of popular expression detectors skips this important step, thereby\nneglecting the root words caught in the web of negation, and making text\nclassification difficult for machine learning and sentiment analysis. This\nstudy adopts the Natural Language Processing (NLP) approach to discover and\nantonimize words that were negated for better accuracy in text classification.\nThis method acts as a lens that reads through a given word sequence using a\nknowledge base provided by an NLP library called WordHoard in order to detect\nnegation signals. Early results show that our initial analysis improved\ntraditional sentiment analysis that sometimes neglects word negations or\nassigns an inverse polarity score. The SentiWordNet analyzer was improved by\n35%, the Vader analyzer by 20% and the TextBlob analyzer by 6%.\n","authors":["Izunna Okpala","Guillermo Romera Rodriguez","Andrea Tapia","Shane Halse","Jess Kropczynski"],"pdf_url":"https://arxiv.org/pdf/2302.02291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02011v3","updated":"2023-02-05T02:33:00Z","published":"2022-11-03T17:26:44Z","title":"Inverse scaling can become U-shaped","summary":"  Scaling up language models has been empirically shown to improve performance\nand unlock emergent abilities. Conversely, observing worse performance as a\nfunction of scale (\"inverse scaling\") would indicate that scaling encourages\nbehaviors that are misaligned with human preferences. The Inverse Scaling Prize\nidentified eleven such inverse scaling tasks, evaluated on models of up to 280B\nparameters and up to 500 zettaFLOPs of training compute.\n  This paper takes a closer look at these inverse scaling tasks. We evaluate\nmodels of up to 540B parameters, trained on five times more compute than those\nevaluated in the Inverse Scaling Prize. With this increased range of model\nsizes and training compute, ten out of the eleven tasks exhibit what we call\n\"U-shaped scaling\" -- performance decreases up to a certain model size, and\nthen increases again up to the largest model evaluated. U-shaped scaling can be\nseen as emergent ability unlocked by scaling and implies that inverse scaling\nmay not hold for larger models.\n","authors":["Jason Wei","Yi Tay","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2211.02011v3.pdf","comment":"v3 includes all 11 tasks in the inverse scaling benchmark"},{"id":"http://arxiv.org/abs/2302.02275v1","updated":"2023-02-05T01:37:26Z","published":"2023-02-05T01:37:26Z","title":"Unleashing the True Potential of Sequence-to-Sequence Models for\n  Sequence Tagging and Structure Parsing","summary":"  Sequence-to-Sequence (S2S) models have achieved remarkable success on various\ntext generation tasks. However, learning complex structures with S2S models\nremains challenging as external neural modules and additional lexicons are\noften supplemented to predict non-textual outputs. We present a systematic\nstudy of S2S modeling using contained decoding on four core tasks:\npart-of-speech tagging, named entity recognition, constituency and dependency\nparsing, to develop efficient exploitation methods costing zero extra\nparameters. In particular, 3 lexically diverse linearization schemas and\ncorresponding constrained decoding methods are designed and evaluated.\nExperiments show that although more lexicalized schemas yield longer output\nsequences that require heavier training, their sequences being closer to\nnatural language makes them easier to learn. Moreover, S2S models using our\nconstrained decoding outperform other S2S approaches using external resources.\nOur best models perform better than or comparably to the state-of-the-art for\nall 4 tasks, lighting a promise for S2S models to generate non-sequential\nstructures.\n","authors":["Han He","Jinho D. Choi"],"pdf_url":"https://arxiv.org/pdf/2302.02275v1.pdf","comment":"Accepted to TACL 2023: Transactions of the Association for\n  Computational Linguistics, post-acceptance final version"},{"id":"http://arxiv.org/abs/2210.06475v2","updated":"2023-02-05T01:02:30Z","published":"2022-10-13T08:45:23Z","title":"Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models","summary":"  We introduce equi-tuning, a novel fine-tuning method that transforms\n(potentially non-equivariant) pretrained models into group equivariant models\nwhile incurring minimum $L_2$ loss between the feature representations of the\npretrained and the equivariant models. Large pretrained models can be\nequi-tuned for different groups to satisfy the needs of various downstream\ntasks. Equi-tuned models benefit from both group equivariance as an inductive\nbias and semantic priors from pretrained models. We provide applications of\nequi-tuning on three different tasks: image classification, compositional\ngeneralization in language, and fairness in natural language generation (NLG).\nWe also provide a novel group-theoretic definition for fairness in NLG. The\neffectiveness of this definition is shown by testing it against a standard\nempirical method of fairness in NLG. We provide experimental results for\nequi-tuning using a variety of pretrained models: Alexnet, Resnet, VGG, and\nDensenet for image classification; RNNs, GRUs, and LSTMs for compositional\ngeneralization; and GPT2 for fairness in NLG. We test these models on benchmark\ndatasets across all considered tasks to show the generality and effectiveness\nof the proposed method.\n","authors":["Sourya Basu","Prasanna Sattigeri","Karthikeyan Natesan Ramamurthy","Vijil Chenthamarakshan","Kush R. Varshney","Lav R. Varshney","Payel Das"],"pdf_url":"https://arxiv.org/pdf/2210.06475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03499v1","updated":"2023-02-05T14:30:32Z","published":"2023-02-05T14:30:32Z","title":"Exploring Data Augmentation for Code Generation Tasks","summary":"  Advances in natural language processing, such as transfer learning from\npre-trained language models, have impacted how models are trained for\nprogramming language tasks too. Previous research primarily explored code\npre-training and expanded it through multi-modality and multi-tasking, yet the\ndata for downstream tasks remain modest in size. Focusing on data utilization\nfor downstream tasks, we propose and adapt augmentation methods that yield\nconsistent improvements in code translation and summarization by up to 6.9% and\n7.5% respectively. Further analysis suggests that our methods work orthogonally\nand show benefits in output code style and numeric consistency. We also discuss\ntest data imperfections.\n","authors":["Pinzhen Chen","Gerasimos Lampouras"],"pdf_url":"https://arxiv.org/pdf/2302.03499v1.pdf","comment":"Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.03498v1","updated":"2023-02-05T09:49:18Z","published":"2023-02-05T09:49:18Z","title":"PAMP: A unified framework boosting low resource automatic speech\n  recognition","summary":"  We propose a novel text-to-speech (TTS) data augmentation framework for low\nresource automatic speech recognition (ASR) tasks, named phoneme audio mix up\n(PAMP). The PAMP method is highly interpretable and can incorporate prior\nknowledge of pronunciation rules. Furthermore, PAMP can be easily deployed in\nalmost any language, extremely for low resource ASR tasks. Extensive\nexperiments have demonstrated the great effectiveness of PAMP on low resource\nASR tasks: we achieve a \\textbf{10.84\\%} character error rate (CER) on the\ncommon voice Cantonese ASR task, bringing a great relative improvement of about\n\\textbf{30\\%} compared to the previous state-of-the-art which was achieved by\nfine-tuning the wav2vec2 pretrained model.\n","authors":["Zeping Min","Qian Ge","Zhong Li","Weinan E"],"pdf_url":"https://arxiv.org/pdf/2302.03498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03507v1","updated":"2023-02-05T07:41:17Z","published":"2023-02-05T07:41:17Z","title":"Meta-Learning Siamese Network for Few-Shot Text Classification","summary":"  Few-shot learning has been used to tackle the problem of label scarcity in\ntext classification, of which meta-learning based methods have shown to be\neffective, such as the prototypical networks (PROTO). Despite the success of\nPROTO, there still exist three main problems: (1) ignore the randomness of the\nsampled support sets when computing prototype vectors; (2) disregard the\nimportance of labeled samples; (3) construct meta-tasks in a purely random\nmanner. In this paper, we propose a Meta-Learning Siamese Network, namely,\nMeta-SN, to address these issues. Specifically, instead of computing prototype\nvectors from the sampled support sets, Meta-SN utilizes external knowledge\n(e.g. class names and descriptive texts) for class labels, which is encoded as\nthe low-dimensional embeddings of prototype vectors. In addition, Meta-SN\npresents a novel sampling strategy for constructing meta-tasks, which gives\nhigher sampling probabilities to hard-to-classify samples. Extensive\nexperiments are conducted on six benchmark datasets to show the clear\nsuperiority of Meta-SN over other state-of-the-art models. For reproducibility,\nall the datasets and codes are provided at https://github.com/hccngu/Meta-SN.\n","authors":["Chengcheng Han","Yuhe Wang","Yingnan Fu","Xiang Li","Minghui Qiu","Ming Gao","Aoying Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.03507v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.02504v1","updated":"2023-02-05T22:51:27Z","published":"2023-02-05T22:51:27Z","title":"Reconstruction-driven motion estimation for motion-compensated MR CINE\n  imaging","summary":"  In cardiac CINE, motion-compensated MR reconstruction (MCMR) is an effective\napproach to address highly undersampled acquisitions by incorporating motion\ninformation between frames. In this work, we propose a deep learning-based\nframework to address the MCMR problem efficiently. Contrary to state-of-the-art\n(SOTA) MCMR methods which break the original problem into two sub-optimization\nproblems, i.e. motion estimation and reconstruction, we formulate this problem\nas a single entity with one single optimization. We discard the canonical\nmotion-warping loss (similarity measurement between motion-warped images and\ntarget images) to estimate the motion, but drive the motion estimation process\ndirectly by the final reconstruction performance. The higher reconstruction\nquality is achieved without using any smoothness loss terms and without\niterative processing between motion estimation and reconstruction. Therefore,\nwe avoid non-trivial loss weighting factors tuning and time-consuming iterative\nprocessing. Experiments on 43 in-house acquired 2D CINE datasets indicate that\nthe proposed MCMR framework can deliver artifact-free motion estimation and\nhigh-quality MR images even for imaging accelerations up to 20x. The proposed\nframework is compared to SOTA non-MCMR and MCMR methods and outperforms these\nmethods qualitatively and quantitatively in all applied metrics across all\nexperiments with different acceleration rates.\n","authors":["Jiazhen Pan","Wenqi Huang","Daniel Rueckert","Thomas Küstner","Kerstin Hammernik"],"pdf_url":"https://arxiv.org/pdf/2302.02504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02503v1","updated":"2023-02-05T22:49:33Z","published":"2023-02-05T22:49:33Z","title":"Leaving Reality to Imagination: Robust Classification via Generated\n  Datasets","summary":"  Recent research on robustness has revealed significant performance gaps\nbetween neural image classifiers trained on datasets that are similar to the\ntest set, and those that are from a naturally shifted distribution, such as\nsketches, paintings, and animations of the object categories observed during\ntraining. Prior work focuses on reducing this gap by designing engineered\naugmentations of training data or through unsupervised pretraining of a single\nlarge model on massive in-the-wild training datasets scraped from the Internet.\nHowever, the notion of a dataset is also undergoing a paradigm shift in recent\nyears. With drastic improvements in the quality, ease-of-use, and access to\nmodern generative models, generated data is pervading the web. In this light,\nwe study the question: How do these generated datasets influence the natural\nrobustness of image classifiers? We find that Imagenet classifiers trained on\nreal data augmented with generated data achieve higher accuracy and effective\nrobustness than standard training and popular augmentation strategies in the\npresence of natural distribution shifts. We analyze various factors influencing\nthese results, including the choice of conditioning strategies and the amount\nof generated data. Lastly, we introduce and analyze an evolving generated\ndataset, ImageNet-G-v1, to better benchmark the design, utility, and critique\nof standalone generated datasets for robust and trustworthy machine learning.\nThe code and datasets are available at\nhttps://github.com/Hritikbansal/generative-robustness.\n","authors":["Hritik Bansal","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2302.02503v1.pdf","comment":"20 pages, 12 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2302.02502v1","updated":"2023-02-05T22:43:50Z","published":"2023-02-05T22:43:50Z","title":"On the Role of Contrastive Representation Learning in Adversarial\n  Robustness: An Empirical Study","summary":"  Self-supervised contrastive learning has solved one of the significant\nobstacles in deep learning by alleviating the annotation cost. This advantage\ncomes with the price of false negative-pair selection without any label\ninformation. Supervised contrastive learning has emerged as an extension of\ncontrastive learning to eliminate this issue. However, aside from accuracy,\nthere is a lack of understanding about the impacts of adversarial training on\nthe representations learned by these learning schemes. In this work, we utilize\nsupervised learning as a baseline to comprehensively study the robustness of\ncontrastive and supervised contrastive learning under different adversarial\ntraining scenarios. Then, we begin by looking at how adversarial training\naffects the learned representations in hidden layers, discovering more\nredundant representations between layers of the model. Our results on CIFAR-10\nand CIFAR-100 image classification benchmarks demonstrate that this redundancy\nis highly reduced by adversarial fine-tuning applied to the contrastive\nlearning scheme, leading to more robust representations. However, adversarial\nfine-tuning is not very effective for supervised contrastive learning and\nsupervised learning schemes. Our code is released at\nhttps://github.com/softsys4ai/CL-Robustness.\n","authors":["Fatemeh Ghofrani","Mehdi Yaghouti","Pooyan Jamshidi"],"pdf_url":"https://arxiv.org/pdf/2302.02502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02499v1","updated":"2023-02-05T22:33:49Z","published":"2023-02-05T22:33:49Z","title":"Handwriting and Drawing for Depression Detection: A Preliminary Study","summary":"  The events of the past 2 years related to the pandemic have shown that it is\nincreasingly important to find new tools to help mental health experts in\ndiagnosing mood disorders. Leaving aside the longcovid cognitive (e.g.,\ndifficulty in concentration) and bodily (e.g., loss of smell) effects, the\nshort-term covid effects on mental health were a significant increase in\nanxiety and depressive symptoms. The aim of this study is to use a new tool,\nthe online handwriting and drawing analysis, to discriminate between healthy\nindividuals and depressed patients. To this aim, patients with clinical\ndepression (n = 14), individuals with high sub-clinical (diagnosed by a test\nrather than a doctor) depressive traits (n = 15) and healthy individuals (n =\n20) were recruited and asked to perform four online drawing /handwriting tasks\nusing a digitizing tablet and a special writing device. From the raw collected\nonline data, seventeen drawing/writing features (categorized into five\ncategories) were extracted, and compared among the three groups of the involved\nparticipants, through ANOVA repeated measures analyses. Results shows that Time\nfeatures are more effective in discriminating between healthy and participants\nwith sub-clinical depressive characteristics. On the other hand, Ductus and\nPressure features are more effective in discriminating between clinical\ndepressed and healthy participants.\n","authors":["Gennaro Raimo","Michele Buonanno","Massimiliano Conson","Gennaro Cordasco","Marcos Faundez-Zanuy","Stefano Marrone","Fiammetta Marulli","Alessandro Vinciarelli","Anna Esposito"],"pdf_url":"https://arxiv.org/pdf/2302.02499v1.pdf","comment":"In: Mahmud, M., Ieracitano, C., Kaiser, M.S., Mammone, N., Morabito,\n  F.C. (eds) Applied Intelligence and Informatics. AII 2022. Communications in\n  Computer and Information Science, vol 1724. Springer, Cham"},{"id":"http://arxiv.org/abs/2302.02483v1","updated":"2023-02-05T21:25:59Z","published":"2023-02-05T21:25:59Z","title":"Multi-Task Self-Supervised Learning for Image Segmentation Task","summary":"  Thanks to breakthroughs in AI and Deep learning methodology, Computer vision\ntechniques are rapidly improving. Most computer vision applications require\nsophisticated image segmentation to comprehend what is image and to make an\nanalysis of each section easier. Training deep learning networks for semantic\nsegmentation required a large amount of annotated data, which presents a major\nchallenge in practice as it is expensive and labor-intensive to produce such\ndata. The paper presents 1. Self-supervised techniques to boost semantic\nsegmentation performance using multi-task learning with Depth prediction and\nSurface Normalization . 2. Performance evaluation of the different types of\nweighing techniques (UW, Nash-MTL) used for Multi-task learning. NY2D dataset\nwas used for performance evaluation. According to our evaluation, the Nash-MTL\nmethod outperforms single task learning(Semantic Segmentation).\n","authors":["Lichun Gao","Chinmaya Khamesra","Uday Kumbhar","Ashay Aglawe"],"pdf_url":"https://arxiv.org/pdf/2302.02483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02456v1","updated":"2023-02-05T18:50:12Z","published":"2023-02-05T18:50:12Z","title":"Deep Learning Approach for Early Stage Lung Cancer Detection","summary":"  Lung cancer is the leading cause of death among different types of cancers.\nEvery year, the lives lost due to lung cancer exceed those lost to pancreatic,\nbreast, and prostate cancer combined. The survival rate for lung cancer\npatients is very low compared to other cancer patients due to late diagnostics.\nThus, early lung cancer diagnostics is crucial for patients to receive early\ntreatments, increasing the survival rate or even becoming cancer-free. This\npaper proposed a deep-learning model for early lung cancer prediction and\ndiagnosis from Computed Tomography (CT) scans. The proposed mode achieves high\naccuracy. In addition, it can be a beneficial tool to support radiologists'\ndecisions in predicting and detecting lung cancer and its stage.\n","authors":["Saleh Abunajm","Nelly Elsayed","Zag ElSayed","Murat Ozer"],"pdf_url":"https://arxiv.org/pdf/2302.02456v1.pdf","comment":"Under review in FLAIRS 2023"},{"id":"http://arxiv.org/abs/2212.03029v3","updated":"2023-02-05T18:41:36Z","published":"2022-12-06T15:00:00Z","title":"AbHE: All Attention-based Homography Estimation","summary":"  Homography estimation is a basic computer vision task, which aims to obtain\nthe transformation from multi-view images for image alignment. Unsupervised\nlearning homography estimation trains a convolution neural network for feature\nextraction and transformation matrix regression. While the state-of-theart\nhomography method is based on convolution neural networks, few work focuses on\ntransformer which shows superiority in highlevel vision tasks. In this paper,\nwe propose a strong-baseline model based on the Swin Transformer, which\ncombines convolution neural network for local features and transformer module\nfor global features. Moreover, a cross non-local layer is introduced to search\nthe matched features within the feature maps coarsely. In the homography\nregression stage, we adopt an attention layer for the channels of correlation\nvolume, which can drop out some weak correlation feature points. The experiment\nshows that in 8 Degree-of-Freedoms(DOFs) homography estimation our method\noverperforms the state-of-the-art method.\n","authors":["Mingxiao Huo","Zhihao Zhang","Xinyang Ren","Xianqiang Yang"],"pdf_url":"https://arxiv.org/pdf/2212.03029v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02451v1","updated":"2023-02-05T18:23:49Z","published":"2023-02-05T18:23:49Z","title":"KDEformer: Accelerating Transformers via Kernel Density Estimation","summary":"  Dot-product attention mechanism plays a crucial role in modern deep\narchitectures (e.g., Transformer) for sequence modeling, however, na\\\"ive exact\ncomputation of this model incurs quadratic time and memory complexities in\nsequence length, hindering the training of long-sequence models. Critical\nbottlenecks are due to the computation of partition functions in the\ndenominator of softmax function as well as the multiplication of the softmax\nmatrix with the matrix of values. Our key observation is that the former can be\nreduced to a variant of the kernel density estimation (KDE) problem, and an\nefficient KDE solver can be further utilized to accelerate the latter via\nsubsampling-based fast matrix products. Our proposed KDEformer can approximate\nthe attention in sub-quadratic time with provable spectral norm bounds, while\nall prior results merely provide entry-wise error bounds. Empirically, we\nverify that KDEformer outperforms other attention approximations in terms of\naccuracy, memory, and runtime on various pre-trained models. On BigGAN image\ngeneration, we achieve better generative scores than the exact computation with\nover $4\\times$ speedup. For ImageNet classification with T2T-ViT, KDEformer\nshows over $18\\times$ speedup while the accuracy drop is less than $0.5\\%$.\n","authors":["Amir Zandieh","Insu Han","Majid Daliri","Amin Karbasi"],"pdf_url":"https://arxiv.org/pdf/2302.02451v1.pdf","comment":"26 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.02444v1","updated":"2023-02-05T18:14:08Z","published":"2023-02-05T18:14:08Z","title":"Spatio-Temporal Point Process for Multiple Object Tracking","summary":"  Multiple Object Tracking (MOT) focuses on modeling the relationship of\ndetected objects among consecutive frames and merge them into different\ntrajectories. MOT remains a challenging task as noisy and confusing detection\nresults often hinder the final performance. Furthermore, most existing research\nare focusing on improving detection algorithms and association strategies. As\nsuch, we propose a novel framework that can effectively predict and mask-out\nthe noisy and confusing detection results before associating the objects into\ntrajectories. In particular, we formulate such \"bad\" detection results as a\nsequence of events and adopt the spatio-temporal point process}to model such\nevents. Traditionally, the occurrence rate in a point process is characterized\nby an explicitly defined intensity function, which depends on the prior\nknowledge of some specific tasks. Thus, designing a proper model is expensive\nand time-consuming, with also limited ability to generalize well. To tackle\nthis problem, we adopt the convolutional recurrent neural network (conv-RNN) to\ninstantiate the point process, where its intensity function is automatically\nmodeled by the training data. Furthermore, we show that our method captures\nboth temporal and spatial evolution, which is essential in modeling events for\nMOT. Experimental results demonstrate notable improvements in addressing noisy\nand confusing detection results in MOT datasets. An improved state-of-the-art\nperformance is achieved by incorporating our baseline MOT algorithm with the\nspatio-temporal point process model.\n","authors":["Tao Wang","Kean Chen","Weiyao Lin","John See","Zenghui Zhang","Qian Xu","Xia Jia"],"pdf_url":"https://arxiv.org/pdf/2302.02444v1.pdf","comment":"This manuscript is the accepted version for TNNLS(IEEE Transactions\n  on Neural Networks and Learning Systems)"},{"id":"http://arxiv.org/abs/2301.07958v2","updated":"2023-02-05T15:53:56Z","published":"2023-01-19T09:18:06Z","title":"RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color\n  Editing of 3D Scenes","summary":"  Radiance fields have gradually become a main representation of media.\nAlthough its appearance editing has been studied, how to achieve\nview-consistent recoloring in an efficient manner is still under explored. We\npresent RecolorNeRF, a novel user-friendly color editing approach for the\nneural radiance fields. Our key idea is to decompose the scene into a set of\npure-colored layers, forming a palette. By this means, color manipulation can\nbe conducted by altering the color components of the palette directly. To\nsupport efficient palette-based editing, the color of each layer needs to be as\nrepresentative as possible. In the end, the problem is formulated as an\noptimization problem, where the layers and their blending weights are jointly\noptimized with the NeRF itself. Extensive experiments show that our\njointly-optimized layer decomposition can be used against multiple backbones\nand produce photo-realistic recolored novel-view renderings. We demonstrate\nthat RecolorNeRF outperforms baseline methods both quantitatively and\nqualitatively for color editing even in complex real-world scenes.\n","authors":["Bingchen Gong","Yuehao Wang","Xiaoguang Han","Qi Dou"],"pdf_url":"https://arxiv.org/pdf/2301.07958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02412v1","updated":"2023-02-05T15:49:26Z","published":"2023-02-05T15:49:26Z","title":"Mixture of Diffusers for scene composition and high resolution image\n  generation","summary":"  Diffusion methods have been proven to be very effective to generate images\nwhile conditioning on a text prompt. However, and although the quality of the\ngenerated images is unprecedented, these methods seem to struggle when trying\nto generate specific image compositions. In this paper we present Mixture of\nDiffusers, an algorithm that builds over existing diffusion models to provide a\nmore detailed control over composition. By harmonizing several diffusion\nprocesses acting on different regions of a canvas, it allows generating larger\nimages, where the location of each object and style is controlled by a separate\ndiffusion process.\n","authors":["Álvaro Barbero Jiménez"],"pdf_url":"https://arxiv.org/pdf/2302.02412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02410v1","updated":"2023-02-05T15:46:57Z","published":"2023-02-05T15:46:57Z","title":"See You Soon: Decoupled Iterative Refinement Framework for Interacting\n  Hands Reconstruction from a Single RGB Image","summary":"  Reconstructing interacting hands from a single RGB image is a very\nchallenging task. On the one hand, severe mutual occlusion and similar local\nappearance between two hands confuse the extraction of visual features,\nresulting in the misalignment of estimated hand meshes and the image. On the\nother hand, there are complex interaction patterns between interacting hands,\nwhich significantly increases the solution space of hand poses and increases\nthe difficulty of network learning. In this paper, we propose a decoupled\niterative refinement framework to achieve pixel-alignment hand reconstruction\nwhile efficiently modeling the spatial relationship between hands.\nSpecifically, we define two feature spaces with different characteristics,\nnamely 2D visual feature space and 3D joint feature space. First, we obtain\njoint-wise features from the visual feature map and utilize a graph convolution\nnetwork and a transformer to perform intra- and inter-hand information\ninteraction in the 3D joint feature space, respectively. Then, we project the\njoint features with global information back into the 2D visual feature space in\nan obfuscation-free manner and utilize the 2D convolution for pixel-wise\nenhancement. By performing multiple alternate enhancements in the two feature\nspaces, our method can achieve an accurate and robust reconstruction of\ninteracting hands. Our method outperforms all existing two-hand reconstruction\nmethods by a large margin on the InterHand2.6M dataset. Meanwhile, our method\nshows a strong generalization ability for in-the-wild images.\n","authors":["Pengfei Ren","Chao Wen","Xiaozheng Zheng","Zhou Xue","Haifeng Sun","Qi Qi","Jingyu Wang","Jianxin Liao"],"pdf_url":"https://arxiv.org/pdf/2302.02410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02408v1","updated":"2023-02-05T15:37:02Z","published":"2023-02-05T15:37:02Z","title":"Multi-View Masked World Models for Visual Robotic Manipulation","summary":"  Visual robotic manipulation research and applications often use multiple\ncameras, or views, to better perceive the world. How else can we utilize the\nrichness of multi-view data? In this paper, we investigate how to learn good\nrepresentations with multi-view data and utilize them for visual robotic\nmanipulation. Specifically, we train a multi-view masked autoencoder which\nreconstructs pixels of randomly masked viewpoints and then learn a world model\noperating on the representations from the autoencoder. We demonstrate the\neffectiveness of our method in a range of scenarios, including multi-view\ncontrol and single-view control with auxiliary cameras for representation\nlearning. We also show that the multi-view masked autoencoder trained with\nmultiple randomized viewpoints enables training a policy with strong viewpoint\nrandomization and transferring the policy to solve real-robot tasks without\ncamera calibration and an adaptation procedure. Videos demonstrations in\nreal-world experiments and source code are available at the project website:\nhttps://sites.google.com/view/mv-mwm.\n","authors":["Younggyo Seo","Junsu Kim","Stephen James","Kimin Lee","Jinwoo Shin","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02408v1.pdf","comment":"First two authors contributed equally. Project webpage:\n  https://sites.google.com/view/mv-mwm"},{"id":"http://arxiv.org/abs/2301.02064v2","updated":"2023-02-05T15:06:28Z","published":"2023-01-05T13:47:36Z","title":"Efficient Distributed Vision Transformer Foundation Model for Medical\n  Imaging through Random Masked Sampling","summary":"  In spite of the recent success of deep learning in the medical domain, the\nproblem of data scarcity in the medical domain gets aggravated due to privacy\nand data ownership issues. Distributed learning approaches including federated\nlearning have been studied to alleviate the problems, but they suffer from\ncumbersome communication overheads and weakness in privacy protection. To\naddress this, here we propose a self-supervised masked sampling distillation\nmethod for vision transformer that can be performed without continuous\ncommunication but still enhance privacy using a vision transformer-specific\nencryption method. The effectiveness of our method is demonstrated with\nextensive experiments on two medical domain data and two different downstream\ntasks, showing superior performances than those obtained with the existing\ndistributed learning strategy as well as the fine-tuning only baseline. As the\nself-supervised model built with the proposed method is capable of having a\ngeneral semantic understanding of the modality, we demonstrate its potential as\na task-agnostic foundation model for various medical tasks, widening the\napplicability in the medical domain.\n","authors":["Sangjoon Park","Ik-Jae Lee","Jun Won Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2301.02064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02398v1","updated":"2023-02-05T14:53:07Z","published":"2023-02-05T14:53:07Z","title":"Diffusion Model for Generative Image Denoising","summary":"  In supervised learning for image denoising, usually the paired clean images\nand noisy images are collected or synthesised to train a denoising model. L2\nnorm loss or other distance functions are used as the objective function for\ntraining. It often leads to an over-smooth result with less image details. In\nthis paper, we regard the denoising task as a problem of estimating the\nposterior distribution of clean images conditioned on noisy images. We apply\nthe idea of diffusion model to realize generative image denoising. According to\nthe noise model in denoising tasks, we redefine the diffusion process such that\nit is different from the original one. Hence, the sampling of the posterior\ndistribution is a reverse process of dozens of steps from the noisy image. We\nconsider three types of noise model, Gaussian, Gamma and Poisson noise. With\nthe guarantee of theory, we derive a unified strategy for model training. Our\nmethod is verified through experiments on three types of noise models and\nachieves excellent performance.\n","authors":["Yutong Xie","Minne Yuan","Bin Dong","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2302.02398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12003v2","updated":"2023-02-05T14:37:02Z","published":"2023-01-27T21:52:03Z","title":"Minimizing Trajectory Curvature of ODE-based Generative Models","summary":"  Recent ODE/SDE-based generative models, such as diffusion models, rectified\nflows, and flow matching, define a generative process as a time reversal of a\nfixed forward process. Even though these models show impressive performance on\nlarge-scale datasets, numerical simulation requires multiple evaluations of a\nneural network, leading to a slow sampling speed. We attribute the reason to\nthe high curvature of the learned generative trajectories, as it is directly\nrelated to the truncation error of a numerical solver. Based on the\nrelationship between the forward process and the curvature, here we present an\nefficient method of training the forward process to minimize the curvature of\ngenerative trajectories without any ODE/SDE simulation. Experiments show that\nour method achieves a lower curvature than previous models and, therefore,\ndecreased sampling costs while maintaining competitive performance. Code is\navailable at https://github.com/sangyun884/fast-ode.\n","authors":["Sangyun Lee","Beomsu Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2301.12003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02394v1","updated":"2023-02-05T14:30:22Z","published":"2023-02-05T14:30:22Z","title":"Eliminating Prior Bias for Semantic Image Editing via Dual-Cycle\n  Diffusion","summary":"  The recent success of text-to-image generation diffusion models has also\nrevolutionized semantic image editing, enabling the manipulation of images\nbased on query/target texts. Despite these advancements, a significant\nchallenge lies in the potential introduction of prior bias in pre-trained\nmodels during image editing, e.g., making unexpected modifications to\ninappropriate regions. To this point, we present a novel Dual-Cycle Diffusion\nmodel that addresses the issue of prior bias by generating an unbiased mask as\nthe guidance of image editing. The proposed model incorporates a Bias\nElimination Cycle that consists of both a forward path and an inverted path,\neach featuring a Structural Consistency Cycle to ensure the preservation of\nimage content during the editing process. The forward path utilizes the\npre-trained model to produce the edited image, while the inverted path converts\nthe result back to the source image. The unbiased mask is generated by\ncomparing differences between the processed source image and the edited image\nto ensure that both conform to the same distribution. Our experiments\ndemonstrate the effectiveness of the proposed method, as it significantly\nimproves the D-CLIP score from 0.272 to 0.283. The code will be available at\nhttps://github.com/JohnDreamer/DualCycleDiffsion.\n","authors":["Zuopeng Yang","Tianshu Chu","Xin Lin","Erdun Gao","Daqing Liu","Jie Yang","Chaoyue Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02373v1","updated":"2023-02-05T12:48:21Z","published":"2023-02-05T12:48:21Z","title":"ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion\n  Trajectories","summary":"  Diffusion models have recently exhibited remarkable abilities to synthesize\nstriking image samples since the introduction of denoising diffusion\nprobabilistic models (DDPMs). Their key idea is to disrupt images into noise\nthrough a fixed forward process and learn its reverse process to generate\nsamples from noise in a denoising way. For conditional DDPMs, most existing\npractices relate conditions only to the reverse process and fit it to the\nreversal of unconditional forward process. We find this will limit the\ncondition modeling and generation in a small time window. In this paper, we\npropose a novel and flexible conditional diffusion model by introducing\nconditions into the forward process. We utilize extra latent space to allocate\nan exclusive diffusion trajectory for each condition based on some shifting\nrules, which will disperse condition modeling to all timesteps and improve the\nlearning capacity of model. We formulate our method, which we call\n\\textbf{ShiftDDPMs}, and provide a unified point of view on existing related\nmethods. Extensive qualitative and quantitative experiments on image synthesis\ndemonstrate the feasibility and effectiveness of ShiftDDPMs.\n","authors":["Zijian Zhang","Zhou Zhao","Jun Yu","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2302.02373v1.pdf","comment":"Accepted by AAAI 2023 Conference"},{"id":"http://arxiv.org/abs/2302.02367v1","updated":"2023-02-05T12:13:27Z","published":"2023-02-05T12:13:27Z","title":"FastPillars: A Deployment-friendly Pillar-based 3D Detector","summary":"  The deployment of 3D detectors strikes one of the major challenges in\nreal-world self-driving scenarios. Existing BEV-based (i.e., Bird Eye View)\ndetectors favor sparse convolution (known as SPConv) to speed up training and\ninference, which puts a hard barrier for deployment especially for on-device\napplications. In this paper, we tackle the problem of efficient 3D object\ndetection from LiDAR point clouds with deployment in mind. To reduce\ncomputational burden, we propose a pillar-based 3D detector with high\nperformance from an industry perspective, termed FastPillars. Compared with\nprevious methods, we introduce a more effective Max-and-Attention pillar\nencoding (MAPE) module, and redesigning a powerful and lightweight backbone\nCRVNet imbued with Cross Stage Partial network (CSP) in a reparameterization\nstyle, forming a compact feature representation framework. Extensive\nexperiments demonstrate that our FastPillars surpasses the state-of-the-art 3D\ndetectors regarding both on-device speed and performance. Specifically,\nFastPillars can be effectively deployed through TensorRT, obtaining real-time\nperformance (24FPS) on a single RTX3070Ti GPU with 64.6 mAP on the nuScenes\ntest set. Our code will be released.\n","authors":["Sifan Zhou","Zhi Tian","Xiangxiang Chu","Xinyu Zhang","Bo Zhang","Xiaobo Lu","Chengjian Feng","Zequn Jie","Patrick Yin Chiang","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2302.02367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09224v2","updated":"2023-02-05T11:45:19Z","published":"2022-08-19T08:57:34Z","title":"SoMoFormer: Social-Aware Motion Transformer for Multi-Person Motion\n  Prediction","summary":"  Multi-person motion prediction remains a challenging problem, especially in\nthe joint representation learning of individual motion and social interactions.\nMost prior methods only involve learning local pose dynamics for individual\nmotion (without global body trajectory) and also struggle to capture complex\ninteraction dependencies for social interactions. In this paper, we propose a\nnovel Social-Aware Motion Transformer (SoMoFormer) to effectively model\nindividual motion and social interactions in a joint manner. Specifically,\nSoMoFormer extracts motion features from sub-sequences in displacement\ntrajectory space to effectively learn both local and global pose dynamics for\neach individual. In addition, we devise a novel social-aware motion attention\nmechanism in SoMoFormer to further optimize dynamics representations and\ncapture interaction dependencies simultaneously via motion similarity\ncalculation across time and social dimensions. On both short- and long-term\nhorizons, we empirically evaluate our framework on multi-person motion datasets\nand demonstrate that our method greatly outperforms state-of-the-art methods of\nsingle- and multi-person motion prediction. Code will be made publicly\navailable upon acceptance.\n","authors":["Xiaogang Peng","Yaodi Shen","Haoran Wang","Binling Nie","Yigang Wang","Zizhao Wu"],"pdf_url":"https://arxiv.org/pdf/2208.09224v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.01775v7","updated":"2023-02-05T11:28:48Z","published":"2021-10-05T01:18:27Z","title":"Deep Instance Segmentation with Automotive Radar Detection Points","summary":"  Automotive radar provides reliable environmental perception in all-weather\nconditions with affordable cost, but it hardly supplies semantic and geometry\ninformation due to the sparsity of radar detection points. With the development\nof automotive radar technologies in recent years, instance segmentation becomes\npossible by using automotive radar. Its data contain contexts such as radar\ncross section and micro-Doppler effects, and sometimes can provide detection\nwhen the field of view is obscured. The outcome from instance segmentation\ncould be potentially used as the input of trackers for tracking targets. The\nexisting methods often utilize a clustering-based classification framework,\nwhich fits the need of real-time processing but has limited performance due to\nminimum information provided by sparse radar detection points. In this paper,\nwe propose an efficient method based on clustering of estimated semantic\ninformation to achieve instance segmentation for the sparse radar detection\npoints. In addition, we show that the performance of the proposed approach can\nbe further enhanced by incorporating the visual multi-layer perceptron. The\neffectiveness of the proposed method is verified by experimental results on the\npopular RadarScenes dataset, achieving 89.53% mean coverage and 86.97% mean\naverage precision with the IoU threshold of 0.5, which is superior to other\napproaches in the literature. More significantly, the consumed memory is around\n1MB, and the inference time is less than 40ms, indicating that our proposed\nalgorithm is storage and time efficient. These two criteria ensure the\npracticality of the proposed method in real-world systems.\n","authors":["Jianan Liu","Weiyi Xiong","Liping Bai","Yuxuan Xia","Tao Huang","Wanli Ouyang","Bing Zhu"],"pdf_url":"https://arxiv.org/pdf/2110.01775v7.pdf","comment":"11 pages, 9 figures, 3 tables, accepted by IEEE Transactions on\n  Intelligent Vehicles"},{"id":"http://arxiv.org/abs/2203.06553v3","updated":"2023-02-05T11:22:43Z","published":"2022-03-13T03:00:34Z","title":"Contrastive Learning for Automotive mmWave Radar Detection Points Based\n  Instance Segmentation","summary":"  The automotive mmWave radar plays a key role in advanced driver assistance\nsystems (ADAS) and autonomous driving. Deep learning-based instance\nsegmentation enables real-time object identification from the radar detection\npoints. In the conventional training process, accurate annotation is the key.\nHowever, high-quality annotations of radar detection points are challenging to\nachieve due to their ambiguity and sparsity. To address this issue, we propose\na contrastive learning approach for implementing radar detection points-based\ninstance segmentation. We define the positive and negative samples according to\nthe ground-truth label, apply the contrastive loss to train the model first,\nand then perform fine-tuning for the following downstream task. In addition,\nthese two steps can be merged into one, and pseudo labels can be generated for\nthe unlabeled data to improve the performance further. Thus, there are four\ndifferent training settings for our method. Experiments show that when the\nground-truth information is only available for a small proportion of the\ntraining data, our method still achieves a comparable performance to the\napproach trained in a supervised manner with 100% ground-truth information.\n","authors":["Weiyi Xiong","Jianan Liu","Yuxuan Xia","Tao Huang","Bing Zhu","Wei Xiang"],"pdf_url":"https://arxiv.org/pdf/2203.06553v3.pdf","comment":"Accepted by IEEE ITSC 2022"},{"id":"http://arxiv.org/abs/2302.02353v1","updated":"2023-02-05T10:09:35Z","published":"2023-02-05T10:09:35Z","title":"Towards Precision in Appearance-based Gaze Estimation in the Wild","summary":"  Appearance-based gaze estimation systems have shown great progress recently,\nyet the performance of these techniques depend on the datasets used for\ntraining. Most of the existing gaze estimation datasets setup in interactive\nsettings were recorded in laboratory conditions and those recorded in the wild\nconditions display limited head pose and illumination variations. Further, we\nobserved little attention so far towards precision evaluations of existing gaze\nestimation approaches. In this work, we present a large gaze estimation\ndataset, PARKS-Gaze, with wider head pose and illumination variation and with\nmultiple samples for a single Point of Gaze (PoG). The dataset contains 974\nminutes of data from 28 participants with a head pose range of 60 degrees in\nboth yaw and pitch directions. Our within-dataset and cross-dataset evaluations\nand precision evaluations indicate that the proposed dataset is more\nchallenging and enable models to generalize on unseen participants better than\nthe existing in-the-wild datasets. The project page can be accessed here:\nhttps://github.com/lrdmurthy/PARKS-Gaze\n","authors":["Murthy L. R. D.","Abhishek Mukhopadhyay","Shambhavi Aggarwal","Ketan Anand","Pradipta Biswas"],"pdf_url":"https://arxiv.org/pdf/2302.02353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02350v1","updated":"2023-02-05T09:48:57Z","published":"2023-02-05T09:48:57Z","title":"Aggregation of Disentanglement: Reconsidering Domain Variations in\n  Domain Generalization","summary":"  Domain Generalization (DG) is a fundamental challenge for machine learning\nmodels, which aims to improve model generalization on various domains. Previous\nmethods focus on generating domain invariant features from various source\ndomains. However, we argue that the domain variantions also contain useful\ninformation, ie, classification-aware information, for downstream tasks, which\nhas been largely ignored. Different from learning domain invariant features\nfrom source domains, we decouple the input images into Domain Expert Features\nand noise. The proposed domain expert features lie in a learned latent space\nwhere the images in each domain can be classified independently, enabling the\nimplicit use of classification-aware domain variations. Based on the analysis,\nwe proposed a novel paradigm called Domain Disentanglement Network (DDN) to\ndisentangle the domain expert features from the source domain images and\naggregate the source domain expert features for representing the target test\ndomain. We also propound a new contrastive learning method to guide the domain\nexpert features to form a more balanced and separable feature space.\nExperiments on the widely-used benchmarks of PACS, VLCS, OfficeHome, DomainNet,\nand TerraIncognita demonstrate the competitive performance of our method\ncompared to the recently proposed alternatives.\n","authors":["Daoan Zhang","Mingkai Chen","Chenming Li","Lingyun Huang","Jianguo Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02347v1","updated":"2023-02-05T09:22:00Z","published":"2023-02-05T09:22:00Z","title":"Explainable Machine Learning: The Importance of a System-Centric\n  Perspective","summary":"  The landscape in the context of several signal processing applications and\neven education appears to be significantly affected by the emergence of machine\nlearning (ML) and in particular deep learning (DL).The main reason for this is\nthe ability of DL to model complex and unknown relationships between signals\nand the tasks of interest. Particularly, supervised DL algorithms have been\nfairly successful at recognizing perceptually or semantically useful signal\ninformation in different applications. In all of these, the training process\nuses labeled data to learn a mapping function (typically implicitly) from\nsignals to the desired information (class label or target label). The trained\nDL model is then expected to correctly recognize/classify relevant information\nin a given test signal. A DL based framework is therefore, in general, very\nappealing since the features and characteristics of the required mapping are\nlearned almost exclusively from the data without resorting to explicit\nmodel/system development. The focus on implicit modeling however also raises\nthe issue of lack of explainability/interpretability of the resultant DL based\nmapping or the black box problem. As a result, explainable ML/DL is an active\nresearch area where the primary goal is to elaborate how the ML/DL model\narrived at a prediction. We however note that despite the efforts, the\ncommentary on black box problem appears to lack a technical discussion from the\nview point of: a) its origin and underlying reasons, and b) its practical\nimplications on the design and deployment of ML/DL systems. Accordingly, a\nreasonable question that can be raised is as follows. Can the traditional\nsystem-centric approach (which places emphasis on explicit system modeling)\nprovide useful insights into the nature of black box problem, and help develop\nmore transparent ML/DL systems?\n","authors":["Manish Narwaria"],"pdf_url":"https://arxiv.org/pdf/2302.02347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02336v1","updated":"2023-02-05T08:46:15Z","published":"2023-02-05T08:46:15Z","title":"Using Intermediate Forward Iterates for Intermediate Generator\n  Optimization","summary":"  Score-based models have recently been introduced as a richer framework to\nmodel distributions in high dimensions and are generally more suitable for\ngenerative tasks. In score-based models, a generative task is formulated using\na parametric model (such as a neural network) to directly learn the gradient of\nsuch high dimensional distributions, instead of the density functions\nthemselves, as is done traditionally. From the mathematical point of view, such\ngradient information can be utilized in reverse by stochastic sampling to\ngenerate diverse samples. However, from a computational perspective, existing\nscore-based models can be efficiently trained only if the forward or the\ncorruption process can be computed in closed form. By using the relationship\nbetween the process and layers in a feed-forward network, we derive a\nbackpropagation-based procedure which we call Intermediate Generator\nOptimization to utilize intermediate iterates of the process with negligible\ncomputational overhead. The main advantage of IGO is that it can be\nincorporated into any standard autoencoder pipeline for the generative task. We\nanalyze the sample complexity properties of IGO to solve downstream tasks like\nGenerative PCA. We show applications of the IGO on two dense predictive tasks\nviz., image extrapolation, and point cloud denoising. Our experiments indicate\nthat obtaining an ensemble of generators for various time points is possible\nusing first-order methods.\n","authors":["Harsh Mishra","Jurijs Nazarovs","Manmohan Dogra","Sathya N. Ravi"],"pdf_url":"https://arxiv.org/pdf/2302.02336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02335v1","updated":"2023-02-05T08:34:04Z","published":"2023-02-05T08:34:04Z","title":"Semi-Supervised Domain Adaptation with Source Label Adaptation","summary":"  Semi-Supervised Domain Adaptation (SSDA) involves learning to classify unseen\ntarget data with a few labeled and lots of unlabeled target data, along with\nmany labeled source data from a related domain. Current SSDA approaches usually\naim at aligning the target data to the labeled source data with feature space\nmapping and pseudo-label assignments. Nevertheless, such a source-oriented\nmodel can sometimes align the target data to source data of the wrong classes,\ndegrading the classification performance. This paper presents a novel\nsource-adaptive paradigm that adapts the source data to match the target data.\nOur key idea is to view the source data as a noisily-labeled version of the\nideal target data. Then, we propose an SSDA model that cleans up the label\nnoise dynamically with the help of a robust cleaner component designed from the\ntarget perspective. Since the paradigm is very different from the core ideas\nbehind existing SSDA approaches, our proposed model can be easily coupled with\nthem to improve their performance. Empirical results on two state-of-the-art\nSSDA approaches demonstrate that the proposed model effectively cleans up the\nnoise within the source labels and exhibits superior performance over those\napproaches across benchmark datasets.\n","authors":["Yu-Chu Yu","Hsuan-Tien Lin"],"pdf_url":"https://arxiv.org/pdf/2302.02335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00912v2","updated":"2023-02-05T07:59:59Z","published":"2023-02-02T07:07:35Z","title":"Advances and Challenges in Multimodal Remote Sensing Image Registration","summary":"  Over the past few decades, with the rapid development of global aerospace and\naerial remote sensing technology, the types of sensors have evolved from the\ntraditional monomodal sensors (e.g., optical sensors) to the new generation of\nmultimodal sensors [e.g., multispectral, hyperspectral, light detection and\nranging (LiDAR) and synthetic aperture radar (SAR) sensors]. These advanced\ndevices can dynamically provide various and abundant multimodal remote sensing\nimages with different spatial, temporal, and spectral resolutions according to\ndifferent application requirements. Since then, it is of great scientific\nsignificance to carry out the research of multimodal remote sensing image\nregistration, which is a crucial step for integrating the complementary\ninformation among multimodal data and making comprehensive observations and\nanalysis of the Earths surface. In this work, we will present our own\ncontributions to the field of multimodal image registration, summarize the\nadvantages and limitations of existing multimodal image registration methods,\nand then discuss the remaining challenges and make a forward-looking prospect\nfor the future development of the field.\n","authors":["Bai Zhu","Liang Zhou","Simiao Pu","Jianwei Fan","Yuanxin Ye"],"pdf_url":"https://arxiv.org/pdf/2302.00912v2.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.02330v1","updated":"2023-02-05T07:50:46Z","published":"2023-02-05T07:50:46Z","title":"CIPER: Combining Invariant and Equivariant Representations Using\n  Contrastive and Predictive Learning","summary":"  Self-supervised representation learning (SSRL) methods have shown great\nsuccess in computer vision. In recent studies, augmentation-based contrastive\nlearning methods have been proposed for learning representations that are\ninvariant or equivariant to pre-defined data augmentation operations. However,\ninvariant or equivariant features favor only specific downstream tasks\ndepending on the augmentations chosen. They may result in poor performance when\na downstream task requires the counterpart of those features (e.g., when the\ntask is to recognize hand-written digits while the model learns to be invariant\nto in-plane image rotations rendering it incapable of distinguishing \"9\" from\n\"6\"). This work introduces Contrastive Invariant and Predictive Equivariant\nRepresentation learning (CIPER). CIPER comprises both invariant and equivariant\nlearning objectives using one shared encoder and two different output heads on\ntop of the encoder. One output head is a projection head with a\nstate-of-the-art contrastive objective to encourage invariance to\naugmentations. The other is a prediction head estimating the augmentation\nparameters, capturing equivariant features. Both heads are discarded after\ntraining and only the encoder is used for downstream tasks. We evaluate our\nmethod on static image tasks and time-augmented image datasets. Our results\nshow that CIPER outperforms a baseline contrastive method on various tasks,\nespecially when the downstream task requires the encoding of\naugmentation-related information.\n","authors":["Xia Xu","Jochen Triesch"],"pdf_url":"https://arxiv.org/pdf/2302.02330v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.02327v1","updated":"2023-02-05T07:43:02Z","published":"2023-02-05T07:43:02Z","title":"Pyramid Self-attention Polymerization Learning for Semi-supervised\n  Skeleton-based Action Recognition","summary":"  Most semi-supervised skeleton-based action recognition approaches aim to\nlearn the skeleton action representations only at the joint level, but neglect\nthe crucial motion characteristics at the coarser-grained body (e.g., limb,\ntrunk) level that provide rich additional semantic information, though the\nnumber of labeled data is limited. In this work, we propose a novel Pyramid\nSelf-attention Polymerization Learning (dubbed as PSP Learning) framework to\njointly learn body-level, part-level, and joint-level action representations of\njoint and motion data containing abundant and complementary semantic\ninformation via contrastive learning covering coarse-to-fine granularity.\nSpecifically, to complement semantic information from coarse to fine\ngranularity in skeleton actions, we design a new Pyramid Polymerizing Attention\n(PPA) mechanism that firstly calculates the body-level attention map,\npart-level attention map, and joint-level attention map, as well as polymerizes\nthese attention maps in a level-by-level way (i.e., from body level to part\nlevel, and further to joint level). Moreover, we present a new Coarse-to-fine\nContrastive Loss (CCL) including body-level contrast loss, part-level contrast\nloss, and joint-level contrast loss to jointly measure the similarity between\nthe body/part/joint-level contrasting features of joint and motion data.\nFinally, extensive experiments are conducted on the NTU RGB+D and North-Western\nUCLA datasets to demonstrate the competitive performance of the proposed PSP\nLearning in the semi-supervised skeleton-based action recognition task. The\nsource codes of PSP Learning are publicly available at\nhttps://github.com/1xbq1/PSP-Learning.\n","authors":["Binqian Xu","Xiangbo Shu"],"pdf_url":"https://arxiv.org/pdf/2302.02327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02659v4","updated":"2023-02-05T07:16:05Z","published":"2022-06-06T14:52:46Z","title":"Robust Fine-Tuning of Deep Neural Networks with Hessian-based\n  Generalization Guarantees","summary":"  We consider transfer learning approaches that fine-tune a pretrained deep\nneural network on a target task. We study the generalization properties of\nfine-tuning to understand the problem of overfitting, which commonly occurs in\npractice. Previous works have shown that constraining the distance from the\ninitialization of fine-tuning improves generalization. Using a PAC-Bayesian\nanalysis, we observe that besides distance from initialization, Hessians affect\ngeneralization through the noise stability of deep neural networks against\nnoise injections. Motivated by the observation, we develop Hessian\ndistance-based generalization bounds for a wide range of fine-tuning methods.\nAdditionally, we study the robustness of fine-tuning in the presence of noisy\nlabels. We design an algorithm incorporating consistent losses and\ndistance-based regularization for fine-tuning, along with a generalization\nerror guarantee under class conditional independent noise in the training set\nlabels. We perform a detailed empirical study of our algorithm on various noisy\nenvironments and architectures. On six image classification tasks whose\ntraining labels are generated with programmatic labeling, we find a 3.26%\naccuracy gain over prior fine-tuning methods. Meanwhile, the Hessian distance\nmeasure of the fine-tuned model decreases by six times more than existing\napproaches.\n","authors":["Haotian Ju","Dongyue Li","Hongyang R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.02659v4.pdf","comment":"36 pages, 5 figures, 8 tables (Fixed typos). ICML 2022"},{"id":"http://arxiv.org/abs/2302.02318v1","updated":"2023-02-05T06:58:35Z","published":"2023-02-05T06:58:35Z","title":"Contrast with Reconstruct: Contrastive 3D Representation Learning Guided\n  by Generative Pretraining","summary":"  Mainstream 3D representation learning approaches are built upon contrastive\nor generative modeling pretext tasks, where great improvements in performance\non various downstream tasks have been achieved. However, by investigating the\nmethods of these two paradigms, we find that (i) contrastive models are\ndata-hungry that suffer from a representation over-fitting issue; (ii)\ngenerative models have a data filling issue that shows inferior data scaling\ncapacity compared to contrastive models. This motivates us to learn 3D\nrepresentations by sharing the merits of both paradigms, which is non-trivial\ndue to the pattern difference between the two paradigms. In this paper, we\npropose contrast with reconstruct (ReCon) that unifies these two paradigms.\nReCon is trained to learn from both generative modeling teachers and\ncross-modal contrastive teachers through ensemble distillation, where the\ngenerative student guides the contrastive student. An encoder-decoder style\nReCon-block is proposed that transfers knowledge through cross attention with\nstop-gradient, which avoids pretraining over-fitting and pattern difference\nissues. ReCon achieves a new state-of-the-art in 3D representation learning,\ne.g., 91.26% accuracy on ScanObjectNN. Codes will be released at\nhttps://github.com/qizekun/ReCon.\n","authors":["Zekun Qi","Runpei Dong","Guofan Fan","Zheng Ge","Xiangyu Zhang","Kaisheng Ma","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2302.02318v1.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2302.02316v1","updated":"2023-02-05T06:52:25Z","published":"2023-02-05T06:52:25Z","title":"Spatiotemporal Decouple-and-Squeeze Contrastive Learning for\n  Semi-Supervised Skeleton-based Action Recognition","summary":"  Contrastive learning has been successfully leveraged to learn action\nrepresentations for addressing the problem of semi-supervised skeleton-based\naction recognition. However, most contrastive learning-based methods only\ncontrast global features mixing spatiotemporal information, which confuses the\nspatial- and temporal-specific information reflecting different semantic at the\nframe level and joint level. Thus, we propose a novel Spatiotemporal\nDecouple-and-Squeeze Contrastive Learning (SDS-CL) framework to comprehensively\nlearn more abundant representations of skeleton-based actions by jointly\ncontrasting spatial-squeezing features, temporal-squeezing features, and global\nfeatures. In SDS-CL, we design a new Spatiotemporal-decoupling Intra-Inter\nAttention (SIIA) mechanism to obtain the spatiotemporal-decoupling attentive\nfeatures for capturing spatiotemporal specific information by calculating\nspatial- and temporal-decoupling intra-attention maps among joint/motion\nfeatures, as well as spatial- and temporal-decoupling inter-attention maps\nbetween joint and motion features. Moreover, we present a new Spatial-squeezing\nTemporal-contrasting Loss (STL), a new Temporal-squeezing Spatial-contrasting\nLoss (TSL), and the Global-contrasting Loss (GL) to contrast the\nspatial-squeezing joint and motion features at the frame level,\ntemporal-squeezing joint and motion features at the joint level, as well as\nglobal joint and motion features at the skeleton level. Extensive experimental\nresults on four public datasets show that the proposed SDS-CL achieves\nperformance gains compared with other competitive methods.\n","authors":["Binqian Xu","Xiangbo Shu"],"pdf_url":"https://arxiv.org/pdf/2302.02316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02314v1","updated":"2023-02-05T06:27:45Z","published":"2023-02-05T06:27:45Z","title":"CECT: Controllable Ensemble CNN and Transformer for COVID-19 image\n  classification by capturing both local and global image features","summary":"  Purpose: Most computer vision models are developed based on either\nconvolutional neural network (CNN) or transformer, while the former (latter)\nmethod captures local (global) features. To relieve model performance\nlimitations due to the lack of global (local) features, we develop a novel\nclassification network named CECT by controllable ensemble CNN and transformer.\nMethods: The proposed CECT is composed of a CNN-based encoder block, a\ndeconvolution-ensemble decoder block, and a transformer-based classification\nblock. Different from conventional CNN- or transformer-based methods, our CECT\ncan capture features at both multi-local and global scales, and the\ncontribution of local features at different scales can be controlled with the\nproposed ensemble coefficients. Results: We evaluate CECT on two public\nCOVID-19 datasets and it outperforms other state-of-the-art methods on all\nevaluation metrics. Conclusion: With remarkable feature capture ability, we\nbelieve CECT can also be used in other medical image classification scenarios\nto assist the diagnosis.\n","authors":["Zhaoshan Liu","Lei Shen"],"pdf_url":"https://arxiv.org/pdf/2302.02314v1.pdf","comment":"20 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.02294v1","updated":"2023-02-05T04:14:19Z","published":"2023-02-05T04:14:19Z","title":"A Disparity Refinement Framework for Learning-based Stereo Matching\n  Methods in Cross-domain Setting for Laparoscopic Images","summary":"  Purpose: Stereo matching methods that enable depth estimation are crucial for\nvisualization enhancement applications in computer-assisted surgery (CAS).\nLearning-based stereo matching methods are promising to predict accurate\nresults on laparoscopic images. However, they require a large amount of\ntraining data, and their performance may be degraded due to domain shifts.\n  Methods: Maintaining robustness and improving the accuracy of learning-based\nmethods are still open problems. To overcome the limitations of learning-based\nmethods, we propose a disparity refinement framework consisting of a local\ndisparity refinement method and a global disparity refinement method to improve\nthe results of learning-based stereo matching methods in a cross-domain\nsetting. Those learning-based stereo matching methods are pre-trained on a\nlarge public dataset of natural images and are tested on two datasets of\nlaparoscopic images.\n  Results: Qualitative and quantitative results suggest that our proposed\ndisparity framework can effectively refine disparity maps when they are\nnoise-corrupted on an unseen dataset, without compromising prediction accuracy\nwhen the network can generalize well on an unseen dataset.\n  Conclusion: Our proposed disparity refinement framework could work with\nlearning-based methods to achieve robust and accurate disparity prediction.\nYet, as a large laparoscopic dataset for training learning-based methods does\nnot exist and the generalization ability of networks remains to be improved,\nthe incorporation of the proposed disparity refinement framework into existing\nnetworks will contribute to improving their overall accuracy and robustness\nassociated with depth estimation.\n","authors":["Zixin Yang","Richard Simon","Cristian A. Linte"],"pdf_url":"https://arxiv.org/pdf/2302.02294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02289v1","updated":"2023-02-05T03:49:27Z","published":"2023-02-05T03:49:27Z","title":"Selecting the Best Optimizers for Deep Learning based Medical Image\n  Segmentation","summary":"  The goal of this work is to identify the best optimizers for deep learning in\nthe context of cardiac image segmentation and to provide guidance on how to\ndesign segmentation networks with effective optimization strategies. Adaptive\nlearning helps with fast convergence by starting with a larger learning rate\n(LR) and gradually decreasing it. Momentum optimizers are particularly\neffective at quickly optimizing neural networks within the accelerated schemes\ncategory. By revealing the potential interplay between these two types of\nalgorithms (LR and momentum optimizers or momentum rate (MR) in short), in this\narticle, we explore the two variants of SGD algorithms in a single setting. We\nsuggest using cyclic learning as the base optimizer and integrating optimal\nvalues of learning rate and momentum rate. We investigated the relationship of\nLR and MR under an important problem of medical image segmentation of cardiac\nstructures from MRI and CT scans. We conducted experiments using the cardiac\nimaging dataset from the ACDC challenge of MICCAI 2017, and four different\narchitectures shown to be successful for cardiac image segmentation problems.\nOur comprehensive evaluations demonstrated that the proposed optimizer achieved\nbetter results (over a 2\\% improvement in the dice metric) than other\noptimizers in deep learning literature with similar or lower computational cost\nin both single and multi-object segmentation settings. We hypothesized that\ncombination of accelerated and adaptive optimization methods can have a drastic\neffect in medical image segmentation performances. To this end, we proposed a\nnew cyclic optimization method (\\textit{CLMR}) to address the efficiency and\naccuracy problems in deep learning based medical image segmentation. The\nproposed strategy yielded better generalization in comparison to adaptive\noptimizers.\n","authors":["Aliasghar Mortazi","Vedat Cicek","Elif Keles","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2302.02289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02285v1","updated":"2023-02-05T03:01:28Z","published":"2023-02-05T03:01:28Z","title":"ReDi: Efficient Learning-Free Diffusion Inference via Trajectory\n  Retrieval","summary":"  Diffusion models show promising generation capability for a variety of data.\nDespite their high generation quality, the inference for diffusion models is\nstill time-consuming due to the numerous sampling iterations required. To\naccelerate the inference, we propose ReDi, a simple yet learning-free\nRetrieval-based Diffusion sampling framework. From a precomputed knowledge\nbase, ReDi retrieves a trajectory similar to the partially generated trajectory\nat an early stage of generation, skips a large portion of intermediate steps,\nand continues sampling from a later step in the retrieved trajectory. We\ntheoretically prove that the generation performance of ReDi is guaranteed. Our\nexperiments demonstrate that ReDi improves the model inference efficiency by 2x\nspeedup. Furthermore, ReDi is able to generalize well in zero-shot cross-domain\nimage generation such as image stylization.\n","authors":["Kexun Zhang","Xianjun Yang","William Yang Wang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2302.02285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02284v1","updated":"2023-02-05T02:47:13Z","published":"2023-02-05T02:47:13Z","title":"Design Booster: A Text-Guided Diffusion Model for Image Translation with\n  Spatial Layout Preservation","summary":"  Diffusion models are able to generate photorealistic images in arbitrary\nscenes. However, when applying diffusion models to image translation, there\nexists a trade-off between maintaining spatial structure and high-quality\ncontent. Besides, existing methods are mainly based on test-time optimization\nor fine-tuning model for each input image, which are extremely time-consuming\nfor practical applications. To address these issues, we propose a new approach\nfor flexible image translation by learning a layout-aware image condition\ntogether with a text condition. Specifically, our method co-encodes images and\ntext into a new domain during the training phase. In the inference stage, we\ncan choose images/text or both as the conditions for each time step, which\ngives users more flexible control over layout and content. Experimental\ncomparisons of our method with state-of-the-art methods demonstrate our model\nperforms best in both style image translation and semantic image translation\nand took the shortest time.\n","authors":["Shiqi Sun","Shancheng Fang","Qian He","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2302.02284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02283v1","updated":"2023-02-05T02:41:46Z","published":"2023-02-05T02:41:46Z","title":"Recurrence With Correlation Network for Medical Image Registration","summary":"  We present Recurrence with Correlation Network (RWCNet), a medical image\nregistration network with multi-scale features and a cost volume layer. We\ndemonstrate that these architectural features improve medical image\nregistration accuracy in two image registration datasets prepared for the\nMICCAI 2022 Learn2Reg Workshop Challenge. On the large-displacement National\nLung Screening Test (NLST) dataset, RWCNet is able to achieve a total\nregistration error (TRE) of 2.11mm between corresponding keypoints without\ninstance fine-tuning. On the OASIS brain MRI dataset, RWCNet is able to achieve\nan average dice overlap of 81.7% for 35 different anatomical labels. It\noutperforms another multi-scale network, the Laplacian Image Registration\nNetwork (LapIRN), on both datasets. Ablation experiments are performed to\nhighlight the contribution of the various architectural features. While\nmulti-scale features improved validation accuracy for both datasets, the cost\nvolume layer and number of recurrent steps only improved performance on the\nlarge-displacement NLST dataset. This result suggests that cost volume layer\nand iterative refinement using RNN provide good support for optimization and\ngeneralization in large-displacement medical image registration. The code for\nRWCNet is available at\nhttps://github.com/vigsivan/optimization-based-registration.\n","authors":["Vignesh Sivan","Teodora Vujovic","Raj Ranabhat","Alexander Wong","Stewart Mclachlin","Michael Hardisty"],"pdf_url":"https://arxiv.org/pdf/2302.02283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09350v2","updated":"2023-02-05T02:40:03Z","published":"2022-08-19T14:00:37Z","title":"PyMIC: A deep learning toolkit for annotation-efficient medical image\n  segmentation","summary":"  Background and Objective: Open-source deep learning toolkits are one of the\ndriving forces for developing medical image segmentation models. Existing\ntoolkits mainly focus on fully supervised segmentation and require full and\naccurate pixel-level annotations that are time-consuming and difficult to\nacquire for segmentation tasks, which makes learning from imperfect labels\nhighly desired for reducing the annotation cost. We aim to develop a new deep\nlearning toolkit to support annotation-efficient learning for medical image\nsegmentation.\n  Methods: Our proposed toolkit named PyMIC is a modular deep learning library\nfor medical image segmentation tasks. In addition to basic components that\nsupport development of high-performance models for fully supervised\nsegmentation, it contains several advanced components tailored for learning\nfrom imperfect annotations, such as loading annotated and unannounced images,\nloss functions for unannotated, partially or inaccurately annotated images, and\ntraining procedures for co-learning between multiple networks, etc. PyMIC\nsupports development of semi-supervised, weakly supervised and noise-robust\nlearning methods for medical image segmentation.\n  Results: We present several illustrative medical image segmentation tasks\nbased on PyMIC: (1) Achieving competitive performance on fully supervised\nlearning; (2) Semi-supervised cardiac structure segmentation with only 10%\ntraining images annotated; (3) Weakly supervised segmentation using scribble\nannotations; and (4) Learning from noisy labels for chest radiograph\nsegmentation.\n  Conclusions: The PyMIC toolkit is easy to use and facilitates efficient\ndevelopment of medical image segmentation models with imperfect annotations. It\nis modular and flexible, which enables researchers to develop high-performance\nmodels with low annotation cost. The source code is available at:\nhttps://github.com/HiLab-git/PyMIC.\n","authors":["Guotai Wang","Xiangde Luo","Ran Gu","Shuojue Yang","Yijie Qu","Shuwei Zhai","Qianfei Zhao","Kang Li","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2208.09350v2.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.02276v1","updated":"2023-02-05T01:42:19Z","published":"2023-02-05T01:42:19Z","title":"JPEG Steganalysis Based on Steganographic Feature Enhancement and Graph\n  Attention Learning","summary":"  The purpose of image steganalysis is to determine whether the carrier image\ncontains hidden information or not. Since JEPG is the most commonly used image\nformat over social networks, steganalysis in JPEG images is also the most\nurgently needed to be explored. However, in order to detect whether secret\ninformation is hidden within JEPG images, the majority of existing algorithms\nare designed in conjunction with the popular computer vision related networks,\nwithout considering the key characteristics appeared in image steganalysis. It\nis crucial that the steganographic signal, as an extremely weak signal, can be\nenhanced during its representation learning process. Motivated by this insight,\nin this paper, we introduce a novel representation learning algorithm for JPEG\nsteganalysis that is mainly consisting of a graph attention learning module and\na feature enhancement module. The graph attention learning module is designed\nto avoid global feature loss caused by the local feature learning of\nconvolutional neural network and reliance on depth stacking to extend the\nperceptual domain. The feature enhancement module is applied to prevent the\nstacking of convolutional layers from weakening the steganographic information.\nIn addition, pretraining as a way to initialize the network weights with a\nlarge-scale dataset is utilized to enhance the ability of the network to\nextract discriminative features. We advocate pretraining with ALASKA2 for the\nmodel trained with BOSSBase+BOWS2. The experimental results indicate that the\nproposed algorithm outperforms previous arts in terms of detection accuracy,\nwhich has verified the superiority and applicability of the proposed work.\n","authors":["Qiyun Liu","Zhiguang Yang","Hanzhou Wu"],"pdf_url":"https://arxiv.org/pdf/2302.02276v1.pdf","comment":"https://scholar.google.com/citations?user=IdiF7M0AAAAJ&hl=en"},{"id":"http://arxiv.org/abs/2302.02272v1","updated":"2023-02-05T00:53:33Z","published":"2023-02-05T00:53:33Z","title":"Divide and Compose with Score Based Generative Models","summary":"  While score based generative models, or diffusion models, have found success\nin image synthesis, they are often coupled with text data or image label to be\nable to manipulate and conditionally generate images. Even though manipulation\nof images by changing the text prompt is possible, our understanding of the\ntext embedding and our ability to modify it to edit images is quite limited.\nTowards the direction of having more control over image manipulation and\nconditional generation, we propose to learn image components in an unsupervised\nmanner so that we can compose those components to generate and manipulate\nimages in informed manner. Taking inspiration from energy based models, we\ninterpret different score components as the gradient of different energy\nfunctions. We show how score based learning allows us to learn interesting\ncomponents and we can visualize them through generation. We also show how this\nnovel decomposition allows us to compose, generate and modify images in\ninteresting ways akin to dreaming. We make our code available at\nhttps://github.com/sandeshgh/Score-based-disentanglement\n","authors":["Sandesh Ghimire","Armand Comas","Davin Hill","Aria Masoomi","Octavia Camps","Jennifer Dy"],"pdf_url":"https://arxiv.org/pdf/2302.02272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.13675v2","updated":"2023-02-05T00:12:36Z","published":"2021-11-26T18:59:28Z","title":"Weakly-guided Self-supervised Pretraining for Temporal Activity\n  Detection","summary":"  Temporal Activity Detection aims to predict activity classes per frame, in\ncontrast to video-level predictions in Activity Classification (i.e., Activity\nRecognition). Due to the expensive frame-level annotations required for\ndetection, the scale of detection datasets is limited. Thus, commonly, previous\nwork on temporal activity detection resorts to fine-tuning a classification\nmodel pretrained on large-scale classification datasets (e.g., Kinetics-400).\nHowever, such pretrained models are not ideal for downstream detection, due to\nthe disparity between the pretraining and the downstream fine-tuning tasks. In\nthis work, we propose a novel 'weakly-guided self-supervised' pretraining\nmethod for detection. We leverage weak labels (classification) to introduce a\nself-supervised pretext task (detection) by generating frame-level pseudo\nlabels, multi-action frames, and action segments. Simply put, we design a\ndetection task similar to downstream, on large-scale classification data,\nwithout extra annotations. We show that the models pretrained with the proposed\nweakly-guided self-supervised detection task outperform prior work on multiple\nchallenging activity detection benchmarks, including Charades and MultiTHUMOS.\nOur extensive ablations further provide insights on when and how to use the\nproposed models for activity detection. Code is available at\nhttps://github.com/kkahatapitiya/SSDet.\n","authors":["Kumara Kahatapitiya","Zhou Ren","Haoxiang Li","Zhenyu Wu","Michael S. Ryoo","Gang Hua"],"pdf_url":"https://arxiv.org/pdf/2111.13675v2.pdf","comment":"Published as a conference paper at AAAI 2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2210.07316v2","updated":"2023-02-05T15:59:49Z","published":"2022-10-13T19:42:08Z","title":"MTEB: Massive Text Embedding Benchmark","summary":"  Text embeddings are commonly evaluated on a small set of datasets from a\nsingle task not covering their possible applications to other tasks. It is\nunclear whether state-of-the-art embeddings on semantic textual similarity\n(STS) can be equally well applied to other tasks like clustering or reranking.\nThis makes progress in the field difficult to track, as various models are\nconstantly being proposed without proper evaluation. To solve this problem, we\nintroduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding\ntasks covering a total of 58 datasets and 112 languages. Through the\nbenchmarking of 33 models on MTEB, we establish the most comprehensive\nbenchmark of text embeddings to date. We find that no particular text embedding\nmethod dominates across all tasks. This suggests that the field has yet to\nconverge on a universal text embedding method and scale it up sufficiently to\nprovide state-of-the-art results on all embedding tasks. MTEB comes with\nopen-source code and a public leaderboard at\nhttps://github.com/embeddings-benchmark/mteb.\n","authors":["Niklas Muennighoff","Nouamane Tazi","Loïc Magne","Nils Reimers"],"pdf_url":"https://arxiv.org/pdf/2210.07316v2.pdf","comment":"24 pages, 14 tables, 6 figures"},{"id":"http://arxiv.org/abs/2302.02352v1","updated":"2023-02-05T10:04:45Z","published":"2023-02-05T10:04:45Z","title":"TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in\n  CTR Prediction at Kuaishou","summary":"  Life-long user behavior modeling, i.e., extracting a user's hidden interests\nfrom rich historical behaviors in months or even years, plays a central role in\nmodern CTR prediction systems. Conventional algorithms mostly follow two\ncascading stages: a simple General Search Unit (GSU) for fast and coarse search\nover tens of thousands of long-term behaviors and an Exact Search Unit (ESU)\nfor effective Target Attention (TA) over the small number of finalists from\nGSU. Although efficient, existing algorithms mostly suffer from a crucial\nlimitation: the \\textit{inconsistent} target-behavior relevance metrics between\nGSU and ESU. As a result, their GSU usually misses highly relevant behaviors\nbut retrieves ones considered irrelevant by ESU. In such case, the TA in ESU,\nno matter how attention is allocated, mostly deviates from the real user\ninterests and thus degrades the overall CTR prediction accuracy. To address\nsuch inconsistency, we propose \\textbf{TWo-stage Interest Network (TWIN)},\nwhere our Consistency-Preserved GSU (CP-GSU) adopts the identical\ntarget-behavior relevance metric as the TA in ESU, making the two stages twins.\nSpecifically, to break TA's computational bottleneck and extend it from ESU to\nGSU, or namely from behavior length $10^2$ to length $10^4-10^5$, we build a\nnovel attention mechanism by behavior feature splitting. For the video inherent\nfeatures of a behavior, we calculate their linear projection by efficient\npre-computing \\& caching strategies. And for the user-item cross features, we\ncompress each into a one-dimentional bias term in the attention score\ncalculation to save the computational cost. The consistency between two stages,\ntogether with the effective TA-based relevance metric in CP-GSU, contributes to\nsignificant performance gain in CTR prediction.\n","authors":["Jianxin Chang","Chenbin Zhang","Zhiyi Fu","Xiaoxue Zang","Lin Guan","Jing Lu","Yiqun Hui","Dewei Leng","Yanan Niu","Yang Song","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.02352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12152v2","updated":"2023-02-05T08:51:10Z","published":"2023-01-28T10:27:53Z","title":"Layout-aware Webpage Quality Assessment","summary":"  Identifying high-quality webpages is fundamental for real-world search\nengines, which can fulfil users' information need with the less cognitive\nburden. Early studies of \\emph{webpage quality assessment} usually design\nhand-crafted features that may only work on particular categories of webpages\n(e.g., shopping websites, medical websites). They can hardly be applied to\nreal-world search engines that serve trillions of webpages with various types\nand purposes. In this paper, we propose a novel layout-aware webpage quality\nassessment model currently deployed in our search engine. Intuitively, layout\nis a universal and critical dimension for the quality assessment of different\ncategories of webpages. Based on this, we directly employ the meta-data that\ndescribes a webpage, i.e., Document Object Model (DOM) tree, as the input of\nour model. The DOM tree data unifies the representation of webpages with\ndifferent categories and purposes and indicates the layout of webpages. To\nassess webpage quality from complex DOM tree data, we propose a graph neural\nnetwork (GNN) based method that extracts rich layout-aware information that\nimplies webpage quality in an end-to-end manner. Moreover, we improve the GNN\nmethod with an attentive readout function, external web categories and a\ncategory-aware sampling method. We conduct rigorous offline and online\nexperiments to show that our proposed solution is effective in real search\nengines, improving the overall usability and user experience.\n","authors":["Anfeng Cheng","Yiding Liu","Weibin Li","Qian Dong","Shuaiqiang Wang","Zhengjie Huang","Shikun Feng","Zhicong Cheng","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2301.12152v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2208.13442v2","updated":"2023-02-05T08:05:58Z","published":"2022-08-29T09:21:09Z","title":"Modeling Adaptive Fine-grained Task Relatedness for Joint CTR-CVR\n  Estimation","summary":"  In modern advertising and recommender systems, multi-task learning (MTL)\nparadigm has been widely employed to jointly predict diverse user feedbacks\n(e.g. click and purchase). While, existing MTL approaches are either rigid to\nadapt to different scenarios, or only capture coarse-grained task relatedness,\nthus making it difficult to effectively transfer knowledge across tasks.\n  To address these issues, in this paper, we propose an Adaptive Fine-grained\nTask Relatedness modeling approach, AdaFTR, for joint CTR-CVR estimation. Our\napproach is developed based on a parameter-sharing MTL architecture, and\nintroduces a novel adaptive inter-task representation alignment method based on\ncontrastive learning.Given an instance, the inter-task representations of the\nsame instance are considered as positive, while the representations of another\nrandom instance are considered as negative. Furthermore, we explicitly model\nfine-grained task relatedness as the contrast strength (i.e. the temperature\ncoefficient in InfoNCE loss) at the instance level. For this purpose, we build\na relatedness prediction network, so that it can predict the contrast strength\nfor inter-task representations of an instance. In this way, we can adaptively\nset the temperature for contrastive learning in a fine-grained way (i.e.\ninstance level), so as to better capture task relatedness. Both offline\nevaluation with public e-commerce datasets and online test in a real\nadvertising system at Alibaba have demonstrated the effectiveness of our\napproach.\n","authors":["Zihan Lin","Xuanhua Yang","Xiaoyu Peng","Wayne Xin Zhao","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2208.13442v2.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.01115v2","updated":"2023-02-05T07:10:34Z","published":"2023-02-02T14:15:36Z","title":"PEPNet: Parameter and Embedding Personalized Network for Infusing with\n  Personalized Prior Information","summary":"  With the increase of content pages and display styles in online services such\nas online-shopping and video-watching websites, industrial-scale recommender\nsystems face challenges in multi-domain and multi-task recommendations. The\ncore of multi-task and multi-domain recommendation is to accurately capture\nuser interests in different domains given different user behaviors. In this\npaper, we propose a plug-and-play \\textit{\\textbf{P}arameter and\n\\textbf{E}mbedding \\textbf{P}ersonalized \\textbf{Net}work (\\textbf{PEPNet})}\nfor multi-task recommendation in the multi-domain setting. PEPNet takes\nfeatures with strong biases as input and dynamically scales the bottom-layer\nembeddings and the top-layer DNN hidden units in the model through a gate\nmechanism. By mapping personalized priors to scaling weights ranging from 0 to\n2, PEPNet introduces both parameter personalization and embedding\npersonalization. Embedding Personalized Network (EPNet) selects and aligns\nembeddings with different semantics under multiple domains. Parameter\nPersonalized Network (PPNet) influences DNN parameters to balance\ninterdependent targets in multiple tasks. We have made a series of special\nengineering optimizations combining the Kuaishou training framework and the\nonline deployment environment. We have deployed the model in Kuaishou apps,\nserving over 300 million daily users. Both online and offline experiments have\ndemonstrated substantial improvements in multiple metrics. In particular, we\nhave seen a more than 1\\% online increase in three major scenarios.\n","authors":["Jianxin Chang","Chenbin Zhang","Yiqun Hui","Dewei Leng","Yanan Niu","Yang Song","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01115v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02317v1","updated":"2023-02-05T06:55:51Z","published":"2023-02-05T06:55:51Z","title":"Adversarial Learning Data Augmentation for Graph Contrastive Learning in\n  Recommendation","summary":"  Recently, Graph Neural Networks (GNNs) achieve remarkable success in\nRecommendation. To reduce the influence of data sparsity, Graph Contrastive\nLearning (GCL) is adopted in GNN-based CF methods for enhancing performance.\nMost GCL methods consist of data augmentation and contrastive loss (e.g.,\nInfoNCE). GCL methods construct the contrastive pairs by hand-crafted graph\naugmentations and maximize the agreement between different views of the same\nnode compared to that of other nodes, which is known as the InfoMax principle.\nHowever, improper data augmentation will hinder the performance of GCL. InfoMin\nprinciple, that the good set of views shares minimal information and gives\nguidelines to design better data augmentation. In this paper, we first propose\na new data augmentation (i.e., edge-operating including edge-adding and\nedge-dropping). Then, guided by InfoMin principle, we propose a novel\ntheoretical guiding contrastive learning framework, named Learnable Data\nAugmentation for Graph Contrastive Learning (LDA-GCL). Our methods include data\naugmentation learning and graph contrastive learning, which follow the InfoMin\nand InfoMax principles, respectively. In implementation, our methods optimize\nthe adversarial loss function to learn data augmentation and effective\nrepresentations of users and items. Extensive experiments on four public\nbenchmark datasets demonstrate the effectiveness of LDA-GCL.\n","authors":["Junjie Huang","Qi Cao","Ruobing Xie","Shaoliang Zhang","Feng Xia","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.02317v1.pdf","comment":"Accepted and to appear at DASFAA2023"},{"id":"http://arxiv.org/abs/2211.11191v2","updated":"2023-02-05T04:16:40Z","published":"2022-11-21T05:33:57Z","title":"Correlative Preference Transfer with Hierarchical Hypergraph Network for\n  Multi-Domain Recommendation","summary":"  Advanced recommender systems usually involve multiple domains (such as\nscenarios or categories) for various marketing strategies, and users interact\nwith them to satisfy diverse demands. The goal of multi-domain recommendation\n(MDR) is to improve the recommendation performance of all domains\nsimultaneously. Conventional graph neural network based methods usually deal\nwith each domain separately, or train a shared model to serve all domains. The\nformer fails to leverage users' cross-domain behaviors, making the behavior\nsparseness issue a great obstacle. The latter learns shared user representation\nwith respect to all domains, which neglects users' domain-specific preferences.\nIn this paper we propose $\\mathsf{H^3Trans}$, a hierarchical hypergraph network\nbased correlative preference transfer framework for MDR, which represents\nmulti-domain user-item interactions into a unified graph to help preference\ntransfer. $\\mathsf{H^3Trans}$ incorporates two hyperedge-based modules, namely\ndynamic item transfer (Hyper-I) and adaptive user aggregation (Hyper-U).\nHyper-I extracts correlative information from multi-domain user-item feedbacks\nfor eliminating domain discrepancy of item representations. Hyper-U aggregates\nusers' scattered preferences in multiple domains and further exploits the\nhigh-order (not only pair-wise) connections to improve user representations.\nExperiments on both public and production datasets verify the superiority of\n$\\mathsf{H^3Trans}$ for MDR.\n","authors":["Zixuan Xu","Penghui Wei","Shaoguo Liu","Liang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2211.11191v2.pdf","comment":"Accepted by WWW 2023 research track. The first two authors\n  contributed equally"},{"id":"http://arxiv.org/abs/2302.02291v1","updated":"2023-02-05T03:58:45Z","published":"2023-02-05T03:58:45Z","title":"A Semantic Approach to Negation Detection and Word Disambiguation with\n  Natural Language Processing","summary":"  This study aims to demonstrate the methods for detecting negations in a\nsentence by uniquely evaluating the lexical structure of the text via word\nsense disambiguation. Additionally, the proposed method examined all the unique\nfeatures of the related expressions within a text to resolve the contextual\nusage of the sentence and the effect of negation on sentiment analysis. The\napplication of popular expression detectors skips this important step, thereby\nneglecting the root words caught in the web of negation, and making text\nclassification difficult for machine learning and sentiment analysis. This\nstudy adopts the Natural Language Processing (NLP) approach to discover and\nantonimize words that were negated for better accuracy in text classification.\nThis method acts as a lens that reads through a given word sequence using a\nknowledge base provided by an NLP library called WordHoard in order to detect\nnegation signals. Early results show that our initial analysis improved\ntraditional sentiment analysis that sometimes neglects word negations or\nassigns an inverse polarity score. The SentiWordNet analyzer was improved by\n35%, the Vader analyzer by 20% and the TextBlob analyzer by 6%.\n","authors":["Izunna Okpala","Guillermo Romera Rodriguez","Andrea Tapia","Shane Halse","Jess Kropczynski"],"pdf_url":"https://arxiv.org/pdf/2302.02291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00179v2","updated":"2023-02-05T03:48:43Z","published":"2022-09-01T02:09:07Z","title":"Universal Vision-Language Dense Retrieval: Learning A Unified\n  Representation Space for Multi-Modal Retrieval","summary":"  This paper presents Universal Vision-Language Dense Retrieval (UniVL-DR),\nwhich builds a unified model for multi-modal retrieval. UniVL-DR encodes\nqueries and multi-modality resources in an embedding space for searching\ncandidates from different modalities. To learn a unified embedding space for\nmulti-modal retrieval, UniVL-DR proposes two techniques: 1) Universal embedding\noptimization strategy, which contrastively optimizes the embedding space using\nthe modality-balanced hard negatives; 2) Image verbalization method, which\nbridges the modality gap between images and texts in the raw data space.\nUniVL-DR achieves the state-of-the-art on the multi-modal open-domain question\nanswering benchmark, WebQA, and outperforms all retrieval models on the two\nsubtasks, text-text retrieval and text-image retrieval. It demonstrates that\nuniversal multi-modal search is feasible to replace the divide-and-conquer\npipeline with a united model and also benefits single/cross modality tasks. All\nsource codes of this work are available at\nhttps://github.com/OpenMatch/UniVL-DR.\n","authors":["Zhenghao Liu","Chenyan Xiong","Yuanhuiyi Lv","Zhiyuan Liu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2209.00179v2.pdf","comment":"Accepted by ICLR 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.02503v1","updated":"2023-02-05T22:49:33Z","published":"2023-02-05T22:49:33Z","title":"Leaving Reality to Imagination: Robust Classification via Generated\n  Datasets","summary":"  Recent research on robustness has revealed significant performance gaps\nbetween neural image classifiers trained on datasets that are similar to the\ntest set, and those that are from a naturally shifted distribution, such as\nsketches, paintings, and animations of the object categories observed during\ntraining. Prior work focuses on reducing this gap by designing engineered\naugmentations of training data or through unsupervised pretraining of a single\nlarge model on massive in-the-wild training datasets scraped from the Internet.\nHowever, the notion of a dataset is also undergoing a paradigm shift in recent\nyears. With drastic improvements in the quality, ease-of-use, and access to\nmodern generative models, generated data is pervading the web. In this light,\nwe study the question: How do these generated datasets influence the natural\nrobustness of image classifiers? We find that Imagenet classifiers trained on\nreal data augmented with generated data achieve higher accuracy and effective\nrobustness than standard training and popular augmentation strategies in the\npresence of natural distribution shifts. We analyze various factors influencing\nthese results, including the choice of conditioning strategies and the amount\nof generated data. Lastly, we introduce and analyze an evolving generated\ndataset, ImageNet-G-v1, to better benchmark the design, utility, and critique\nof standalone generated datasets for robust and trustworthy machine learning.\nThe code and datasets are available at\nhttps://github.com/Hritikbansal/generative-robustness.\n","authors":["Hritik Bansal","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2302.02503v1.pdf","comment":"20 pages, 12 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2302.02396v1","updated":"2023-02-05T14:42:20Z","published":"2023-02-05T14:42:20Z","title":"OAcode: Overall Aesthetic 2D Barcode on Screen","summary":"  Nowadays, two-dimensional (2D) barcodes have been widely used in various\ndomains. And a series of aesthetic 2D barcode schemes have been proposed to\nimprove the visual quality and readability of 2D barcodes for better\nintegration with marketing materials. Yet we believe that the existing\naesthetic 2D barcode schemes are partially aesthetic because they only beautify\nthe data area but retain the position detection patterns with the blackwhite\nappearance of traditional 2D barcode schemes. Thus, in this paper, we propose\nthe first overall aesthetic 2D barcode scheme, called OAcode, in which the\nposition detection pattern is canceled. Its detection process is based on the\npre-designed symmetrical data area of OAcode, whose symmetry could be used as\nthe calibration signal to restore the perspective transformation in the barcode\nscanning process. Moreover, an enhanced demodulation method is proposed to\nresist the lens distortion common in the camera-shooting process. The\nexperimental results illustrate that when 5$\\times$5 cm OAcode is captured with\na resolution of 720$\\times$1280 pixels, at the screen-camera distance of 10 cm\nand the angle less or equal to 25{\\deg}, OAcode has 100% detection rate and\n99.5% demodulation accuracy. For 10$\\times$10 cm OAcode, it could be extracted\nby consumer-grade mobile phones at a distance of 90 cm with around 90%\naccuracy.\n","authors":["Zehua Ma","Xi Yang","Han Fang","Weiming Zhang","Nenghai Yu"],"pdf_url":"https://arxiv.org/pdf/2302.02396v1.pdf","comment":"Published in: IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2302.02276v1","updated":"2023-02-05T01:42:19Z","published":"2023-02-05T01:42:19Z","title":"JPEG Steganalysis Based on Steganographic Feature Enhancement and Graph\n  Attention Learning","summary":"  The purpose of image steganalysis is to determine whether the carrier image\ncontains hidden information or not. Since JEPG is the most commonly used image\nformat over social networks, steganalysis in JPEG images is also the most\nurgently needed to be explored. However, in order to detect whether secret\ninformation is hidden within JEPG images, the majority of existing algorithms\nare designed in conjunction with the popular computer vision related networks,\nwithout considering the key characteristics appeared in image steganalysis. It\nis crucial that the steganographic signal, as an extremely weak signal, can be\nenhanced during its representation learning process. Motivated by this insight,\nin this paper, we introduce a novel representation learning algorithm for JPEG\nsteganalysis that is mainly consisting of a graph attention learning module and\na feature enhancement module. The graph attention learning module is designed\nto avoid global feature loss caused by the local feature learning of\nconvolutional neural network and reliance on depth stacking to extend the\nperceptual domain. The feature enhancement module is applied to prevent the\nstacking of convolutional layers from weakening the steganographic information.\nIn addition, pretraining as a way to initialize the network weights with a\nlarge-scale dataset is utilized to enhance the ability of the network to\nextract discriminative features. We advocate pretraining with ALASKA2 for the\nmodel trained with BOSSBase+BOWS2. The experimental results indicate that the\nproposed algorithm outperforms previous arts in terms of detection accuracy,\nwhich has verified the superiority and applicability of the proposed work.\n","authors":["Qiyun Liu","Zhiguang Yang","Hanzhou Wu"],"pdf_url":"https://arxiv.org/pdf/2302.02276v1.pdf","comment":"https://scholar.google.com/citations?user=IdiF7M0AAAAJ&hl=en"}]},"2023-02-04T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2210.06331v2","updated":"2023-02-04T23:10:44Z","published":"2022-10-12T15:50:32Z","title":"RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims\n  on Social Media","summary":"  We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly\nannotated social media posts from Reddit spanning 24 health conditions.\nAnnotations include demarcations of spans corresponding to medical claims,\npersonal experiences, and questions. We collect additional granular annotations\non identified claims. Specifically, we mark snippets that describe patient\nPopulations, Interventions, and Outcomes (PIO elements) within these. Using\nthis corpus, we introduce the task of retrieving trustworthy evidence relevant\nto a given claim made on social media. We propose a new method to automatically\nderive (noisy) supervision for this task which we use to train a dense\nretrieval model; this outperforms baseline models. Manual evaluation of\nretrieval results performed by medical doctors indicate that while our system\nperformance is promising, there is considerable room for improvement. Collected\nannotations (and scripts to assemble the dataset), are available at\nhttps://github.com/sominw/redhot.\n","authors":["Somin Wadhwa","Vivek Khetan","Silvio Amir","Byron Wallace"],"pdf_url":"https://arxiv.org/pdf/2210.06331v2.pdf","comment":"To appear in the 17th Conference of the European Chapter of the\n  Association for Computational Linguistics (EACL), 2023"},{"id":"http://arxiv.org/abs/2301.03029v3","updated":"2023-02-04T22:45:20Z","published":"2023-01-08T12:33:58Z","title":"Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case\n  Study using Latent Dirichlet Allocation Method","summary":"  Topic Modelling (TM) is from the research branches of natural language\nunderstanding (NLU) and natural language processing (NLP) that is to facilitate\ninsightful analysis from large documents and datasets, such as a summarisation\nof main topics and the topic changes. This kind of discovery is getting more\npopular in real-life applications due to its impact on big data analytics. In\nthis study, from the social-media and healthcare domain, we apply popular\nLatent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish\nnewspaper articles about Coronavirus. We describe the corpus we created\nincluding 6515 articles, methods applied, and statistics on topic changes over\napproximately 1 year and two months period of time from 17th January 2020 to\n13th March 2021. We hope this work can be an asset for grounding applications\nof topic modelling and can be inspiring for similar case studies in an era with\npandemics, to support socio-economic impact research as well as clinical and\nhealthcare analytics. Our data and source code are openly available at\nhttps://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation\n(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding\n","authors":["Bernadeta Griciūtė","Lifeng Han","Hao Li","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2301.03029v3.pdf","comment":"14 pages, 13 figures"},{"id":"http://arxiv.org/abs/2302.02232v1","updated":"2023-02-04T20:30:32Z","published":"2023-02-04T20:30:32Z","title":"A Benchmark and Scoring Algorithm for Enriching Arabic Synonyms","summary":"  This paper addresses the task of extending a given synset with additional\nsynonyms taking into account synonymy strength as a fuzzy value. Given a\nmono/multilingual synset and a threshold (a fuzzy value [0-1]), our goal is to\nextract new synonyms above this threshold from existing lexicons. We present\ntwofold contributions: an algorithm and a benchmark dataset. The dataset\nconsists of 3K candidate synonyms for 500 synsets. Each candidate synonym is\nannotated with a fuzzy value by four linguists. The dataset is important for\n(i) understanding how much linguists (dis/)agree on synonymy, in addition to\n(ii) using the dataset as a baseline to evaluate our algorithm. Our proposed\nalgorithm extracts synonyms from existing lexicons and computes a fuzzy value\nfor each candidate. Our evaluations show that the algorithm behaves like a\nlinguist and its fuzzy values are close to those proposed by linguists (using\nRMSE and MAE). The dataset and a demo page are publicly available at\nhttps://portal.sina.birzeit.edu/synonyms.\n","authors":["Sana Ghanem","Mustafa Jarrar","Radi Jarrar","Ibrahim Bounhas"],"pdf_url":"https://arxiv.org/pdf/2302.02232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09017v2","updated":"2023-02-04T17:29:01Z","published":"2023-01-21T21:58:00Z","title":"Transfer Knowledge from Natural Language to Electrocardiography: Can We\n  Detect Cardiovascular Disease Through Language Models?","summary":"  Recent advancements in Large Language Models (LLMs) have drawn increasing\nattention since the learned embeddings pretrained on large-scale datasets have\nshown powerful ability in various downstream applications. However, whether the\nlearned knowledge by LLMs can be transferred to clinical cardiology remains\nunknown. In this work, we aim to bridge this gap by transferring the knowledge\nof LLMs to clinical Electrocardiography (ECG). We propose an approach for\ncardiovascular disease diagnosis and automatic ECG diagnosis report generation.\nWe also introduce an additional loss function by Optimal Transport (OT) to\nalign the distribution between ECG and language embedding. The learned\nembeddings are evaluated on two downstream tasks: (1) automatic ECG diagnosis\nreport generation, and (2) zero-shot cardiovascular disease detection. Our\napproach is able to generate high-quality cardiac diagnosis reports and also\nachieves competitive zero-shot classification performance even compared with\nsupervised baselines, which proves the feasibility of transferring knowledge\nfrom LLMs to the cardiac domain.\n","authors":["Jielin Qiu","William Han","Jiacheng Zhu","Mengdi Xu","Michael Rosenberg","Emerson Liu","Douglas Weber","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2301.09017v2.pdf","comment":"EACL 2023. arXiv admin note: text overlap with arXiv:2202.00567"},{"id":"http://arxiv.org/abs/2110.07002v2","updated":"2023-02-04T17:01:22Z","published":"2021-10-13T19:30:40Z","title":"Bag-of-Vectors Autoencoders for Unsupervised Conditional Text Generation","summary":"  Text autoencoders are often used for unsupervised conditional text generation\nby applying mappings in the latent space to change attributes to the desired\nvalues. Recently, Mai et al. (2020) proposed Emb2Emb, a method to learn these\nmappings in the embedding space of an autoencoder. However, their method is\nrestricted to autoencoders with a single-vector embedding, which limits how\nmuch information can be retained. We address this issue by extending their\nmethod to Bag-of-Vectors Autoencoders (BoV-AEs), which encode the text into a\nvariable-size bag of vectors that grows with the size of the text, as in\nattention-based models. This allows to encode and reconstruct much longer texts\nthan standard autoencoders. Analogous to conventional autoencoders, we propose\nregularization techniques that facilitate learning meaningful operations in the\nlatent space. Finally, we adapt Emb2Emb for a training scheme that learns to\nmap an input bag to an output bag, including a novel loss function and neural\narchitecture. Our empirical evaluations on unsupervised sentiment transfer show\nthat our method performs substantially better than a standard autoencoder.\n","authors":["Florian Mai","James Henderson"],"pdf_url":"https://arxiv.org/pdf/2110.07002v2.pdf","comment":"Published at AACL 2022"},{"id":"http://arxiv.org/abs/2302.02178v1","updated":"2023-02-04T15:06:26Z","published":"2023-02-04T15:06:26Z","title":"Construction Grammar Provides Unique Insight into Neural Language Models","summary":"  Construction Grammar (CxG) has recently been used as the basis for probing\nstudies that have investigated the performance of large pretrained language\nmodels (PLMs) with respect to the structure and meaning of constructions. In\nthis position paper, we make suggestions for the continuation and augmentation\nof this line of research. We look at probing methodology that was not designed\nwith CxG in mind, as well as probing methodology that was designed for specific\nconstructions. We analyse selected previous work in detail, and provide our\nview of the most important challenges and research questions that this\npromising new field faces.\n","authors":["Leonie Weissweiler","Taiqi He","Naoki Otani","David R. Mortensen","Lori Levin","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2302.02178v1.pdf","comment":"GURT 2023"},{"id":"http://arxiv.org/abs/2302.02169v1","updated":"2023-02-04T13:55:12Z","published":"2023-02-04T13:55:12Z","title":"How Many and Which Training Points Would Need to be Removed to Flip this\n  Prediction?","summary":"  We consider the problem of identifying a minimal subset of training data\n$\\mathcal{S}_t$ such that if the instances comprising $\\mathcal{S}_t$ had been\nremoved prior to training, the categorization of a given test point $x_t$ would\nhave been different. Identifying such a set may be of interest for a few\nreasons. First, the cardinality of $\\mathcal{S}_t$ provides a measure of\nrobustness (if $|\\mathcal{S}_t|$ is small for $x_t$, we might be less confident\nin the corresponding prediction), which we show is correlated with but\ncomplementary to predicted probabilities. Second, interrogation of\n$\\mathcal{S}_t$ may provide a novel mechanism for contesting a particular model\nprediction: If one can make the case that the points in $\\mathcal{S}_t$ are\nwrongly labeled or irrelevant, this may argue for overturning the associated\nprediction. Identifying $\\mathcal{S}_t$ via brute-force is intractable. We\npropose comparatively fast approximation methods to find $\\mathcal{S}_t$ based\non influence functions, and find that -- for simple convex text classification\nmodels -- these approaches can often successfully identify relatively small\nsets of training examples which, if removed, would flip the prediction. To our\nknowledge, this is the first work in to investigate the problem of identifying\na minimal training set necessary to flip a given prediction in the context of\nmachine learning.\n","authors":["Jinghan Yang","Sarthak Jain","Byron C. Wallace"],"pdf_url":"https://arxiv.org/pdf/2302.02169v1.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.02149v1","updated":"2023-02-04T11:40:40Z","published":"2023-02-04T11:40:40Z","title":"Invariants for neural automata","summary":"  Computational modeling of neurodynamical systems often deploys neural\nnetworks and symbolic dynamics. A particular way for combining these approaches\nwithin a framework called vector symbolic architectures leads to neural\nautomata. An interesting research direction we have pursued under this\nframework has been to consider mapping symbolic dynamics onto neurodynamics,\nrepresented as neural automata. This representation theory, enables us to ask\nquestions, such as, how does the brain implement Turing computations.\nSpecifically, in this representation theory, neural automata result from the\nassignment of symbols and symbol strings to numbers, known as G\\\"odel encoding.\nUnder this assignment symbolic computation becomes represented by trajectories\nof state vectors in a real phase space, that allows for statistical correlation\nanalyses with real-world measurements and experimental data. However, these\nassignments are usually completely arbitrary. Hence, it makes sense to address\nthe problem question of, which aspects of the dynamics observed under such a\nrepresentation is intrinsic to the dynamics and which are not. In this study,\nwe develop a formally rigorous mathematical framework for the investigation of\nsymmetries and invariants of neural automata under different encodings. As a\ncentral concept we define patterns of equality for such systems. We consider\ndifferent macroscopic observables, such as the mean activation level of the\nneural network, and ask for their invariance properties. Our main result shows\nthat only step functions that are defined over those patterns of equality are\ninvariant under recodings, while the mean activation is not. Our work could be\nof substantial importance for related regression studies of real-world\nmeasurements with neurosymbolic processors for avoiding confounding results\nthat are dependant on a particular encoding and not intrinsic to the dynamics.\n","authors":["Jone Uria-Albizuri","Giovanni Sirio Carmantini","Peter beim Graben","Serafim Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2302.02149v1.pdf","comment":"28 pages, 8 figures"},{"id":"http://arxiv.org/abs/2301.12920v2","updated":"2023-02-04T11:25:35Z","published":"2023-01-30T14:19:29Z","title":"Active Learning for Multilingual Semantic Parser","summary":"  Current multilingual semantic parsing (MSP) datasets are almost all collected\nby translating the utterances in the existing datasets from the resource-rich\nlanguage to the target language. However, manual translation is costly. To\nreduce the translation effort, this paper proposes the first active learning\nprocedure for MSP (AL-MSP). AL-MSP selects only a subset from the existing\ndatasets to be translated. We also propose a novel selection method that\nprioritizes the examples diversifying the logical form structures with more\nlexical choices, and a novel hyperparameter tuning method that needs no extra\nannotation cost. Our experiments show that AL-MSP significantly reduces\ntranslation costs with ideal selection methods. Our selection method with\nproper hyperparameters yields better parsing performance than the other\nbaselines on two multilingual datasets.\n","authors":["Zhuang Li","Gholamreza Haffari"],"pdf_url":"https://arxiv.org/pdf/2301.12920v2.pdf","comment":"EACL 2023 (findings)"},{"id":"http://arxiv.org/abs/2301.00503v2","updated":"2023-02-04T10:58:11Z","published":"2023-01-02T02:10:18Z","title":"A Concept Knowledge Graph for User Next Intent Prediction at Alipay","summary":"  This paper illustrates the technologies of user next intent prediction with a\nconcept knowledge graph. The system has been deployed on the Web at Alipay,\nserving more than 100 million daily active users. To explicitly characterize\nuser intent, we propose \\textbf{AlipayKG}, which is an offline concept\nknowledge graph in the Life-Service domain modeling the historical behaviors of\nusers, the rich content interacted by users and the relations between them. We\nfurther introduce a Transformer-based model which integrates expert rules from\nthe knowledge graph to infer the online user's next intent. Experimental\nresults demonstrate that the proposed system can effectively enhance the\nperformance of the downstream tasks while retaining explainability.\n","authors":["Yacheng He","Qianghuai Jia","Lin Yuan","Ruopeng Li","Yixin Ou","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.00503v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2109.13662v4","updated":"2023-02-04T10:30:09Z","published":"2021-09-28T12:30:33Z","title":"DeepPSL: End-to-end perception and reasoning","summary":"  We introduce DeepPSL a variant of probabilistic soft logic (PSL) to produce\nan end-to-end trainable system that integrates reasoning and perception. PSL\nrepresents first-order logic in terms of a convex graphical model -- hinge-loss\nMarkov random fields (HL-MRFs). PSL stands out among probabilistic logic\nframeworks due to its tractability having been applied to systems of more than\n1 billion ground rules. The key to our approach is to represent predicates in\nfirst-order logic using deep neural networks and then to approximately\nback-propagate through the HL-MRF and thus train every aspect of the\nfirst-order system being represented. We believe that this approach represents\nan interesting direction for the integration of deep learning and reasoning\ntechniques with applications to knowledge base learning, multi-task learning,\nand explainability. Evaluation on three different tasks demonstrates that\nDeepPSL significantly outperforms state-of-the-art neuro-symbolic methods on\nscalability while achieving comparable or better accuracy.\n","authors":["Sridhar Dasaratha","Sai Akhil Puranam","Karmvir Singh Phogat","Sunil Reddy Tiyyagura","Nigel P. Duffy"],"pdf_url":"https://arxiv.org/pdf/2109.13662v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02141v1","updated":"2023-02-04T10:22:18Z","published":"2023-02-04T10:22:18Z","title":"LipFormer: Learning to Lipread Unseen Speakers based on Visual-Landmark\n  Transformers","summary":"  Lipreading refers to understanding and further translating the speech of a\nspeaker in the video into natural language. State-of-the-art lipreading methods\nexcel in interpreting overlap speakers, i.e., speakers appear in both training\nand inference sets. However, generalizing these methods to unseen speakers\nincurs catastrophic performance degradation due to the limited number of\nspeakers in training bank and the evident visual variations caused by the\nshape/color of lips for different speakers. Therefore, merely depending on the\nvisible changes of lips tends to cause model overfitting. To address this\nproblem, we propose to use multi-modal features across visual and landmarks,\nwhich can describe the lip motion irrespective to the speaker identities. Then,\nwe develop a sentence-level lipreading framework based on visual-landmark\ntransformers, namely LipFormer. Specifically, LipFormer consists of a lip\nmotion stream, a facial landmark stream, and a cross-modal fusion. The\nembeddings from the two streams are produced by self-attention, which are fed\nto the cross-attention module to achieve the alignment between visuals and\nlandmarks. Finally, the resulting fused features can be decoded to output texts\nby a cascade seq2seq model. Experiments demonstrate that our method can\neffectively enhance the model generalization to unseen speakers.\n","authors":["Feng Xue","Yu Li","Deyin Liu","Yincen Xie","Lin Wu","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2302.02141v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2106.05970v2","updated":"2023-02-04T09:27:27Z","published":"2021-06-10T17:59:52Z","title":"ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural\n  Language Generation","summary":"  Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with text references. This\ndiffers from human language processing, for which visual imagination often\nimproves comprehension. In this work, we propose ImaginE, an imagination-based\nautomatic evaluation metric for natural language generation. With the help of\nStableDiffusion, a state-of-the-art text-to-image generator, we automatically\ngenerate an image as the embodied imagination for the text snippet and compute\nthe imagination similarity using contextual embeddings. Experiments spanning\nseveral text generation tasks demonstrate that adding machine-generated images\nwith our ImaginE displays great potential in introducing multi-modal\ninformation into NLG evaluation, and improves existing automatic metrics'\ncorrelations with human similarity judgments in both reference-based and\nreference-free evaluation scenarios.\n","authors":["Wanrong Zhu","Xin Eric Wang","An Yan","Miguel Eckstein","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2106.05970v2.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2302.02128v1","updated":"2023-02-04T08:19:13Z","published":"2023-02-04T08:19:13Z","title":"Interaction Order Prediction for Temporal Graphs","summary":"  Link prediction in graphs is a task that has been widely investigated. It has\nbeen applied in various domains such as knowledge graph completion,\ncontent/item recommendation, social network recommendations and so on. The\ninitial focus of most research was on link prediction in static graphs.\nHowever, there has recently been abundant work on modeling temporal graphs, and\nconsequently one of the tasks that has been researched is link prediction in\ntemporal graphs. However, most of the existing work does not focus on the order\nof link formation, and only predicts the existence of links. In this study, we\naim to predict the order of node interactions.\n","authors":["Nayana Bannur","Mashrin Srivastava","Harsha Vardhan"],"pdf_url":"https://arxiv.org/pdf/2302.02128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02123v1","updated":"2023-02-04T07:44:23Z","published":"2023-02-04T07:44:23Z","title":"Weight, Is Attention All We Need? AEIUOrder: Greedy Ordering of Layer\n  Weight Matrices in Transformer Improves Translation","summary":"  Prior work has attempted to understand the internal structures and\nfunctionalities of Transformer-based encoder-decoder architectures on the level\nof multi-head attention and feed-forward sublayers. Interpretations have\nfocused on the encoder and decoder, along with the combinatorial possibilities\nof the self-attention, cross-attention, and feed-forward sublayers. Could we\nimprove the quality of translation by diving into the Transformer sublayer\nabstractions and permuting its layer weight matrices? We propose AEIUOrder to\ngreedily reorder layer weight matrices in the encoder by their\nwell-trainedness, as measured by Random Matrix Theory (RMT) metrics, and\nreverse the ordering scheme for the encoder. The objective is to maximize Total\nwell-trainedness in the encoder while the decoder structure serves to represent\nthe reverse process of encoding. On the standard Transformer (6 layers, model\ndimension 512), AEIUOrder achieves a BLEU score of 34.62 (baseline 34.31) on\nthe IWSLT 2016 German-to-English translation task, and 27.95 BLEU on the WMT\n2014 English-to-German translation task (baseline 27.91). AEIUOrder is also\nrealized on Transformers with various depths and embedding dimensions, showing\nsignificant improvements on deeper, wider models than on their shallower,\nslimmer counterparts. For instance, the 8-layer, 768-dimension and the 4-layer,\n1024-dimension Transformers achieve respective 29.1 and 29.31 BLEU scores on\nthe IWSLT 2016 English-to-German translation task (28.53 and 28.97 on\nrespective baselines). Our results suggest that the RMT-motivated approach to\nmaximize \\textit{Total well-trainedness}, by greedily reordering its layer\nweight matrices, facilitates the model to learn representations and generate\ntranslations more effectively.\n","authors":["Elicia Ye"],"pdf_url":"https://arxiv.org/pdf/2302.02123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02122v1","updated":"2023-02-04T07:36:17Z","published":"2023-02-04T07:36:17Z","title":"A New cross-domain strategy based XAI models for fake news detection","summary":"  In this study, we presented a four-level cross-domain strategy for fake news\ndetection on pre-trained models. Cross-domain text classification is a task of\na model adopting a target domain by using the knowledge of the source domain.\nExplainability is crucial in understanding the behaviour of these complex\nmodels. A fine-tune BERT model is used to. perform cross-domain classification\nwith several experiments using datasets from different domains. Explanatory\nmodels like Anchor, ELI5, LIME and SHAP are used to design a novel explainable\napproach to cross-domain levels. The experimental analysis has given an ideal\npair of XAI models on different levels of cross-domain.\n","authors":["Deepak Kanneganti"],"pdf_url":"https://arxiv.org/pdf/2302.02122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00982v2","updated":"2023-02-04T07:34:56Z","published":"2023-01-03T07:24:05Z","title":"Analogical Inference Enhanced Knowledge Graph Embedding","summary":"  Knowledge graph embedding (KGE), which maps entities and relations in a\nknowledge graph into continuous vector spaces, has achieved great success in\npredicting missing links in knowledge graphs. However, knowledge graphs often\ncontain incomplete triples that are difficult to inductively infer by KGEs. To\naddress this challenge, we resort to analogical inference and propose a novel\nand general self-supervised framework AnKGE to enhance KGE models with\nanalogical inference capability. We propose an analogical object retriever that\nretrieves appropriate analogical objects from entity-level, relation-level, and\ntriple-level. And in AnKGE, we train an analogy function for each level of\nanalogical inference with the original element embedding from a well-trained\nKGE model as input, which outputs the analogical object embedding. In order to\ncombine inductive inference capability from the original KGE model and\nanalogical inference capability enhanced by AnKGE, we interpolate the analogy\nscore with the base model score and introduce the adaptive weights in the score\nfunction for prediction. Through extensive experiments on FB15k-237 and WN18RR\ndatasets, we show that AnKGE achieves competitive results on link prediction\ntask and well performs analogical inference.\n","authors":["Zhen Yao","Wen Zhang","Mingyang Chen","Yufeng Huang","Yi Yang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2301.00982v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.02116v1","updated":"2023-02-04T07:01:02Z","published":"2023-02-04T07:01:02Z","title":"Knowledge Graph Completion Method Combined With Adaptive Enhanced\n  Semantic Information","summary":"  Translation models tend to ignore the rich semantic information in triads in\nthe process of knowledge graph complementation. To remedy this shortcoming,\nthis paper constructs a knowledge graph complementation method that\nincorporates adaptively enhanced semantic information. The hidden semantic\ninformation inherent in the triad is obtained by fine-tuning the BERT model,\nand the attention feature embedding method is used to calculate the semantic\nattention scores between relations and entities in positive and negative triads\nand incorporate them into the structural information to form a soft constraint\nrule for semantic information. The rule is added to the original translation\nmodel to realize the adaptive enhancement of semantic information. In addition,\nthe method takes into account the effect of high-dimensional vectors on the\neffect, and uses the BERT-whitening method to reduce the dimensionality and\ngenerate a more efficient semantic vector representation. After experimental\ncomparison, the proposed method performs better on both FB15K and WIN18\ndatasets, with a numerical improvement of about 2.6% compared with the original\ntranslation model, which verifies the reasonableness and effectiveness of the\nmethod.\n","authors":["Weidong Ji","Zengxiang Yin","Guohui Zhou","Yuqi Yue","Xinru Zhang","Chenghong Sun"],"pdf_url":"https://arxiv.org/pdf/2302.02116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02083v1","updated":"2023-02-04T03:50:01Z","published":"2023-02-04T03:50:01Z","title":"Theory of Mind May Have Spontaneously Emerged in Large Language Models","summary":"  Theory of mind (ToM), or the ability to impute unobservable mental states to\nothers, is central to human social interactions, communication, empathy,\nself-consciousness, and morality. We administer classic false-belief tasks,\nwidely used to test ToM in humans, to several language models, without any\nexamples or pre-training. Our results show that models published before 2022\nshow virtually no ability to solve ToM tasks. Yet, the January 2022 version of\nGPT-3 (davinci-002) solved 70% of ToM tasks, a performance comparable with that\nof seven-year-old children. Moreover, its November 2022 version (davinci-003),\nsolved 93% of ToM tasks, a performance comparable with that of nine-year-old\nchildren. These findings suggest that ToM-like ability (thus far considered to\nbe uniquely human) may have spontaneously emerged as a byproduct of language\nmodels' improving language skills.\n","authors":["Michal Kosinski"],"pdf_url":"https://arxiv.org/pdf/2302.02083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02080v1","updated":"2023-02-04T03:40:35Z","published":"2023-02-04T03:40:35Z","title":"Improving Prediction Backward-Compatiblility in NLP Model Upgrade with\n  Gated Fusion","summary":"  When upgrading neural models to a newer version, new errors that were not\nencountered in the legacy version can be introduced, known as regression\nerrors. This inconsistent behavior during model upgrade often outweighs the\nbenefits of accuracy gain and hinders the adoption of new models. To mitigate\nregression errors from model upgrade, distillation and ensemble have proven to\nbe viable solutions without significant compromise in performance. Despite the\nprogress, these approaches attained an incremental reduction in regression\nwhich is still far from achieving backward-compatible model upgrade. In this\nwork, we propose a novel method, Gated Fusion, that promotes backward\ncompatibility via learning to mix predictions between old and new models.\nEmpirical results on two distinct model upgrade scenarios show that our method\nreduces the number of regression errors by 62% on average, outperforming the\nstrongest baseline by an average of 25%.\n","authors":["Yi-An Lai","Elman Mansimov","Yuqing Xie","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02080v1.pdf","comment":"Camera-ready for EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2302.02078v1","updated":"2023-02-04T03:30:07Z","published":"2023-02-04T03:30:07Z","title":"FGSI: Distant Supervision for Relation Extraction method based on\n  Fine-Grained Semantic Information","summary":"  The main purpose of relation extraction is to extract the semantic\nrelationships between tagged pairs of entities in a sentence, which plays an\nimportant role in the semantic understanding of sentences and the construction\nof knowledge graphs. In this paper, we propose that the key semantic\ninformation within a sentence plays a key role in the relationship extraction\nof entities. We propose the hypothesis that the key semantic information inside\nthe sentence plays a key role in entity relationship extraction. And based on\nthis hypothesis, we split the sentence into three segments according to the\nlocation of the entity from the inside of the sentence, and find the\nfine-grained semantic features inside the sentence through the intra-sentence\nattention mechanism to reduce the interference of irrelevant noise information.\nThe proposed relational extraction model can make full use of the available\npositive semantic information. The experimental results show that the proposed\nrelation extraction model improves the accuracy-recall curves and P@N values\ncompared with existing methods, which proves the effectiveness of this model.\n","authors":["Chenghong Sun","Weidong Ji","Guohui Zhou","Hui Guo","Zengxiang Yin","Yuqi Yue"],"pdf_url":"https://arxiv.org/pdf/2302.02078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02069v1","updated":"2023-02-04T02:44:48Z","published":"2023-02-04T02:44:48Z","title":"Heterogeneous Federated Knowledge Graph Embedding Learning and\n  Unlearning","summary":"  Federated Learning (FL) recently emerges as a paradigm to train a global\nmachine learning model across distributed clients without sharing raw data.\nKnowledge Graph (KG) embedding represents KGs in a continuous vector space,\nserving as the backbone of many knowledge-driven applications. As a promising\ncombination, federated KG embedding can fully take advantage of knowledge\nlearned from different clients while preserving the privacy of local data.\nHowever, realistic problems such as data heterogeneity and knowledge forgetting\nstill remain to be concerned. In this paper, we propose FedLU, a novel FL\nframework for heterogeneous KG embedding learning and unlearning. To cope with\nthe drift between local optimization and global convergence caused by data\nheterogeneity, we propose mutual knowledge distillation to transfer local\nknowledge to global, and absorb global knowledge back. Moreover, we present an\nunlearning method based on cognitive neuroscience, which combines retroactive\ninterference and passive decay to erase specific knowledge from local clients\nand propagate to the global model by reusing knowledge distillation. We\nconstruct new datasets for assessing realistic performance of the\nstate-of-the-arts. Extensive experiments show that FedLU achieves superior\nresults in both link prediction and knowledge forgetting.\n","authors":["Xiangrong Zhu","Guangyao Li","Wei Hu"],"pdf_url":"https://arxiv.org/pdf/2302.02069v1.pdf","comment":"Accepted in the ACM Web Conference (WWW 2023)"},{"id":"http://arxiv.org/abs/2302.02064v1","updated":"2023-02-04T02:26:08Z","published":"2023-02-04T02:26:08Z","title":"Lived Experience Matters: Automatic Detection of Stigma toward People\n  Who Use Substances on Social Media","summary":"  Stigma toward people who use substances (PWUS) is a leading barrier to\nseeking treatment. Further, those in treatment are more likely to drop out if\nthey experience higher levels of stigmatization. While related concepts of hate\nspeech and toxicity, including those targeted toward vulnerable populations,\nhave been the focus of automatic content moderation research, stigma and, in\nparticular, people who use substances have not. This paper explores stigma\ntoward PWUS using a data set of roughly 5,000 public Reddit posts. We performed\na crowd-sourced annotation task where workers are asked to annotate each post\nfor the presence of stigma toward PWUS and answer a series of questions related\nto their experiences with substance use. Results show that workers who use\nsubstances or know someone with a substance use disorder are more likely to\nrate a post as stigmatizing. Building on this, we use a supervised machine\nlearning framework that centers workers with lived substance use experience to\nlabel each Reddit post as stigmatizing. Modeling person-level demographics in\naddition to comment-level language results in a classification accuracy (as\nmeasured by AUC) of 0.69 -- a 17% increase over modeling language alone.\nFinally, we explore the linguist cues which distinguish stigmatizing content:\nPWUS substances and those who don't agree that language around othering\n(\"people\", \"they\") and terms like \"addict\" are stigmatizing, while PWUS (as\nopposed to those who do not) find discussions around specific substances more\nstigmatizing. Our findings offer insights into the nature of perceived stigma\nin substance use. Additionally, these results further establish the subjective\nnature of such machine learning tasks, highlighting the need for understanding\ntheir social contexts.\n","authors":["Salvatore Giorgi","Douglas Bellew","Daniel Roy Sadek Habib","Joao Sedoc","Chase Smitterberg","Amanda Devoto","McKenzie Himelein-Wachowiak","Brenda Curtis"],"pdf_url":"https://arxiv.org/pdf/2302.02064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02060v1","updated":"2023-02-04T01:54:17Z","published":"2023-02-04T01:54:17Z","title":"Representation Deficiency in Masked Language Modeling","summary":"  Masked Language Modeling (MLM) has been one of the most prominent approaches\nfor pretraining bidirectional text encoders due to its simplicity and\neffectiveness. One notable concern about MLM is that the special\n$\\texttt{[MASK]}$ symbol causes a discrepancy between pretraining data and\ndownstream data as it is present only in pretraining but not in fine-tuning. In\nthis work, we offer a new perspective on the consequence of such a discrepancy:\nWe demonstrate empirically and theoretically that MLM pretraining allocates\nsome model dimensions exclusively for representing $\\texttt{[MASK]}$ tokens,\nresulting in a representation deficiency for real tokens and limiting the\npretrained model's expressiveness when it is adapted to downstream data without\n$\\texttt{[MASK]}$ tokens. Motivated by the identified issue, we propose MAE-LM,\nwhich pretrains the Masked Autoencoder architecture with MLM where\n$\\texttt{[MASK]}$ tokens are excluded from the encoder. Empirically, we show\nthat MAE-LM improves the utilization of model dimensions for real token\nrepresentations, and MAE-LM consistently outperforms MLM-pretrained models\nacross different pretraining settings and model sizes when fine-tuned on the\nGLUE and SQuAD benchmarks.\n","authors":["Yu Meng","Jitin Krishnan","Sinong Wang","Qifan Wang","Yuning Mao","Han Fang","Marjan Ghazvininejad","Jiawei Han","Luke Zettlemoyer"],"pdf_url":"https://arxiv.org/pdf/2302.02060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03496v1","updated":"2023-02-04T06:55:24Z","published":"2023-02-04T06:55:24Z","title":"Sentiment Analysis on YouTube Smart Phone Unboxing Video Reviews in Sri\n  Lanka","summary":"  Product-related reviews are based on users' experiences that are mostly\nshared on videos in YouTube. It is the second most popular website globally in\n2021. People prefer to watch videos on recently released products prior to\npurchasing, in order to gather overall feedback and make worthy decisions.\nThese videos are created by vloggers who are enthusiastic about technical\nmaterials and feedback is usually placed by experienced users of the product or\nits brand. Analyzing the sentiment of the user reviews gives useful insights\ninto the product in general. This study is focused on three smartphone reviews,\nnamely, Apple iPhone 13, Google Pixel 6, and Samsung Galaxy S21 which were\nreleased in 2021. VADER, which is a lexicon and rule-based sentiment analysis\ntool was used to classify each comment to its appropriate positive or negative\norientation. All three smartphones show a positive sentiment from the users'\nperspective and iPhone 13 has the highest number of positive reviews. The\nresulting models have been tested using N\\\"aive Bayes, Decision Tree, and\nSupport Vector Machine. Among these three classifiers, Support Vector Machine\nshows higher accuracies and F1-scores.\n","authors":["Sherina Sally"],"pdf_url":"https://arxiv.org/pdf/2302.03496v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.02259v1","updated":"2023-02-04T23:30:04Z","published":"2023-02-04T23:30:04Z","title":"CLiNet: Joint Detection of Road Network Centerlines in 2D and 3D","summary":"  This work introduces a new approach for joint detection of centerlines based\non image data by localizing the features jointly in 2D and 3D. In contrast to\nexisting work that focuses on detection of visual cues, we explore feature\nextraction methods that are directly amenable to the urban driving task. To\ndevelop and evaluate our approach, a large urban driving dataset dubbed AV\nBreadcrumbs is automatically labeled by leveraging vector map representations\nand projective geometry to annotate over 900,000 images. Our results\ndemonstrate potential for dynamic scene modeling across various urban driving\nscenarios. Our model achieves an F1 score of 0.684 and an average normalized\ndepth error of 2.083. The code and data annotations are publicly available.\n","authors":["David Paz","Srinidhi Kalgundi Srinivas","Yunchao Yao","Henrik I. Christensen"],"pdf_url":"https://arxiv.org/pdf/2302.02259v1.pdf","comment":"5 pages, 4 figures, 1 table. Under review at IEEE Intelligent\n  Vehicles Symposium 2023"},{"id":"http://arxiv.org/abs/2302.02255v1","updated":"2023-02-04T22:58:46Z","published":"2023-02-04T22:58:46Z","title":"Human-Imperceptible Identification with Learnable Lensless Imaging","summary":"  Lensless imaging protects visual privacy by capturing heavily blurred images\nthat are imperceptible for humans to recognize the subject but contain enough\ninformation for machines to infer information. Unfortunately, protecting visual\nprivacy comes with a reduction in recognition accuracy and vice versa. We\npropose a learnable lensless imaging framework that protects visual privacy\nwhile maintaining recognition accuracy. To make captured images imperceptible\nto humans, we designed several loss functions based on total variation,\ninvertibility, and the restricted isometry property. We studied the effect of\nprivacy protection with blurriness on the identification of personal identity\nvia a quantitative method based on a subjective evaluation. Moreover, we\nvalidate our simulation by implementing a hardware realization of lensless\nimaging with photo-lithographically printed masks.\n","authors":["Thuong Nguyen Canh","Trung Thanh Ngo","Hajime Nagahara"],"pdf_url":"https://arxiv.org/pdf/2302.02255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02249v1","updated":"2023-02-04T22:09:17Z","published":"2023-02-04T22:09:17Z","title":"Self-supervised Multi-view Disentanglement for Expansion of Visual\n  Collections","summary":"  Image search engines enable the retrieval of images relevant to a query\nimage. In this work, we consider the setting where a query for similar images\nis derived from a collection of images. For visual search, the similarity\nmeasurements may be made along multiple axes, or views, such as style and\ncolor. We assume access to a set of feature extractors, each of which computes\nrepresentations for a specific view. Our objective is to design a retrieval\nalgorithm that effectively combines similarities computed over representations\nfrom multiple views. To this end, we propose a self-supervised learning method\nfor extracting disentangled view-specific representations for images such that\nthe inter-view overlap is minimized. We show how this allows us to compute the\nintent of a collection as a distribution over views. We show how effective\nretrieval can be performed by prioritizing candidate expansion images that\nmatch the intent of a query collection. Finally, we present a new querying\nmechanism for image search enabled by composing multiple collections and\nperform retrieval under this setting using the techniques presented in this\npaper.\n","authors":["Nihal Jain","Praneetha Vaddamanu","Paridhi Maheshwari","Vishwa Vinay","Kuldeep Kulkarni"],"pdf_url":"https://arxiv.org/pdf/2302.02249v1.pdf","comment":"A version of this paper has been accepted at WSDM 2023"},{"id":"http://arxiv.org/abs/2302.00162v2","updated":"2023-02-04T21:51:19Z","published":"2023-02-01T00:49:21Z","title":"Continual Segment: Towards a Single, Unified and Accessible Continual\n  Segmentation Model of 143 Whole-body Organs in CT Scans","summary":"  Deep learning empowers the mainstream medical image segmentation methods.\nNevertheless current deep segmentation approaches are not capable of\nefficiently and effectively adapting and updating the trained models when new\nincremental segmentation classes (along with new training datasets or not) are\nrequired to be added. In real clinical environment, it can be preferred that\nsegmentation models could be dynamically extended to segment new organs/tumors\nwithout the (re-)access to previous training datasets due to obstacles of\npatient privacy and data storage. This process can be viewed as a continual\nsemantic segmentation (CSS) problem, being understudied for multi-organ\nsegmentation. In this work, we propose a new architectural CSS learning\nframework to learn a single deep segmentation model for segmenting a total of\n143 whole-body organs. Using the encoder/decoder network structure, we\ndemonstrate that a continually-trained then frozen encoder coupled with\nincrementally-added decoders can extract and preserve sufficiently\nrepresentative image features for new classes to be subsequently and validly\nsegmented. To maintain a single network model complexity, we trim each decoder\nprogressively using neural architecture search and teacher-student based\nknowledge distillation. To incorporate with both healthy and pathological\norgans appearing in different datasets, a novel anomaly-aware and confidence\nlearning module is proposed to merge the overlapped organ predictions,\noriginated from different decoders. Trained and validated on 3D CT scans of\n2500+ patients from four datasets, our single network can segment total 143\nwhole-body organs with very high accuracy, closely reaching the upper bound\nperformance level by training four separate segmentation models (i.e., one\nmodel per dataset/task).\n","authors":["Zhanghexuan Ji","Dazhou Guo","Puyang Wang","Ke Yan","Le Lu","Minfeng Xu","Jingren Zhou","Qifeng Wang","Jia Ge","Mingchen Gao","Xianghua Ye","Dakai Jin"],"pdf_url":"https://arxiv.org/pdf/2302.00162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06870v2","updated":"2023-02-04T21:44:34Z","published":"2022-11-13T10:29:25Z","title":"Detecting Disengagement in Virtual Learning as an Anomaly using Temporal\n  Convolutional Network Autoencoder","summary":"  Student engagement is an important factor in meeting the goals of virtual\nlearning programs. Automatic measurement of student engagement provides helpful\ninformation for instructors to meet learning program objectives and\nindividualize program delivery. Many existing approaches solve video-based\nengagement measurement using the traditional frameworks of binary\nclassification (classifying video snippets into engaged or disengaged classes),\nmulti-class classification (classifying video snippets into multiple classes\ncorresponding to different levels of engagement), or regression (estimating a\ncontinuous value corresponding to the level of engagement). However, we observe\nthat while the engagement behaviour is mostly well-defined (e.g., focused, not\ndistracted), disengagement can be expressed in various ways. In addition, in\nsome cases, the data for disengaged classes may not be sufficient to train\ngeneralizable binary or multi-class classifiers. To handle this situation, in\nthis paper, for the first time, we formulate detecting disengagement in virtual\nlearning as an anomaly detection problem. We design various autoencoders,\nincluding temporal convolutional network autoencoder, long-short-term memory\nautoencoder, and feedforward autoencoder using different behavioral and affect\nfeatures for video-based student disengagement detection. The result of our\nexperiments on two publicly available student engagement datasets, DAiSEE and\nEmotiW, shows the superiority of the proposed approach for disengagement\ndetection as an anomaly compared to binary classifiers for classifying videos\ninto engaged versus disengaged classes (with an average improvement of 9% on\nthe area under the curve of the receiver operating characteristic curve and 22%\non the area under the curve of the precision-recall curve).\n","authors":["Ali Abedi","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2211.06870v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01370v2","updated":"2023-02-04T21:09:19Z","published":"2022-06-03T02:41:59Z","title":"Towards Improving the Generation Quality of Autoregressive Slot VAEs","summary":"  Unconditional scene inference and generation are challenging to learn jointly\nwith a single compositional model. Despite encouraging progress on models that\nextract object-centric representations (\"slots\") from images, unconditional\ngeneration of scenes from slots has received less attention. This is primarily\nbecause learning the multi-object relations necessary to imagine coherent\nscenes is difficult. We hypothesize that most existing slot-based models have a\nlimited ability to learn object correlations. We propose two improvements that\nstrengthen slot correlation learning. The first is to condition the slots on a\nglobal, scene-level variable that captures higher-order correlations between\nslots. Second, we address the fundamental lack of a canonical order for objects\nby proposing to learn a consistent order to use for the autoregressive\ngeneration of scene objects. Specifically, we train an autoregressive slot\nprior to sequentially generate scene objects following the learned order. Slot\ninference entails estimating a randomly ordered set of slots using existing\napproaches for extracting slots from images, then aligning those slots to\nordered slots generated autoregressively with the prior. Our experiments across\nthree multi-object environments demonstrate clear gains in scene generation\nquality. Detailed ablation studies are also provided that validate the two\nproposed improvements.\n","authors":["Patrick Emami","Pan He","Sanjay Ranka","Anand Rangarajan"],"pdf_url":"https://arxiv.org/pdf/2206.01370v2.pdf","comment":"39 pages, 16 figures. Under review. Code and videos available at\n  https://github.com/pemami4911/segregate-relate-imagine"},{"id":"http://arxiv.org/abs/2208.02205v3","updated":"2023-02-04T20:48:21Z","published":"2022-08-03T16:41:39Z","title":"Large-scale Building Damage Assessment using a Novel Hierarchical\n  Transformer Architecture on Satellite Images","summary":"  This paper presents \\dahitra, a novel deep-learning model with hierarchical\ntransformers to classify building damages based on satellite images in the\naftermath of natural disasters. Satellite imagery provides real-time and\nhigh-coverage information and offers opportunities to inform large-scale\npost-disaster building damage assessment, which is critical for rapid emergency\nresponse. In this work, a novel transformer-based network is proposed for\nassessing building damage. This network leverages hierarchical spatial features\nof multiple resolutions and captures the temporal differences in the feature\ndomain after applying a transformer encoder on the spatial features. The\nproposed network achieves state-of-the-art performance when tested on a\nlarge-scale disaster damage dataset (xBD) for building localization and damage\nclassification, as well as on LEVIR-CD dataset for change detection tasks. In\naddition, this work introduces a new high-resolution satellite imagery dataset,\nIda-BD (related to 2021 Hurricane Ida in Louisiana in 2021) for domain\nadaptation. Further, it demonstrates an approach of using this dataset by\nadapting the model with limited fine-tuning and hence applying the model to\nnewly damaged areas with scarce data.\n","authors":["Navjot Kaur","Cheng-Chun Lee","Ali Mostafavi","Ali Mahdavi-Amiri"],"pdf_url":"https://arxiv.org/pdf/2208.02205v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02234v1","updated":"2023-02-04T20:42:46Z","published":"2023-02-04T20:42:46Z","title":"Revisiting Image Deblurring with an Efficient ConvNet","summary":"  Image deblurring aims to recover the latent sharp image from its blurry\ncounterpart and has a wide range of applications in computer vision. The\nConvolution Neural Networks (CNNs) have performed well in this domain for many\nyears, and until recently an alternative network architecture, namely\nTransformer, has demonstrated even stronger performance. One can attribute its\nsuperiority to the multi-head self-attention (MHSA) mechanism, which offers a\nlarger receptive field and better input content adaptability than CNNs.\nHowever, as MHSA demands high computational costs that grow quadratically with\nrespect to the input resolution, it becomes impractical for high-resolution\nimage deblurring tasks. In this work, we propose a unified lightweight CNN\nnetwork that features a large effective receptive field (ERF) and demonstrates\ncomparable or even better performance than Transformers while bearing less\ncomputational costs. Our key design is an efficient CNN block dubbed LaKD,\nequipped with a large kernel depth-wise convolution and spatial-channel mixing\nstructure, attaining comparable or larger ERF than Transformers but with a\nsmaller parameter scale. Specifically, we achieve +0.17dB / +0.43dB PSNR over\nthe state-of-the-art Restormer on defocus / motion deblurring benchmark\ndatasets with 32% fewer parameters and 39% fewer MACs. Extensive experiments\ndemonstrate the superior performance of our network and the effectiveness of\neach module. Furthermore, we propose a compact and intuitive ERFMeter metric\nthat quantitatively characterizes ERF, and shows a high correlation to the\nnetwork performance. We hope this work can inspire the research community to\nfurther explore the pros and cons of CNN and Transformer architectures beyond\nimage deblurring tasks.\n","authors":["Lingyan Ruan","Mojtaba Bemana","Hans-peter Seidel","Karol Myszkowski","Bin Chen"],"pdf_url":"https://arxiv.org/pdf/2302.02234v1.pdf","comment":"30 pages (12 pages for the main manuscript and 18 for the\n  supplementary materials)"},{"id":"http://arxiv.org/abs/2302.02216v1","updated":"2023-02-04T18:21:22Z","published":"2023-02-04T18:21:22Z","title":"A Minimax Approach Against Multi-Armed Adversarial Attacks Detection","summary":"  Multi-armed adversarial attacks, in which multiple algorithms and objective\nloss functions are simultaneously used at evaluation time, have been shown to\nbe highly successful in fooling state-of-the-art adversarial examples detectors\nwhile requiring no specific side information about the detection mechanism. By\nformalizing the problem at hand, we can propose a solution that aggregates the\nsoft-probability outputs of multiple pre-trained detectors according to a\nminimax approach. The proposed framework is mathematically sound, easy to\nimplement, and modular, allowing for integrating existing or future detectors.\nThrough extensive evaluation on popular datasets (e.g., CIFAR10 and SVHN), we\nshow that our aggregation consistently outperforms individual state-of-the-art\ndetectors against multi-armed adversarial attacks, making it an effective\nsolution to improve the resilience of available methods.\n","authors":["Federica Granese","Marco Romanelli","Siddharth Garg","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2302.02216v1.pdf","comment":"10 pages, 13 figures, 14 tables"},{"id":"http://arxiv.org/abs/2302.02214v1","updated":"2023-02-04T18:01:47Z","published":"2023-02-04T18:01:47Z","title":"Variational multichannel multiclass segmentation\\endgraf using\n  unsupervised lifting with CNNs","summary":"  We propose an unsupervised image segmentation approach, that combines a\nvariational energy functional and deep convolutional neural networks. The\nvariational part is based on a recent multichannel multiphase Chan-Vese model,\nwhich is capable to extract useful information from multiple input images\nsimultaneously. We implement a flexible multiclass segmentation method that\ndivides a given image into $K$ different regions. We use convolutional neural\nnetworks (CNNs) targeting a pre-decomposition of the image. By subsequently\nminimising the segmentation functional, the final segmentation is obtained in a\nfully unsupervised manner. Special emphasis is given to the extraction of\ninformative feature maps serving as a starting point for the segmentation. The\ninitial results indicate that the proposed method is able to decompose and\nsegment the different regions of various types of images, such as texture and\nmedical images and compare its performance with another multiphase segmentation\nmethod.\n","authors":["Nadja Gruber","Johannes Schwab","Sebastien Court","Elke Gizewski","Markus Haltmeier"],"pdf_url":"https://arxiv.org/pdf/2302.02214v1.pdf","comment":"20th INTERNATIONAL CONFERENCE OF NUMERICAL ANALYSIS AND APPLIED\n  MATHEMATICS"},{"id":"http://arxiv.org/abs/2302.02213v1","updated":"2023-02-04T17:59:30Z","published":"2023-02-04T17:59:30Z","title":"CosPGD: a unified white-box adversarial attack for pixel-wise prediction\n  tasks","summary":"  While neural networks allow highly accurate predictions in many tasks, their\nlack in robustness towards even slight input perturbations hampers their\ndeployment in many real-world applications. Recent research towards evaluating\nthe robustness of neural networks such as the seminal \\emph{projected gradient\ndescent} (PGD) attack and subsequent works and benchmarks have therefore drawn\nsignificant attention. Yet, such methods focus predominantly on classification\ntasks, while only a few approaches specifically address the analysis of\npixel-wise prediction tasks such as semantic segmentation, optical flow, or\ndisparity estimation. One notable exception is the recently proposed SegPGD\nattack, which could showcase the importance of pixel-wise attacks for\nevaluating semantic segmentation. While SegPGD is limited to pixel-wise\nclassification (i.e. segmentation), in this work, we propose CosPGD, a novel\nwhite-box adversarial attack that allows to optimize dedicated attacks for any\npixel-wise prediction task in a unified setting. It leverages the cosine\nsimilarity between the predictions and ground truth to extend directly from\nclassification tasks to regression settings. Further, we empirically show the\nsuperior performance of CosPGD for semantic segmentation as well as for optical\nflow and disparity estimation.\n","authors":["Shashank Agnihotri","Margret Keuper"],"pdf_url":"https://arxiv.org/pdf/2302.02213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02210v1","updated":"2023-02-04T17:40:39Z","published":"2023-02-04T17:40:39Z","title":"Oscillation-free Quantization for Low-bit Vision Transformers","summary":"  Weight oscillation is an undesirable side effect of quantization-aware\ntraining, in which quantized weights frequently jump between two quantized\nlevels, resulting in training instability and a sub-optimal final model. We\ndiscover that the learnable scaling factor, a widely-used $\\textit{de facto}$\nsetting in quantization aggravates weight oscillation. In this study, we\ninvestigate the connection between the learnable scaling factor and quantized\nweight oscillation and use ViT as a case driver to illustrate the findings and\nremedies. In addition, we also found that the interdependence between quantized\nweights in $\\textit{query}$ and $\\textit{key}$ of a self-attention layer makes\nViT vulnerable to oscillation. We, therefore, propose three techniques\naccordingly: statistical weight quantization ($\\rm StatsQ$) to improve\nquantization robustness compared to the prevalent learnable-scale-based method;\nconfidence-guided annealing ($\\rm CGA$) that freezes the weights with\n$\\textit{high confidence}$ and calms the oscillating weights; and\n$\\textit{query}$-$\\textit{key}$ reparameterization ($\\rm QKR$) to resolve the\nquery-key intertwined oscillation and mitigate the resulting gradient\nmisestimation. Extensive experiments demonstrate that these proposed techniques\nsuccessfully abate weight oscillation and consistently achieve substantial\naccuracy improvement on ImageNet. Specifically, our 2-bit DeiT-T/DeiT-S\nalgorithms outperform the previous state-of-the-art by 9.8% and 7.7%,\nrespectively. The code is included in the supplementary material and will be\nreleased.\n","authors":["Shih-Yang Liu","Zechun Liu","Kwang-Ting Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.02210v1.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2212.13425v3","updated":"2023-02-04T17:37:46Z","published":"2022-12-27T09:33:50Z","title":"GEDI: GEnerative and DIscriminative Training for Self-Supervised\n  Learning","summary":"  Self-supervised learning is a popular and powerful method for utilizing large\namounts of unlabeled data, for which a wide variety of training objectives have\nbeen proposed in the literature. In this study, we perform a Bayesian analysis\nof state-of-the-art self-supervised learning objectives and propose a unified\nformulation based on likelihood learning. Our analysis suggests a simple method\nfor integrating self-supervised learning with generative models, allowing for\nthe joint training of these two seemingly distinct approaches. We refer to this\ncombined framework as GEDI, which stands for GEnerative and DIscriminative\ntraining. Additionally, we demonstrate an instantiation of the GEDI framework\nby integrating an energy-based model with a cluster-based self-supervised\nlearning model. Through experiments on synthetic and real-world data, including\nSVHN, CIFAR10, and CIFAR100, we show that GEDI outperforms existing\nself-supervised learning strategies in terms of clustering performance by a\nwide margin. We also demonstrate that GEDI can be integrated into a\nneural-symbolic framework to address tasks in the small data regime, where it\ncan use logical constraints to further improve clustering and classification\nperformance.\n","authors":["Emanuele Sansone","Robin Manhaeve"],"pdf_url":"https://arxiv.org/pdf/2212.13425v3.pdf","comment":"Fixed typos/cleaned the experimental section"},{"id":"http://arxiv.org/abs/2211.04867v2","updated":"2023-02-04T17:08:45Z","published":"2022-11-09T13:18:35Z","title":"Trackerless freehand ultrasound with sequence modelling and auxiliary\n  transformation over past and future frames","summary":"  Three-dimensional (3D) freehand ultrasound (US) reconstruction without a\ntracker can be advantageous over its two-dimensional or tracked counterparts in\nmany clinical applications. In this paper, we propose to estimate 3D spatial\ntransformation between US frames from both past and future 2D images, using\nfeed-forward and recurrent neural networks (RNNs). With the temporally\navailable frames, a further multi-task learning algorithm is proposed to\nutilise a large number of auxiliary transformation-predicting tasks between\nthem. Using more than 40,000 US frames acquired from 228 scans on 38 forearms\nof 19 volunteers in a volunteer study, the hold-out test performance is\nquantified by frame prediction accuracy, volume reconstruction overlap,\naccumulated tracking error and final drift, based on ground-truth from an\noptical tracker. The results show the importance of modelling the\ntemporal-spatially correlated input frames as well as output transformations,\nwith further improvement owing to additional past and/or future frames. The\nbest performing model was associated with predicting transformation between\nmoderately-spaced frames, with an interval of less than ten frames at 20 frames\nper second (fps). Little benefit was observed by adding frames more than one\nsecond away from the predicted transformation, with or without LSTM-based RNNs.\nInterestingly, with the proposed approach, explicit within-sequence loss that\nencourages consistency in composing transformations or minimises accumulated\nerror may no longer be required. The implementation code and volunteer data\nwill be made publicly available ensuring reproducibility and further research.\n","authors":["Qi Li","Ziyi Shen","Qian Li","Dean C Barratt","Thomas Dowrick","Matthew J Clarkson","Tom Vercauteren","Yipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2211.04867v2.pdf","comment":"Accepted to IEEE International Symposium on Biomedical Imaging (ISBI)\n  2023"},{"id":"http://arxiv.org/abs/2302.02194v1","updated":"2023-02-04T16:39:38Z","published":"2023-02-04T16:39:38Z","title":"Laplacian ICP for Progressive Registration of 3D Human Head Meshes","summary":"  We present a progressive 3D registration framework that is a highly-efficient\nvariant of classical non-rigid Iterative Closest Points (N-ICP). Since it uses\nthe Laplace-Beltrami operator for deformation regularisation, we view the\noverall process as Laplacian ICP (L-ICP). This exploits a `small deformation\nper iteration' assumption and is progressively coarse-to-fine, employing an\nincreasingly flexible deformation model, an increasing number of correspondence\nsets, and increasingly sophisticated correspondence estimation. Correspondence\nmatching is only permitted within predefined vertex subsets derived from\ndomain-specific feature extractors. Additionally, we present a new benchmark\nand a pair of evaluation metrics for 3D non-rigid registration, based on\nannotation transfer. We use this to evaluate our framework on a\npublicly-available dataset of 3D human head scans (Headspace). The method is\nrobust and only requires a small fraction of the computation time compared to\nthe most popular classical approach, yet has comparable registration\nperformance.\n","authors":["Nick Pears","Hang Dai","Will Smith","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2302.02194v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.02184v1","updated":"2023-02-04T15:42:42Z","published":"2023-02-04T15:42:42Z","title":"Real-Time Image Demoireing on Mobile Devices","summary":"  Moire patterns appear frequently when taking photos of digital screens,\ndrastically degrading the image quality. Despite the advance of CNNs in image\ndemoireing, existing networks are with heavy design, causing redundant\ncomputation burden for mobile devices. In this paper, we launch the first study\non accelerating demoireing networks and propose a dynamic demoireing\nacceleration method (DDA) towards a real-time deployment on mobile devices. Our\nstimulus stems from a simple-yet-universal fact that moire patterns often\nunbalancedly distribute across an image. Consequently, excessive computation is\nwasted upon non-moire areas. Therefore, we reallocate computation costs in\nproportion to the complexity of image patches. In order to achieve this aim, we\nmeasure the complexity of an image patch by designing a novel moire prior that\nconsiders both colorfulness and frequency information of moire patterns. Then,\nwe restore image patches with higher-complexity using larger networks and the\nones with lower-complexity are assigned with smaller networks to relieve the\ncomputation burden. At last, we train all networks in a parameter-shared\nsupernet paradigm to avoid additional parameter burden. Extensive experiments\non several benchmarks demonstrate the efficacy of our proposed DDA. In\naddition, the acceleration evaluated on the VIVO X80 Pro smartphone equipped\nwith a chip of Snapdragon 8 Gen 1 shows that our method can drastically reduce\nthe inference time, leading to a real-time image demoireing on mobile devices.\nSource codes and models are released at https://github.com/zyxxmu/DDA\n","authors":["Yuxin Zhang","Mingbao Lin","Xunchao Li","Han Liu","Guozhi Wang","Fei Chao","Shuai Ren","Yafei Wen","Xiaoxin Chen","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2302.02184v1.pdf","comment":"To appear in the eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2302.02181v1","updated":"2023-02-04T15:28:49Z","published":"2023-02-04T15:28:49Z","title":"Model Stitching and Visualization How GAN Generators can Invert Networks\n  in Real-Time","summary":"  Critical applications, such as in the medical field, require the rapid\nprovision of additional information to interpret decisions made by deep\nlearning methods. In this work, we propose a fast and accurate method to\nvisualize activations of classification and semantic segmentation networks by\nstitching them with a GAN generator utilizing convolutions. We test our\napproach on images of animals from the AFHQ wild dataset and real-world digital\npathology scans of stained tissue samples. Our method provides comparable\nresults to established gradient descent methods on these datasets while running\nabout two orders of magnitude faster.\n","authors":["Rudolf Herdt","Maximilian Schmidt","Daniel Otero Baguer","Jean Le'Clerc Arrastia","Peter Maass"],"pdf_url":"https://arxiv.org/pdf/2302.02181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01332v2","updated":"2023-02-04T14:11:00Z","published":"2023-02-02T18:59:23Z","title":"Bayesian Metric Learning for Uncertainty Quantification in Image\n  Retrieval","summary":"  We propose the first Bayesian encoder for metric learning. Rather than\nrelying on neural amortization as done in prior works, we learn a distribution\nover the network weights with the Laplace Approximation. We actualize this by\nfirst proving that the contrastive loss is a valid log-posterior. We then\npropose three methods that ensure a positive definite Hessian. Lastly, we\npresent a novel decomposition of the Generalized Gauss-Newton approximation.\nEmpirically, we show that our Laplacian Metric Learner (LAM) estimates\nwell-calibrated uncertainties, reliably detects out-of-distribution examples,\nand yields state-of-the-art predictive performance.\n","authors":["Frederik Warburg","Marco Miani","Silas Brack","Soren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2302.01332v2.pdf","comment":"Code: https://github.com/FrederikWarburg/bayesian-metric-learning"},{"id":"http://arxiv.org/abs/2204.09924v2","updated":"2023-02-04T13:45:13Z","published":"2022-04-21T07:24:14Z","title":"Progressive Training of A Two-Stage Framework for Video Restoration","summary":"  As a widely studied task, video restoration aims to enhance the quality of\nthe videos with multiple potential degradations, such as noises, blurs and\ncompression artifacts. Among video restorations, compressed video quality\nenhancement and video super-resolution are two of the main tacks with\nsignificant values in practical scenarios. Recently, recurrent neural networks\nand transformers attract increasing research interests in this field, due to\ntheir impressive capability in sequence-to-sequence modeling. However, the\ntraining of these models is not only costly but also relatively hard to\nconverge, with gradient exploding and vanishing problems. To cope with these\nproblems, we proposed a two-stage framework including a multi-frame recurrent\nnetwork and a single-frame transformer. Besides, multiple training strategies,\nsuch as transfer learning and progressive training, are developed to shorten\nthe training time and improve the model performance. Benefiting from the above\ntechnical contributions, our solution wins two champions and a runner-up in the\nNTIRE 2022 super-resolution and quality enhancement of compressed video\nchallenges. Code is available at\nhttps://github.com/ryanxingql/winner-ntire22-vqe.\n","authors":["Meisong Zheng","Qunliang Xing","Minglang Qiao","Mai Xu","Lai Jiang","Huaida Liu","Ying Chen"],"pdf_url":"https://arxiv.org/pdf/2204.09924v2.pdf","comment":"Winning two championships and one runner-up in the NTIRE 2022\n  challenge on super-resolution and quality enhancement of compressed video;\n  Accepted to CVPRW 2022"},{"id":"http://arxiv.org/abs/2302.02155v1","updated":"2023-02-04T12:20:32Z","published":"2023-02-04T12:20:32Z","title":"Guaranteed Tensor Recovery Fused Low-rankness and Smoothness","summary":"  The tensor data recovery task has thus attracted much research attention in\nrecent years. Solving such an ill-posed problem generally requires to explore\nintrinsic prior structures underlying tensor data, and formulate them as\ncertain forms of regularization terms for guiding a sound estimate of the\nrestored tensor. Recent research have made significant progress by adopting two\ninsightful tensor priors, i.e., global low-rankness (L) and local smoothness\n(S) across different tensor modes, which are always encoded as a sum of two\nseparate regularization terms into the recovery models. However, unlike the\nprimary theoretical developments on low-rank tensor recovery, these joint L+S\nmodels have no theoretical exact-recovery guarantees yet, making the methods\nlack reliability in real practice. To this crucial issue, in this work, we\nbuild a unique regularization term, which essentially encodes both L and S\npriors of a tensor simultaneously. Especially, by equipping this single\nregularizer into the recovery models, we can rigorously prove the exact\nrecovery guarantees for two typical tensor recovery tasks, i.e., tensor\ncompletion (TC) and tensor robust principal component analysis (TRPCA). To the\nbest of our knowledge, this should be the first exact-recovery results among\nall related L+S methods for tensor recovery. Significant recovery accuracy\nimprovements over many other SOTA methods in several TC and TRPCA tasks with\nvarious kinds of visual tensor data are observed in extensive experiments.\nTypically, our method achieves a workable performance when the missing rate is\nextremely large, e.g., 99.5%, for the color image inpainting task, while all\nits peers totally fail in such challenging case.\n","authors":["Hailin Wang","Jiangjun Peng","Wenjin Qin","Jianjun Wang","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2302.02155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02150v1","updated":"2023-02-04T11:49:38Z","published":"2023-02-04T11:49:38Z","title":"This Intestine Does Not Exist: Multiscale Residual Variational\n  Autoencoder for Realistic Wireless Capsule Endoscopy Image Generation","summary":"  Medical image synthesis has emerged as a promising solution to address the\nlimited availability of annotated medical data needed for training machine\nlearning algorithms in the context of image-based Clinical Decision Support\n(CDS) systems. To this end, Generative Adversarial Networks (GANs) have been\nmainly applied to support the algorithm training process by generating\nsynthetic images for data augmentation. However, in the field of Wireless\nCapsule Endoscopy (WCE), the limited content diversity and size of existing\npublicly available annotated datasets, adversely affect both the training\nstability and synthesis performance of GANs. Aiming to a viable solution for\nWCE image synthesis, a novel Variational Autoencoder architecture is proposed,\nnamely \"This Intestine Does not Exist\" (TIDE). The proposed architecture\ncomprises multiscale feature extraction convolutional blocks and residual\nconnections, which enable the generation of high-quality and diverse datasets\neven with a limited number of training images. Contrary to the current\napproaches, which are oriented towards the augmentation of the available\ndatasets, this study demonstrates that using TIDE, real WCE datasets can be\nfully substituted by artificially generated ones, without compromising\nclassification performance. Furthermore, qualitative and user evaluation\nstudies by experienced WCE specialists, validate from a medical viewpoint that\nboth the normal and abnormal WCE images synthesized by TIDE are sufficiently\nrealistic.\n","authors":["Dimitrios E. Diamantis","Panagiota Gatoula","Anastasios Koulaouzidis","Dimitris K. Iakovidis"],"pdf_url":"https://arxiv.org/pdf/2302.02150v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2302.02141v1","updated":"2023-02-04T10:22:18Z","published":"2023-02-04T10:22:18Z","title":"LipFormer: Learning to Lipread Unseen Speakers based on Visual-Landmark\n  Transformers","summary":"  Lipreading refers to understanding and further translating the speech of a\nspeaker in the video into natural language. State-of-the-art lipreading methods\nexcel in interpreting overlap speakers, i.e., speakers appear in both training\nand inference sets. However, generalizing these methods to unseen speakers\nincurs catastrophic performance degradation due to the limited number of\nspeakers in training bank and the evident visual variations caused by the\nshape/color of lips for different speakers. Therefore, merely depending on the\nvisible changes of lips tends to cause model overfitting. To address this\nproblem, we propose to use multi-modal features across visual and landmarks,\nwhich can describe the lip motion irrespective to the speaker identities. Then,\nwe develop a sentence-level lipreading framework based on visual-landmark\ntransformers, namely LipFormer. Specifically, LipFormer consists of a lip\nmotion stream, a facial landmark stream, and a cross-modal fusion. The\nembeddings from the two streams are produced by self-attention, which are fed\nto the cross-attention module to achieve the alignment between visuals and\nlandmarks. Finally, the resulting fused features can be decoded to output texts\nby a cascade seq2seq model. Experiments demonstrate that our method can\neffectively enhance the model generalization to unseen speakers.\n","authors":["Feng Xue","Yu Li","Deyin Liu","Yincen Xie","Lin Wu","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2302.02141v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2106.05970v2","updated":"2023-02-04T09:27:27Z","published":"2021-06-10T17:59:52Z","title":"ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural\n  Language Generation","summary":"  Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with text references. This\ndiffers from human language processing, for which visual imagination often\nimproves comprehension. In this work, we propose ImaginE, an imagination-based\nautomatic evaluation metric for natural language generation. With the help of\nStableDiffusion, a state-of-the-art text-to-image generator, we automatically\ngenerate an image as the embodied imagination for the text snippet and compute\nthe imagination similarity using contextual embeddings. Experiments spanning\nseveral text generation tasks demonstrate that adding machine-generated images\nwith our ImaginE displays great potential in introducing multi-modal\ninformation into NLG evaluation, and improves existing automatic metrics'\ncorrelations with human similarity judgments in both reference-based and\nreference-free evaluation scenarios.\n","authors":["Wanrong Zhu","Xin Eric Wang","An Yan","Miguel Eckstein","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2106.05970v2.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2302.02136v1","updated":"2023-02-04T09:14:18Z","published":"2023-02-04T09:14:18Z","title":"Efficient End-to-End Video Question Answering with Pyramidal Multimodal\n  Transformer","summary":"  This paper presents a new method for end-to-end Video Question Answering\n(VideoQA), aside from the current popularity of using large-scale pre-training\nwith huge feature extractors. We achieve this with a pyramidal multimodal\ntransformer (PMT) model, which simply incorporates a learnable word embedding\nlayer, a few convolutional and transformer layers. We use the anisotropic\npyramid to fulfill video-language interactions across different spatio-temporal\nscales. In addition to the canonical pyramid, which includes both bottom-up and\ntop-down pathways with lateral connections, novel strategies are proposed to\ndecompose the visual feature stream into spatial and temporal sub-streams at\ndifferent scales and implement their interactions with the linguistic semantics\nwhile preserving the integrity of local and global semantics. We demonstrate\nbetter or on-par performances with high computational efficiency against\nstate-of-the-art methods on five VideoQA benchmarks. Our ablation study shows\nthe scalability of our model that achieves competitive results for\ntext-to-video retrieval by leveraging feature extractors with reusable\npre-trained weights, and also the effectiveness of the pyramid.\n","authors":["Min Peng","Chongyang Wang","Yu Shi","Xiang-Dong Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.02136v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2301.10908v2","updated":"2023-02-04T09:11:39Z","published":"2023-01-26T02:38:37Z","title":"Distilling Cognitive Backdoor Patterns within an Image","summary":"  This paper proposes a simple method to distill and detect backdoor patterns\nwithin an image: \\emph{Cognitive Distillation} (CD). The idea is to extract the\n\"minimal essence\" from an input image responsible for the model's prediction.\nCD optimizes an input mask to extract a small pattern from the input image that\ncan lead to the same model output (i.e., logits or deep features). The\nextracted pattern can help understand the cognitive mechanism of a model on\nclean vs. backdoor images and is thus called a \\emph{Cognitive Pattern} (CP).\nUsing CD and the distilled CPs, we uncover an interesting phenomenon of\nbackdoor attacks: despite the various forms and sizes of trigger patterns used\nby different attacks, the CPs of backdoor samples are all surprisingly and\nsuspiciously small. One thus can leverage the learned mask to detect and remove\nbackdoor examples from poisoned training datasets. We conduct extensive\nexperiments to show that CD can robustly detect a wide range of advanced\nbackdoor attacks. We also show that CD can potentially be applied to help\ndetect potential biases from face datasets. Code is available at\n\\url{https://github.com/HanxunH/CognitiveDistillation}.\n","authors":["Hanxun Huang","Xingjun Ma","Sarah Erfani","James Bailey"],"pdf_url":"https://arxiv.org/pdf/2301.10908v2.pdf","comment":"ICLR2023"},{"id":"http://arxiv.org/abs/2302.02125v1","updated":"2023-02-04T07:55:30Z","published":"2023-02-04T07:55:30Z","title":"Weakly-Supervised 3D Medical Image Segmentation using Geometric Prior\n  and Contrastive Similarity","summary":"  Medical image segmentation is almost the most important pre-processing\nprocedure in computer-aided diagnosis but is also a very challenging task due\nto the complex shapes of segments and various artifacts caused by medical\nimaging, (i.e., low-contrast tissues, and non-homogenous textures). In this\npaper, we propose a simple yet effective segmentation framework that\nincorporates the geometric prior and contrastive similarity into the\nweakly-supervised segmentation framework in a loss-based fashion. The proposed\ngeometric prior built on point cloud provides meticulous geometry to the\nweakly-supervised segmentation proposal, which serves as better supervision\nthan the inherent property of the bounding-box annotation (i.e., height and\nwidth). Furthermore, we propose contrastive similarity to encourage organ\npixels to gather around in the contrastive embedding space, which helps better\ndistinguish low-contrast tissues. The proposed contrastive embedding space can\nmake up for the poor representation of the conventionally-used gray space.\nExtensive experiments are conducted to verify the effectiveness and the\nrobustness of the proposed weakly-supervised segmentation framework. The\nproposed framework is superior to state-of-the-art weakly-supervised methods on\nthe following publicly accessible datasets: LiTS 2017 Challenge, KiTS 2021\nChallenge, and LPBA40. We also dissect our method and evaluate the performance\nof each component.\n","authors":["Hao Du","Qihua Dong","Yan Xu","Jing Liao"],"pdf_url":"https://arxiv.org/pdf/2302.02125v1.pdf","comment":"Weakly-supervised Segmentation, Medical Image Segmentation,\n  Contrastive Similarity, Geometric Prior, Point Cloud"},{"id":"http://arxiv.org/abs/2108.01654v2","updated":"2023-02-04T07:53:37Z","published":"2021-08-03T17:52:30Z","title":"Comparison of modern open-source visual SLAM approaches","summary":"  SLAM is one of the most fundamental areas of research in robotics and\ncomputer vision. State of the art solutions has advanced significantly in terms\nof accuracy and stability. Unfortunately, not all the approaches are available\nas open-source solutions and free to use. The results of some of them are\ndifficult to reproduce, and there is a lack of comparison on common datasets.\nIn our work, we make a comparative analysis of state of the art open-source\nmethods. We assess the algorithms based on accuracy, computational performance,\nrobustness, and fault tolerance. Moreover, we present a comparison of datasets\nas well as an analysis of algorithms from a practical point of view. The\nfindings of the work raise several crucial questions for SLAM researchers.\n","authors":["Dinar Sharafutdinov","Mark Griguletskii","Pavel Kopanev","Mikhail Kurenkov","Gonzalo Ferrer","Aleksey Burkov","Aleksei Gonnochenko","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2108.01654v2.pdf","comment":"Preprint, 19 pages"},{"id":"http://arxiv.org/abs/2302.02124v1","updated":"2023-02-04T07:50:31Z","published":"2023-02-04T07:50:31Z","title":"Transform, Contrast and Tell: Coherent Entity-Aware Multi-Image\n  Captioning","summary":"  Coherent entity-aware multi-image captioning aims to generate coherent\ncaptions for multiple adjacent images in a news document. There are coherence\nrelationships among adjacent images because they often describe same entities\nor events. These relationships are important for entity-aware multi-image\ncaptioning, but are neglected in entity-aware single-image captioning. Most\nexisting work focuses on single-image captioning, while multi-image captioning\nhas not been explored before. Hence, this paper proposes a coherent\nentity-aware multi-image captioning model by making use of coherence\nrelationships. The model consists of a Transformer-based caption generation\nmodel and two types of contrastive learning-based coherence mechanisms. The\ngeneration model generates the caption by paying attention to the image and the\naccompanying text. The horizontal coherence mechanism aims to the make the\ncaption coherent with captions of adjacent images. The vertical coherence\nmechanism aims to make the caption coherent with the image and the accompanying\ntext. To evaluate coherence between captions, two coherence evaluation metrics\nare proposed. The new dataset DM800K is constructed that has more images per\ndocument than two existing datasets GoodNews and NYT800K, and are more suitable\nfor multi-image captioning. Experiments on three datasets show the proposed\ncaptioning model outperforms 6 baselines according to single-image captioning\nevaluations, and the generated captions are more coherent than that of\nbaselines according to coherence evaluations and human evaluations.\n","authors":["Jingqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2302.02124v1.pdf","comment":"28 pages, 9 tables, 3 figures"},{"id":"http://arxiv.org/abs/2302.02117v1","updated":"2023-02-04T07:02:29Z","published":"2023-02-04T07:02:29Z","title":"Learning to Agree on Vision Attention for Visual Commonsense Reasoning","summary":"  Visual Commonsense Reasoning (VCR) remains a significant yet challenging\nresearch problem in the realm of visual reasoning. A VCR model generally aims\nat answering a textual question regarding an image, followed by the rationale\nprediction for the preceding answering process. Though these two processes are\nsequential and intertwined, existing methods always consider them as two\nindependent matching-based instances. They, therefore, ignore the pivotal\nrelationship between the two processes, leading to sub-optimal model\nperformance. This paper presents a novel visual attention alignment method to\nefficaciously handle these two processes in a unified framework. To achieve\nthis, we first design a re-attention module for aggregating the vision\nattention map produced in each process. Thereafter, the resultant two sets of\nattention maps are carefully aligned to guide the two processes to make\ndecisions based on the same image regions. We apply this method to both\nconventional attention and the recent Transformer models and carry out\nextensive experiments on the VCR benchmark dataset. The results demonstrate\nthat with the attention alignment module, our method achieves a considerable\nimprovement over the baseline methods, evidently revealing the feasibility of\nthe coupling of the two processes as well as the effectiveness of the proposed\nmethod.\n","authors":["Zhenyang Li","Yangyang Guo","Yangyang Guo","Fan Liu","Liqiang Nie","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2302.02117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02108v1","updated":"2023-02-04T06:30:57Z","published":"2023-02-04T06:30:57Z","title":"Knowledge Distillation in Vision Transformers: A Critical Review","summary":"  In Natural Language Processing (NLP), Transformers have already\nrevolutionized the field by utilizing an attention-based encoder-decoder model.\nRecently, some pioneering works have employed Transformer-like architectures in\nComputer Vision (CV) and they have reported outstanding performance of these\narchitectures in tasks such as image classification, object detection, and\nsemantic segmentation. Vision Transformers (ViTs) have demonstrated impressive\nperformance improvements over Convolutional Neural Networks (CNNs) due to their\ncompetitive modelling capabilities. However, these architectures demand massive\ncomputational resources which makes these models difficult to be deployed in\nthe resource-constrained applications. Many solutions have been developed to\ncombat this issue, such as compressive transformers and compression functions\nsuch as dilated convolution, min-max pooling, 1D convolution, etc. Model\ncompression has recently attracted considerable research attention as a\npotential remedy. A number of model compression methods have been proposed in\nthe literature such as weight quantization, weight multiplexing, pruning and\nKnowledge Distillation (KD). However, techniques like weight quantization,\npruning and weight multiplexing typically involve complex pipelines for\nperforming the compression. KD has been found to be a simple and much effective\nmodel compression technique that allows a relatively simple model to perform\ntasks almost as accurately as a complex model. This paper discusses various\napproaches based upon KD for effective compression of ViT models. The paper\nelucidates the role played by KD in reducing the computational and memory\nrequirements of these models. The paper also presents the various challenges\nfaced by ViTs that are yet to be resolved.\n","authors":["Gousia Habib","Tausifa Jan Saleem","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2302.02108v1.pdf","comment":"28pages, 16 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.02241v1","updated":"2023-02-04T21:03:49Z","published":"2023-02-04T21:03:49Z","title":"Feature Representation Learning for Click-through Rate Prediction: A\n  Review and New Perspectives","summary":"  Representation learning has been a critical topic in machine learning. In\nClick-through Rate Prediction, most features are represented as embedding\nvectors and learned simultaneously with other parameters in the model. With the\ndevelopment of CTR models, feature representation learning has become a\ntrending topic and has been extensively studied by both industrial and academic\nresearchers in recent years. This survey aims at summarizing the feature\nrepresentation learning in a broader picture and pave the way for future\nresearch. To achieve such a goal, we first present a taxonomy of current\nresearch methods on feature representation learning following two main issues:\n(i) which feature to represent and (ii) how to represent these features. Then\nwe give a detailed description of each method regarding these two issues.\nFinally, the review concludes with a discussion on the future directions of\nthis field.\n","authors":["Fuyuan Lyu","Xing Tang","Dugang Liu","Haolun Wu","Chen Ma","Xiuqiang He","Xue Liu"],"pdf_url":"https://arxiv.org/pdf/2302.02241v1.pdf","comment":"Submitted to IJCAI 2023 Survey Track"},{"id":"http://arxiv.org/abs/2301.11223v3","updated":"2023-02-04T12:17:14Z","published":"2023-01-26T16:56:52Z","title":"CitationSum: Citation-aware Graph Contrastive Learning for Scientific\n  Paper Summarization","summary":"  Citation graphs can be helpful in generating high-quality summaries of\nscientific papers, where references of a scientific paper and their\ncorrelations can provide additional knowledge for contextualising its\nbackground and main contributions. Despite the promising contributions of\ncitation graphs, it is still challenging to incorporate them into summarization\ntasks. This is due to the difficulty of accurately identifying and leveraging\nrelevant content in references for a source paper, as well as capturing their\ncorrelations of different intensities. Existing methods either ignore\nreferences or utilize only abstracts indiscriminately from them, failing to\ntackle the challenge mentioned above. To fill that gap, we propose a novel\ncitation-aware scientific paper summarization framework based on citation\ngraphs, able to accurately locate and incorporate the salient contents from\nreferences, as well as capture varying relevance between source papers and\ntheir references. Specifically, we first build a domain-specific dataset\nPubMedCite with about 192K biomedical scientific papers and a large citation\ngraph preserving 917K citation relationships between them. It is characterized\nby preserving the salient contents extracted from full texts of references, and\nthe weighted correlation between the salient contents of references and the\nsource paper. Based on it, we design a self-supervised citation-aware\nsummarization framework (CitationSum) with graph contrastive learning, which\nboosts the summarization generation by efficiently fusing the salient\ninformation in references with source paper contents under the guidance of\ntheir correlations. Experimental results show that our model outperforms the\nstate-of-the-art methods, due to efficiently leveraging the information of\nreferences and citation correlations.\n","authors":["Zheheng Luo","Qianqian Xie","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2301.11223v3.pdf","comment":"accepted to WWW2023"},{"id":"http://arxiv.org/abs/2302.02151v1","updated":"2023-02-04T11:55:46Z","published":"2023-02-04T11:55:46Z","title":"Contrastive Collaborative Filtering for Cold-Start Item Recommendation","summary":"  The cold-start problem is a long-standing challenge in recommender systems.\nAs a promising solution, content-based generative models usually project a\ncold-start item's content onto a warm-start item embedding to capture\ncollaborative signals from item content so that collaborative filtering can be\napplied. However, since the training of the cold-start recommendation models is\nconducted on warm datasets, the existent methods face the issue that the\ncollaborative embeddings of items will be blurred, which significantly\ndegenerates the performance of cold-start item recommendation. To address this\nissue, we propose a novel model called Contrastive Collaborative Filtering for\nCold-start item Recommendation (CCFCRec), which capitalizes on the\nco-occurrence collaborative signals in warm training data to alleviate the\nissue of blurry collaborative embeddings for cold-start item recommendation. In\nparticular, we devise a contrastive collaborative filtering (CF) framework,\nconsisting of a content CF module and a co-occurrence CF module to generate the\ncontent-based collaborative embedding and the co-occurrence collaborative\nembedding for a training item, respectively. During the joint training of the\ntwo CF modules, we apply a contrastive learning between the two collaborative\nembeddings, by which the knowledge about the co-occurrence signals can be\nindirectly transferred to the content CF module, so that the blurry\ncollaborative embeddings can be rectified implicitly by the memorized\nco-occurrence collaborative signals during the applying phase. Together with\nthe sound theoretical analysis, the extensive experiments conducted on real\ndatasets demonstrate the superiority of the proposed model. The codes and\ndatasets are available on https://github.com/zzhin/CCFCRec.\n","authors":["Zhihui Zhou","Lilin Zhang","Ning Yang"],"pdf_url":"https://arxiv.org/pdf/2302.02151v1.pdf","comment":"This paper has been accepted by WWW '23"},{"id":"http://arxiv.org/abs/2301.00503v2","updated":"2023-02-04T10:58:11Z","published":"2023-01-02T02:10:18Z","title":"A Concept Knowledge Graph for User Next Intent Prediction at Alipay","summary":"  This paper illustrates the technologies of user next intent prediction with a\nconcept knowledge graph. The system has been deployed on the Web at Alipay,\nserving more than 100 million daily active users. To explicitly characterize\nuser intent, we propose \\textbf{AlipayKG}, which is an offline concept\nknowledge graph in the Life-Service domain modeling the historical behaviors of\nusers, the rich content interacted by users and the relations between them. We\nfurther introduce a Transformer-based model which integrates expert rules from\nthe knowledge graph to infer the online user's next intent. Experimental\nresults demonstrate that the proposed system can effectively enhance the\nperformance of the downstream tasks while retaining explainability.\n","authors":["Yacheng He","Qianghuai Jia","Lin Yuan","Ruopeng Li","Yixin Ou","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.00503v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.02113v1","updated":"2023-02-04T06:49:52Z","published":"2023-02-04T06:49:52Z","title":"Personalized Graph Signal Processing for Collaborative Filtering","summary":"  The collaborative filtering (CF) problem with only user-item interaction\ninformation can be solved by graph signal processing (GSP), which uses low-pass\nfilters to smooth the observed interaction signals on the similarity graph to\nobtain the prediction signals. However, the interaction signal may not be\nsufficient to accurately characterize user interests and the low-pass filters\nmay ignore the useful information contained in the high-frequency component of\nthe observed signals, resulting in suboptimal accuracy. To this end, we propose\na personalized graph signal processing (PGSP) method for collaborative\nfiltering. Firstly, we design the personalized graph signal containing richer\nuser information and construct an augmented similarity graph containing more\ngraph topology information, to more effectively characterize user interests.\nSecondly, we devise a mixed-frequency graph filter to introduce useful\ninformation in the high-frequency components of the observed signals by\ncombining an ideal low-pass filter that smooths signals globally and a linear\nlow-pass filter that smooths signals locally. Finally, we combine the\npersonalized graph signal, the augmented similarity graph and the\nmixed-frequency graph filter by proposing a pipeline consisting of three key\nsteps: pre-processing, graph convolution and post-processing. Extensive\nexperiments show that PGSP can achieve superior accuracy compared with\nstate-of-the-art CF methods and, as a nonparametric method, PGSP has very high\ntraining efficiency.\n","authors":["Jiahao Liu","Dongsheng Li","Hansu Gu","Tun Lu","Peng Zhang","Li Shang","Ning Gu"],"pdf_url":"https://arxiv.org/pdf/2302.02113v1.pdf","comment":"Accepted by WWW 2023, 9 pages"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.02176v1","updated":"2023-02-04T15:02:23Z","published":"2023-02-04T15:02:23Z","title":"An analysis of the technology acceptance model in understanding\n  university students behavioral intention to use metaverse technologies","summary":"  Metaverse can be applied in several aspects of life such as the Economy,\nfinance, social life, working environment, healthcare, real estate, and\neducation. In the last 2 and a half years, during the COVID-19 pandemic,\nuniversities made immediate use of learning technologies, providing students\nwith access to online learning content and platforms. Previous considerations\non how to better integrate technology into universities or how the institutions\ncan be better prepared in terms of infrastructure vanished almost immediately\ndue to the necessity of immediate actions towards the need for social distance\nand global health. The present study proposes a framework for university\nstudents metaverse technologies in education acceptance and intention to use.\nThe present study develops a structural model of MetaEducation acceptance. This\nmodel will be useful to university managers, policymakers, and professors to\nbetter incorporate the upcoming metaverse technology. The present study tests\n(if supported) the correlations among the aforementioned constructs.\nPreliminary results show hesitance to use MetaEducation technologies from\nuniversity students. Self-efficacy and Subjective Norms affect Attitude and\nPerceived Usefulness positively, but on the other side, there is no strong\ncorrelation between Perceived Ease of Use and Attitude or Perceived Usefulness\nand Attitude. Authors believe that the weak ties among the study constructs\nhave to do with the lack of knowledge of what really MetaEducation really is,\nand which are its advantages of use.\n","authors":["Nikolaos Misirlis","Harris Bin Munawar"],"pdf_url":"https://arxiv.org/pdf/2302.02176v1.pdf","comment":"4 pages, 3 figures, conference article"},{"id":"http://arxiv.org/abs/2204.09924v2","updated":"2023-02-04T13:45:13Z","published":"2022-04-21T07:24:14Z","title":"Progressive Training of A Two-Stage Framework for Video Restoration","summary":"  As a widely studied task, video restoration aims to enhance the quality of\nthe videos with multiple potential degradations, such as noises, blurs and\ncompression artifacts. Among video restorations, compressed video quality\nenhancement and video super-resolution are two of the main tacks with\nsignificant values in practical scenarios. Recently, recurrent neural networks\nand transformers attract increasing research interests in this field, due to\ntheir impressive capability in sequence-to-sequence modeling. However, the\ntraining of these models is not only costly but also relatively hard to\nconverge, with gradient exploding and vanishing problems. To cope with these\nproblems, we proposed a two-stage framework including a multi-frame recurrent\nnetwork and a single-frame transformer. Besides, multiple training strategies,\nsuch as transfer learning and progressive training, are developed to shorten\nthe training time and improve the model performance. Benefiting from the above\ntechnical contributions, our solution wins two champions and a runner-up in the\nNTIRE 2022 super-resolution and quality enhancement of compressed video\nchallenges. Code is available at\nhttps://github.com/ryanxingql/winner-ntire22-vqe.\n","authors":["Meisong Zheng","Qunliang Xing","Minglang Qiao","Mai Xu","Lai Jiang","Huaida Liu","Ying Chen"],"pdf_url":"https://arxiv.org/pdf/2204.09924v2.pdf","comment":"Winning two championships and one runner-up in the NTIRE 2022\n  challenge on super-resolution and quality enhancement of compressed video;\n  Accepted to CVPRW 2022"},{"id":"http://arxiv.org/abs/2302.02141v1","updated":"2023-02-04T10:22:18Z","published":"2023-02-04T10:22:18Z","title":"LipFormer: Learning to Lipread Unseen Speakers based on Visual-Landmark\n  Transformers","summary":"  Lipreading refers to understanding and further translating the speech of a\nspeaker in the video into natural language. State-of-the-art lipreading methods\nexcel in interpreting overlap speakers, i.e., speakers appear in both training\nand inference sets. However, generalizing these methods to unseen speakers\nincurs catastrophic performance degradation due to the limited number of\nspeakers in training bank and the evident visual variations caused by the\nshape/color of lips for different speakers. Therefore, merely depending on the\nvisible changes of lips tends to cause model overfitting. To address this\nproblem, we propose to use multi-modal features across visual and landmarks,\nwhich can describe the lip motion irrespective to the speaker identities. Then,\nwe develop a sentence-level lipreading framework based on visual-landmark\ntransformers, namely LipFormer. Specifically, LipFormer consists of a lip\nmotion stream, a facial landmark stream, and a cross-modal fusion. The\nembeddings from the two streams are produced by self-attention, which are fed\nto the cross-attention module to achieve the alignment between visuals and\nlandmarks. Finally, the resulting fused features can be decoded to output texts\nby a cascade seq2seq model. Experiments demonstrate that our method can\neffectively enhance the model generalization to unseen speakers.\n","authors":["Feng Xue","Yu Li","Deyin Liu","Yincen Xie","Lin Wu","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2302.02141v1.pdf","comment":"Under review"}]},"2023-02-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.03675v1","updated":"2023-02-07T18:52:22Z","published":"2023-02-07T18:52:22Z","title":"Auditing Gender Presentation Differences in Text-to-Image Models","summary":"  Text-to-image models, which can generate high-quality images based on textual\ninput, have recently enabled various content-creation tools. Despite\nsignificantly affecting a wide range of downstream applications, the\ndistributions of these generated images are still not fully understood,\nespecially when it comes to the potential stereotypical attributes of different\ngenders. In this work, we propose a paradigm (Gender Presentation Differences)\nthat utilizes fine-grained self-presentation attributes to study how gender is\npresented differently in text-to-image models. By probing gender indicators in\nthe input text (e.g., \"a woman\" or \"a man\"), we quantify the frequency\ndifferences of presentation-centric attributes (e.g., \"a shirt\" and \"a dress\")\nthrough human annotation and introduce a novel metric: GEP. Furthermore, we\npropose an automatic method to estimate such differences. The automatic GEP\nmetric based on our approach yields a higher correlation with human annotations\nthan that based on existing CLIP scores, consistently across three\nstate-of-the-art text-to-image models. Finally, we demonstrate the\ngeneralization ability of our metrics in the context of gender stereotypes\nrelated to occupations.\n","authors":["Yanzhe Zhang","Lu Jiang","Greg Turk","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2302.03675v1.pdf","comment":"Preprint, 23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2302.03668v1","updated":"2023-02-07T18:40:18Z","published":"2023-02-07T18:40:18Z","title":"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt\n  Tuning and Discovery","summary":"  The strength of modern generative models lies in their ability to be\ncontrolled through text-based prompts. Typical \"hard\" prompts are made from\ninterpretable words and tokens, and must be hand-crafted by humans. There are\nalso \"soft\" prompts, which consist of continuous feature vectors. These can be\ndiscovered using powerful optimization methods, but they cannot be easily\ninterpreted, re-used across models, or plugged into a text-based interface.\n  We describe an approach to robustly optimize hard text prompts through\nefficient gradient-based optimization. Our approach automatically generates\nhard text-based prompts for both text-to-image and text-to-text applications.\nIn the text-to-image setting, the method creates hard prompts for diffusion\nmodels, allowing API users to easily generate, discover, and mix and match\nimage concepts without prior knowledge on how to prompt the model. In the\ntext-to-text setting, we show that hard prompts can be automatically discovered\nthat are effective in tuning LMs for classification.\n","authors":["Yuxin Wen","Neel Jain","John Kirchenbauer","Micah Goldblum","Jonas Geiping","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2302.03668v1.pdf","comment":"14 pages, 10 figures, Code is available at\n  \\url{https://github.com/YuxinWenRick/hard-prompts-made-easy}"},{"id":"http://arxiv.org/abs/2302.03645v1","updated":"2023-02-07T17:52:33Z","published":"2023-02-07T17:52:33Z","title":"Exploitation and exploration in text evolution. Quantifying planning and\n  translation flows during writing","summary":"  Writing is a complex process at the center of much of modern human activity.\nDespite it appears to be a linear process, writing conceals many highly\nnon-linear processes. Previous research has focused on three phases of writing:\nplanning, translation and transcription, and revision. While research has shown\nthese are non-linear, they are often treated linearly when measured. Here, we\nintroduce measures to detect and quantify subcycles of planning (exploration)\nand translation (exploitation) during the writing process. We apply these to a\nnovel dataset that recorded the creation of a text in all its phases, from\nearly attempts to the finishing touches on a final version. This dataset comes\nfrom a series of writing workshops in which, through innovative versioning\nsoftware, we were able to record all the steps in the construction of a text.\nMore than 60 junior researchers in science wrote a scientific essay intended\nfor a general readership. We recorded each essay as a writing cloud, defined as\na complex topological structure capturing the history of the essay itself.\nThrough this unique dataset of writing clouds, we expose a representation of\nthe writing process that quantifies its complexity and the writer's efforts\nthroughout the draft and through time. Interestingly, this representation\nhighlights the phases of \"translation flow\", where authors improve existing\nideas, and exploration, where creative deviations appear as the writer returns\nto the planning phase. These turning points between translation and exploration\nbecome rarer as the writing process progresses and the author approaches the\nfinal version. Our results and the new measures introduced have the potential\nto foster the discussion about the non-linear nature of writing and support the\ndevelopment of tools that can support more creative and impactful writing\nprocesses.\n","authors":["Donald Ruggiero Lo Sardo","Pietro Gravino","Christine Cuskley","Vittorio Loreto"],"pdf_url":"https://arxiv.org/pdf/2302.03645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03589v1","updated":"2023-02-07T16:56:48Z","published":"2023-02-07T16:56:48Z","title":"CALaMo: a Constructionist Assessment of Language Models","summary":"  This paper presents a novel framework for evaluating Neural Language Models'\nlinguistic abilities using a constructionist approach. Not only is the\nusage-based model in line with the underlying stochastic philosophy of neural\narchitectures, but it also allows the linguist to keep meaning as a determinant\nfactor in the analysis. We outline the framework and present two possible\nscenarios for its application.\n","authors":["Ludovica Pannitto","Aurélie Herbelot"],"pdf_url":"https://arxiv.org/pdf/2302.03589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03528v1","updated":"2023-02-07T15:20:13Z","published":"2023-02-07T15:20:13Z","title":"Efficiently Upgrading Multilingual Machine Translation Models to Support\n  More Languages","summary":"  With multilingual machine translation (MMT) models continuing to grow in size\nand number of supported languages, it is natural to reuse and upgrade existing\nmodels to save computation as data becomes available in more languages.\nHowever, adding new languages requires updating the vocabulary, which\ncomplicates the reuse of embeddings. The question of how to reuse existing\nmodels while also making architectural changes to provide capacity for both old\nand new languages has also not been closely studied. In this work, we introduce\nthree techniques that help speed up effective learning of the new languages and\nalleviate catastrophic forgetting despite vocabulary and architecture\nmismatches. Our results show that by (1) carefully initializing the network,\n(2) applying learning rate scaling, and (3) performing data up-sampling, it is\npossible to exceed the performance of a same-sized baseline model with 30%\ncomputation and recover the performance of a larger model trained from scratch\nwith over 50% reduction in computation. Furthermore, our analysis reveals that\nthe introduced techniques help learn the new directions more effectively and\nalleviate catastrophic forgetting at the same time. We hope our work will guide\nresearch into more efficient approaches to growing languages for these MMT\nmodels and ultimately maximize the reuse of existing models.\n","authors":["Simeng Sun","Maha Elbayad","Anna Sun","James Cross"],"pdf_url":"https://arxiv.org/pdf/2302.03528v1.pdf","comment":"Accepted to EACL 2023 (Main)"},{"id":"http://arxiv.org/abs/2210.00660v3","updated":"2023-02-07T15:02:14Z","published":"2022-10-03T00:28:44Z","title":"A Non-monotonic Self-terminating Language Model","summary":"  Recent large-scale neural autoregressive sequence models have shown\nimpressive performances on a variety of natural language generation tasks.\nHowever, their generated sequences often exhibit degenerate properties such as\nnon-termination, undesirable repetition, and premature termination, when\ngenerated with decoding algorithms such as greedy search, beam search, top-$k$\nsampling, and nucleus sampling. In this paper, we focus on the problem of\nnon-terminating sequences resulting from an incomplete decoding algorithm. We\nfirst define an incomplete probable decoding algorithm which includes greedy\nsearch, top-$k$ sampling, and nucleus sampling, beyond the incomplete decoding\nalgorithm originally put forward by Welleck et al. (2020). We then propose a\nnon-monotonic self-terminating language model, which significantly relaxes the\nconstraint of monotonically increasing termination probability in the\noriginally proposed self-terminating language model by Welleck et al. (2020),\nto address the issue of non-terminating sequences when using incomplete\nprobable decoding algorithms. We prove that our proposed model prevents\nnon-terminating sequences when using not only incomplete probable decoding\nalgorithms but also beam search. We empirically validate our model on sequence\ncompletion tasks with various architectures.\n","authors":["Eugene Choi","Kyunghyun Cho","Cheolhyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2210.00660v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03512v1","updated":"2023-02-07T14:56:52Z","published":"2023-02-07T14:56:52Z","title":"A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and\n  Future Trends","summary":"  As more and more Arabic texts emerged on the Internet, extracting important\ninformation from these Arabic texts is especially useful. As a fundamental\ntechnology, Named entity recognition (NER) serves as the core component in\ninformation extraction technology, while also playing a critical role in many\nother Natural Language Processing (NLP) systems, such as question answering and\nknowledge graph building. In this paper, we provide a comprehensive review of\nthe development of Arabic NER, especially the recent advances in deep learning\nand pre-trained language model. Specifically, we first introduce the background\nof Arabic NER, including the characteristics of Arabic and existing resources\nfor Arabic NER. Then, we systematically review the development of Arabic NER\nmethods. Traditional Arabic NER systems focus on feature engineering and\ndesigning domain-specific rules. In recent years, deep learning methods achieve\nsignificant progress by representing texts via continuous vector\nrepresentations. With the growth of pre-trained language model, Arabic NER\nyields better performance. Finally, we conclude the method gap between Arabic\nNER and NER methods from other languages, which helps outline future directions\nfor Arabic NER.\n","authors":["Xiaoye Qu","Yingjie Gu","Qingrong Xia","Zechang Li","Zhefeng Wang","Baoxing Huai"],"pdf_url":"https://arxiv.org/pdf/2302.03512v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2210.09263 by other authors"},{"id":"http://arxiv.org/abs/2302.03508v1","updated":"2023-02-07T14:49:20Z","published":"2023-02-07T14:49:20Z","title":"Cluster-Level Contrastive Learning for Emotion Recognition in\n  Conversations","summary":"  A key challenge for Emotion Recognition in Conversations (ERC) is to\ndistinguish semantically similar emotions. Some works utilise Supervised\nContrastive Learning (SCL) which uses categorical emotion labels as supervision\nsignals and contrasts in high-dimensional semantic space. However, categorical\nlabels fail to provide quantitative information between emotions. ERC is also\nnot equally dependent on all embedded features in the semantic space, which\nmakes the high-dimensional SCL inefficient. To address these issues, we propose\na novel low-dimensional Supervised Cluster-level Contrastive Learning (SCCL)\nmethod, which first reduces the high-dimensional SCL space to a\nthree-dimensional affect representation space Valence-Arousal-Dominance (VAD),\nthen performs cluster-level contrastive learning to incorporate measurable\nemotion prototypes. To help modelling the dialogue and enriching the context,\nwe leverage the pre-trained knowledge adapters to infuse linguistic and factual\nknowledge. Experiments show that our method achieves new state-of-the-art\nresults with 69.81% on IEMOCAP, 65.7% on MELD, and 62.51% on DailyDialog\ndatasets. The analysis also proves that the VAD space is not only suitable for\nERC but also interpretable, with VAD prototypes enhancing its performance and\nstabilising the training of SCCL. In addition, the pre-trained knowledge\nadapters benefit the performance of the utterance encoder and SCCL. Our code is\navailable at: https://github.com/SteveKGYang/SCCL\n","authors":["Kailai Yang","Tianlin Zhang","Hassan Alhuzali","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2302.03508v1.pdf","comment":"Accepted by IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2302.03491v1","updated":"2023-02-07T14:35:35Z","published":"2023-02-07T14:35:35Z","title":"Learning Translation Quality Evaluation on Low Resource Languages from\n  Large Language Models","summary":"  Learned metrics such as BLEURT have in recent years become widely employed to\nevaluate the quality of machine translation systems. Training such metrics\nrequires data which can be expensive and difficult to acquire, particularly for\nlower-resource languages. We show how knowledge can be distilled from Large\nLanguage Models (LLMs) to improve upon such learned metrics without requiring\nhuman annotators, by creating synthetic datasets which can be mixed into\nexisting datasets, requiring only a corpus of text in the target language. We\nshow that the performance of a BLEURT-like model on lower resource languages\ncan be improved in this way.\n","authors":["Amirkeivan Mohtashami","Mauro Verzetti","Paul K. Rubenstein"],"pdf_url":"https://arxiv.org/pdf/2302.03491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03490v1","updated":"2023-02-07T14:34:39Z","published":"2023-02-07T14:34:39Z","title":"Natural Language Processing for Policymaking","summary":"  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n","authors":["Zhijing Jin","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2302.03490v1.pdf","comment":"Handbook of Computational Social Science for Policy (2023), Chapter 7\n  (pages 141-162). Open Access on Springer:\n  https://doi.org/10.1007/978-3-031-16624-2"},{"id":"http://arxiv.org/abs/2301.12866v2","updated":"2023-02-07T14:15:26Z","published":"2023-01-30T13:19:19Z","title":"N-Gram Nearest Neighbor Machine Translation","summary":"  Nearest neighbor machine translation augments the Autoregressive\nTranslation~(AT) with $k$-nearest-neighbor retrieval, by comparing the\nsimilarity between the token-level context representations of the target tokens\nin the query and the datastore. However, the token-level representation may\nintroduce noise when translating ambiguous words, or fail to provide accurate\nretrieval results when the representation generated by the model contains\nindistinguishable context information, e.g., Non-Autoregressive\nTranslation~(NAT) models. In this paper, we propose a novel $n$-gram nearest\nneighbor retrieval method that is model agnostic and applicable to both AT and\nNAT models. Specifically, we concatenate the adjacent $n$-gram hidden\nrepresentations as the key, while the tuple of corresponding target tokens is\nthe value. In inference, we propose tailored decoding algorithms for AT and NAT\nmodels respectively. We demonstrate that the proposed method consistently\noutperforms the token-level method on both AT and NAT models as well on general\nas on domain adaptation translation tasks. On domain adaptation, the proposed\nmethod brings $1.03$ and $2.76$ improvements regarding the average BLEU score\non AT and NAT models respectively.\n","authors":["Rui Lv","Junliang Guo","Rui Wang","Xu Tan","Qi Liu","Tao Qin"],"pdf_url":"https://arxiv.org/pdf/2301.12866v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03475v1","updated":"2023-02-07T14:00:40Z","published":"2023-02-07T14:00:40Z","title":"Entity-Aware Dual Co-Attention Network for Fake News Detection","summary":"  Fake news and misinformation spread rapidly on the Internet. How to identify\nit and how to interpret the identification results have become important\nissues. In this paper, we propose a Dual Co-Attention Network (Dual-CAN) for\nfake news detection, which takes news content, social media replies, and\nexternal knowledge into consideration. Our experimental results support that\nthe proposed Dual-CAN outperforms current representative models in two\nbenchmark datasets. We further make in-depth discussions by comparing how\nmodels work in both datasets with empirical analysis of attention weights.\n","authors":["Sin-Han Yang","Chung-Chi Chen","Hen-Hsen Huang","Hsin-Hsi Chen"],"pdf_url":"https://arxiv.org/pdf/2302.03475v1.pdf","comment":"EACL 2023 Findings"},{"id":"http://arxiv.org/abs/2211.00250v3","updated":"2023-02-07T13:37:19Z","published":"2022-11-01T03:37:30Z","title":"FADO: Feedback-Aware Double COntrolling Network for Emotional Support\n  Conversation","summary":"  Emotional Support Conversation (ESConv) aims to reduce help-seekers'emotional\ndistress with the supportive strategy and response. It is essential for the\nsupporter to select an appropriate strategy with the feedback of the\nhelp-seeker (e.g., emotion change during dialog turns, etc) in ESConv. However,\nprevious methods mainly focus on the dialog history to select the strategy and\nignore the help-seeker's feedback, leading to the wrong and user-irrelevant\nstrategy prediction. In addition, these approaches only model the\ncontext-to-strategy flow and pay less attention to the strategy-to-context flow\nthat can focus on the strategy-related context for generating the\nstrategy-constrain response. In this paper, we propose a Feedback-Aware Double\nCOntrolling Network (FADO) to make a strategy schedule and generate the\nsupportive response. The core module in FADO consists of a dual-level feedback\nstrategy selector and a double control reader. Specifically, the dual-level\nfeedback strategy selector leverages the turn-level and conversation-level\nfeedback to encourage or penalize strategies. The double control reader\nconstructs the novel strategy-to-context flow for generating the\nstrategy-constrain response. Furthermore, a strategy dictionary is designed to\nenrich the semantic information of the strategy and improve the quality of\nstrategy-constrain response. Experimental results on ESConv show that the\nproposed FADO has achieved the state-of-the-art performance in terms of both\nstrategy selection and response generation. Our code is available at\nhttps://github.com/Thedatababbler/FADO.\n","authors":["Wei Peng","Ziyuan Qin","Yue Hu","Yuqiang Xie","Yunpeng Li"],"pdf_url":"https://arxiv.org/pdf/2211.00250v3.pdf","comment":"Accepted on Knowl. Based Syst. (SCI I)"},{"id":"http://arxiv.org/abs/2203.03047v2","updated":"2023-02-07T10:52:04Z","published":"2022-03-06T20:47:49Z","title":"Recent Advances in Neural Text Generation: A Task-Agnostic Survey","summary":"  In recent years much effort has been devoted to applying neural models to the\ntask of natural language generation. The challenge is to generate natural\nhuman-like text, and to control the generation process. This paper presents a\ntask-agnostic survey of recent advances in neural text generation. These\nadvances have been achieved by numerous developments, which we group under the\nfollowing four headings: data construction, neural frameworks, training and\ninference strategies, and evaluation metrics. Finally we discuss the future\ndirections for the development of neural text generation including neural\npipelines and exploiting back-ground knowledge.\n","authors":["Chen Tang","Frank Guerin","Yucheng Li","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2203.03047v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03353v1","updated":"2023-02-07T09:55:07Z","published":"2023-02-07T09:55:07Z","title":"What do Language Models know about word senses? Zero-Shot WSD with\n  Language Models and Domain Inventories","summary":"  Language Models are the core for almost any Natural Language Processing\nsystem nowadays. One of their particularities is their contextualized\nrepresentations, a game changer feature when a disambiguation between word\nsenses is necessary. In this paper we aim to explore to what extent language\nmodels are capable of discerning among senses at inference time. We performed\nthis analysis by prompting commonly used Languages Models such as BERT or\nRoBERTa to perform the task of Word Sense Disambiguation (WSD). We leverage the\nrelation between word senses and domains, and cast WSD as a textual entailment\nproblem, where the different hypothesis refer to the domains of the word\nsenses. Our results show that this approach is indeed effective, close to\nsupervised systems.\n","authors":["Oscar Sainz","Oier Lopez de Lacalle","Eneko Agirre","German Rigau"],"pdf_url":"https://arxiv.org/pdf/2302.03353v1.pdf","comment":"Presented at GWC2023"},{"id":"http://arxiv.org/abs/2302.03341v1","updated":"2023-02-07T09:34:41Z","published":"2023-02-07T09:34:41Z","title":"The Effect of Metadata on Scientific Literature Tagging: A Cross-Field\n  Cross-Model Study","summary":"  Due to the exponential growth of scientific publications on the Web, there is\na pressing need to tag each paper with fine-grained topics so that researchers\ncan track their interested fields of study rather than drowning in the whole\nliterature. Scientific literature tagging is beyond a pure multi-label text\nclassification task because papers on the Web are prevalently accompanied by\nmetadata information such as venues, authors, and references, which may serve\nas additional signals to infer relevant tags. Although there have been studies\nmaking use of metadata in academic paper classification, their focus is often\nrestricted to one or two scientific fields (e.g., computer science and\nbiomedicine) and to one specific model. In this work, we systematically study\nthe effect of metadata on scientific literature tagging across 19 fields. We\nselect three representative multi-label classifiers (i.e., a bag-of-words\nmodel, a sequence-based model, and a pre-trained language model) and explore\ntheir performance change in scientific literature tagging when metadata are fed\nto the classifiers as additional features. We observe some ubiquitous patterns\nof metadata's effects across all fields (e.g., venues are consistently\nbeneficial to paper tagging in almost all cases), as well as some unique\npatterns in fields other than computer science and biomedicine, which are not\nexplored in previous studies.\n","authors":["Yu Zhang","Bowen Jin","Qi Zhu","Yu Meng","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2302.03341v1.pdf","comment":"11 pages; Accepted to WWW 2023"},{"id":"http://arxiv.org/abs/2302.03338v1","updated":"2023-02-07T09:25:58Z","published":"2023-02-07T09:25:58Z","title":"Learning Manner of Execution from Partial Corrections","summary":"  Some actions must be executed in different ways depending on the context. For\nexample, wiping away marker requires vigorous force while wiping away almonds\nrequires more gentle force. In this paper we provide a model where an agent\nlearns which manner of action execution to use in which context, drawing on\nevidence from trial and error and verbal corrections when it makes a mistake\n(e.g., ``no, gently''). The learner starts out with a domain model that lacks\nthe concepts denoted by the words in the teacher's feedback; both the words\ndescribing the context (e.g., marker) and the adverbs like ``gently''. We show\nthat through the the semantics of coherence, our agent can perform the symbol\ngrounding that's necessary for exploiting the teacher's feedback so as to solve\nits domain-level planning problem: to perform its actions in the current\ncontext in the right way.\n","authors":["Mattias Appelgren","Alex Lascarides"],"pdf_url":"https://arxiv.org/pdf/2302.03338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07054v2","updated":"2023-02-07T09:19:20Z","published":"2022-10-13T14:25:08Z","title":"Scaling Back-Translation with Domain Text Generation for Sign Language\n  Gloss Translation","summary":"  Sign language gloss translation aims to translate the sign glosses into\nspoken language texts, which is challenging due to the scarcity of labeled\ngloss-text parallel data. Back translation (BT), which generates\npseudo-parallel data by translating in-domain spoken language texts into sign\nglosses, has been applied to alleviate the data scarcity problem. However, the\nlack of large-scale high-quality domain spoken language text data limits the\neffect of BT. In this paper, to overcome the limitation, we propose a Prompt\nbased domain text Generation (PGEN) approach to produce the large-scale\nin-domain spoken language text data. Specifically, PGEN randomly concatenates\nsentences from the original in-domain spoken language text data as prompts to\ninduce a pre-trained language model (i.e., GPT-2) to generate spoken language\ntexts in a similar style. Experimental results on three benchmarks of sign\nlanguage gloss translation in varied languages demonstrate that BT with spoken\nlanguage texts generated by PGEN significantly outperforms the compared\nmethods. In addition, as the scale of spoken language texts generated by PGEN\nincreases, the BT technique can achieve further improvements, demonstrating the\neffectiveness of our approach. We release the code and data for facilitating\nfuture research in this field.\n","authors":["Jinhui Ye","Wenxiang Jiao","Xing Wang","Zhaopeng Tu"],"pdf_url":"https://arxiv.org/pdf/2210.07054v2.pdf","comment":"Accepted at EACL 2023 (main conference)"},{"id":"http://arxiv.org/abs/2302.02568v2","updated":"2023-02-07T08:12:45Z","published":"2023-02-06T05:11:27Z","title":"Less is More: Understanding Word-level Textual Adversarial Attack via\n  n-gram Frequency Descend","summary":"  Word-level textual adversarial attacks have achieved striking performance in\nfooling natural language processing models. However, the fundamental questions\nof why these attacks are effective, and the intrinsic properties of the\nadversarial examples (AEs), are still not well understood. This work attempts\nto interpret textual attacks through the lens of $n$-gram frequency.\nSpecifically, it is revealed that existing word-level attacks exhibit a strong\ntendency toward generation of examples with $n$-gram frequency descend\n($n$-FD). Intuitively, this finding suggests a natural way to improve model\nrobustness by training the model on the $n$-FD examples. To verify this idea,\nwe devise a model-agnostic and gradient-free AE generation approach that relies\nsolely on the $n$-gram frequency information, and further integrate it into the\nrecently proposed convex hull framework for adversarial training. Surprisingly,\nthe resultant method performs quite similarly to the original gradient-based\nmethod in terms of model robustness. These findings provide a\nhuman-understandable perspective for interpreting word-level textual\nadversarial attacks, and a new direction to improve model robustness.\n","authors":["Ning Lu","Shengcai Liu","Zhirui Zhang","Qi Wang","Haifeng Liu","Ke Tang"],"pdf_url":"https://arxiv.org/pdf/2302.02568v2.pdf","comment":"8 pages, 4 figures. In progress"},{"id":"http://arxiv.org/abs/2301.05380v2","updated":"2023-02-07T08:10:07Z","published":"2023-01-13T03:33:26Z","title":"Prompting Neural Machine Translation with Translation Memories","summary":"  Improving machine translation (MT) systems with translation memories (TMs) is\nof great interest to practitioners in the MT community. However, previous\napproaches require either a significant update of the model architecture and/or\nadditional training efforts to make the models well-behaved when TMs are taken\nas additional input. In this paper, we present a simple but effective method to\nintroduce TMs into neural machine translation (NMT) systems. Specifically, we\ntreat TMs as prompts to the NMT model at test time, but leave the training\nprocess unchanged. The result is a slight update of an existing NMT system,\nwhich can be implemented in a few hours by anyone who is familiar with NMT.\nExperimental results on several datasets demonstrate that our system\nsignificantly outperforms strong baselines.\n","authors":["Abudurexiti Reheman","Tao Zhou","Yingfeng Luo","Di Yang","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.05380v2.pdf","comment":"Accepted to AAAI 2023"},{"id":"http://arxiv.org/abs/2106.11483v8","updated":"2023-02-07T07:52:16Z","published":"2021-06-22T02:12:29Z","title":"A Comprehensive Comparison of Pre-training Language Models","summary":"  Recently, the development of pre-trained language models has brought natural\nlanguage processing (NLP) tasks to the new state-of-the-art. In this paper we\nexplore the efficiency of various pre-trained language models. We pre-train a\nlist of transformer-based models with the same amount of text and the same\ntraining steps. The experimental results shows that the most improvement upon\nthe origin BERT is adding the RNN-layer to capture more contextual information\nfor short text understanding. But the conclusion is: There are no remarkable\nimprovement for short text understanding for similar BERT structures.\nData-centric method[12] can achieve better performance.\n","authors":["Tong Guo"],"pdf_url":"https://arxiv.org/pdf/2106.11483v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03297v1","updated":"2023-02-07T07:12:05Z","published":"2023-02-07T07:12:05Z","title":"AutoWS: Automated Weak Supervision Framework for Text Classification","summary":"  Creating large, good quality labeled data has become one of the major\nbottlenecks for developing machine learning applications. Multiple techniques\nhave been developed to either decrease the dependence of labeled data\n(zero/few-shot learning, weak supervision) or to improve the efficiency of\nlabeling process (active learning). Among those, Weak Supervision has been\nshown to reduce labeling costs by employing hand crafted labeling functions\ndesigned by domain experts. We propose AutoWS -- a novel framework for\nincreasing the efficiency of weak supervision process while decreasing the\ndependency on domain experts. Our method requires a small set of labeled\nexamples per label class and automatically creates a set of labeling functions\nto assign noisy labels to numerous unlabeled data. Noisy labels can then be\naggregated into probabilistic labels used by a downstream discriminative\nclassifier. Our framework is fully automatic and requires no hyper-parameter\nspecification by users. We compare our approach with different state-of-the-art\nwork on weak supervision and noisy training. Experimental results show that our\nmethod outperforms competitive baselines.\n","authors":["Abhinav Bohra","Huy Nguyen","Devashish Khatwani"],"pdf_url":"https://arxiv.org/pdf/2302.03297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03269v1","updated":"2023-02-07T05:48:16Z","published":"2023-02-07T05:48:16Z","title":"PLACES: Prompting Language Models for Social Conversation Synthesis","summary":"  Collecting high quality conversational data can be very expensive for most\napplications and infeasible for others due to privacy, ethical, or similar\nconcerns. A promising direction to tackle this problem is to generate synthetic\ndialogues by prompting large language models. In this work, we use a small set\nof expert-written conversations as in-context examples to synthesize a social\nconversation dataset using prompting. We perform several thorough evaluations\nof our synthetic conversations compared to human-collected conversations. This\nincludes various dimensions of conversation quality with human evaluation\ndirectly on the synthesized conversations, and interactive human evaluation of\nchatbots fine-tuned on the synthetically generated dataset. We additionally\ndemonstrate that this prompting approach is generalizable to multi-party\nconversations, providing potential to create new synthetic data for multi-party\ntasks. Our synthetic multi-party conversations were rated more favorably across\nall measured dimensions compared to conversation excerpts sampled from a\nhuman-collected multi-party dataset.\n","authors":["Maximillian Chen","Alexandros Papangelis","Chenyang Tao","Seokhwan Kim","Andy Rosenbaum","Yang Liu","Zhou Yu","Dilek Hakkani-Tur"],"pdf_url":"https://arxiv.org/pdf/2302.03269v1.pdf","comment":"In EACL 2023. 25 pages, 4 figures, 26 tables. Link to code\n  forthcoming"},{"id":"http://arxiv.org/abs/2205.00415v2","updated":"2023-02-07T03:58:25Z","published":"2022-05-01T07:51:22Z","title":"Don't Blame the Annotator: Bias Already Starts in the Annotation\n  Instructions","summary":"  In recent years, progress in NLU has been driven by benchmarks. These\nbenchmarks are typically collected by crowdsourcing, where annotators write\nexamples based on annotation instructions crafted by dataset creators. In this\nwork, we hypothesize that annotators pick up on patterns in the crowdsourcing\ninstructions, which bias them to write many similar examples that are then\nover-represented in the collected data. We study this form of bias, termed\ninstruction bias, in 14 recent NLU benchmarks, showing that instruction\nexamples often exhibit concrete patterns, which are propagated by crowdworkers\nto the collected data. This extends previous work (Geva et al., 2019) and\nraises a new concern of whether we are modeling the dataset creator's\ninstructions, rather than the task. Through a series of experiments, we show\nthat, indeed, instruction bias can lead to overestimation of model performance,\nand that models struggle to generalize beyond biases originating in the\ncrowdsourcing instructions. We further analyze the influence of instruction\nbias in terms of pattern frequency and model size, and derive concrete\nrecommendations for creating future NLU benchmarks.\n","authors":["Mihir Parmar","Swaroop Mishra","Mor Geva","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2205.00415v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.03241v1","updated":"2023-02-07T03:57:55Z","published":"2023-02-07T03:57:55Z","title":"Continual Learning of Language Models","summary":"  Language models (LMs) have been instrumental for the rapid advance of natural\nlanguage processing. This paper studies continual learning of LMs, in\nparticular, continual domain-adaptive pre-training (or continual DAP-training).\nExisting research has shown that further pre-training an LM using a domain\ncorpus to adapt the LM to the domain can improve the end-task performance in\nthe domain. This paper proposes a novel method to continually DAP-train an LM\nwith a sequence of unlabeled domain corpora to adapt the LM to these domains to\nimprove their end-task performances. The key novelty of our method is a\nsoft-masking mechanism that directly controls the update to the LM. A novel\nproxy is also proposed to preserve the general knowledge in the original LM.\nAdditionally, it contrasts the representations of the previously learned domain\nknowledge (including the general knowledge in the pre-trained LM) and the\nknowledge from the current full network to achieve knowledge integration. The\nmethod not only overcomes catastrophic forgetting, but also achieves knowledge\ntransfer to improve end-task performances. Empirical evaluation demonstrates\nthe effectiveness of the proposed method.\n","authors":["Zixuan Ke","Yijia Shao","Haowei Lin","Tatsuya Konishi","Gyuhak Kim","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03241v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2112.01922v4","updated":"2023-02-07T03:15:32Z","published":"2021-12-03T14:05:52Z","title":"MetaQA: Combining Expert Agents for Multi-Skill Question Answering","summary":"  The recent explosion of question answering (QA) datasets and models has\nincreased the interest in the generalization of models across multiple domains\nand formats by either training on multiple datasets or by combining multiple\nmodels. Despite the promising results of multi-dataset models, some domains or\nQA formats may require specific architectures, and thus the adaptability of\nthese models might be limited. In addition, current approaches for combining\nmodels disregard cues such as question-answer compatibility. In this work, we\npropose to combine expert agents with a novel, flexible, and training-efficient\narchitecture that considers questions, answer predictions, and\nanswer-prediction confidence scores to select the best answer among a list of\nanswer candidates. Through quantitative and qualitative experiments we show\nthat our model i) creates a collaboration between agents that outperforms\nprevious multi-agent and multi-dataset approaches in both in-domain and\nout-of-domain scenarios, ii) is highly data-efficient to train, and iii) can be\nadapted to any QA format. We release our code and a dataset of answer\npredictions from expert agents for 16 QA datasets to foster future developments\nof multi-agent systems on https://github.com/UKPLab/MetaQA.\n","authors":["Haritz Puerto","Gözde Gül Şahin","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2112.01922v4.pdf","comment":"Accepted at EACL 2023"},{"id":"http://arxiv.org/abs/2203.08388v2","updated":"2023-02-07T03:12:50Z","published":"2022-03-16T04:21:50Z","title":"MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages","summary":"  While there has been a recent burgeoning of applications at the intersection\nof natural and programming languages, such as code generation and code\nsummarization, these applications are usually English-centric. This creates a\nbarrier for program developers who are not proficient in English. To mitigate\nthis gap in technology development across languages, we propose a multilingual\ndataset, MCoNaLa, to benchmark code generation from natural language commands\nextending beyond English. Modeled off of the methodology from the English\nCode/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896\nNL-code pairs in three languages: Spanish, Japanese, and Russian. We present a\nquantitative evaluation of performance on the MCoNaLa dataset by testing with\nstate-of-the-art code generation systems. While the difficulties vary across\nthese three languages, all systems lag significantly behind their English\ncounterparts, revealing the challenges in adapting code generation to new\nlanguages.\n","authors":["Zhiruo Wang","Grace Cuenca","Shuyan Zhou","Frank F. Xu","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2203.08388v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03222v1","updated":"2023-02-07T03:11:06Z","published":"2023-02-07T03:11:06Z","title":"Bringing the State-of-the-Art to Customers: A Neural Agent Assistant\n  Framework for Customer Service Support","summary":"  Building Agent Assistants that can help improve customer service support\nrequires inputs from industry users and their customers, as well as knowledge\nabout state-of-the-art Natural Language Processing (NLP) technology. We combine\nexpertise from academia and industry to bridge the gap and build\ntask/domain-specific Neural Agent Assistants (NAA) with three high-level\ncomponents for: (1) Intent Identification, (2) Context Retrieval, and (3)\nResponse Generation. In this paper, we outline the pipeline of the NAA's core\nsystem and also present three case studies in which three industry partners\nsuccessfully adapt the framework to find solutions to their unique challenges.\nOur findings suggest that a collaborative process is instrumental in spurring\nthe development of emerging NLP models for Conversational AI tasks in industry.\nThe full reference implementation code and results are available at\n\\url{https://github.com/VectorInstitute/NAA}\n","authors":["Stephen Obadinma","Faiza Khan Khattak","Shirley Wang","Tania Sidhom","Elaine Lau","Sean Robertson","Jingcheng Niu","Winnie Au","Alif Munim","Karthik Raja K. Bhaskar","Bencheng Wei","Iris Ren","Waqar Muhammad","Erin Li","Bukola Ishola","Michael Wang","Griffin Tanner","Yu-Jia Shiah","Sean X. Zhang","Kwesi P. Apponsah","Kanishk Patel","Jaswinder Narain","Deval Pandya","Xiaodan Zhu","Frank Rudzicz","Elham Dolatabadi"],"pdf_url":"https://arxiv.org/pdf/2302.03222v1.pdf","comment":"Camera Ready Version of Paper Published in EMNLP 2022 Industry Track"},{"id":"http://arxiv.org/abs/2302.03205v1","updated":"2023-02-07T02:27:21Z","published":"2023-02-07T02:27:21Z","title":"An entity-guided text summarization framework with relational\n  heterogeneous graph neural network","summary":"  Two crucial issues for text summarization to generate faithful summaries are\nto make use of knowledge beyond text and to make use of cross-sentence\nrelations in text. Intuitive ways for the two issues are Knowledge Graph (KG)\nand Graph Neural Network (GNN) respectively. Entities are semantic units in\ntext and in KG. This paper focuses on both issues by leveraging entities\nmentioned in text to connect GNN and KG for summarization. Firstly, entities\nare leveraged to construct a sentence-entity graph with weighted multi-type\nedges to model sentence relations, and a relational heterogeneous GNN for\nsummarization is proposed to calculate node encodings. Secondly, entities are\nleveraged to link the graph to KG to collect knowledge. Thirdly, entities guide\na two-step summarization framework defining a multi-task selector to select\nsalient sentences and entities, and using an entity-focused abstractor to\ncompress the sentences. GNN is connected with KG by constructing\nsentence-entity graphs where entity-entity edges are built based on KG,\ninitializing entity embeddings on KG, and training entity embeddings using\nentity-entity edges. The relational heterogeneous GNN utilizes both edge\nweights and edge types in GNN to calculate graphs with weighted multi-type\nedges. Experiments show the proposed method outperforms extractive baselines\nincluding the HGNN-based HGNNSum and abstractive baselines including the\nentity-driven SENECA on CNN/DM, and outperforms most baselines on NYT50.\nExperiments on sub-datasets show the density of sentence-entity edges greatly\ninfluences the performance of the proposed method. The greater the density, the\nbetter the performance. Ablations show effectiveness of the method.\n","authors":["Jingqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2302.03205v1.pdf","comment":"7 tables, 5 figures"},{"id":"http://arxiv.org/abs/2302.03202v1","updated":"2023-02-07T02:24:30Z","published":"2023-02-07T02:24:30Z","title":"Exploring the Benefits of Training Expert Language Models over\n  Instruction Tuning","summary":"  Recently, Language Models (LMs) instruction-tuned on multiple tasks, also\nknown as multitask-prompted fine-tuning (MT), have shown the capability to\ngeneralize to unseen tasks. Previous work has shown that scaling the number of\ntraining tasks is the key component in making stronger MT LMs. In this work, we\nreport an unexpected finding that an expert LM fine-tuned on just a single task\ncan outperform an MT LM trained with 300+ different tasks on 11 different\nunseen datasets and on 13 datasets of the BIG-bench benchmark by a mean\naccuracy of 3.20% and 1.29%, respectively. This finding casts doubt on the\npreviously held belief that simply scaling the number of tasks makes stronger\nMT LMs. Leveraging this finding, we further show that this distributed approach\nof training a separate expert LM per training task instead of a single MT LM\nfor zero-shot inference possesses many benefits including (1) avoiding negative\ntask transfer that often occurs during instruction tuning, (2) being able to\ncontinually learn new tasks without having to re-train on previous tasks to\navoid catastrophic forgetting, and (3) showing compositional capabilities when\nmerging individual experts together. The code is available at\nhttps://github.com/joeljang/ELM.\n","authors":["Joel Jang","Seungone Kim","Seonghyeon Ye","Doyoung Kim","Lajanugen Logeswaran","Moontae Lee","Kyungjae Lee","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2302.03202v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08855v2","updated":"2023-02-07T02:05:39Z","published":"2023-01-21T02:20:43Z","title":"ProKD: An Unsupervised Prototypical Knowledge Distillation Network for\n  Zero-Resource Cross-Lingual Named Entity Recognition","summary":"  For named entity recognition (NER) in zero-resource languages, utilizing\nknowledge distillation methods to transfer language-independent knowledge from\nthe rich-resource source languages to zero-resource languages is an effective\nmeans. Typically, these approaches adopt a teacher-student architecture, where\nthe teacher network is trained in the source language, and the student network\nseeks to learn knowledge from the teacher network and is expected to perform\nwell in the target language. Despite the impressive performance achieved by\nthese methods, we argue that they have two limitations. Firstly, the teacher\nnetwork fails to effectively learn language-independent knowledge shared across\nlanguages due to the differences in the feature distribution between the source\nand target languages. Secondly, the student network acquires all of its\nknowledge from the teacher network and ignores the learning of target\nlanguage-specific knowledge. Undesirably, these limitations would hinder the\nmodel's performance in the target language. This paper proposes an unsupervised\nprototype knowledge distillation network (ProKD) to address these issues.\nSpecifically, ProKD presents a contrastive learning-based prototype alignment\nmethod to achieve class feature alignment by adjusting the distance among\nprototypes in the source and target languages, boosting the teacher network's\ncapacity to acquire language-independent knowledge. In addition, ProKD\nintroduces a prototypical self-training method to learn the intrinsic structure\nof the language by retraining the student network on the target data using\nsamples' distance information from prototypes, thereby enhancing the student\nnetwork's ability to acquire language-specific knowledge. Extensive experiments\non three benchmark cross-lingual NER datasets demonstrate the effectiveness of\nour approach.\n","authors":["Ling Ge","Chunming Hu","Guanghui Ma","Hong Zhang","Jihong Liu"],"pdf_url":"https://arxiv.org/pdf/2301.08855v2.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2302.03194v1","updated":"2023-02-07T02:04:17Z","published":"2023-02-07T02:04:17Z","title":"UDApter -- Efficient Domain Adaptation Using Adapters","summary":"  We propose two methods to make unsupervised domain adaptation (UDA) more\nparameter efficient using adapters, small bottleneck layers interspersed with\nevery layer of the large-scale pre-trained language model (PLM). The first\nmethod deconstructs UDA into a two-step process: first by adding a domain\nadapter to learn domain-invariant information and then by adding a task adapter\nthat uses domain-invariant information to learn task representations in the\nsource domain. The second method jointly learns a supervised classifier while\nreducing the divergence measure. Compared to strong baselines, our simple\nmethods perform well in natural language inference (MNLI) and the cross-domain\nsentiment classification task. We even outperform unsupervised domain\nadaptation methods such as DANN and DSN in sentiment classification, and we are\nwithin 0.85% F1 for natural language inference task, by fine-tuning only a\nfraction of the full model parameters. We release our code at\nhttps://github.com/declare-lab/UDAPTER\n","authors":["Bhavitvya Malik","Abhinav Ramesh Kashyap","Min-Yen Kan","Soujanya Poria"],"pdf_url":"https://arxiv.org/pdf/2302.03194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03183v1","updated":"2023-02-07T01:23:14Z","published":"2023-02-07T01:23:14Z","title":"Capturing Topic Framing via Masked Language Modeling","summary":"  Differential framing of issues can lead to divergent world views on important\nissues. This is especially true in domains where the information presented can\nreach a large audience, such as traditional and social media. Scalable and\nreliable measurement of such differential framing is an important first step in\naddressing them. In this work, based on the intuition that framing affects the\ntone and word choices in written language, we propose a framework for modeling\nthe differential framing of issues through masked token prediction via\nlarge-scale fine-tuned language models (LMs). Specifically, we explore three\nkey factors for our framework: 1) prompt generation methods for the masked\ntoken prediction; 2) methods for normalizing the output of fine-tuned LMs; 3)\nrobustness to the choice of pre-trained LMs used for fine-tuning. Through\nexperiments on a dataset of articles from traditional media outlets covering\nfive diverse and politically polarized topics, we show that our framework can\ncapture differential framing of these topics with high reliability.\n","authors":["Xiaobo Guo","Weicheng Ma","Soroush Vosoughi"],"pdf_url":"https://arxiv.org/pdf/2302.03183v1.pdf","comment":"In Findings of EMNLP 2022"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.03679v1","updated":"2023-02-07T18:54:39Z","published":"2023-02-07T18:54:39Z","title":"How Reliable is Your Regression Model's Uncertainty Under Real-World\n  Distribution Shifts?","summary":"  Many important computer vision applications are naturally formulated as\nregression problems. Within medical imaging, accurate regression models have\nthe potential to automate various tasks, helping to lower costs and improve\npatient outcomes. Such safety-critical deployment does however require reliable\nestimation of model uncertainty, also under the wide variety of distribution\nshifts that might be encountered in practice. Motivated by this, we set out to\ninvestigate the reliability of regression uncertainty estimation methods under\nvarious real-world distribution shifts. To that end, we propose an extensive\nbenchmark of 8 image-based regression datasets with different types of\nchallenging distribution shifts. We then employ our benchmark to evaluate many\nof the most common uncertainty estimation methods, as well as two\nstate-of-the-art uncertainty scores from the task of out-of-distribution\ndetection. We find that while methods are well calibrated when there is no\ndistribution shift, they all become highly overconfident on many of the\nbenchmark datasets. This uncovers important limitations of current uncertainty\nestimation methods, and the proposed benchmark therefore serves as a challenge\nto the research community. We hope that our benchmark will spur more work on\nhow to develop truly reliable regression uncertainty estimation methods. Code\nis available at https://github.com/fregu856/regression_uncertainty.\n","authors":["Fredrik K. Gustafsson","Martin Danelljan","Thomas B. Schön"],"pdf_url":"https://arxiv.org/pdf/2302.03679v1.pdf","comment":"Code is available at\n  https://github.com/fregu856/regression_uncertainty"},{"id":"http://arxiv.org/abs/2302.03675v1","updated":"2023-02-07T18:52:22Z","published":"2023-02-07T18:52:22Z","title":"Auditing Gender Presentation Differences in Text-to-Image Models","summary":"  Text-to-image models, which can generate high-quality images based on textual\ninput, have recently enabled various content-creation tools. Despite\nsignificantly affecting a wide range of downstream applications, the\ndistributions of these generated images are still not fully understood,\nespecially when it comes to the potential stereotypical attributes of different\ngenders. In this work, we propose a paradigm (Gender Presentation Differences)\nthat utilizes fine-grained self-presentation attributes to study how gender is\npresented differently in text-to-image models. By probing gender indicators in\nthe input text (e.g., \"a woman\" or \"a man\"), we quantify the frequency\ndifferences of presentation-centric attributes (e.g., \"a shirt\" and \"a dress\")\nthrough human annotation and introduce a novel metric: GEP. Furthermore, we\npropose an automatic method to estimate such differences. The automatic GEP\nmetric based on our approach yields a higher correlation with human annotations\nthan that based on existing CLIP scores, consistently across three\nstate-of-the-art text-to-image models. Finally, we demonstrate the\ngeneralization ability of our metrics in the context of gender stereotypes\nrelated to occupations.\n","authors":["Yanzhe Zhang","Lu Jiang","Greg Turk","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2302.03675v1.pdf","comment":"Preprint, 23 pages, 14 figures"},{"id":"http://arxiv.org/abs/2302.03665v1","updated":"2023-02-07T18:34:59Z","published":"2023-02-07T18:34:59Z","title":"HumanMAC: Masked Motion Completion for Human Motion Prediction","summary":"  Human motion prediction is a classical problem in computer vision and\ncomputer graphics, which has a wide range of practical applications. Previous\neffects achieve great empirical performance based on an encoding-decoding\nfashion. The methods of this fashion work by first encoding previous motions to\nlatent representations and then decoding the latent representations into\npredicted motions. However, in practice, they are still unsatisfactory due to\nseveral issues, including complicated loss constraints, cumbersome training\nprocesses, and scarce switch of different categories of motions in prediction.\nIn this paper, to address the above issues, we jump out of the foregoing\nfashion and propose a novel framework from a new perspective. Specifically, our\nframework works in a denoising diffusion style. In the training stage, we learn\na motion diffusion model that generates motions from random noise. In the\ninference stage, with a denoising procedure, we make motion prediction\nconditioning on observed motions to output more continuous and controllable\npredictions. The proposed framework enjoys promising algorithmic properties,\nwhich only needs one loss in optimization and is trained in an end-to-end\nmanner. Additionally, it accomplishes the switch of different categories of\nmotions effectively, which is significant in realistic tasks, \\textit{e.g.},\nthe animation task. Comprehensive experiments on benchmarks confirm the\nsuperiority of the proposed framework. The project page is available at\n\\url{https://lhchen.top/Human-MAC}.\n","authors":["Ling-Hao Chen","Jiawei Zhang","Yewen Li","Yiren Pang","Xiaobo Xia","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01908v2","updated":"2023-02-07T18:19:48Z","published":"2022-10-04T21:08:27Z","title":"Supervised Metric Learning to Rank for Retrieval via Contextual\n  Similarity Optimization","summary":"  There is extensive interest in metric learning methods for image retrieval.\nMany metric learning loss functions focus on learning a correct ranking of\ntraining samples, but strongly overfit semantically inconsistent labels and\nrequire a large amount of data. To address these shortcomings, we propose a new\nmetric learning method, called contextual loss, which optimizes contextual\nsimilarity in addition to cosine similarity. Our contextual loss implicitly\nenforces semantic consistency among neighbors while converging to the correct\nranking. We empirically show that the proposed loss is more robust to label\nnoise, and is less prone to overfitting even when a large portion of train data\nis withheld. Extensive experiments demonstrate that our method achieves a new\nstate-of-the-art across four image retrieval benchmarks and multiple different\nevaluation settings. Code is available at:\nhttps://github.com/Chris210634/metric-learning-using-contextual-similarity\n","authors":["Christopher Liao","Theodoros Tsiligkaridis","Brian Kulis"],"pdf_url":"https://arxiv.org/pdf/2210.01908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03657v1","updated":"2023-02-07T18:17:41Z","published":"2023-02-07T18:17:41Z","title":"Toward Face Biometric De-identification using Adversarial Examples","summary":"  The remarkable success of face recognition (FR) has endangered the privacy of\ninternet users particularly in social media. Recently, researchers turned to\nuse adversarial examples as a countermeasure. In this paper, we assess the\neffectiveness of using two widely known adversarial methods (BIM and ILLC) for\nde-identifying personal images. We discovered, unlike previous claims in the\nliterature, that it is not easy to get a high protection success rate\n(suppressing identification rate) with imperceptible adversarial perturbation\nto the human visual system. Finally, we found out that the transferability of\nadversarial examples is highly affected by the training parameters of the\nnetwork with which they are generated.\n","authors":["Mahdi Ghafourian","Julian Fierrez","Luis Felipe Gomez","Ruben Vera-Rodriguez","Aythami Morales","Zohra Rezgui","Raymond Veldhuis"],"pdf_url":"https://arxiv.org/pdf/2302.03657v1.pdf","comment":"Accepted at the AAAI-23 workshop on Artificial Intelligence for Cyber\n  Security (AICS)"},{"id":"http://arxiv.org/abs/2302.03648v1","updated":"2023-02-07T17:59:05Z","published":"2023-02-07T17:59:05Z","title":"Deep Class-Incremental Learning: A Survey","summary":"  Deep models, e.g., CNNs and Vision Transformers, have achieved impressive\nachievements in many vision tasks in the closed world. However, novel classes\nemerge from time to time in our ever-changing world, requiring a learning\nsystem to acquire new knowledge continually. For example, a robot needs to\nunderstand new instructions, and an opinion monitoring system should analyze\nemerging topics every day. Class-Incremental Learning (CIL) enables the learner\nto incorporate the knowledge of new classes incrementally and build a universal\nclassifier among all seen classes. Correspondingly, when directly training the\nmodel with new class instances, a fatal problem occurs -- the model tends to\ncatastrophically forget the characteristics of former ones, and its performance\ndrastically degrades. There have been numerous efforts to tackle catastrophic\nforgetting in the machine learning community. In this paper, we survey\ncomprehensively recent advances in deep class-incremental learning and\nsummarize these methods from three aspects, i.e., data-centric, model-centric,\nand algorithm-centric. We also provide a rigorous and unified evaluation of 16\nmethods in benchmark image classification tasks to find out the characteristics\nof different algorithms empirically. Furthermore, we notice that the current\ncomparison protocol ignores the influence of memory budget in model storage,\nwhich may result in unfair comparison and biased results. Hence, we advocate\nfair comparison by aligning the memory budget in evaluation, as well as several\nmemory-agnostic performance measures. The source code to reproduce these\nevaluations is available at https://github.com/zhoudw-zdw/CIL_Survey/\n","authors":["Da-Wei Zhou","Qi-Wei Wang","Zhi-Hong Qi","Han-Jia Ye","De-Chuan Zhan","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03648v1.pdf","comment":"Code is available at https://github.com/zhoudw-zdw/CIL_Survey/"},{"id":"http://arxiv.org/abs/2302.03640v1","updated":"2023-02-07T17:47:52Z","published":"2023-02-07T17:47:52Z","title":"S4R: Self-Supervised Semantic Scene Reconstruction from RGB-D Scans","summary":"  Most deep learning approaches to comprehensive semantic modeling of 3D indoor\nspaces require costly dense annotations in the 3D domain. In this work, we\nexplore a central 3D scene modeling task, namely, semantic scene\nreconstruction, using a fully self-supervised approach. To this end, we design\na trainable model that employs both incomplete 3D reconstructions and their\ncorresponding source RGB-D images, fusing cross-domain features into volumetric\nembeddings to predict complete 3D geometry, color, and semantics. Our key\ntechnical innovation is to leverage differentiable rendering of color and\nsemantics, using the observed RGB images and a generic semantic segmentation\nmodel as color and semantics supervision, respectively. We additionally develop\na method to synthesize an augmented set of virtual training views complementing\nthe original real captures, enabling more efficient self-supervision for\nsemantics. In this work we propose an end-to-end trainable solution jointly\naddressing geometry completion, colorization, and semantic mapping from a few\nRGB-D images, without 3D or 2D ground-truth. Our method is the first, to our\nknowledge, fully self-supervised method addressing completion and semantic\nsegmentation of real-world 3D scans. It performs comparably well with the 3D\nsupervised baselines, surpasses baselines with 2D supervision on real datasets,\nand generalizes well to unseen scenes.\n","authors":["Junwen Huang","Alexey Artemorv","Yujin Chen","Shuaifeng Zhi","Kai Xu","Matthias Niessner"],"pdf_url":"https://arxiv.org/pdf/2302.03640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02088v2","updated":"2023-02-07T17:38:18Z","published":"2023-02-04T04:17:19Z","title":"AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene\n  Synthesis","summary":"  Human perception of the complex world relies on a comprehensive analysis of\nmulti-modal signals, and the co-occurrences of audio and video signals provide\nhumans with rich cues. This paper focuses on novel audio-visual scene synthesis\nin the real world. Given a video recording of an audio-visual scene, the task\nis to synthesize new videos with spatial audios along arbitrary novel camera\ntrajectories in that audio-visual scene. Directly using a NeRF-based model for\naudio synthesis is insufficient due to its lack of prior knowledge and acoustic\nsupervision. To tackle the challenges, we first propose an acoustic-aware audio\ngeneration module that integrates our prior knowledge of audio propagation into\nNeRF, in which we associate audio generation with the 3D geometry of the visual\nenvironment. In addition, we propose a coordinate transformation module that\nexpresses a viewing direction relative to the sound source. Such a direction\ntransformation helps the model learn sound source-centric acoustic fields.\nMoreover, we utilize a head-related impulse response function to synthesize\npseudo binaural audio for data augmentation that strengthens training. We\nqualitatively and quantitatively demonstrate the advantage of our model on\nreal-world audio-visual scenes. We refer interested readers to view our video\nresults for convincing comparisons.\n","authors":["Susan Liang","Chao Huang","Yapeng Tian","Anurag Kumar","Chenliang Xu"],"pdf_url":"https://arxiv.org/pdf/2302.02088v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03629v1","updated":"2023-02-07T17:33:00Z","published":"2023-02-07T17:33:00Z","title":"Ethical Considerations for Collecting Human-Centric Image Datasets","summary":"  Human-centric image datasets are critical to the development of computer\nvision technologies. However, recent investigations have foregrounded\nsignificant ethical issues related to privacy and bias, which have resulted in\nthe complete retraction, or modification, of several prominent datasets. Recent\nworks have tried to reverse this trend, for example, by proposing analytical\nframeworks for ethically evaluating datasets, the standardization of dataset\ndocumentation and curation practices, privacy preservation methodologies, as\nwell as tools for surfacing and mitigating representational biases. Little\nattention, however, has been paid to the realities of operationalizing ethical\ndata collection. To fill this gap, we present a set of key ethical\nconsiderations and practical recommendations for collecting more\nethically-minded human-centric image data. Our research directly addresses\nissues of privacy and bias by contributing to the research community best\npractices for ethical data collection, covering purpose, privacy and consent,\nas well as diversity. We motivate each consideration by drawing on lessons from\ncurrent practices, dataset withdrawals and audits, and analytical ethical\nframeworks. Our research is intended to augment recent scholarship,\nrepresenting an important step toward more responsible data curation practices.\n","authors":["Jerone T. A. Andrews","Dora Zhao","William Thong","Apostolos Modas","Orestis Papakyriakopoulos","Shruti Nagpal","Alice Xiang"],"pdf_url":"https://arxiv.org/pdf/2302.03629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03609v1","updated":"2023-02-07T17:13:52Z","published":"2023-02-07T17:13:52Z","title":"Pole Estimation and Optical Navigation using Circle of Latitude\n  Projections","summary":"  Images of both rotating celestial bodies (e.g., asteroids) and spheroidal\nplanets with banded atmospheres (e.g., Jupiter) can contain features that are\nwell-modeled as a circle of latitude (CoL). The projections of these CoLs\nappear as ellipses in images collected by cameras or telescopes onboard\nexploration spacecraft. This work shows how CoL projections may be used to\ndetermine the pole orientation and covariance for a spinning asteroid. In the\ncase of a known planet modeled as an oblate spheroid, it is shown how similar\nCoL projections may be used for spacecraft localization. These methods are\ndeveloped using the principles of projective geometry. Numerical results are\nprovided for simulated images of asteroid Bennu (for pole orientation) and of\nJupiter (for spacecraft localization).\n","authors":["John A. Christian"],"pdf_url":"https://arxiv.org/pdf/2302.03609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03594v1","updated":"2023-02-07T17:06:34Z","published":"2023-02-07T17:06:34Z","title":"NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM","summary":"  Neural implicit representations have recently become popular in simultaneous\nlocalization and mapping (SLAM), especially in dense visual SLAM. However,\nprevious works in this direction either rely on RGB-D sensors, or require a\nseparate monocular SLAM approach for camera tracking and do not produce\nhigh-fidelity dense 3D scene reconstruction. In this paper, we present\nNICER-SLAM, a dense RGB SLAM system that simultaneously optimizes for camera\nposes and a hierarchical neural implicit map representation, which also allows\nfor high-quality novel view synthesis. To facilitate the optimization process\nfor mapping, we integrate additional supervision signals including\neasy-to-obtain monocular geometric cues and optical flow, and also introduce a\nsimple warping loss to further enforce geometry consistency. Moreover, to\nfurther boost performance in complicated indoor scenes, we also propose a local\nadaptive transformation from signed distance functions (SDFs) to density in the\nvolume rendering equation. On both synthetic and real-world datasets we\ndemonstrate strong performance in dense mapping, tracking, and novel view\nsynthesis, even competitive with recent RGB-D SLAM systems.\n","authors":["Zihan Zhu","Songyou Peng","Viktor Larsson","Zhaopeng Cui","Martin R. Oswald","Andreas Geiger","Marc Pollefeys"],"pdf_url":"https://arxiv.org/pdf/2302.03594v1.pdf","comment":"Video: https://youtu.be/tUXzqEZWg2w"},{"id":"http://arxiv.org/abs/1912.11164v3","updated":"2023-02-07T17:05:26Z","published":"2019-12-24T01:12:36Z","title":"Unsupervised Scene Adaptation with Memory Regularization in vivo","summary":"  We consider the unsupervised scene adaptation problem of learning from both\nlabeled source data and unlabeled target data. Existing methods focus on\nminoring the inter-domain gap between the source and target domains. However,\nthe intra-domain knowledge and inherent uncertainty learned by the network are\nunder-explored. In this paper, we propose an orthogonal method, called memory\nregularization in vivo to exploit the intra-domain knowledge and regularize the\nmodel training. Specifically, we refer to the segmentation model itself as the\nmemory module, and minor the discrepancy of the two classifiers, i.e., the\nprimary classifier and the auxiliary classifier, to reduce the prediction\ninconsistency. Without extra parameters, the proposed method is complementary\nto the most existing domain adaptation methods and could generally improve the\nperformance of existing methods. Albeit simple, we verify the effectiveness of\nmemory regularization on two synthetic-to-real benchmarks: GTA5 -> Cityscapes\nand SYNTHIA -> Cityscapes, yielding +11.1% and +11.3% mIoU improvement over the\nbaseline model, respectively. Besides, a similar +12.0% mIoU improvement is\nobserved on the cross-city benchmark: Cityscapes -> Oxford RobotCar.\n","authors":["Zhedong Zheng","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/1912.11164v3.pdf","comment":"7 pages, 4 figures, 6 tables (accepted by IJCAI 2020)"},{"id":"http://arxiv.org/abs/2302.03573v1","updated":"2023-02-07T16:37:19Z","published":"2023-02-07T16:37:19Z","title":"Local Neural Descriptor Fields: Locally Conditioned Object\n  Representations for Manipulation","summary":"  A robot operating in a household environment will see a wide range of unique\nand unfamiliar objects. While a system could train on many of these, it is\ninfeasible to predict all the objects a robot will see. In this paper, we\npresent a method to generalize object manipulation skills acquired from a\nlimited number of demonstrations, to novel objects from unseen shape\ncategories. Our approach, Local Neural Descriptor Fields (L-NDF), utilizes\nneural descriptors defined on the local geometry of the object to effectively\ntransfer manipulation demonstrations to novel objects at test time. In doing\nso, we leverage the local geometry shared between objects to produce a more\ngeneral manipulation framework. We illustrate the efficacy of our approach in\nmanipulating novel objects in novel poses -- both in simulation and in the real\nworld.\n","authors":["Ethan Chun","Yilun Du","Anthony Simeonov","Tomas Lozano-Perez","Leslie Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2302.03573v1.pdf","comment":"ICRA 2023, Project Page: https://elchun.github.io/lndf/"},{"id":"http://arxiv.org/abs/2302.03570v1","updated":"2023-02-07T16:32:05Z","published":"2023-02-07T16:32:05Z","title":"A Deep Learning-based in silico Framework for Optimization on Retinal\n  Prosthetic Stimulation","summary":"  We propose a neural network-based framework to optimize the perceptions\nsimulated by the in silico retinal implant model pulse2percept. The overall\npipeline consists of a trainable encoder, a pre-trained retinal implant model\nand a pre-trained evaluator. The encoder is a U-Net, which takes the original\nimage and outputs the stimulus. The pre-trained retinal implant model is also a\nU-Net, which is trained to mimic the biomimetic perceptual model implemented in\npulse2percept. The evaluator is a shallow VGG classifier, which is trained with\noriginal images. Based on 10,000 test images from the MNIST dataset, we show\nthat the convolutional neural network-based encoder performs significantly\nbetter than the trivial downsampling approach, yielding a boost in the weighted\nF1-Score by 36.17% in the pre-trained classifier with 6x10 electrodes. With\nthis fully neural network-based encoder, the quality of the downstream\nperceptions can be fine-tuned using gradient descent in an end-to-end fashion.\n","authors":["Yuli Wu","Ivan Karetic","Johannes Stegmaier","Peter Walter","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2302.03570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03003v2","updated":"2023-02-07T16:31:32Z","published":"2023-02-06T18:39:40Z","title":"OTRE: Where Optimal Transport Guided Unpaired Image-to-Image Translation\n  Meets Regularization by Enhancing","summary":"  Non-mydriatic retinal color fundus photography (CFP) is widely available due\nto the advantage of not requiring pupillary dilation, however, is prone to poor\nquality due to operators, systemic imperfections, or patient-related causes.\nOptimal retinal image quality is mandated for accurate medical diagnoses and\nautomated analyses. Herein, we leveraged the Optimal Transport (OT) theory to\npropose an unpaired image-to-image translation scheme for mapping low-quality\nretinal CFPs to high-quality counterparts. Furthermore, to improve the\nflexibility, robustness, and applicability of our image enhancement pipeline in\nthe clinical practice, we generalized a state-of-the-art model-based image\nreconstruction method, regularization by denoising, by plugging in priors\nlearned by our OT-guided image-to-image translation network. We named it as\nregularization by enhancing (RE). We validated the integrated framework, OTRE,\non three publicly available retinal image datasets by assessing the quality\nafter enhancement and their performance on various downstream tasks, including\ndiabetic retinopathy grading, vessel segmentation, and diabetic lesion\nsegmentation. The experimental results demonstrated the superiority of our\nproposed framework over some state-of-the-art unsupervised competitors and a\nstate-of-the-art supervised method.\n","authors":["Wenhui Zhu","Peijie Qiu","Oana M. Dumitrascu","Jacob Jacob","Mohammad Farazi","Zhangsihao Yang","Keshav Nandakumar","Yalin Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03003v2.pdf","comment":"Accepted as a conference paper to The 28th biennial international\n  conference on Information Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2302.03566v1","updated":"2023-02-07T16:26:45Z","published":"2023-02-07T16:26:45Z","title":"Look around and learn: self-improving object detection by exploration","summary":"  Object detectors often experience a drop in performance when new\nenvironmental conditions are insufficiently represented in the training data.\nThis paper studies how to automatically fine-tune a pre-existing object\ndetector while exploring and acquiring images in a new environment without\nrelying on human intervention, i.e., in an utterly self-supervised fashion. In\nour setting, an agent initially learns to explore the environment using a\npre-trained off-the-shelf detector to locate objects and associate\npseudo-labels. By assuming that pseudo-labels for the same object must be\nconsistent across different views, we learn an exploration policy mining hard\nsamples and we devise a novel mechanism for producing refined predictions from\nthe consensus among observations. Our approach outperforms the current\nstate-of-the-art, and it closes the performance gap against a fully supervised\nsetting without relying on ground-truth annotations. We also compare various\nexploration policies for the agent to gather more informative observations.\nCode and dataset will be made available upon paper acceptance\n","authors":["ianluca Scarpellini","Stefano Rosa","Pietro Morerio","Lorenzo Natale","Alessio Del Bue"],"pdf_url":"https://arxiv.org/pdf/2302.03566v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12625v2","updated":"2023-02-07T16:19:43Z","published":"2022-08-26T12:34:55Z","title":"Take One Gram of Neural Features, Get Enhanced Group Robustness","summary":"  Predictive performance of machine learning models trained with empirical risk\nminimization (ERM) can degrade considerably under distribution shifts. The\npresence of spurious correlations in training datasets leads ERM-trained models\nto display high loss when evaluated on minority groups not presenting such\ncorrelations. Extensive attempts have been made to develop methods improving\nworst-group robustness. However, they require group information for each\ntraining input or at least, a validation set with group labels to tune their\nhyperparameters, which may be expensive to get or unknown a priori. In this\npaper, we address the challenge of improving group robustness without group\nannotation during training or validation. To this end, we propose to partition\nthe training dataset into groups based on Gram matrices of features extracted\nby an ``identification'' model and to apply robust optimization based on these\npseudo-groups. In the realistic context where no group labels are available,\nour experiments show that our approach not only improves group robustness over\nERM but also outperforms all recent baselines\n","authors":["Simon Roburin","Charles Corbière","Gilles Puy","Nicolas Thome","Matthieu Aubry","Renaud Marlet","Patrick Pérez"],"pdf_url":"https://arxiv.org/pdf/2208.12625v2.pdf","comment":"Long version (Previous version: OOD-CV Workshop @ ECCV 2022)"},{"id":"http://arxiv.org/abs/2209.15517v2","updated":"2023-02-07T16:11:42Z","published":"2022-09-30T15:06:13Z","title":"Medical Image Understanding with Pretrained Vision Language Models: A\n  Comprehensive Study","summary":"  The large-scale pre-trained vision language models (VLM) have shown\nremarkable domain transfer capability on natural images. However, it remains\nunknown whether this capability can also apply to the medical image domain.\nThis paper thoroughly studies the knowledge transferability of pre-trained VLMs\nto the medical domain, where we show that well-designed medical prompts are the\nkey to elicit knowledge from pre-trained VLMs. We demonstrate that by prompting\nwith expressive attributes that are shared between domains, the VLM can carry\nthe knowledge across domains and improve its generalization. This mechanism\nempowers VLMs to recognize novel objects with fewer or without image samples.\nFurthermore, to avoid the laborious manual designing process, we develop three\napproaches for automatic generation of medical prompts, which can inject\nexpert-level medical knowledge and image-specific information into the prompts\nfor fine-grained grounding. We conduct extensive experiments on thirteen\ndifferent medical datasets across various modalities, showing that our\nwell-designed prompts greatly improve the zero-shot performance compared to the\ndefault prompts, and our fine-tuned models surpass the supervised models by a\nsignificant margin.\n","authors":["Ziyuan Qin","Huahui Yi","Qicheng Lao","Kang Li"],"pdf_url":"https://arxiv.org/pdf/2209.15517v2.pdf","comment":"Accepted to ICLR2023"},{"id":"http://arxiv.org/abs/2302.03548v1","updated":"2023-02-07T15:56:03Z","published":"2023-02-07T15:56:03Z","title":"PhysFormer++: Facial Video-based Physiological Measurement with SlowFast\n  Temporal Difference Transformer","summary":"  Remote photoplethysmography (rPPG), which aims at measuring heart activities\nand physiological signals from facial video without any contact, has great\npotential in many applications (e.g., remote healthcare and affective\ncomputing). Recent deep learning approaches focus on mining subtle rPPG clues\nusing convolutional neural networks with limited spatio-temporal receptive\nfields, which neglect the long-range spatio-temporal perception and interaction\nfor rPPG modeling. In this paper, we propose two end-to-end video transformer\nbased architectures, namely PhysFormer and PhysFormer++, to adaptively\naggregate both local and global spatio-temporal features for rPPG\nrepresentation enhancement. As key modules in PhysFormer, the temporal\ndifference transformers first enhance the quasi-periodic rPPG features with\ntemporal difference guided global attention, and then refine the local\nspatio-temporal representation against interference. To better exploit the\ntemporal contextual and periodic rPPG clues, we also extend the PhysFormer to\nthe two-pathway SlowFast based PhysFormer++ with temporal difference periodic\nand cross-attention transformers. Furthermore, we propose the label\ndistribution learning and a curriculum learning inspired dynamic constraint in\nfrequency domain, which provide elaborate supervisions for PhysFormer and\nPhysFormer++ and alleviate overfitting. Comprehensive experiments are performed\non four benchmark datasets to show our superior performance on both intra- and\ncross-dataset testings. Unlike most transformer networks needed pretraining\nfrom large-scale datasets, the proposed PhysFormer family can be easily trained\nfrom scratch on rPPG datasets, which makes it promising as a novel transformer\nbaseline for the rPPG community.\n","authors":["Zitong Yu","Yuming Shen","Jingang Shi","Hengshuang Zhao","Yawen Cui","Jiehua Zhang","Philip Torr","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03548v1.pdf","comment":"Accepted by International Journal of Computer Vision (IJCV). arXiv\n  admin note: substantial text overlap with arXiv:2111.12082"},{"id":"http://arxiv.org/abs/2209.08803v3","updated":"2023-02-07T15:46:11Z","published":"2022-09-19T07:18:46Z","title":"Zero-shot Active Visual Search (ZAVIS): Intelligent Object Search for\n  Robotic Assistants","summary":"  In this paper, we focus on the problem of efficiently locating a target\nobject described with free-form language using a mobile robot equipped with\nvision sensors (e.g., an RGBD camera). Conventional active visual search\npredefines a set of objects to search for, rendering these techniques\nrestrictive in practice. To provide added flexibility in active visual\nsearching, we propose a system where a user can enter target commands using\nfree-form language; we call this system Active Visual Search in the Wild\n(AVSW). AVSW detects and plans to search for a target object inputted by a user\nthrough a semantic grid map represented by static landmarks (e.g., desk or\nbed). For efficient planning of object search patterns, AVSW considers\ncommonsense knowledge-based co-occurrence and predictive uncertainty while\ndeciding which landmarks to visit first. We validate the proposed method with\nrespect to SR (success rate) and SPL (success weighted by path length) in both\nsimulated and real-world environments. The proposed method outperforms previous\nmethods in terms of SPL in simulated scenarios with an average gap of 0.283. We\nfurther demonstrate AVSW with a Pioneer-3AT robot in real-world studies.\n","authors":["Jeongeun Park","Taerim Yoon","Jejoon Hong","Youngjae Yu","Matthew Pan","Sungjoon Choi"],"pdf_url":"https://arxiv.org/pdf/2209.08803v3.pdf","comment":"To be appear on ICRA 2023"},{"id":"http://arxiv.org/abs/2302.03537v1","updated":"2023-02-07T15:41:40Z","published":"2023-02-07T15:41:40Z","title":"Aligning Multi-Sequence CMR Towards Fully Automated Myocardial Pathology\n  Segmentation","summary":"  Myocardial pathology segmentation (MyoPS) is critical for the risk\nstratification and treatment planning of myocardial infarction (MI).\nMulti-sequence cardiac magnetic resonance (MS-CMR) images can provide valuable\ninformation. For instance, balanced steady-state free precession cine sequences\npresent clear anatomical boundaries, while late gadolinium enhancement and\nT2-weighted CMR sequences visualize myocardial scar and edema of MI,\nrespectively. Existing methods usually fuse anatomical and pathological\ninformation from different CMR sequences for MyoPS, but assume that these\nimages have been spatially aligned. However, MS-CMR images are usually\nunaligned due to the respiratory motions in clinical practices, which poses\nadditional challenges for MyoPS. This work presents an automatic MyoPS\nframework for unaligned MS-CMR images. Specifically, we design a combined\ncomputing model for simultaneous image registration and information fusion,\nwhich aggregates multi-sequence features into a common space to extract\nanatomical structures (i.e., myocardium). Consequently, we can highlight the\ninformative regions in the common space via the extracted myocardium to improve\nMyoPS performance, considering the spatial relationship between myocardial\npathologies and myocardium. Experiments on a private MS-CMR dataset and a\npublic dataset from the MYOPS2020 challenge show that our framework could\nachieve promising performance for fully automatic MyoPS.\n","authors":["Wangbin Ding","Lei Li","Junyi Qiu","Sihan Wang","Liqin Huang","Yinyin Chen","Shan Yang","Xiahai Zhuang"],"pdf_url":"https://arxiv.org/pdf/2302.03537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03533v1","updated":"2023-02-07T15:34:14Z","published":"2023-02-07T15:34:14Z","title":"Revisiting Pre-training in Audio-Visual Learning","summary":"  Pre-training technique has gained tremendous success in enhancing model\nperformance on various tasks, but found to perform worse than training from\nscratch in some uni-modal situations. This inspires us to think: are the\npre-trained models always effective in the more complex multi-modal scenario,\nespecially for the heterogeneous modalities such as audio and visual ones? We\nfind that the answer is No. Specifically, we explore the effects of pre-trained\nmodels on two audio-visual learning scenarios: cross-modal initialization and\nmulti-modal joint learning. When cross-modal initialization is applied, the\nphenomena of \"dead channel\" caused by abnormal Batchnorm parameters hinders the\nutilization of model capacity. Thus, we propose Adaptive Batchnorm\nRe-initialization (ABRi) to better exploit the capacity of pre-trained models\nfor target tasks. In multi-modal joint learning, we find a strong pre-trained\nuni-modal encoder would bring negative effects on the encoder of another\nmodality. To alleviate such problem, we introduce a two-stage Fusion Tuning\nstrategy, taking better advantage of the pre-trained knowledge while making the\nuni-modal encoders cooperate with an adaptive masking method. The experiment\nresults show that our methods could further exploit pre-trained models'\npotential and boost performance in audio-visual learning.\n","authors":["Ruoxuan Feng","Wenke Xia","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2302.03533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03531v1","updated":"2023-02-07T15:23:52Z","published":"2023-02-07T15:23:52Z","title":"Structured Generative Models for Scene Understanding","summary":"  This position paper argues for the use of \\emph{structured generative models}\n(SGMs) for scene understanding. This requires the reconstruction of a 3D scene\nfrom an input image, whereby the contents of the image are causally explained\nin terms of models of instantiated objects, each with their own type, shape,\nappearance and pose, along with global variables like scene lighting and camera\nparameters. This approach also requires scene models which account for the\nco-occurrences and inter-relationships of objects in a scene. The SGM approach\nhas the merits that it is compositional and generative, which lead to\ninterpretability.\n  To pursue the SGM agenda, we need models for objects and scenes, and\napproaches to carry out inference. We first review models for objects, which\ninclude ``things'' (object categories that have a well defined shape), and\n``stuff'' (categories which have amorphous spatial extent). We then move on to\nreview \\emph{scene models} which describe the inter-relationships of objects.\nPerhaps the most challenging problem for SGMs is \\emph{inference} of the\nobjects, lighting and camera parameters, and scene inter-relationships from\ninput consisting of a single or multiple images. We conclude with a discussion\nof issues that need addressing to advance the SGM agenda.\n","authors":["Christopher K. I. Williams"],"pdf_url":"https://arxiv.org/pdf/2302.03531v1.pdf","comment":"33 pages, 10 figures"},{"id":"http://arxiv.org/abs/2205.13349v4","updated":"2023-02-07T14:32:49Z","published":"2022-05-26T13:30:14Z","title":"Learning What and Where: Disentangling Location and Identity Tracking\n  Without Supervision","summary":"  Our brain can almost effortlessly decompose visual data streams into\nbackground and salient objects. Moreover, it can anticipate object motion and\ninteractions, which are crucial abilities for conceptual planning and\nreasoning. Recent object reasoning datasets, such as CATER, have revealed\nfundamental shortcomings of current vision-based AI systems, particularly when\ntargeting explicit object representations, object permanence, and object\nreasoning. Here we introduce a self-supervised LOCation and Identity tracking\nsystem (Loci), which excels on the CATER tracking challenge. Inspired by the\ndorsal and ventral pathways in the brain, Loci tackles the binding problem by\nprocessing separate, slot-wise encodings of `what' and `where'. Loci's\npredictive coding-like processing encourages active error minimization, such\nthat individual slots tend to encode individual objects. Interactions between\nobjects and object dynamics are processed in the disentangled latent space.\nTruncated backpropagation through time combined with forward eligibility\naccumulation significantly speeds up learning and improves memory efficiency.\nBesides exhibiting superior performance in current benchmarks, Loci effectively\nextracts objects from video streams and separates them into location and\nGestalt components. We believe that this separation offers a representation\nthat will facilitate effective planning and reasoning on conceptual levels.\n","authors":["Manuel Traub","Sebastian Otte","Tobias Menge","Matthias Karlbauer","Jannik Thümmel","Martin V. Butz"],"pdf_url":"https://arxiv.org/pdf/2205.13349v4.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03477v1","updated":"2023-02-07T14:05:02Z","published":"2023-02-07T14:05:02Z","title":"Explainable Action Prediction through Self-Supervision on Scene Graphs","summary":"  This work explores scene graphs as a distilled representation of high-level\ninformation for autonomous driving, applied to future driver-action prediction.\nGiven the scarcity and strong imbalance of data samples, we propose a\nself-supervision pipeline to infer representative and well-separated\nembeddings. Key aspects are interpretability and explainability; as such, we\nembed in our architecture attention mechanisms that can create spatial and\ntemporal heatmaps on the scene graphs. We evaluate our system on the ROAD\ndataset against a fully-supervised approach, showing the superiority of our\ntraining regime.\n","authors":["Pawit Kochakarn","Daniele De Martini","Daniel Omeiza","Lars Kunze"],"pdf_url":"https://arxiv.org/pdf/2302.03477v1.pdf","comment":"Accepted to the 2023 IEEE International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2302.03476v1","updated":"2023-02-07T14:01:32Z","published":"2023-02-07T14:01:32Z","title":"VertXNet: An Ensemble Method for Vertebrae Segmentation and\n  Identification of Spinal X-Ray","summary":"  Reliable vertebrae annotations are key to perform analysis of spinal X-ray\nimages. However, obtaining annotation of vertebrae from those images is usually\ncarried out manually due to its complexity (i.e. small structures with varying\nshape), making it a costly and tedious process. To accelerate this process, we\nproposed an ensemble pipeline, VertXNet, that combines two state-of-the-art\n(SOTA) segmentation models (respectively U-Net and Mask R-CNN) to automatically\nsegment and label vertebrae in X-ray spinal images. Moreover, VertXNet\nintroduces a rule-based approach that allows to robustly infer vertebrae labels\n(by locating the 'reference' vertebrae which are easier to segment than others)\nfor a given spinal X-ray image. We evaluated the proposed pipeline on three\nspinal X-ray datasets (two internal and one publicly available), and compared\nagainst vertebrae annotated by radiologists. Our experimental results have\nshown that the proposed pipeline outperformed two SOTA segmentation models on\nour test dataset (MEASURE 1) with a mean Dice of 0.90, vs. a mean Dice of 0.73\nfor Mask R-CNN and 0.72 for U-Net. To further evaluate the generalization\nability of VertXNet, the pre-trained pipeline was directly tested on two\nadditional datasets (PREVENT and NHANES II) and consistent performance was\nobserved with a mean Dice of 0.89 and 0.88, respectively. Overall, VertXNet\ndemonstrated significantly improved performance for vertebra segmentation and\nlabeling for spinal X-ray imaging, and evaluation on both in-house clinical\ntrial data and publicly available data further proved its generalization.\n","authors":["Yao Chen","Yuanhan Mo","Aimee Readie","Gregory Ligozio","Indrajeet Mandal","Faiz Jabbar","Thibaud Coroller","Bartlomiej W. Papiez"],"pdf_url":"https://arxiv.org/pdf/2302.03476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03473v1","updated":"2023-02-07T13:58:08Z","published":"2023-02-07T13:58:08Z","title":"Med-NCA: Robust and Lightweight Segmentation with Neural Cellular\n  Automata","summary":"  Access to the proper infrastructure is critical when performing medical image\nsegmentation with Deep Learning. This requirement makes it difficult to run\nstate-of-the-art segmentation models in resource-constrained scenarios like\nprimary care facilities in rural areas and during crises. The recently emerging\nfield of Neural Cellular Automata (NCA) has shown that locally interacting\none-cell models can achieve competitive results in tasks such as image\ngeneration or segmentations in low-resolution inputs. However, they are\nconstrained by high VRAM requirements and the difficulty of reaching\nconvergence for high-resolution images. To counteract these limitations we\npropose Med-NCA, an end-to-end NCA training pipeline for high-resolution image\nsegmentation. Our method follows a two-step process. Global knowledge is first\ncommunicated between cells across the downscaled image. Following that,\npatch-based segmentation is performed. Our proposed Med-NCA outperforms the\nclassic UNet by 2% and 3% Dice for hippocampus and prostate segmentation,\nrespectively, while also being 500 times smaller. We also show that Med-NCA is\nby design invariant with respect to image scale, shape and translation,\nexperiencing only slight performance degradation even with strong shifts; and\nis robust against MRI acquisition artefacts. Med-NCA enables high-resolution\nmedical image segmentation even on a Raspberry Pi B+, arguably the smallest\ndevice able to run PyTorch and that can be powered by a standard power bank.\n","authors":["John Kalkhof","Camila González","Anirban Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2302.03473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02367v2","updated":"2023-02-07T13:33:14Z","published":"2023-02-05T12:13:27Z","title":"FastPillars: A Deployment-friendly Pillar-based 3D Detector","summary":"  The deployment of 3D detectors strikes one of the major challenges in\nreal-world self-driving scenarios. Existing BEV-based (i.e., Bird Eye View)\ndetectors favor sparse convolution (known as SPConv) to speed up training and\ninference, which puts a hard barrier for deployment especially for on-device\napplications. In this paper, we tackle the problem of efficient 3D object\ndetection from LiDAR point clouds with deployment in mind. To reduce\ncomputational burden, we propose a pillar-based 3D detector with high\nperformance from an industry perspective, termed FastPillars. Compared with\nprevious methods, we introduce a more effective Max-and-Attention pillar\nencoding (MAPE) module, and redesigning a powerful and lightweight backbone\nCRVNet imbued with Cross Stage Partial network (CSP) in a reparameterization\nstyle, forming a compact feature representation framework. Extensive\nexperiments demonstrate that our FastPillars surpasses the state-of-the-art 3D\ndetectors regarding both on-device speed and performance. Specifically,\nFastPillars can be effectively deployed through TensorRT, obtaining real-time\nperformance (24FPS) on a single RTX3070Ti GPU with 64.6 mAP on the nuScenes\ntest set. Our code is publicly available at:\nhttps://github.com/StiphyJay/FastPillars.\n","authors":["Sifan Zhou","Zhi Tian","Xiangxiang Chu","Xinyu Zhang","Bo Zhang","Xiaobo Lu","Chengjian Feng","Zequn Jie","Patrick Yin Chiang","Lin Ma"],"pdf_url":"https://arxiv.org/pdf/2302.02367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03453v1","updated":"2023-02-07T13:19:59Z","published":"2023-02-07T13:19:59Z","title":"OSRT: Omnidirectional Image Super-Resolution with Distortion-aware\n  Transformer","summary":"  Omnidirectional images (ODIs) have obtained lots of research interest for\nimmersive experiences. Although ODIs require extremely high resolution to\ncapture details of the entire scene, the resolutions of most ODIs are\ninsufficient. Previous methods attempt to solve this issue by image\nsuper-resolution (SR) on equirectangular projection (ERP) images. However, they\nomit geometric properties of ERP in the degradation process, and their models\ncan hardly generalize to real ERP images. In this paper, we propose Fisheye\ndownsampling, which mimics the real-world imaging process and synthesizes more\nrealistic low-resolution samples. Then we design a distortion-aware Transformer\n(OSRT) to modulate ERP distortions continuously and self-adaptively. Without a\ncumbersome process, OSRT outperforms previous methods by about 0.2dB on PSNR.\nMoreover, we propose a convenient data augmentation strategy, which synthesizes\npseudo ERP images from plain images. This simple strategy can alleviate the\nover-fitting problem of large networks and significantly boost the performance\nof ODISR. Extensive experiments have demonstrated the state-of-the-art\nperformance of our OSRT. Codes and models will be available at\nhttps://github.com/Fanghua-Yu/OSRT.\n","authors":["Fanghua Yu","Xintao Wang","Mingdeng Cao","Gen Li","Ying Shan","Chao Dong"],"pdf_url":"https://arxiv.org/pdf/2302.03453v1.pdf","comment":"main paper + supplement"},{"id":"http://arxiv.org/abs/2302.02693v2","updated":"2023-02-07T13:14:04Z","published":"2023-02-06T10:51:21Z","title":"PatchDCT: Patch Refinement for High Quality Instance Segmentation","summary":"  High-quality instance segmentation has shown emerging importance in computer\nvision. Without any refinement, DCT-Mask directly generates high-resolution\nmasks by compressed vectors. To further refine masks obtained by compressed\nvectors, we propose for the first time a compressed vector based multi-stage\nrefinement framework. However, the vanilla combination does not bring\nsignificant gains, because changes in some elements of the DCT vector will\naffect the prediction of the entire mask. Thus, we propose a simple and novel\nmethod named PatchDCT, which separates the mask decoded from a DCT vector into\nseveral patches and refines each patch by the designed classifier and\nregressor. Specifically, the classifier is used to distinguish mixed patches\nfrom all patches, and to correct previously mispredicted foreground and\nbackground patches. In contrast, the regressor is used for DCT vector\nprediction of mixed patches, further refining the segmentation quality at\nboundary locations. Experiments on COCO show that our method achieves 2.0%,\n3.2%, 4.5% AP and 3.4%, 5.3%, 7.0% Boundary AP improvements over Mask-RCNN on\nCOCO, LVIS, and Cityscapes, respectively. It also surpasses DCT-Mask by 0.7%,\n1.1%, 1.3% AP and 0.9%, 1.7%, 4.2% Boundary AP on COCO, LVIS and Cityscapes.\nBesides, the performance of PatchDCT is also competitive with other\nstate-of-the-art methods.\n","authors":["Qinrou Wen","Jirui Yang","Xue Yang","Kewei Liang"],"pdf_url":"https://arxiv.org/pdf/2302.02693v2.pdf","comment":"15 pages, 7 figures, 13 tables, accepted by ICLR 2023, the source\n  code is available at https://github.com/olivia-w12/PatchDCT"},{"id":"http://arxiv.org/abs/2212.03434v2","updated":"2023-02-07T13:00:04Z","published":"2022-12-07T03:39:18Z","title":"Name Your Colour For the Task: Artificially Discover Colour Naming via\n  Colour Quantisation Transformer","summary":"  The long-standing theory that a colour-naming system evolves under dual\npressure of efficient communication and perceptual mechanism is supported by\nmore and more linguistic studies, including analysing four decades of\ndiachronic data from the Nafaanra language. This inspires us to explore whether\nmachine learning could evolve and discover a similar colour-naming system via\noptimising the communication efficiency represented by high-level recognition\nperformance. Here, we propose a novel colour quantisation transformer,\nCQFormer, that quantises colour space while maintaining the accuracy of machine\nrecognition on the quantised images. Given an RGB image, Annotation Branch maps\nit into an index map before generating the quantised image with a colour\npalette; meanwhile the Palette Branch utilises a key-point detection way to\nfind proper colours in the palette among the whole colour space. By interacting\nwith colour annotation, CQFormer is able to balance both the machine vision\naccuracy and colour perceptual structure such as distinct and stable colour\ndistribution for discovered colour system. Very interestingly, we even observe\nthe consistent evolution pattern between our artificial colour system and basic\ncolour terms across human languages. Besides, our colour quantisation method\nalso offers an efficient quantisation method that effectively compresses the\nimage storage while maintaining high performance in high-level recognition\ntasks such as classification and detection. Extensive experiments demonstrate\nthe superior performance of our method with extremely low bit-rate colours,\nshowing potential to integrate into quantisation network to quantities from\nimage to network activation. We will release the source code upon acceptance.\n","authors":["Shenghan Su","Lin Gu","Yue Yang","Jingjing Shen","Hiroaki Yamane","Zenghui Zhang","Tatsuya Harada"],"pdf_url":"https://arxiv.org/pdf/2212.03434v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03442v1","updated":"2023-02-07T12:55:15Z","published":"2023-02-07T12:55:15Z","title":"Using t-distributed stochastic neighbor embedding for visualization and\n  segmentation of 3D point clouds of plants","summary":"  In this work, the use of t-SNE is proposed to embed 3D point clouds of plants\ninto 2D space for plant characterization. It is demonstrated that t-SNE\noperates as a practical tool to flatten and visualize a complete 3D plant model\nin 2D space. The perplexity parameter of t-SNE allows 2D rendering of plant\nstructures at various organizational levels. Aside from the promise of serving\nas a visualization tool for plant scientists, t-SNE also provides a gateway for\nprocessing 3D point clouds of plants using their embedded counterparts in 2D.\nIn this paper, simple methods were proposed to perform semantic segmentation\nand instance segmentation via grouping the embedded 2D points. The evaluation\nof these methods on a public 3D plant data set conveys the potential of t-SNE\nfor enabling of 2D implementation of various steps involved in automatic 3D\nphenotyping pipelines.\n","authors":["Helin Dutagaci"],"pdf_url":"https://arxiv.org/pdf/2302.03442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11482v3","updated":"2023-02-07T12:43:42Z","published":"2023-01-27T01:11:42Z","title":"Diffusion Denoising for Low-Dose-CT Model","summary":"  Low-dose Computed Tomography (LDCT) reconstruction is an important task in\nmedical image analysis. Recent years have seen many deep learning based\nmethods, proved to be effective in this area. However, these methods mostly\nfollow a supervised architecture, which needs paired CT image of full dose and\nquarter dose, and the solution is highly dependent on specific measurements. In\nthis work, we introduce Denoising Diffusion LDCT Model, dubbed as DDLM,\ngenerating noise-free CT image using conditioned sampling. DDLM uses pretrained\nmodel, and need no training nor tuning process, thus our proposal is in\nunsupervised manner. Experiments on LDCT images have shown comparable\nperformance of DDLM using less inference time, surpassing other\nstate-of-the-art methods, proving both accurate and efficient. Implementation\ncode will be set to public soon.\n","authors":["Runyi Li"],"pdf_url":"https://arxiv.org/pdf/2301.11482v3.pdf","comment":"The method and experiment of this paper has some error, and we need\n  to revise it"},{"id":"http://arxiv.org/abs/2211.13726v2","updated":"2023-02-07T12:42:18Z","published":"2022-11-24T17:26:27Z","title":"Lightweight Event-based Optical Flow Estimation via Iterative Deblurring","summary":"  Inspired by frame-based methods, state-of-the-art event-based optical flow\nnetworks rely on the explicit computation of correlation volumes, which are\nexpensive to compute and store on systems with limited processing budget and\nmemory. To this end, we introduce IDNet (Iterative Deblurring Network), a\nlightweight yet well-performing event-based optical flow network without using\ncorrelation volumes. IDNet leverages the unique spatiotemporally continuous\nnature of event streams to propose an alternative way of implicitly capturing\ncorrelation through iterative refinement and motion deblurring. Our network\ndoes not compute correlation volumes but rather utilizes a recurrent network to\nmaximize the spatiotemporal correlation of events iteratively. We further\npropose two iterative update schemes: \"ID\" which iterates over the same batch\nof events, and \"TID\" which iterates over time with streaming events in an\nonline fashion. Benchmark results show the former \"ID\" scheme can reach close\nto state-of-the-art performance with 33% of savings in compute and 90% in\nmemory footprint, while the latter \"TID\" scheme is even more efficient\npromising 83% of compute savings and 15 times less latency at the cost of 18%\nof performance drop.\n","authors":["Yilun Wu","Federico Paredes-Vallés","Guido C. H. E. de Croon"],"pdf_url":"https://arxiv.org/pdf/2211.13726v2.pdf","comment":"Added supplementary materials"},{"id":"http://arxiv.org/abs/2302.03432v1","updated":"2023-02-07T12:36:35Z","published":"2023-02-07T12:36:35Z","title":"SimCon Loss with Multiple Views for Text Supervised Semantic\n  Segmentation","summary":"  Learning to segment images purely by relying on the image-text alignment from\nweb data can lead to sub-optimal performance due to noise in the data. The\nnoise comes from the samples where the associated text does not correlate with\nthe image's visual content. Instead of purely relying on the alignment from the\nnoisy data, this paper proposes a novel loss function termed SimCon, which\naccounts for intra-modal similarities to determine the appropriate set of\npositive samples to align. Further, using multiple views of the image (created\nsynthetically) for training and combining the SimCon loss with it makes the\ntraining more robust. This version of the loss is termed MV-SimCon. The\nempirical results demonstrate that using the proposed loss function leads to\nconsistent improvements on zero-shot, text supervised semantic segmentation and\noutperforms state-of-the-art by $+3.0\\%$, $+3.3\\%$ and $+6.9\\%$ on PASCAL VOC,\nPASCAL Context and MSCOCO, respectively. With test time augmentations, we set a\nnew record by improving these results further to $58.7\\%$, $26.6\\%$, and\n$33.3\\%$ on PASCAL VOC, PASCAL Context, and MSCOCO, respectively. In addition,\nusing the proposed loss function leads to robust training and faster\nconvergence.\n","authors":["Yash Patel","Yusheng Xie","Yi Zhu","Srikar Appalaraju","R. Manmatha"],"pdf_url":"https://arxiv.org/pdf/2302.03432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.04220v2","updated":"2023-02-07T12:35:18Z","published":"2022-07-09T08:01:11Z","title":"Rethinking Persistent Homology for Visual Recognition","summary":"  Persistent topological properties of an image serve as an additional\ndescriptor providing an insight that might not be discovered by traditional\nneural networks. The existing research in this area focuses primarily on\nefficiently integrating topological properties of the data in the learning\nprocess in order to enhance the performance. However, there is no existing\nstudy to demonstrate all possible scenarios where introducing topological\nproperties can boost or harm the performance. This paper performs a detailed\nanalysis of the effectiveness of topological properties for image\nclassification in various training scenarios, defined by: the number of\ntraining samples, the complexity of the training data and the complexity of the\nbackbone network. We identify the scenarios that benefit the most from\ntopological features, e.g., training simple networks on small datasets.\nAdditionally, we discuss the problem of topological consistency of the datasets\nwhich is one of the major bottlenecks for using topological features for\nclassification. We further demonstrate how the topological inconsistency can\nharm the performance for certain scenarios.\n","authors":["Ekaterina Khramtsova","Guido Zuccon","Xi Wang","Mahsa Baktashmotlagh"],"pdf_url":"https://arxiv.org/pdf/2207.04220v2.pdf","comment":"ICML 2022 Workshop on Topology, Algebra, and Geometry in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2302.02524v2","updated":"2023-02-07T12:25:20Z","published":"2023-02-06T01:44:45Z","title":"Novel Fundus Image Preprocessing for Retcam Images to Improve Deep\n  Learning Classification of Retinopathy of Prematurity","summary":"  Retinopathy of Prematurity (ROP) is a potentially blinding eye disorder\nbecause of damage to the eye's retina which can affect babies born prematurely.\nScreening of ROP is essential for early detection and treatment. This is a\nlaborious and manual process which requires trained physician performing\ndilated ophthalmological examination which can be subjective resulting in lower\ndiagnosis success for clinically significant disease. Automated diagnostic\nmethods can assist ophthalmologists increase diagnosis accuracy using deep\nlearning. Several research groups have highlighted various approaches. This\npaper proposes the use of new novel fundus preprocessing methods using\npretrained transfer learning frameworks to create hybrid models to give higher\ndiagnosis accuracy. The evaluations show that these novel methods in comparison\nto traditional imaging processing contribute to higher accuracy in classifying\nPlus disease, Stages of ROP and Zones. We achieve accuracy of 97.65% for Plus\ndisease, 89.44% for Stage, 90.24% for Zones with limited training dataset.\n","authors":["Sajid Rahim","Kourosh Sabri","Anna Ells","Alan Wassyng","Mark Lawford","Linyang Chu","Wenbo He"],"pdf_url":"https://arxiv.org/pdf/2302.02524v2.pdf","comment":"10 pages, 4 figures, 7 tables. arXiv admin note: text overlap with\n  arXiv:1904.08796 by other authors"},{"id":"http://arxiv.org/abs/2302.03406v1","updated":"2023-02-07T11:24:11Z","published":"2023-02-07T11:24:11Z","title":"High-Resolution GAN Inversion for Degraded Images in Large Diverse\n  Datasets","summary":"  The last decades are marked by massive and diverse image data, which shows\nincreasingly high resolution and quality. However, some images we obtained may\nbe corrupted, affecting the perception and the application of downstream tasks.\nA generic method for generating a high-quality image from the degraded one is\nin demand. In this paper, we present a novel GAN inversion framework that\nutilizes the powerful generative ability of StyleGAN-XL for this problem. To\nease the inversion challenge with StyleGAN-XL, Clustering \\& Regularize\nInversion (CRI) is proposed. Specifically, the latent space is firstly divided\ninto finer-grained sub-spaces by clustering. Instead of initializing the\ninversion with the average latent vector, we approximate a centroid latent\nvector from the clusters, which generates an image close to the input image.\nThen, an offset with a regularization term is introduced to keep the inverted\nlatent vector within a certain range. We validate our CRI scheme on multiple\nrestoration tasks (i.e., inpainting, colorization, and super-resolution) of\ncomplex natural images, and show preferable quantitative and qualitative\nresults. We further demonstrate our technique is robust in terms of data and\ndifferent GAN models. To our best knowledge, we are the first to adopt\nStyleGAN-XL for generating high-quality natural images from diverse degraded\ninputs. Code is available at https://github.com/Booooooooooo/CRI.\n","authors":["Yanbo Wang","Chuming Lin","Donghao Luo","Ying Tai","Zhizhong Zhang","Yuan Xie"],"pdf_url":"https://arxiv.org/pdf/2302.03406v1.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.03397v1","updated":"2023-02-07T11:04:14Z","published":"2023-02-07T11:04:14Z","title":"AniPixel: Towards Animatable Pixel-Aligned Human Avatar","summary":"  Neural radiance field using pixel-aligned features can render photo-realistic\nnovel views. However, when pixel-aligned features are directly introduced to\nhuman avatar reconstruction, the rendering can only be conducted for still\nhumans, rather than animatable avatars. In this paper, we propose AniPixel, a\nnovel animatable and generalizable human avatar reconstruction method that\nleverages pixel-aligned features for body geometry prediction and RGB color\nblending. Technically, to align the canonical space with the target space and\nthe observation space, we propose a bidirectional neural skinning field based\non skeleton-driven deformation to establish the target-to-canonical and\ncanonical-to-observation correspondences. Then, we disentangle the canonical\nbody geometry into a normalized neutral-sized body and a subject-specific\nresidual for better generalizability. As the geometry and appearance are\nclosely related, we introduce pixel-aligned features to facilitate the body\ngeometry prediction and detailed surface normals to reinforce the RGB color\nblending. Moreover, we devise a pose-dependent and view direction-related\nshading module to represent the local illumination variance. Experiments show\nthat our AniPixel renders comparable novel views while delivering better novel\npose animation results than state-of-the-art methods. The code will be\nreleased.\n","authors":["Jinlong Fan","Jing Zhang","Zhi Hou","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.03397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08414v2","updated":"2023-02-07T09:48:34Z","published":"2023-01-20T04:02:13Z","title":"FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation","summary":"  The great potential of unsupervised monocular depth estimation has been\ndemonstrated by many works due to low annotation cost and impressive accuracy\ncomparable to supervised methods. To further improve the performance, recent\nworks mainly focus on designing more complex network structures and exploiting\nextra supervised information, e.g., semantic segmentation. These methods\noptimize the models by exploiting the reconstructed relationship between the\ntarget and reference images in varying degrees. However, previous methods prove\nthat this image reconstruction optimization is prone to get trapped in local\nminima. In this paper, our core idea is to guide the optimization with prior\nknowledge from pretrained Flow-Net. And we show that the bottleneck of\nunsupervised monocular depth estimation can be broken with our simple but\neffective framework named FG-Depth. In particular, we propose (i) a flow\ndistillation loss to replace the typical photometric loss that limits the\ncapacity of the model and (ii) a prior flow based mask to remove invalid pixels\nthat bring the noise in training loss. Extensive experiments demonstrate the\neffectiveness of each component, and our approach achieves state-of-the-art\nresults on both KITTI and NYU-Depth-v2 datasets.\n","authors":["Junyu Zhu","Lina Liu","Yong Liu","Wanlong Li","Feng Wen","Hongbo Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08414v2.pdf","comment":"Accepted by ICRA2023"},{"id":"http://arxiv.org/abs/2211.12109v2","updated":"2023-02-07T09:28:48Z","published":"2022-11-22T09:22:28Z","title":"Video compression dataset and benchmark of learning-based video-quality\n  metrics","summary":"  Video-quality measurement is a critical task in video processing. Nowadays,\nmany implementations of new encoding standards - such as AV1, VVC, and LCEVC -\nuse deep-learning-based decoding algorithms with perceptual metrics that serve\nas optimization objectives. But investigations of the performance of modern\nvideo- and image-quality metrics commonly employ videos compressed using older\nstandards, such as AVC. In this paper, we present a new benchmark for\nvideo-quality metrics that evaluates video compression. It is based on a new\ndataset consisting of about 2,500 streams encoded using different standards,\nincluding AVC, HEVC, AV1, VP9, and VVC. Subjective scores were collected using\ncrowdsourced pairwise comparisons. The list of evaluated metrics includes\nrecent ones based on machine learning and neural networks. The results\ndemonstrate that new no-reference metrics exhibit a high correlation with\nsubjective quality and approach the capability of top full-reference metrics.\n","authors":["Anastasia Antsiferova","Sergey Lavrushkin","Maksim Smirnov","Alexander Gushchin","Dmitriy Vatolin","Dmitriy Kulikov"],"pdf_url":"https://arxiv.org/pdf/2211.12109v2.pdf","comment":"10 pages, 4 figures, 6 tables, 1 supplementary material"},{"id":"http://arxiv.org/abs/2302.03318v1","updated":"2023-02-07T08:48:34Z","published":"2023-02-07T08:48:34Z","title":"PAMI: partition input and aggregate outputs for model interpretation","summary":"  There is an increasing demand for interpretation of model predictions\nespecially in high-risk applications. Various visualization approaches have\nbeen proposed to estimate the part of input which is relevant to a specific\nmodel prediction. However, most approaches require model structure and\nparameter details in order to obtain the visualization results, and in general\nmuch effort is required to adapt each approach to multiple types of tasks\nparticularly when model backbone and input format change over tasks. In this\nstudy, a simple yet effective visualization framework called PAMI is proposed\nbased on the observation that deep learning models often aggregate features\nfrom local regions for model predictions. The basic idea is to mask majority of\nthe input and use the corresponding model output as the relative contribution\nof the preserved input part to the original model prediction. For each input,\nsince only a set of model outputs are collected and aggregated, PAMI does not\nrequire any model detail and can be applied to various prediction tasks with\ndifferent model backbones and input formats. Extensive experiments on multiple\ntasks confirm the proposed method performs better than existing visualization\napproaches in more precisely finding class-specific input regions, and when\napplied to different model backbones and input formats. The source code will be\nreleased publicly.\n","authors":["Wei Shi","Wentao Zhang","Ruixuan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03318v1.pdf","comment":"28 figures"},{"id":"http://arxiv.org/abs/2207.07253v4","updated":"2023-02-07T08:41:17Z","published":"2022-07-15T01:59:14Z","title":"Single Shot Self-Reliant Scene Text Spotter by Decoupled yet\n  Collaborative Detection and Recognition","summary":"  Typical text spotters follow the two-stage spotting paradigm which detects\nthe boundary for a text instance first and then performs text recognition\nwithin the detected regions. Despite the remarkable progress of such spotting\nparadigm, an important limitation is that the performance of text recognition\ndepends heavily on the precision of text detection, resulting in the potential\nerror propagation from detection to recognition. In this work, we propose the\nsingle shot Self-Reliant Scene Text Spotter v2 (SRSTS v2), which circumvents\nthis limitation by decoupling recognition from detection while optimizing two\ntasks collaboratively. Specifically, our SRSTS v2 samples representative\nfeature points around each potential text instance, and conducts both text\ndetection and recognition in parallel guided by these sampled points. Thus, the\ntext recognition is no longer dependent on detection, thereby alleviating the\nerror propagation from detection to recognition. Moreover, the sampling module\nis learned under the supervision from both detection and recognition, which\nallows for the collaborative optimization and mutual enhancement between two\ntasks. Benefiting from such sampling-driven concurrent spotting framework, our\napproach is able to recognize the text instances correctly even if the precise\ntext boundaries are challenging to detect. Extensive experiments on four\nbenchmarks demonstrate that our method compares favorably to state-of-the-art\nspotters.\n","authors":["Jingjing Wu","Pengyuan Lyu","Guangming Lu","Chengquan Zhang","Wenjie Pei"],"pdf_url":"https://arxiv.org/pdf/2207.07253v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08892v2","updated":"2023-02-07T08:31:36Z","published":"2022-12-17T15:05:25Z","title":"Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud\n  Analysis","summary":"  Point clouds are characterized by irregularity and unstructuredness, which\npose challenges in efficient data exploitation and discriminative feature\nextraction. In this paper, we present an unsupervised deep neural architecture\ncalled Flattening-Net to represent irregular 3D point clouds of arbitrary\ngeometry and topology as a completely regular 2D point geometry image (PGI)\nstructure, in which coordinates of spatial points are captured in colors of\nimage pixels. \\mr{Intuitively, Flattening-Net implicitly approximates a locally\nsmooth 3D-to-2D surface flattening process while effectively preserving\nneighborhood consistency.} \\mr{As a generic representation modality, PGI\ninherently encodes the intrinsic property of the underlying manifold structure\nand facilitates surface-style point feature aggregation.} To demonstrate its\npotential, we construct a unified learning framework directly operating on PGIs\nto achieve \\mr{diverse types of high-level and low-level} downstream\napplications driven by specific task networks, including classification,\nsegmentation, reconstruction, and upsampling. Extensive experiments demonstrate\nthat our methods perform favorably against the current state-of-the-art\ncompetitors. We will make the code and data publicly available at\nhttps://github.com/keeganhk/Flattening-Net.\n","authors":["Qijian Zhang","Junhui Hou","Yue Qian","Yiming Zeng","Juyong Zhang","Ying He"],"pdf_url":"https://arxiv.org/pdf/2212.08892v2.pdf","comment":"Accepted to TPAMI"},{"id":"http://arxiv.org/abs/2212.02277v4","updated":"2023-02-07T08:03:40Z","published":"2022-12-05T13:55:02Z","title":"R2FD2: Fast and Robust Matching of Multimodal Remote Sensing Image via\n  Repeatable Feature Detector and Rotation-invariant Feature Descriptor","summary":"  Automatically identifying feature correspondences between multimodal images\nis facing enormous challenges because of the significant differences both in\nradiation and geometry. To address these problems, we propose a novel feature\nmatching method (named R2FD2) that is robust to radiation and rotation\ndifferences. Our R2FD2 is conducted in two critical contributions, consisting\nof a repeatable feature detector and a rotation-invariant feature descriptor.\nIn the first stage, a repeatable feature detector called the Multi-channel\nAuto-correlation of the Log-Gabor (MALG) is presented for feature detection,\nwhich combines the multi-channel auto-correlation strategy with the Log-Gabor\nwavelets to detect interest points (IPs) with high repeatability and uniform\ndistribution. In the second stage, a rotation-invariant feature descriptor is\nconstructed, named the Rotation-invariant Maximum index map of the Log-Gabor\n(RMLG), which consists of two components: fast assignment of dominant\norientation and construction of feature representation. In the process of fast\nassignment of dominant orientation, a Rotation-invariant Maximum Index Map\n(RMIM) is built to address rotation deformations. Then, the proposed RMLG\nincorporates the rotation-invariant RMIM with the spatial configuration of\nDAISY to depict a more discriminative feature representation, which improves\nRMLG's resistance to radiation and rotation variances.Experimental results show\nthat the proposed R2FD2 outperforms five state-of-the-art feature matching\nmethods, and has superior advantages in adaptability and universality.\nMoreover, our R2FD2 achieves the accuracy of matching within two pixels and has\na great advantage in matching efficiency over other state-of-the-art methods.\n","authors":["Bai Zhu","Chao Yang","Jinkun Dai","Jianwei Fan","Yuanxin Ye"],"pdf_url":"https://arxiv.org/pdf/2212.02277v4.pdf","comment":"33 pages, 15 figures"},{"id":"http://arxiv.org/abs/2302.00912v3","updated":"2023-02-07T08:01:50Z","published":"2023-02-02T07:07:35Z","title":"Advances and Challenges in Multimodal Remote Sensing Image Registration","summary":"  Over the past few decades, with the rapid development of global aerospace and\naerial remote sensing technology, the types of sensors have evolved from the\ntraditional monomodal sensors (e.g., optical sensors) to the new generation of\nmultimodal sensors [e.g., multispectral, hyperspectral, light detection and\nranging (LiDAR) and synthetic aperture radar (SAR) sensors]. These advanced\ndevices can dynamically provide various and abundant multimodal remote sensing\nimages with different spatial, temporal, and spectral resolutions according to\ndifferent application requirements. Since then, it is of great scientific\nsignificance to carry out the research of multimodal remote sensing image\nregistration, which is a crucial step for integrating the complementary\ninformation among multimodal data and making comprehensive observations and\nanalysis of the Earths surface. In this work, we will present our own\ncontributions to the field of multimodal image registration, summarize the\nadvantages and limitations of existing multimodal image registration methods,\nand then discuss the remaining challenges and make a forward-looking prospect\nfor the future development of the field.\n","authors":["Bai Zhu","Liang Zhou","Simiao Pu","Jianwei Fan","Yuanxin Ye"],"pdf_url":"https://arxiv.org/pdf/2302.00912v3.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2203.07720v3","updated":"2023-02-07T07:54:51Z","published":"2022-03-15T08:18:27Z","title":"Revitalize Region Feature for Democratizing Video-Language Pre-training\n  of Retrieval","summary":"  Recent dominant methods for video-language pre-training (VLP) learn\ntransferable representations from the raw pixels in an end-to-end manner to\nachieve advanced performance on downstream video-language retrieval. Despite\nthe impressive results, VLP research becomes extremely expensive with the need\nfor massive data and a long training time, preventing further explorations. In\nthis work, we revitalize region features of sparsely sampled video clips to\nsignificantly reduce both spatial and temporal visual redundancy towards\ndemocratizing VLP research at the same time achieving state-of-the-art results.\nSpecifically, to fully explore the potential of region features, we introduce a\nnovel bidirectional region-word alignment regularization that properly\noptimizes the fine-grained relations between regions and certain words in\nsentences, eliminating the domain/modality disconnections between pre-extracted\nregion features and text. Extensive results of downstream video-language\nretrieval tasks on four datasets demonstrate the superiority of our method on\nboth effectiveness and efficiency, \\textit{e.g.}, our method achieves competing\nresults with 80\\% fewer data and 85\\% less pre-training time compared to the\nmost efficient VLP method so far \\cite{lei2021less}. The code will be available\nat \\url{https://github.com/showlab/DemoVLP}.\n","authors":["Guanyu Cai","Yixiao Ge","Binjie Zhang","Alex Jinpeng Wang","Rui Yan","Xudong Lin","Ying Shan","Lianghua He","Xiaohu Qie","Jianping Wu","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2203.07720v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03916v2","updated":"2023-02-07T07:33:25Z","published":"2022-04-08T08:29:52Z","title":"A Survey of Supernet Optimization and its Applications: Spatial and\n  Temporal Optimization for Neural Architecture Search","summary":"  This survey focuses on categorizing and evaluating the methods of supernet\noptimization in the field of Neural Architecture Search (NAS). Supernet\noptimization involves training a single, over-parameterized network that\nencompasses the search space of all possible network architectures. The survey\nanalyses supernet optimization methods based on their approaches to spatial and\ntemporal optimization. Spatial optimization relates to optimizing the\narchitecture and parameters of the supernet and its subnets, while temporal\noptimization deals with improving the efficiency of selecting architectures\nfrom the supernet. The benefits, limitations, and potential applications of\nthese methods in various tasks and settings, including transferability, domain\ngeneralization, and Transformer models, are also discussed.\n","authors":["Stephen Cha","Taehyeon Kim","Hayeon Lee","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2204.03916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10690v2","updated":"2023-02-07T07:33:25Z","published":"2022-06-21T19:12:06Z","title":"Learning Continuous Rotation Canonicalization with Radial Beam Sampling","summary":"  Nearly all state of the art vision models are sensitive to image rotations.\nExisting methods often compensate for missing inductive biases by using\naugmented training data to learn pseudo-invariances. Alongside the resource\ndemanding data inflation process, predictions often poorly generalize. The\ninductive biases inherent to convolutional neural networks allow for\ntranslation equivariance through kernels acting parallely to the horizontal and\nvertical axes of the pixel grid. This inductive bias, however, does not allow\nfor rotation equivariance. We propose a radial beam sampling strategy along\nwith radial kernels operating on these beams to inherently incorporate\ncenter-rotation covariance. Together with an angle distance loss, we present a\nradial beam-based image canonicalization model, short BIC. Our model allows for\nmaximal continuous angle regression and canonicalizes arbitrary center-rotated\ninput images. As a pre-processing model, this enables rotation-invariant vision\npipelines with model-agnostic rotation-sensitive downstream predictions. We\nshow that our end-to-end trained angle regressor is able to predict continuous\nrotation angles on several vision datasets, i.e. FashionMNIST, CIFAR10,\nCOIL100, and LFW.\n","authors":["Johann Schmidt","Sebastian Stober"],"pdf_url":"https://arxiv.org/pdf/2206.10690v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03299v1","updated":"2023-02-07T07:26:00Z","published":"2023-02-07T07:26:00Z","title":"3D Vessel Segmentation with Limited Guidance of 2D Structure-agnostic\n  Vessel Annotations","summary":"  Delineating 3D blood vessels is essential for clinical diagnosis and\ntreatment, however, is challenging due to complex structure variations and\nvaried imaging conditions. Supervised deep learning has demonstrated its\nsuperior capacity in automatic 3D vessel segmentation. However, the reliance on\nexpensive 3D manual annotations and limited capacity for annotation reuse\nhinder the clinical applications of supervised models. To avoid the repetitive\nand laborious annotating and make full use of existing vascular annotations,\nthis paper proposes a novel 3D shape-guided local discrimination model for 3D\nvascular segmentation under limited guidance from public 2D vessel annotations.\nThe primary hypothesis is that 3D vessels are composed of semantically similar\nvoxels and exhibit tree-shaped morphology. Accordingly, the 3D region\ndiscrimination loss is firstly proposed to learn the discriminative\nrepresentation measuring voxel-wise similarities and cluster semantically\nconsistent voxels to form the candidate 3D vascular segmentation in unlabeled\nimages; secondly, based on the similarity of the tree-shaped morphology between\n2D and 3D vessels, the Crop-and-Overlap strategy is presented to generate\nreference masks from 2D structure-agnostic vessel annotations, which are fit\nfor varied vascular structures, and the adversarial loss is introduced to guide\nthe tree-shaped morphology of 3D vessels; thirdly, the temporal consistency\nloss is proposed to foster the training stability and keep the model updated\nsmoothly. To further enhance the model's robustness and reliability, the\norientation-invariant CNN module and Reliability-Refinement algorithm are\npresented. Experimental results from the public 3D cerebrovascular and 3D\narterial tree datasets demonstrate that our model achieves comparable\neffectiveness against nine supervised models.\n","authors":["Huai Chen","Xiuying Wang","Lisheng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03299v1.pdf","comment":"Submitted to IEEE TMI Journal"},{"id":"http://arxiv.org/abs/2302.03298v1","updated":"2023-02-07T07:13:53Z","published":"2023-02-07T07:13:53Z","title":"Boosting Zero-shot Classification with Synthetic Data Diversity via\n  Stable Diffusion","summary":"  Recent research has shown it is possible to perform zero-shot classification\ntasks by training a classifier with synthetic data generated by a diffusion\nmodel. However, the performance of this approach is still inferior to that of\nrecent vision-language models. It has been suggested that the reason for this\nis a domain gap between the synthetic and real data. In our work, we show that\nthis domain gap is not the main issue, and that diversity in the synthetic\ndataset is more important. We propose a \\textit{bag of tricks} to improve\ndiversity and are able to achieve performance on par with one of the\nvision-language models, CLIP. More importantly, this insight allows us to endow\nzero-shot classification capabilities on any classification model.\n","authors":["Jordan Shipard","Arnold Wiliem","Kien Nguyen Thanh","Wei Xiang","Clinton Fookes"],"pdf_url":"https://arxiv.org/pdf/2302.03298v1.pdf","comment":"(7 pages, 3 figures, 2 tables, preprint)"},{"id":"http://arxiv.org/abs/2302.03296v1","updated":"2023-02-07T07:09:19Z","published":"2023-02-07T07:09:19Z","title":"Multi-organ segmentation: a progressive exploration of learning\n  paradigms under scarce annotation","summary":"  Precise delineation of multiple organs or abnormal regions in the human body\nfrom medical images plays an essential role in computer-aided diagnosis,\nsurgical simulation, image-guided interventions, and especially in radiotherapy\ntreatment planning. Thus, it is of great significance to explore automatic\nsegmentation approaches, among which deep learning-based approaches have\nevolved rapidly and witnessed remarkable progress in multi-organ segmentation.\nHowever, obtaining an appropriately sized and fine-grained annotated dataset of\nmultiple organs is extremely hard and expensive. Such scarce annotation limits\nthe development of high-performance multi-organ segmentation models but\npromotes many annotation-efficient learning paradigms. Among these, studies on\ntransfer learning leveraging external datasets, semi-supervised learning using\nunannotated datasets and partially-supervised learning integrating\npartially-labeled datasets have led the dominant way to break such dilemma in\nmulti-organ segmentation. We first review the traditional fully supervised\nmethod, then present a comprehensive and systematic elaboration of the 3\nabovementioned learning paradigms in the context of multi-organ segmentation\nfrom both technical and methodological perspectives, and finally summarize\ntheir challenges and future trends.\n","authors":["Shiman Li","Haoran Wang","Yucong Meng","Chenxi Zhang","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2302.03296v1.pdf","comment":"23 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2302.03292v1","updated":"2023-02-07T07:05:00Z","published":"2023-02-07T07:05:00Z","title":"Fine-grained Affordance Annotation for Egocentric Hand-Object\n  Interaction Videos","summary":"  Object affordance is an important concept in hand-object interaction,\nproviding information on action possibilities based on human motor capacity and\nobjects' physical property thus benefiting tasks such as action anticipation\nand robot imitation learning. However, the definition of affordance in existing\ndatasets often: 1) mix up affordance with object functionality; 2) confuse\naffordance with goal-related action; and 3) ignore human motor capacity. This\npaper proposes an efficient annotation scheme to address these issues by\ncombining goal-irrelevant motor actions and grasp types as affordance labels\nand introducing the concept of mechanical action to represent the action\npossibilities between two objects. We provide new annotations by applying this\nscheme to the EPIC-KITCHENS dataset and test our annotation with tasks such as\naffordance recognition, hand-object interaction hotspots prediction, and\ncross-domain evaluation of affordance. The results show that models trained\nwith our annotation can distinguish affordance from other concepts, predict\nfine-grained interaction possibilities on objects, and generalize through\ndifferent domains.\n","authors":["Zecheng Yu","Yifei Huang","Ryosuke Furuta","Takuma Yagi","Yusuke Goutsu","Yoichi Sato"],"pdf_url":"https://arxiv.org/pdf/2302.03292v1.pdf","comment":"WACV. arXiv admin note: substantial text overlap with\n  arXiv:2206.05424"},{"id":"http://arxiv.org/abs/2207.05515v5","updated":"2023-02-07T06:48:40Z","published":"2022-07-12T13:17:38Z","title":"Compound Prototype Matching for Few-shot Action Recognition","summary":"  Few-shot action recognition aims to recognize novel action classes using only\na small number of labeled training samples. In this work, we propose a novel\napproach that first summarizes each video into compound prototypes consisting\nof a group of global prototypes and a group of focused prototypes, and then\ncompares video similarity based on the prototypes. Each global prototype is\nencouraged to summarize a specific aspect from the entire video, for example,\nthe start/evolution of the action. Since no clear annotation is provided for\nthe global prototypes, we use a group of focused prototypes to focus on certain\ntimestamps in the video. We compare video similarity by matching the compound\nprototypes between the support and query videos. The global prototypes are\ndirectly matched to compare videos from the same perspective, for example, to\ncompare whether two actions start similarly. For the focused prototypes, since\nactions have various temporal variations in the videos, we apply bipartite\nmatching to allow the comparison of actions with different temporal positions\nand shifts. Experiments demonstrate that our proposed method achieves\nstate-of-the-art results on multiple benchmarks.\n","authors":["Yifei Huang","Lijin Yang","Yoichi Sato"],"pdf_url":"https://arxiv.org/pdf/2207.05515v5.pdf","comment":"ECCV 2022"},{"id":"http://arxiv.org/abs/2302.03285v1","updated":"2023-02-07T06:34:10Z","published":"2023-02-07T06:34:10Z","title":"Improving CT Image Segmentation Accuracy Using StyleGAN Driven Data\n  Augmentation","summary":"  Medical Image Segmentation is a useful application for medical image analysis\nincluding detecting diseases and abnormalities in imaging modalities such as\nMRI, CT etc. Deep learning has proven to be promising for this task but usually\nhas a low accuracy because of the lack of appropriate publicly available\nannotated or segmented medical datasets. In addition, the datasets that are\navailable may have a different texture because of different dosage values or\nscanner properties than the images that need to be segmented. This paper\npresents a StyleGAN-driven approach for segmenting publicly available large\nmedical datasets by using readily available extremely small annotated datasets\nin similar modalities. The approach involves augmenting the small segmented\ndataset and eliminating texture differences between the two datasets. The\ndataset is augmented by being passed through six different StyleGANs that are\ntrained on six different style images taken from the large non-annotated\ndataset we want to segment. Specifically, style transfer is used to augment the\ntraining dataset. The annotations of the training dataset are hence combined\nwith the textures of the non-annotated dataset to generate new anatomically\nsound images. The augmented dataset is then used to train a U-Net segmentation\nnetwork which displays a significant improvement in the segmentation accuracy\nin segmenting the large non-annotated dataset.\n","authors":["Soham Bhosale","Arjun Krishna","Ge Wang","Klaus Mueller"],"pdf_url":"https://arxiv.org/pdf/2302.03285v1.pdf","comment":"17th International Meeting on Fully Three-Dimensional Image\n  Reconstruction in Radiology and Nuclear Medicine(Fully3D Conference)"},{"id":"http://arxiv.org/abs/2302.03282v1","updated":"2023-02-07T06:22:14Z","published":"2023-02-07T06:22:14Z","title":"An End-to-End Two-Phase Deep Learning-Based workflow to Segment Man-made\n  Objects Around Reservoirs","summary":"  Reservoirs are fundamental infrastructures for the management of water\nresources. Constructions around them can negatively impact their quality. Such\nunauthorized constructions can be monitored by land cover mapping (LCM) remote\nsensing (RS) images. In this paper, we develop a new approach based on DL and\nimage processing techniques for man-made object segmentation around the\nreservoirs. In order to segment man-made objects around the reservoirs in an\nend-to-end procedure, segmenting reservoirs and identifying the region of\ninterest (RoI) around them are essential. In the proposed two-phase workflow,\nthe reservoir is initially segmented using a DL model. A post-processing stage\nis proposed to remove errors such as floating vegetation. Next, the RoI around\nthe reservoir (RoIaR) is identified using the proposed image processing\ntechniques. Finally, the man-made objects in the RoIaR are segmented using a DL\narchitecture. We trained the proposed workflow using collected Google Earth\n(GE) images of eight reservoirs in Brazil over two different years. The\nU-Net-based and SegNet-based architectures are trained to segment the\nreservoirs. To segment man-made objects in the RoIaR, we trained and evaluated\nfour possible architectures, U-Net, FPN, LinkNet, and PSPNet. Although the\ncollected data has a high diversity (for example, they belong to different\nstates, seasons, resolutions, etc.), we achieved good performances in both\nphases. Furthermore, applying the proposed post-processing to the output of\nreservoir segmentation improves the precision in all studied reservoirs except\ntwo cases. We validated the prepared workflow with a reservoir dataset outside\nthe training reservoirs. The results show high generalization ability of the\nprepared workflow.\n","authors":["Nayereh Hamidishad","Roberto Marcondes Cesar Junior"],"pdf_url":"https://arxiv.org/pdf/2302.03282v1.pdf","comment":"21 pages, 13 figures"},{"id":"http://arxiv.org/abs/2302.01735v2","updated":"2023-02-07T06:05:05Z","published":"2023-02-03T13:50:25Z","title":"Rethinking Semi-Supervised Medical Image Segmentation: A\n  Variance-Reduction Perspective","summary":"  For medical image segmentation, contrastive learning is the dominant practice\nto improve the quality of visual representations by contrasting semantically\nsimilar and dissimilar pairs of samples. This is enabled by the observation\nthat without accessing ground truth label, negative examples with truly\ndissimilar anatomical features, if sampled, can significantly improve the\nperformance. In reality, however, these samples may come from similar\nanatomical features and the models may struggle to distinguish the minority\ntail-class samples, making the tail classes more prone to misclassification,\nboth of which typically lead to model collapse. In this paper, we propose ARCO,\na semi-supervised contrastive learning (CL) framework with stratified group\nsampling theory in medical image segmentation. In particular, we first propose\nbuilding ARCO through the concept of variance-reduced estimation, and show that\ncertain variance-reduction techniques are particularly beneficial in medical\nimage segmentation tasks with extremely limited labels. Furthermore, we\ntheoretically prove these sampling techniques are universal in variance\nreduction. Finally, we experimentally validate our approaches on three\nbenchmark datasets with different label settings, and our methods consistently\noutperform state-of-the-art semi- and fully-supervised methods. Additionally,\nwe augment the CL frameworks with these sampling techniques and demonstrate\nsignificant gains over previous methods. We believe our work is an important\nstep towards semi-supervised medical image segmentation by quantifying the\nlimitation of current self-supervision objectives for accomplishing medical\nimage analysis tasks.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Fenglin Liu","Xiaoran Zhang","Chen Feng","David A. Clifton","S Kevin Zhou","Lawrence Hamilton Staib","James S Duncan"],"pdf_url":"https://arxiv.org/pdf/2302.01735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.12924v3","updated":"2023-02-07T05:53:41Z","published":"2021-11-25T05:52:30Z","title":"Joint stereo 3D object detection and implicit surface reconstruction","summary":"  We present a new learning-based framework S-3D-RCNN that can recover accurate\nobject orientation in SO(3) and simultaneously predict implicit shapes for\noutdoor rigid objects from stereo RGB images. In contrast to previous studies\nthat map local appearance to observation angles, we explore a progressive\napproach by extracting meaningful Intermediate Geometrical Representations\n(IGRs) to estimate egocentric object orientation. This approach features a deep\nmodel that transforms perceived intensities to object part coordinates, which\nare mapped to a 3D representation encoding object orientation in the camera\ncoordinate system. To enable implicit shape estimation, the IGRs are further\nextended to model visible object surface with a point-based representation and\nexplicitly addresses the unseen surface hallucination problem. Extensive\nexperiments validate the effectiveness of the proposed IGRs and S-3D-RCNN\nachieves superior 3D scene understanding performance using existing and\nproposed new metrics on the KITTI benchmark. Code and pre-trained models will\nbe available at this https URL.\n","authors":["Shichao Li","Kwang-Ting Cheng"],"pdf_url":"https://arxiv.org/pdf/2111.12924v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06994v3","updated":"2023-02-07T05:45:00Z","published":"2022-09-15T01:48:08Z","title":"PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on\n  Transformer","summary":"  Lane detection is one of the fundamental modules in self-driving. In this\npaper we employ a transformer-only method for lane detection, thus it could\nbenefit from the blooming development of fully vision transformer and achieve\nthe state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks,\nby fine-tuning the weight fully pre-trained on large datasets. More\nimportantly, this paper proposes a novel and general framework called\nPriorLane, which is used to enhance the segmentation performance of the fully\nvision transformer by introducing the low-cost local prior knowledge.\nSpecifically, PriorLane utilizes an encoder-only transformer to fuse the\nfeature extracted by a pre-trained segmentation model with prior knowledge\nembeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted\nto enhance the fusion performance by aligning the knowledge embedding.\nExtensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA\nlane detection methods by a 2.82% mIoU when prior knowledge is employed, and\nthe code will be released at: https://github.com/vincentqqb/PriorLane.\n","authors":["Qibo Qiu","Haiming Gao","Wei Hua","Gang Huang","Xiaofei He"],"pdf_url":"https://arxiv.org/pdf/2209.06994v3.pdf","comment":"Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2302.03264v1","updated":"2023-02-07T05:29:38Z","published":"2023-02-07T05:29:38Z","title":"Delving Deep into Simplicity Bias for Long-Tailed Image Recognition","summary":"  Simplicity Bias (SB) is a phenomenon that deep neural networks tend to rely\nfavorably on simpler predictive patterns but ignore some complex features when\napplied to supervised discriminative tasks. In this work, we investigate SB in\nlong-tailed image recognition and find the tail classes suffer more severely\nfrom SB, which harms the generalization performance of such underrepresented\nclasses. We empirically report that self-supervised learning (SSL) can mitigate\nSB and perform in complementary to the supervised counterpart by enriching the\nfeatures extracted from tail samples and consequently taking better advantage\nof such rare samples. However, standard SSL methods are designed without\nexplicitly considering the inherent data distribution in terms of classes and\nmay not be optimal for long-tailed distributed data. To address this\nlimitation, we propose a novel SSL method tailored to imbalanced data. It\nleverages SSL by triple diverse levels, i.e., holistic-, partial-, and\naugmented-level, to enhance the learning of predictive complex patterns, which\nprovides the potential to overcome the severe SB on tail data. Both\nquantitative and qualitative experimental results on five long-tailed benchmark\ndatasets show our method can effectively mitigate SB and significantly\noutperform the competing state-of-the-arts.\n","authors":["Xiu-Shen Wei","Xuhao Sun","Yang Shen","Anqi Xu","Peng Wang","Faen Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02551v2","updated":"2023-02-07T04:39:13Z","published":"2023-02-06T03:59:15Z","title":"CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets","summary":"  Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot\nclassification through their ability generate embeddings for each class based\non their (natural language) names. Prior work has focused on improving the\naccuracy of these models through prompt engineering or by incorporating a small\namount of labeled downstream data (via finetuning). However, there has been\nlittle focus on improving the richness of the class names themselves, which can\npose issues when class labels are coarsely-defined and uninformative. We\npropose Classification with Hierarchical Label Sets (or CHiLS), an alternative\nstrategy for zero-shot classification specifically designed for datasets with\nimplicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each\nclass, produce a set of subclasses, using either existing label hierarchies or\nby querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though\nthese subclasses were the labels of interest; (iii) map the predicted subclass\nback to its parent to produce the final prediction. Across numerous datasets\nwith underlying hierarchical structure, CHiLS leads to improved accuracy in\nsituations both with and without ground-truth hierarchical information. CHiLS\nis simple to implement within existing CLIP pipelines and requires no\nadditional training cost. Code is available at:\nhttps://github.com/acmi-lab/CHILS.\n","authors":["Zachary Novack","Saurabh Garg","Julian McAuley","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2302.02551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10772v4","updated":"2023-02-07T04:38:39Z","published":"2022-12-21T05:08:37Z","title":"Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond","summary":"  This paper presents a comprehensive survey of low-light image and video\nenhancement. We begin with the challenging mixed over-/under-exposed images,\nwhich are under-performed by existing methods. To this end, we propose two\nvariants of the SICE dataset named SICE\\_Grad and SICE\\_Mix. Next, we introduce\nNight Wenzhou, a large-scale, high-resolution video dataset, to address the\nlack of low-light video datasets that discourages the use of low-light image\nenhancement (LLIE) methods in videos. Our Night Wenzhou dataset is challenging\nsince it consists of fast-moving aerial scenes and streetscapes with varying\nilluminations and degradation. We then construct a hierarchical taxonomy,\nconduct extensive key technique analysis, and performs experimental comparisons\nfor representative LLIE approaches using our proposed datasets and the current\nbenchmark datasets. Finally, we identify emerging applications, address\nunresolved challenges, and propose future research topics for the LLIE\ncommunity. Our datasets are available at\nhttps://github.com/ShenZheng2000/LLIE_Survey.\n","authors":["Shen Zheng","Yiling Ma","Jinqian Pan","Changjie Lu","Gaurav Gupta"],"pdf_url":"https://arxiv.org/pdf/2212.10772v4.pdf","comment":"21 pages, 9 tables, and 25 figures"},{"id":"http://arxiv.org/abs/2212.13425v4","updated":"2023-02-07T04:19:54Z","published":"2022-12-27T09:33:50Z","title":"GEDI: GEnerative and DIscriminative Training for Self-Supervised\n  Learning","summary":"  Self-supervised learning is a popular and powerful method for utilizing large\namounts of unlabeled data, for which a wide variety of training objectives have\nbeen proposed in the literature. In this study, we perform a Bayesian analysis\nof state-of-the-art self-supervised learning objectives and propose a unified\nformulation based on likelihood learning. Our analysis suggests a simple method\nfor integrating self-supervised learning with generative models, allowing for\nthe joint training of these two seemingly distinct approaches. We refer to this\ncombined framework as GEDI, which stands for GEnerative and DIscriminative\ntraining. Additionally, we demonstrate an instantiation of the GEDI framework\nby integrating an energy-based model with a cluster-based self-supervised\nlearning model. Through experiments on synthetic and real-world data, including\nSVHN, CIFAR10, and CIFAR100, we show that GEDI outperforms existing\nself-supervised learning strategies in terms of clustering performance by a\nwide margin. We also demonstrate that GEDI can be integrated into a\nneural-symbolic framework to address tasks in the small data regime, where it\ncan use logical constraints to further improve clustering and classification\nperformance.\n","authors":["Emanuele Sansone","Robin Manhaeve"],"pdf_url":"https://arxiv.org/pdf/2212.13425v4.pdf","comment":"Fixed typos/cleaned the experimental section"},{"id":"http://arxiv.org/abs/2210.07983v3","updated":"2023-02-07T04:13:39Z","published":"2022-10-14T17:27:56Z","title":"Improving Transfer Learning with a Dual Image and Video Transformer for\n  Multi-label Movie Trailer Genre Classification","summary":"  In this paper, we study the transferability of ImageNet spatial and Kinetics\nspatio-temporal representations to multi-label Movie Trailer Genre\nClassification (MTGC). In particular, we present an extensive evaluation of the\ntransferability of ConvNet and Transformer models pretrained on ImageNet and\nKinetics to Trailers12k, a new manually-curated movie trailer dataset composed\nof 12,000 videos labeled with 10 different genres and associated metadata. We\nanalyze different aspects that can influence transferability, such as frame\nrate, input video extension, and spatio-temporal modeling. In order to reduce\nthe spatio-temporal structure gap between ImageNet/Kinetics and Trailers12k, we\npropose Dual Image and Video Transformer Architecture (DIViTA), which performs\nshot detection so as to segment the trailer into highly correlated clips,\nproviding a more cohesive input for pretrained backbones and improving\ntransferability (a 1.83% increase for ImageNet and 3.75% for Kinetics). Our\nresults demonstrate that representations learned on either ImageNet or Kinetics\nare comparatively transferable to Trailers12k. Moreover, both datasets provide\ncomplementary information that can be combined to improve classification\nperformance (a 2.91% gain compared to the top single pretraining).\nInterestingly, using lightweight ConvNets as pretrained backbones resulted in\nonly a 3.46% drop in classification performance compared with the top\nTransformer while requiring only 11.82% of its parameters and 0.81% of its\nFLOPS.\n","authors":["Ricardo Montalvo-Lezama","Berenice Montalvo-Lezama","Gibran Fuentes-Pineda"],"pdf_url":"https://arxiv.org/pdf/2210.07983v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03242v1","updated":"2023-02-07T04:03:55Z","published":"2023-02-07T04:03:55Z","title":"Online Misinformation Video Detection: A Survey","summary":"  With information consumption via online video streaming becoming increasingly\npopular, misinformation video poses a new threat to the health of the online\ninformation ecosystem. Though previous studies have made much progress in\ndetecting misinformation in text and image formats, video-based misinformation\nbrings new and unique challenges to automatic detection systems: 1) high\ninformation heterogeneity brought by various modalities, 2) blurred distinction\nbetween misleading video manipulation and ubiquitous artistic video editing,\nand 3) new patterns of misinformation propagation due to the dominant role of\nrecommendation systems on online video platforms. To facilitate research on\nthis challenging task, we conduct this survey to present advances in\nmisinformation video detection research. We first analyze and characterize the\nmisinformation video from three levels including signals, semantics, and\nintents. Based on the characterization, we systematically review existing works\nfor detection from features of various modalities to techniques for clue\nintegration. We also introduce existing resources including representative\ndatasets and widely used tools. Besides summarizing existing studies, we\ndiscuss related areas and outline open issues and future directions to\nencourage and guide more research on misinformation video detection. Our\ncorresponding public repository is available at\nhttps://github.com/ICTMCG/Awesome-Misinfo-Video-Detection.\n","authors":["Yuyan Bu","Qiang Sheng","Juan Cao","Peng Qi","Danding Wang","Jintao Li"],"pdf_url":"https://arxiv.org/pdf/2302.03242v1.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2205.00415v2","updated":"2023-02-07T03:58:25Z","published":"2022-05-01T07:51:22Z","title":"Don't Blame the Annotator: Bias Already Starts in the Annotation\n  Instructions","summary":"  In recent years, progress in NLU has been driven by benchmarks. These\nbenchmarks are typically collected by crowdsourcing, where annotators write\nexamples based on annotation instructions crafted by dataset creators. In this\nwork, we hypothesize that annotators pick up on patterns in the crowdsourcing\ninstructions, which bias them to write many similar examples that are then\nover-represented in the collected data. We study this form of bias, termed\ninstruction bias, in 14 recent NLU benchmarks, showing that instruction\nexamples often exhibit concrete patterns, which are propagated by crowdworkers\nto the collected data. This extends previous work (Geva et al., 2019) and\nraises a new concern of whether we are modeling the dataset creator's\ninstructions, rather than the task. Through a series of experiments, we show\nthat, indeed, instruction bias can lead to overestimation of model performance,\nand that models struggle to generalize beyond biases originating in the\ncrowdsourcing instructions. We further analyze the influence of instruction\nbias in terms of pattern frequency and model size, and derive concrete\nrecommendations for creating future NLU benchmarks.\n","authors":["Mihir Parmar","Swaroop Mishra","Mor Geva","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2205.00415v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.02150v2","updated":"2023-02-07T03:50:25Z","published":"2023-02-04T11:49:38Z","title":"This Intestine Does Not Exist: Multiscale Residual Variational\n  Autoencoder for Realistic Wireless Capsule Endoscopy Image Generation","summary":"  Medical image synthesis has emerged as a promising solution to address the\nlimited availability of annotated medical data needed for training machine\nlearning algorithms in the context of image-based Clinical Decision Support\n(CDS) systems. To this end, Generative Adversarial Networks (GANs) have been\nmainly applied to support the algorithm training process by generating\nsynthetic images for data augmentation. However, in the field of Wireless\nCapsule Endoscopy (WCE), the limited content diversity and size of existing\npublicly available annotated datasets, adversely affect both the training\nstability and synthesis performance of GANs. Aiming to a viable solution for\nWCE image synthesis, a novel Variational Autoencoder architecture is proposed,\nnamely \"This Intestine Does not Exist\" (TIDE). The proposed architecture\ncomprises multiscale feature extraction convolutional blocks and residual\nconnections, which enable the generation of high-quality and diverse datasets\neven with a limited number of training images. Contrary to the current\napproaches, which are oriented towards the augmentation of the available\ndatasets, this study demonstrates that using TIDE, real WCE datasets can be\nfully substituted by artificially generated ones, without compromising\nclassification performance. Furthermore, qualitative and user evaluation\nstudies by experienced WCE specialists, validate from a medical viewpoint that\nboth the normal and abnormal WCE images synthesized by TIDE are sufficiently\nrealistic.\n","authors":["Dimitrios E. Diamantis","Panagiota Gatoula","Anastasios Koulaouzidis","Dimitris K. Iakovidis"],"pdf_url":"https://arxiv.org/pdf/2302.02150v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2302.02550v2","updated":"2023-02-07T03:37:01Z","published":"2023-02-06T03:55:35Z","title":"Domain Re-Modulation for Few-Shot Generative Domain Adaptation","summary":"  In this study, we investigate the task of few-shot Generative Domain\nAdaptation (GDA), which involves transferring a pre-trained generator from one\ndomain to a new domain using one or a few reference images. Building upon\nprevious research that has focused on Target-domain Consistency, Large\nDiversity, and Cross-domain Consistency, we conclude two additional desired\nproperties for GDA: Memory and Domain Association. To meet these properties, we\nproposed a novel method Domain Re-Modulation (DoRM). Specifically, DoRM freezes\nthe source generator and employs additional mapping and affine modules (M&A\nmodule) to capture the attributes of the target domain, resulting in a linearly\ncombinable domain shift in style space. This allows for high-fidelity\nmulti-domain and hybrid-domain generation by integrating multiple M&A modules\nin a single generator. DoRM is lightweight and easy to implement. Extensive\nexperiments demonstrated the superior performance of DoRM on both one-shot and\n10-shot GDA, both quantitatively and qualitatively. Additionally, for the first\ntime, multi-domain and hybrid-domain generation can be achieved with a minimal\nstorage cost by using a single model. The code will be available at\nhttps://github.com/wuyi2020/DoRM.\n","authors":["Yi Wu","Ziqiang Li","Chaoyue Wang","Heliang Zheng","Shanshan Zhao","Bin Li","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.02550v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2108.03443v6","updated":"2023-02-07T03:15:42Z","published":"2021-08-07T12:54:17Z","title":"NODEO: A Neural Ordinary Differential Equation Based Optimization\n  Framework for Deformable Image Registration","summary":"  Deformable image registration (DIR), aiming to find spatial correspondence\nbetween images, is one of the most critical problems in the domain of medical\nimage analysis. In this paper, we present a novel, generic, and accurate\ndiffeomorphic image registration framework that utilizes neural ordinary\ndifferential equations (NODEs). We model each voxel as a moving particle and\nconsider the set of all voxels in a 3D image as a high-dimensional dynamical\nsystem whose trajectory determines the targeted deformation field. Our method\nleverages deep neural networks for their expressive power in modeling dynamical\nsystems, and simultaneously optimizes for a dynamical system between the image\npairs and the corresponding transformation. Our formulation allows various\nconstraints to be imposed along the transformation to maintain desired\nregularities. Our experiment results show that our method outperforms the\nbenchmarks under various metrics. Additionally, we demonstrate the feasibility\nto expand our framework to register multiple image sets using a unified form of\ntransformation,which could possibly serve a wider range of applications.\n","authors":["Yifan Wu","Tom Z. Jiahao","Jiancong Wang","Paul A. Yushkevich","M. Ani Hsieh","James C. Gee"],"pdf_url":"https://arxiv.org/pdf/2108.03443v6.pdf","comment":"Accepted by the IEEE / CVF Computer Vision and Pattern Recognition\n  Conference (CVPR) 2022"},{"id":"http://arxiv.org/abs/2302.02394v2","updated":"2023-02-07T02:57:45Z","published":"2023-02-05T14:30:22Z","title":"Eliminating Prior Bias for Semantic Image Editing via Dual-Cycle\n  Diffusion","summary":"  The recent success of text-to-image generation diffusion models has also\nrevolutionized semantic image editing, enabling the manipulation of images\nbased on query/target texts. Despite these advancements, a significant\nchallenge lies in the potential introduction of prior bias in pre-trained\nmodels during image editing, e.g., making unexpected modifications to\ninappropriate regions. To this point, we present a novel Dual-Cycle Diffusion\nmodel that addresses the issue of prior bias by generating an unbiased mask as\nthe guidance of image editing. The proposed model incorporates a Bias\nElimination Cycle that consists of both a forward path and an inverted path,\neach featuring a Structural Consistency Cycle to ensure the preservation of\nimage content during the editing process. The forward path utilizes the\npre-trained model to produce the edited image, while the inverted path converts\nthe result back to the source image. The unbiased mask is generated by\ncomparing differences between the processed source image and the edited image\nto ensure that both conform to the same distribution. Our experiments\ndemonstrate the effectiveness of the proposed method, as it significantly\nimproves the D-CLIP score from 0.272 to 0.283. The code will be available at\nhttps://github.com/JohnDreamer/DualCycleDiffsion.\n","authors":["Zuopeng Yang","Tianshu Chu","Xin Lin","Erdun Gao","Daqing Liu","Jie Yang","Chaoyue Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07126v2","updated":"2023-02-07T02:34:50Z","published":"2022-09-15T08:19:12Z","title":"Forgetting to Remember: A Scalable Incremental Learning Framework for\n  Cross-Task Blind Image Quality Assessment","summary":"  Recent years have witnessed the great success of blind image quality\nassessment (BIQA) in various task-specific scenarios, which present invariable\ndistortion types and evaluation criteria. However, due to the rigid structure\nand learning framework, they cannot apply to the cross-task BIQA scenario,\nwhere the distortion types and evaluation criteria keep changing in practical\napplications. This paper proposes a scalable incremental learning framework\n(SILF) that could sequentially conduct BIQA across multiple evaluation tasks\nwith limited memory capacity. More specifically, we develop a dynamic parameter\nisolation strategy to sequentially update the task-specific parameter subsets,\nwhich are non-overlapped with each other. Each parameter subset is temporarily\nsettled to Remember one evaluation preference toward its corresponding task,\nand the previously settled parameter subsets can be adaptively reused in the\nfollowing BIQA to achieve better performance based on the task relevance. To\nsuppress the unrestrained expansion of memory capacity in sequential tasks\nlearning, we develop a scalable memory unit by gradually and selectively\npruning unimportant neurons from previously settled parameter subsets, which\nenable us to Forget part of previous experiences and free the limited memory\ncapacity for adapting to the emerging new tasks. Extensive experiments on\neleven IQA datasets demonstrate that our proposed method significantly\noutperforms the other state-of-the-art methods in cross-task BIQA. The source\ncode of the proposed method is available at\nhttps://github.com/maruiperfect/SILF.\n","authors":["Rui Ma","Qingbo Wu","King Ngi Ngan","Hongliang Li","Fanman Meng","Linfeng Xu"],"pdf_url":"https://arxiv.org/pdf/2209.07126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03198v1","updated":"2023-02-07T02:14:45Z","published":"2023-02-07T02:14:45Z","title":"Scaling Self-Supervised End-to-End Driving with Multi-View Attention\n  Learning","summary":"  On end-to-end driving, a large amount of expert driving demonstrations is\nused to train an agent that mimics the expert by predicting its control\nactions. This process is self-supervised on vehicle signals (e.g., steering\nangle, acceleration) and does not require extra costly supervision (human\nlabeling). Yet, the improvement of existing self-supervised end-to-end driving\nmodels has mostly given room to modular end-to-end models where labeling data\nintensive format such as semantic segmentation are required during training\ntime. However, we argue that the latest self-supervised end-to-end models were\ndeveloped in sub-optimal conditions with low-resolution images and no attention\nmechanisms. Further, those models are confined with limited field of view and\nfar from the human visual cognition which can quickly attend far-apart scene\nfeatures, a trait that provides an useful inductive bias. In this context, we\npresent a new end-to-end model, trained by self-supervised imitation learning,\nleveraging a large field of view and a self-attention mechanism. These settings\nare more contributing to the agent's understanding of the driving scene, which\nbrings a better imitation of human drivers. With only self-supervised training\ndata, our model yields almost expert performance in CARLA's Nocrash metrics and\ncould be rival to the SOTA models requiring large amounts of human labeled\ndata. To facilitate further research, our code will be released.\n","authors":["Yi Xiao","Felipe Codevilla","Diego Porres Bustamante","Antonio M. Lopez"],"pdf_url":"https://arxiv.org/pdf/2302.03198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03193v1","updated":"2023-02-07T01:56:09Z","published":"2023-02-07T01:56:09Z","title":"On the Ideal Number of Groups for Isometric Gradient Propagation","summary":"  Recently, various normalization layers have been proposed to stabilize the\ntraining of deep neural networks. Among them, group normalization is a\ngeneralization of layer normalization and instance normalization by allowing a\ndegree of freedom in the number of groups it uses. However, to determine the\noptimal number of groups, trial-and-error-based hyperparameter tuning is\nrequired, and such experiments are time-consuming. In this study, we discuss a\nreasonable method for setting the number of groups. First, we find that the\nnumber of groups influences the gradient behavior of the group normalization\nlayer. Based on this observation, we derive the ideal number of groups, which\ncalibrates the gradient scale to facilitate gradient descent optimization. Our\nproposed number of groups is theoretically grounded, architecture-aware, and\ncan provide a proper value in a layer-wise manner for all layers. The proposed\nmethod exhibited improved performance over existing methods in numerous neural\nnetwork architectures, tasks, and datasets.\n","authors":["Bum Jun Kim","Hyeyeon Choi","Hyeonah Jang","Sang Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2302.03193v1.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2211.03919v2","updated":"2023-02-07T00:55:23Z","published":"2022-11-08T00:20:38Z","title":"ShaSTA: Modeling Shape and Spatio-Temporal Affinities for 3D\n  Multi-Object Tracking","summary":"  Multi-object tracking is a cornerstone capability of any robotic system. The\nquality of tracking is largely dependent on the quality of the detector used.\nIn many applications, such as autonomous vehicles, it is preferable to\nover-detect objects to avoid catastrophic outcomes due to missed detections. As\na result, current state-of-the-art 3D detectors produce high rates of\nfalse-positives to ensure a low number of false-negatives. This can negatively\naffect tracking by making data association and track lifecycle management more\nchallenging. Additionally, occasional false-negative detections due to\ndifficult scenarios like occlusions can harm tracking performance. To address\nthese issues in a unified framework, we propose to learn shape and\nspatio-temporal affinities between tracks and detections in consecutive frames.\nOur affinity provides a probabilistic matching that leads to robust data\nassociation, track lifecycle management, false-positive elimination,\nfalse-negative propagation, and sequential track confidence refinement. Though\npast 3D MOT approaches address a subset of components in this problem domain,\nwe offer the first self-contained framework that addresses all these aspects of\nthe 3D MOT problem. We quantitatively evaluate our method on the nuScenes\ntracking benchmark where we achieve 1st place amongst LiDAR-only trackers using\nCenterPoint detections. Our method estimates accurate and precise tracks, while\ndecreasing the overall number of false-positive and false-negative tracks and\nincreasing the number of true-positive tracks. We analyze our performance with\n5 metrics, giving a comprehensive overview of our approach to indicate how our\ntracking framework may impact the ultimate goal of an autonomous mobile agent.\nWe also present ablative experiments and qualitative results that demonstrate\nour framework's capabilities in complex scenarios.\n","authors":["Tara Sadjadpour","Jie Li","Rares Ambrus","Jeannette Bohg"],"pdf_url":"https://arxiv.org/pdf/2211.03919v2.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2210.11582v4","updated":"2023-02-07T00:37:49Z","published":"2022-10-20T20:51:48Z","title":"Deep Learning for Diagonal Earlobe Crease Detection","summary":"  An article published on Medical News Today in June 2022 presented a\nfundamental question in its title: Can an earlobe crease predict heart attacks?\nThe author explained that end arteries supply the heart and ears. In other\nwords, if they lose blood supply, no other arteries can take over, resulting in\ntissue damage. Consequently, some earlobes have a diagonal crease, line, or\ndeep fold that resembles a wrinkle. In this paper, we take a step toward\ndetecting this specific marker, commonly known as DELC or Frank's Sign. For\nthis reason, we have made the first DELC dataset available to the public. In\naddition, we have investigated the performance of numerous cutting-edge\nbackbones on annotated photos. Experimentally, we demonstrate that it is\npossible to solve this challenge by combining pre-trained encoders with a\ncustomized classifier to achieve 97.7% accuracy. Moreover, we have analyzed the\nbackbone trade-off between performance and size, estimating MobileNet as the\nmost promising encoder.\n","authors":["Sara L. Almonacid-Uribe","Oliverio J. Santana","Daniel Hernández-Sosa","David Freire-Obregón"],"pdf_url":"https://arxiv.org/pdf/2210.11582v4.pdf","comment":"Accepted at 12th International Conference on Pattern Recognition\n  Applications (ICPRAM 2023)"},{"id":"http://arxiv.org/abs/2301.05345v2","updated":"2023-02-07T00:30:36Z","published":"2023-01-13T00:40:24Z","title":"GOHSP: A Unified Framework of Graph and Optimization-based Heterogeneous\n  Structured Pruning for Vision Transformer","summary":"  The recently proposed Vision transformers (ViTs) have shown very impressive\nempirical performance in various computer vision tasks, and they are viewed as\nan important type of foundation model. However, ViTs are typically constructed\nwith large-scale sizes, which then severely hinder their potential deployment\nin many practical resources-constrained applications. To mitigate this\nchallenging problem, structured pruning is a promising solution to compress\nmodel size and enable practical efficiency. However, unlike its current\npopularity for CNNs and RNNs, structured pruning for ViT models is little\nexplored.\n  In this paper, we propose GOHSP, a unified framework of Graph and\nOptimization-based Structured Pruning for ViT models. We first develop a\ngraph-based ranking for measuring the importance of attention heads, and the\nextracted importance information is further integrated to an optimization-based\nprocedure to impose the heterogeneous structured sparsity patterns on the ViT\nmodels. Experimental results show that our proposed GOHSP demonstrates\nexcellent compression performance. On CIFAR-10 dataset, our approach can bring\n40% parameters reduction with no accuracy loss for ViT-Small model. On ImageNet\ndataset, with 30% and 35% sparsity ratio for DeiT-Tiny and DeiT-Small models,\nour approach achieves 1.65% and 0.76% accuracy increase over the existing\nstructured pruning methods, respectively.\n","authors":["Miao Yin","Burak Uzkent","Yilin Shen","Hongxia Jin","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2301.05345v2.pdf","comment":"This manuscript was accepted to AAAI 2023 Main Track"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.03561v1","updated":"2023-02-07T16:17:25Z","published":"2023-02-07T16:17:25Z","title":"Optimizing Audio Recommendations for the Long-Term: A Reinforcement\n  Learning Perspective","summary":"  We study the problem of optimizing a recommender system for outcomes that\noccur over several weeks or months. We begin by drawing on reinforcement\nlearning to formulate a comprehensive model of users' recurring relationships\nwith a recommender system. Measurement, attribution, and coordination\nchallenges complicate algorithm design. We describe careful modeling --\nincluding a new representation of user state and key conditional independence\nassumptions -- which overcomes these challenges and leads to simple, testable\nrecommender system prototypes. We apply our approach to a podcast recommender\nsystem that makes personalized recommendations to hundreds of millions of\nlisteners. A/B tests demonstrate that purposefully optimizing for long-term\noutcomes leads to large performance gains over conventional approaches that\noptimize for short-term proxies.\n","authors":["Lucas Maystre","Daniel Russo","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03555v1","updated":"2023-02-07T16:06:27Z","published":"2023-02-07T16:06:27Z","title":"ConsRec: Learning Consensus Behind Interactions for Group Recommendation","summary":"  Since group activities have become very common in daily life, there is an\nurgent demand for generating recommendations for a group of users, referred to\nas group recommendation task. Existing group recommendation methods usually\ninfer groups' preferences via aggregating diverse members' interests. Actually,\ngroups' ultimate choice involves compromises between members, and finally, an\nagreement can be reached. However, existing individual information aggregation\nlacks a holistic group-level consideration, failing to capture the consensus\ninformation. Besides, their specific aggregation strategies either suffer from\nhigh computational costs or become too coarse-grained to make precise\npredictions. To solve the aforementioned limitations, in this paper, we focus\non exploring consensus behind group behavior data. To comprehensively capture\nthe group consensus, we innovatively design three distinct views which provide\nmutually complementary information to enable multi-view learning, including\nmember-level aggregation, item-level tastes, and group-level inherent\npreferences. To integrate and balance the multi-view information, an adaptive\nfusion component is further proposed. As to member-level aggregation, different\nfrom existing linear or attentive strategies, we design a novel hypergraph\nneural network that allows for efficient hypergraph convolutional operations to\ngenerate expressive member-level aggregation. We evaluate our ConsRec on two\nreal-world datasets and experimental results show that our model outperforms\nstate-of-the-art methods. An extensive case study also verifies the\neffectiveness of consensus modeling.\n","authors":["Xixi Wu","Yun Xiong","Yao Zhang","Yizhu Jiao","Jiawei Zhang","Yangyong Zhu","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2302.03555v1.pdf","comment":"Accepted by WWW'2023"},{"id":"http://arxiv.org/abs/2302.03525v1","updated":"2023-02-07T15:15:58Z","published":"2023-02-07T15:15:58Z","title":"Multi-Task Deep Recommender Systems: A Survey","summary":"  Multi-task learning (MTL) aims at learning related tasks in a unified model\nto achieve mutual improvement among tasks considering their shared knowledge.\nIt is an important topic in recommendation due to the demand for multi-task\nprediction considering performance and efficiency. Although MTL has been well\nstudied and developed, there is still a lack of systematic review in the\nrecommendation community. To fill the gap, we provide a comprehensive review of\nexisting multi-task deep recommender systems (MTDRS) in this survey. To be\nspecific, the problem definition of MTDRS is first given, and it is compared\nwith other related areas. Next, the development of MTDRS is depicted and the\ntaxonomy is introduced from the task relation and methodology aspects.\nSpecifically, the task relation is categorized into parallel, cascaded, and\nauxiliary with main, while the methodology is grouped into parameter sharing,\noptimization, and training mechanism. The survey concludes by summarizing the\napplication and public datasets of MTDRS and highlighting the challenges and\nfuture directions of the field.\n","authors":["Yuhao Wang","Ha Tsz Lam","Yi Wong","Ziru Liu","Xiangyu Zhao","Yichao Wang","Bo Chen","Huifeng Guo","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2302.03525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03472v1","updated":"2023-02-07T13:57:03Z","published":"2023-02-07T13:57:03Z","title":"On the Theories Behind Hard Negative Sampling for Recommendation","summary":"  Negative sampling has been heavily used to train recommender models on\nlarge-scale data, wherein sampling hard examples usually not only accelerates\nthe convergence but also improves the model accuracy. Nevertheless, the reasons\nfor the effectiveness of Hard Negative Sampling (HNS) have not been revealed\nyet. In this work, we fill the research gap by conducting thorough theoretical\nanalyses on HNS. Firstly, we prove that employing HNS on the Bayesian\nPersonalized Ranking (BPR) learner is equivalent to optimizing One-way Partial\nAUC (OPAUC). Concretely, the BPR equipped with Dynamic Negative Sampling (DNS)\nis an exact estimator, while with softmax-based sampling is a soft estimator.\nSecondly, we prove that OPAUC has a stronger connection with Top-K evaluation\nmetrics than AUC and verify it with simulation experiments. These analyses\nestablish the theoretical foundation of HNS in optimizing Top-K recommendation\nperformance for the first time. On these bases, we offer two insightful\nguidelines for effective usage of HNS: 1) the sampling hardness should be\ncontrollable, e.g., via pre-defined hyper-parameters, to adapt to different\nTop-K metrics and datasets; 2) the smaller the $K$ we emphasize in Top-K\nevaluation metrics, the harder the negative samples we should draw. Extensive\nexperiments on three real-world benchmarks verify the two guidelines.\n","authors":["Wentao Shi","Jiawei Chen","Fuli Feng","Jizhi Zhang","Junkang Wu","Chongming Gao","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2302.03472v1.pdf","comment":"Accepted by WWW'2023"},{"id":"http://arxiv.org/abs/2301.13364v2","updated":"2023-02-07T13:19:38Z","published":"2023-01-31T02:08:34Z","title":"A Counterfactual Collaborative Session-based Recommender System","summary":"  Most session-based recommender systems (SBRSs) focus on extracting\ninformation from the observed items in the current session of a user to predict\na next item, ignoring the causes outside the session (called outer-session\ncauses, OSCs) that influence the user's selection of items. However, these\ncauses widely exist in the real world, and few studies have investigated their\nrole in SBRSs. In this work, we analyze the causalities and correlations of the\nOSCs in SBRSs from the perspective of causal inference. We find that the OSCs\nare essentially the confounders in SBRSs, which leads to spurious correlations\nin the data used to train SBRS models. To address this problem, we propose a\nnovel SBRS framework named COCO-SBRS (COunterfactual COllaborative\nSession-Based Recommender Systems) to learn the causality between OSCs and\nuser-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised\napproach to pre-train a recommendation model by designing pseudo-labels of\ncauses for each user's selection of the item in data to guide the training\nprocess. Next, COCO-SBRS adopts counterfactual inference to recommend items\nbased on the outputs of the pre-trained recommendation model considering the\ncausalities to alleviate the data sparsity problem. As a result, COCO-SBRS can\nlearn the causalities in data, preventing the model from learning spurious\ncorrelations. The experimental results of our extensive experiments conducted\non three real-world datasets demonstrate the superiority of our proposed\nframework over ten representative SBRSs.\n","authors":["Wenzhuo Song","Shoujin Wang","Yan Wang","Kunpeng Liu","Xueyan Liu","Minghao Yin"],"pdf_url":"https://arxiv.org/pdf/2301.13364v2.pdf","comment":"accepted by the ACM WebConf 2023"},{"id":"http://arxiv.org/abs/2302.03431v1","updated":"2023-02-07T12:34:31Z","published":"2023-02-07T12:34:31Z","title":"Exploration and Regularization of the Latent Action Space in\n  Recommendation","summary":"  In recommender systems, reinforcement learning solutions have effectively\nboosted recommendation performance because of their ability to capture\nlong-term user-system interaction. However, the action space of the\nrecommendation policy is a list of items, which could be extremely large with a\ndynamic candidate item pool. To overcome this challenge, we propose a\nhyper-actor and critic learning framework where the policy decomposes the item\nlist generation process into a hyper-action inference step and an effect-action\nselection step. The first step maps the given state space into a vectorized\nhyper-action space, and the second step selects the item list based on the\nhyper-action. In order to regulate the discrepancy between the two action\nspaces, we design an alignment module along with a kernel mapping function for\nitems to ensure inference accuracy and include a supervision module to\nstabilize the learning process. We build simulated environments on public\ndatasets and empirically show that our framework is superior in recommendation\ncompared to standard RL baselines.\n","authors":["Shuchang Liu","Qingpeng Cai","Bowen Sun","Yuhao Wang","Ji Jiang","Dong Zheng","Kun Gai","Peng Jiang","Xiangyu Zhao","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03419v1","updated":"2023-02-07T12:09:42Z","published":"2023-02-07T12:09:42Z","title":"Self-Sampling Training and Evaluation for the Accuracy-Bias Tradeoff in\n  Recommendation","summary":"  Research on debiased recommendation has shown promising results. However,\nsome issues still need to be handled for its application in industrial\nrecommendation. For example, most of the existing methods require some specific\ndata, architectures and training methods. In this paper, we first argue through\nan online study that arbitrarily removing all the biases in industrial\nrecommendation may not consistently yield a desired performance improvement.\nFor the situation that a randomized dataset is not available, we propose a\nnovel self-sampling training and evaluation (SSTE) framework to achieve the\naccuracy-bias tradeoff in recommendation, i.e., eliminate the harmful biases\nand preserve the beneficial ones. Specifically, SSTE uses a self-sampling\nmodule to generate some subsets with different degrees of bias from the\noriginal training and validation data. A self-training module infers the\nbeneficial biases and learns better tradeoff based on these subsets, and a\nself-evaluation module aims to use these subsets to construct more plausible\nreferences to reflect the optimized model. Finally, we conduct extensive\noffline experiments on two datasets to verify the effectiveness of our SSTE.\nMoreover, we deploy our SSTE in homepage recommendation of a famous financial\nmanagement product called Tencent Licaitong, and find very promising results in\nan online A/B test.\n","authors":["Dugang Liu","Yang Qiao","Xing Tang","Liang Chen","Xiuqiang He","Weike Pan","Zhong Ming"],"pdf_url":"https://arxiv.org/pdf/2302.03419v1.pdf","comment":"Accepted by DASFAA 2023 Industry Track"},{"id":"http://arxiv.org/abs/2302.03328v1","updated":"2023-02-07T09:11:17Z","published":"2023-02-07T09:11:17Z","title":"Multi-Task Recommendations with Reinforcement Learning","summary":"  In recent years, Multi-task Learning (MTL) has yielded immense success in\nRecommender System (RS) applications. However, current MTL-based recommendation\nmodels tend to disregard the session-wise patterns of user-item interactions\nbecause they are predominantly constructed based on item-wise datasets.\nMoreover, balancing multiple objectives has always been a challenge in this\nfield, which is typically avoided via linear estimations in existing works. To\naddress these issues, in this paper, we propose a Reinforcement Learning (RL)\nenhanced MTL framework, namely RMTL, to combine the losses of different\nrecommendation tasks using dynamic weights. To be specific, the RMTL structure\ncan address the two aforementioned issues by (i) constructing an MTL\nenvironment from session-wise interactions and (ii) training multi-task\nactor-critic network structure, which is compatible with most existing\nMTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL\nloss function using the weights generated by critic networks. Experiments on\ntwo real-world public datasets demonstrate the effectiveness of RMTL with a\nhigher AUC against state-of-the-art MTL-based recommendation models.\nAdditionally, we evaluate and validate RMTL's compatibility and transferability\nacross various MTL models.\n","authors":["Ziru Liu","Jiejie Tian","Qingpeng Cai","Xiangyu Zhao","Jingtong Gao","Shuchang Liu","Dayou Chen","Tonghao He","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.03328v1.pdf","comment":"TheWebConf2023"},{"id":"http://arxiv.org/abs/2302.03269v1","updated":"2023-02-07T05:48:16Z","published":"2023-02-07T05:48:16Z","title":"PLACES: Prompting Language Models for Social Conversation Synthesis","summary":"  Collecting high quality conversational data can be very expensive for most\napplications and infeasible for others due to privacy, ethical, or similar\nconcerns. A promising direction to tackle this problem is to generate synthetic\ndialogues by prompting large language models. In this work, we use a small set\nof expert-written conversations as in-context examples to synthesize a social\nconversation dataset using prompting. We perform several thorough evaluations\nof our synthetic conversations compared to human-collected conversations. This\nincludes various dimensions of conversation quality with human evaluation\ndirectly on the synthesized conversations, and interactive human evaluation of\nchatbots fine-tuned on the synthetically generated dataset. We additionally\ndemonstrate that this prompting approach is generalizable to multi-party\nconversations, providing potential to create new synthetic data for multi-party\ntasks. Our synthetic multi-party conversations were rated more favorably across\nall measured dimensions compared to conversation excerpts sampled from a\nhuman-collected multi-party dataset.\n","authors":["Maximillian Chen","Alexandros Papangelis","Chenyang Tao","Seokhwan Kim","Andy Rosenbaum","Yang Liu","Zhou Yu","Dilek Hakkani-Tur"],"pdf_url":"https://arxiv.org/pdf/2302.03269v1.pdf","comment":"In EACL 2023. 25 pages, 4 figures, 26 tables. Link to code\n  forthcoming"},{"id":"http://arxiv.org/abs/2302.03248v1","updated":"2023-02-07T04:18:28Z","published":"2023-02-07T04:18:28Z","title":"Disentangled Causal Embedding With Contrastive Learning For Recommender\n  System","summary":"  Recommender systems usually rely on observed user interaction data to build\npersonalized recommendation models, assuming that the observed data reflect\nuser interest. However, user interacting with an item may also due to\nconformity, the need to follow popular items. Most previous studies neglect\nuser's conformity and entangle interest with it, which may cause the\nrecommender systems fail to provide satisfying results. Therefore, from the\ncause-effect view, disentangling these interaction causes is a crucial issue.\nIt also contributes to OOD problems, where training and test data are\nout-of-distribution. Nevertheless, it is quite challenging as we lack the\nsignal to differentiate interest and conformity. The data sparsity of pure\ncause and the items' long-tail problem hinder disentangled causal embedding. In\nthis paper, we propose DCCL, a framework that adopts contrastive learning to\ndisentangle these two causes by sample augmentation for interest and conformity\nrespectively. Futhermore, DCCL is model-agnostic, which can be easily deployed\nin any industrial online system. Extensive experiments are conducted over two\nreal-world datasets and DCCL outperforms state-of-the-art baselines on top of\nvarious backbone models in various OOD environments. We also demonstrate the\nperformance improvements by online A/B testing on Kuaishou, a billion-user\nscale short-video recommender system.\n","authors":["Weiqi Zhao","Dian Tang","Xin Chen","Dawei Lv","Daoli Ou","Biao Li","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.03248v1.pdf","comment":"Accepted by WWW'23"},{"id":"http://arxiv.org/abs/2302.01724v2","updated":"2023-02-07T04:12:02Z","published":"2023-02-03T13:25:43Z","title":"Reinforcing User Retention in a Billion Scale Short Video Recommender\n  System","summary":"  Recently, short video platforms have achieved rapid user growth by\nrecommending interesting content to users. The objective of the recommendation\nis to optimize user retention, thereby driving the growth of DAU (Daily Active\nUsers). Retention is a long-term feedback after multiple interactions of users\nand the system, and it is hard to decompose retention reward to each item or a\nlist of items. Thus traditional point-wise and list-wise models are not able to\noptimize retention. In this paper, we choose reinforcement learning methods to\noptimize the retention as they are designed to maximize the long-term\nperformance. We formulate the problem as an infinite-horizon request-based\nMarkov Decision Process, and our objective is to minimize the accumulated time\ninterval of multiple sessions, which is equal to improving the app open\nfrequency and user retention. However, current reinforcement learning\nalgorithms can not be directly applied in this setting due to uncertainty,\nbias, and long delay time incurred by the properties of user retention. We\npropose a novel method, dubbed RLUR, to address the aforementioned challenges.\nBoth offline and live experiments show that RLUR can significantly improve user\nretention. RLUR has been fully launched in Kuaishou app for a long time, and\nachieves consistent performance improvement on user retention and DAU.\n","authors":["Qingpeng Cai","Shuchang Liu","Xueliang Wang","Tianyou Zuo","Wentao Xie","Bin Yang","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03221v1","updated":"2023-02-07T03:06:29Z","published":"2023-02-07T03:06:29Z","title":"Towards Lightweight Cross-domain Sequential Recommendation via External\n  Attention-enhanced Graph Convolution Network","summary":"  Cross-domain Sequential Recommendation (CSR) is an emerging yet challenging\ntask that depicts the evolution of behavior patterns for overlapped users by\nmodeling their interactions from multiple domains. Existing studies on CSR\nmainly focus on using composite or in-depth structures that achieve significant\nimprovement in accuracy but bring a huge burden to the model training.\nMoreover, to learn the user-specific sequence representations, existing works\nusually adopt the global relevance weighting strategy (e.g., self-attention\nmechanism), which has quadratic computational complexity. In this work, we\nintroduce a lightweight external attention-enhanced GCN-based framework to\nsolve the above challenges, namely LEA-GCN. Specifically, by only keeping the\nneighborhood aggregation component and using the Single-Layer Aggregating\nProtocol (SLAP), our lightweight GCN encoder performs more efficiently to\ncapture the collaborative filtering signals of the items from both domains. To\nfurther alleviate the framework structure and aggregate the user-specific\nsequential pattern, we devise a novel dual-channel External Attention (EA)\ncomponent, which calculates the correlation among all items via a lightweight\nlinear structure. Extensive experiments are conducted on two real-world\ndatasets, demonstrating that LEA-GCN requires a smaller volume and less\ntraining time without affecting the accuracy compared with several\nstate-of-the-art methods.\n","authors":["Jinyu Zhang","Huichuan Duan","Lei Guo","Liancheng Xu","Xinhua Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03221v1.pdf","comment":"16 pages, 4 figures, conference paper, accepted by DASFAA 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.03686v1","updated":"2023-02-07T18:59:32Z","published":"2023-02-07T18:59:32Z","title":"Long Horizon Temperature Scaling","summary":"  Temperature scaling is a popular technique for tuning the sharpness of a\nmodel distribution. It is used extensively for sampling likely generations and\ncalibrating model uncertainty, and even features as a controllable parameter to\nmany large language models in deployment. However, autoregressive models rely\non myopic temperature scaling that greedily optimizes the next token. To\naddress this, we propose Long Horizon Temperature Scaling (LHTS), a novel\napproach for sampling from temperature-scaled joint distributions. LHTS is\ncompatible with all likelihood-based models, and optimizes for the long-horizon\nlikelihood of samples. We derive a temperature-dependent LHTS objective, and\nshow that fine-tuning a model on a range of temperatures produces a single\nmodel capable of generation with a controllable long-horizon temperature\nparameter. We experiment with LHTS on image diffusion models and\ncharacter/language autoregressive models, demonstrating advantages over myopic\ntemperature scaling in likelihood and sample quality, and showing improvements\nin accuracy on a multiple choice analogy task by $10\\%$.\n","authors":["Andy Shih","Dorsa Sadigh","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2302.03686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03684v1","updated":"2023-02-07T18:59:19Z","published":"2023-02-07T18:59:19Z","title":"Temporal Robustness against Data Poisoning","summary":"  Data poisoning considers cases when an adversary maliciously inserts and\nremoves training data to manipulate the behavior of machine learning\nalgorithms. Traditional threat models of data poisoning center around a single\nmetric, the number of poisoned samples. In consequence, existing defenses are\nessentially vulnerable in practice when poisoning more samples remains a\nfeasible option for attackers. To address this issue, we leverage timestamps\ndenoting the birth dates of data, which are often available but neglected in\nthe past. Benefiting from these timestamps, we propose a temporal threat model\nof data poisoning and derive two novel metrics, earliness and duration, which\nrespectively measure how long an attack started in advance and how long an\nattack lasted. With these metrics, we define the notions of temporal robustness\nagainst data poisoning, providing a meaningful sense of protection even with\nunbounded amounts of poisoned samples. We present a benchmark with an\nevaluation protocol simulating continuous data collection and periodic\ndeployments of updated models, thus enabling empirical evaluation of temporal\nrobustness. Lastly, we develop and also empirically verify a baseline defense,\nnamely temporal aggregation, offering provable temporal robustness and\nhighlighting the potential of our temporal modeling of data poisoning.\n","authors":["Wenxiao Wang","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2302.03684v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.03683v1","updated":"2023-02-07T18:58:25Z","published":"2023-02-07T18:58:25Z","title":"Linear Partial Monitoring for Sequential Decision-Making: Algorithms,\n  Regret Bounds and Applications","summary":"  Partial monitoring is an expressive framework for sequential decision-making\nwith an abundance of applications, including graph-structured and dueling\nbandits, dynamic pricing and transductive feedback models. We survey and extend\nrecent results on the linear formulation of partial monitoring that naturally\ngeneralizes the standard linear bandit setting. The main result is that a\nsingle algorithm, information-directed sampling (IDS), is (nearly) worst-case\nrate optimal in all finite-action games. We present a simple and unified\nanalysis of stochastic partial monitoring, and further extend the model to the\ncontextual and kernelized setting.\n","authors":["Johannes Kirschner","Tor Lattimore","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2302.03683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1911.03508v3","updated":"2023-02-07T18:55:49Z","published":"2019-11-08T19:20:36Z","title":"Incentive-aware Contextual Pricing with Non-parametric Market Noise","summary":"  We consider a dynamic pricing problem for repeated contextual second-price\nauctions with multiple strategic buyers who aim to maximize their long-term\ntime discounted utility. The seller has limited information on buyers' overall\ndemand curves which depends on a non-parametric market-noise distribution, and\nbuyers may potentially submit corrupted bids (relative to true valuations) to\nmanipulate the seller's pricing policy for more favorable reserve prices in the\nfuture. We focus on designing the seller's learning policy to set contextual\nreserve prices where the seller's goal is to minimize regret compared to the\nrevenue of a benchmark clairvoyant policy that has full information of buyers'\ndemand. We propose a policy with a phased-structure that incorporates\nrandomized \"isolation\" periods, during which a buyer is randomly chosen to\nsolely participate in the auction. We show that this design allows the seller\nto control the number of periods in which buyers significantly corrupt their\nbids. We then prove that our policy enjoys a $T$-period regret of\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ facing strategic buyers. Finally, we\nconduct numerical simulations to compare our proposed algorithm to standard\npricing policies. Our numerical results show that our algorithm outperforms\nthese policies under various buyer bidding behavior.\n","authors":["Negin Golrezaei","Patrick Jaillet","Jason Cheuk Nam Liang"],"pdf_url":"https://arxiv.org/pdf/1911.03508v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03679v1","updated":"2023-02-07T18:54:39Z","published":"2023-02-07T18:54:39Z","title":"How Reliable is Your Regression Model's Uncertainty Under Real-World\n  Distribution Shifts?","summary":"  Many important computer vision applications are naturally formulated as\nregression problems. Within medical imaging, accurate regression models have\nthe potential to automate various tasks, helping to lower costs and improve\npatient outcomes. Such safety-critical deployment does however require reliable\nestimation of model uncertainty, also under the wide variety of distribution\nshifts that might be encountered in practice. Motivated by this, we set out to\ninvestigate the reliability of regression uncertainty estimation methods under\nvarious real-world distribution shifts. To that end, we propose an extensive\nbenchmark of 8 image-based regression datasets with different types of\nchallenging distribution shifts. We then employ our benchmark to evaluate many\nof the most common uncertainty estimation methods, as well as two\nstate-of-the-art uncertainty scores from the task of out-of-distribution\ndetection. We find that while methods are well calibrated when there is no\ndistribution shift, they all become highly overconfident on many of the\nbenchmark datasets. This uncovers important limitations of current uncertainty\nestimation methods, and the proposed benchmark therefore serves as a challenge\nto the research community. We hope that our benchmark will spur more work on\nhow to develop truly reliable regression uncertainty estimation methods. Code\nis available at https://github.com/fregu856/regression_uncertainty.\n","authors":["Fredrik K. Gustafsson","Martin Danelljan","Thomas B. Schön"],"pdf_url":"https://arxiv.org/pdf/2302.03679v1.pdf","comment":"Code is available at\n  https://github.com/fregu856/regression_uncertainty"},{"id":"http://arxiv.org/abs/2302.03673v1","updated":"2023-02-07T18:47:48Z","published":"2023-02-07T18:47:48Z","title":"Breaking the Curse of Multiagents in a Large State Space: RL in Markov\n  Games with Independent Linear Function Approximation","summary":"  We propose a new model, independent linear Markov game, for multi-agent\nreinforcement learning with a large state space and a large number of agents.\nThis is a class of Markov games with independent linear function approximation,\nwhere each agent has its own function approximation for the state-action value\nfunctions that are marginalized by other players' policies. We design new\nalgorithms for learning the Markov coarse correlated equilibria (CCE) and\nMarkov correlated equilibria (CE) with sample complexity bounds that only scale\npolynomially with each agent's own function class complexity, thus breaking the\ncurse of multiagents. In contrast, existing works for Markov games with\nfunction approximation have sample complexity bounds scale with the size of the\n\\emph{joint action space} when specialized to the canonical tabular Markov game\nsetting, which is exponentially large in the number of agents. Our algorithms\nrely on two key technical innovations: (1) utilizing policy replay to tackle\nnon-stationarity incurred by multiple agents and the use of function\napproximation; (2) separating learning Markov equilibria and exploration in the\nMarkov games, which allows us to use the full-information no-regret learning\noracle instead of the stronger bandit-feedback no-regret learning oracle used\nin the tabular setting. Furthermore, we propose an iterative-best-response type\nalgorithm that can learn pure Markov Nash equilibria in independent linear\nMarkov potential games. In the tabular case, by adapting the policy replay\nmechanism for independent linear Markov games, we propose an algorithm with\n$\\widetilde{O}(\\epsilon^{-2})$ sample complexity to learn Markov CCE, which\nimproves the state-of-the-art result $\\widetilde{O}(\\epsilon^{-3})$ in\nDaskalakis et al. 2022, where $\\epsilon$ is the desired accuracy, and also\nsignificantly improves other problem parameters.\n","authors":["Qiwen Cui","Kaiqing Zhang","Simon S. Du"],"pdf_url":"https://arxiv.org/pdf/2302.03673v1.pdf","comment":"51 pages"},{"id":"http://arxiv.org/abs/2302.03668v1","updated":"2023-02-07T18:40:18Z","published":"2023-02-07T18:40:18Z","title":"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt\n  Tuning and Discovery","summary":"  The strength of modern generative models lies in their ability to be\ncontrolled through text-based prompts. Typical \"hard\" prompts are made from\ninterpretable words and tokens, and must be hand-crafted by humans. There are\nalso \"soft\" prompts, which consist of continuous feature vectors. These can be\ndiscovered using powerful optimization methods, but they cannot be easily\ninterpreted, re-used across models, or plugged into a text-based interface.\n  We describe an approach to robustly optimize hard text prompts through\nefficient gradient-based optimization. Our approach automatically generates\nhard text-based prompts for both text-to-image and text-to-text applications.\nIn the text-to-image setting, the method creates hard prompts for diffusion\nmodels, allowing API users to easily generate, discover, and mix and match\nimage concepts without prior knowledge on how to prompt the model. In the\ntext-to-text setting, we show that hard prompts can be automatically discovered\nthat are effective in tuning LMs for classification.\n","authors":["Yuxin Wen","Neel Jain","John Kirchenbauer","Micah Goldblum","Jonas Geiping","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2302.03668v1.pdf","comment":"14 pages, 10 figures, Code is available at\n  \\url{https://github.com/YuxinWenRick/hard-prompts-made-easy}"},{"id":"http://arxiv.org/abs/2110.10745v3","updated":"2023-02-07T18:37:04Z","published":"2021-10-20T19:36:55Z","title":"Iterated Block Particle Filter for High-dimensional Parameter Learning:\n  Beating the Curse of Dimensionality","summary":"  Parameter learning for high-dimensional, partially observed, and nonlinear\nstochastic processes is a methodological challenge. Spatiotemporal disease\ntransmission systems provide examples of such processes giving rise to open\ninference problems. We propose the iterated block particle filter (IBPF)\nalgorithm for learning high-dimensional parameters over graphical state space\nmodels with general state spaces, measures, transition densities and graph\nstructure. Theoretical performance guarantees are obtained on beating the curse\nof dimensionality (COD), algorithm convergence, and likelihood maximization.\nExperiments on a highly nonlinear and non-Gaussian spatiotemporal model for\nmeasles transmission reveal that the iterated ensemble Kalman filter algorithm\n(Li et al. (2020)) is ineffective and the iterated filtering algorithm (Ionides\net al. (2015)) suffers from the COD, while our IBPF algorithm beats COD\nconsistently across various experiments with different metrics.\n","authors":["Ning Ning","Edward L. Ionides"],"pdf_url":"https://arxiv.org/pdf/2110.10745v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07980v2","updated":"2023-02-07T18:31:27Z","published":"2022-10-14T17:25:36Z","title":"Representation Theory for Geometric Quantum Machine Learning","summary":"  Recent advances in classical machine learning have shown that creating models\nwith inductive biases encoding the symmetries of a problem can greatly improve\nperformance. Importation of these ideas, combined with an existing rich body of\nwork at the nexus of quantum theory and symmetry, has given rise to the field\nof Geometric Quantum Machine Learning (GQML). Following the success of its\nclassical counterpart, it is reasonable to expect that GQML will play a crucial\nrole in developing problem-specific and quantum-aware models capable of\nachieving a computational advantage. Despite the simplicity of the main idea of\nGQML -- create architectures respecting the symmetries of the data -- its\npractical implementation requires a significant amount of knowledge of group\nrepresentation theory. We present an introduction to representation theory\ntools from the optics of quantum learning, driven by key examples involving\ndiscrete and continuous groups. These examples are sewn together by an\nexposition outlining the formal capture of GQML symmetries via \"label\ninvariance under the action of a group representation\", a brief (but rigorous)\ntour through finite and compact Lie group representation theory, a\nreexamination of ubiquitous tools like Haar integration and twirling, and an\noverview of some successful strategies for detecting symmetries.\n","authors":["Michael Ragone","Paolo Braccia","Quynh T. Nguyen","Louis Schatzki","Patrick J. Coles","Frederic Sauvage","Martin Larocca","M. Cerezo"],"pdf_url":"https://arxiv.org/pdf/2210.07980v2.pdf","comment":"43 pages, 10 figures. Updated to add relevant references"},{"id":"http://arxiv.org/abs/2302.03663v1","updated":"2023-02-07T18:28:09Z","published":"2023-02-07T18:28:09Z","title":"SDYN-GANs: Adversarial Learning Methods for Multistep Generative Models\n  for General Order Stochastic Dynamics","summary":"  We introduce adversarial learning methods for data-driven generative modeling\nof the dynamics of $n^{th}$-order stochastic systems. Our approach builds on\nGenerative Adversarial Networks (GANs) with generative model classes based on\nstable $m$-step stochastic numerical integrators. We introduce different\nformulations and training methods for learning models of stochastic dynamics\nbased on observation of trajectory samples. We develop approaches using\ndiscriminators based on Maximum Mean Discrepancy (MMD), training protocols\nusing conditional and marginal distributions, and methods for learning dynamic\nresponses over different time-scales. We show how our approaches can be used\nfor modeling physical systems to learn force-laws, damping coefficients, and\nnoise-related parameters. The adversarial learning approaches provide methods\nfor obtaining stable generative models for dynamic tasks including long-time\nprediction and developing simulations for stochastic systems.\n","authors":["Panos Stinis","Constantinos Daskalakis","Paul J. Atzberger"],"pdf_url":"https://arxiv.org/pdf/2302.03663v1.pdf","comment":"7 figures"},{"id":"http://arxiv.org/abs/2302.03662v1","updated":"2023-02-07T18:26:07Z","published":"2023-02-07T18:26:07Z","title":"Federated Learning with Regularized Client Participation","summary":"  Federated Learning (FL) is a distributed machine learning approach where\nmultiple clients work together to solve a machine learning task. One of the key\nchallenges in FL is the issue of partial participation, which occurs when a\nlarge number of clients are involved in the training process. The traditional\nmethod to address this problem is randomly selecting a subset of clients at\neach communication round. In our research, we propose a new technique and\ndesign a novel regularized client participation scheme. Under this scheme, each\nclient joins the learning process every $R$ communication rounds, which we\nrefer to as a meta epoch. We have found that this participation scheme leads to\na reduction in the variance caused by client sampling. Combined with the\npopular FedAvg algorithm (McMahan et al., 2017), it results in superior rates\nunder standard assumptions. For instance, the optimization term in our main\nconvergence bound decreases linearly with the product of the number of\ncommunication rounds and the size of the local dataset of each client, and the\nstatistical term scales with step size quadratically instead of linearly (the\ncase for client sampling with replacement), leading to better convergence rate\n$\\mathcal{O}\\left(\\frac{1}{T^2}\\right)$ compared to\n$\\mathcal{O}\\left(\\frac{1}{T}\\right)$, where $T$ is the total number of\ncommunication rounds. Furthermore, our results permit arbitrary client\navailability as long as each client is available for training once per each\nmeta epoch.\n","authors":["Grigory Malinovsky","Samuel Horváth","Konstantin Burlachenko","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2302.03662v1.pdf","comment":"33 pages, 10 figures,1 algorithm, 3 theorems"},{"id":"http://arxiv.org/abs/2302.03660v1","updated":"2023-02-07T18:21:24Z","published":"2023-02-07T18:21:24Z","title":"Riemannian Flow Matching on General Geometries","summary":"  We propose Riemannian Flow Matching (RFM), a simple yet powerful framework\nfor training continuous normalizing flows on manifolds. Existing methods for\ngenerative modeling on manifolds either require expensive simulation,\ninherently cannot scale to high dimensions, or use approximations to limiting\nquantities that result in biased objectives. Riemannian Flow Matching bypasses\nthese inconveniences and exhibits multiple benefits over prior approaches: It\nis completely simulation-free on simple geometries, it does not require\ndivergence computation, and its target vector field is computed in closed form\neven on general geometries. The key ingredient behind RFM is the construction\nof a simple kernel function for defining per-sample vector fields, which\nsubsumes existing Euclidean cases. Extending to general geometries, we rely on\nthe use of spectral decompositions to efficiently compute kernel functions. Our\nmethod achieves state-of-the-art performance on real-world non-Euclidean\ndatasets, and we showcase, for the first time, tractable training on general\ngeometries, including on triangular meshes and maze-like manifolds with\nboundaries.\n","authors":["Ricky T. Q. Chen","Yaron Lipman"],"pdf_url":"https://arxiv.org/pdf/2302.03660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01908v2","updated":"2023-02-07T18:19:48Z","published":"2022-10-04T21:08:27Z","title":"Supervised Metric Learning to Rank for Retrieval via Contextual\n  Similarity Optimization","summary":"  There is extensive interest in metric learning methods for image retrieval.\nMany metric learning loss functions focus on learning a correct ranking of\ntraining samples, but strongly overfit semantically inconsistent labels and\nrequire a large amount of data. To address these shortcomings, we propose a new\nmetric learning method, called contextual loss, which optimizes contextual\nsimilarity in addition to cosine similarity. Our contextual loss implicitly\nenforces semantic consistency among neighbors while converging to the correct\nranking. We empirically show that the proposed loss is more robust to label\nnoise, and is less prone to overfitting even when a large portion of train data\nis withheld. Extensive experiments demonstrate that our method achieves a new\nstate-of-the-art across four image retrieval benchmarks and multiple different\nevaluation settings. Code is available at:\nhttps://github.com/Chris210634/metric-learning-using-contextual-similarity\n","authors":["Christopher Liao","Theodoros Tsiligkaridis","Brian Kulis"],"pdf_url":"https://arxiv.org/pdf/2210.01908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03658v1","updated":"2023-02-07T18:18:17Z","published":"2023-02-07T18:18:17Z","title":"Planted Bipartite Graph Detection","summary":"  We consider the task of detecting a hidden bipartite subgraph in a given\nrandom graph. Specifically, under the null hypothesis, the graph is a\nrealization of an Erd\\H{o}s-R\\'{e}nyi random graph over $n$ vertices with edge\ndensity $q$. Under the alternative, there exists a planted $k_{\\mathsf{R}}\n\\times k_{\\mathsf{L}}$ bipartite subgraph with edge density $p>q$. We derive\nasymptotically tight upper and lower bounds for this detection problem in both\nthe dense regime, where $q,p = \\Theta\\left(1\\right)$, and the sparse regime\nwhere $q,p = \\Theta\\left(n^{-\\alpha}\\right), \\alpha \\in \\left(0,2\\right]$.\nMoreover, we consider a variant of the above problem, where one can only\nobserve a relatively small part of the graph, by using at most $\\mathsf{Q}$\nedge queries. For this problem, we derive upper and lower bounds in both the\ndense and sparse regimes.\n","authors":["Asaf Rotenberg","Wasim Huleihel","Ofer Shayevitz"],"pdf_url":"https://arxiv.org/pdf/2302.03658v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2302.03657v1","updated":"2023-02-07T18:17:41Z","published":"2023-02-07T18:17:41Z","title":"Toward Face Biometric De-identification using Adversarial Examples","summary":"  The remarkable success of face recognition (FR) has endangered the privacy of\ninternet users particularly in social media. Recently, researchers turned to\nuse adversarial examples as a countermeasure. In this paper, we assess the\neffectiveness of using two widely known adversarial methods (BIM and ILLC) for\nde-identifying personal images. We discovered, unlike previous claims in the\nliterature, that it is not easy to get a high protection success rate\n(suppressing identification rate) with imperceptible adversarial perturbation\nto the human visual system. Finally, we found out that the transferability of\nadversarial examples is highly affected by the training parameters of the\nnetwork with which they are generated.\n","authors":["Mahdi Ghafourian","Julian Fierrez","Luis Felipe Gomez","Ruben Vera-Rodriguez","Aythami Morales","Zohra Rezgui","Raymond Veldhuis"],"pdf_url":"https://arxiv.org/pdf/2302.03657v1.pdf","comment":"Accepted at the AAAI-23 workshop on Artificial Intelligence for Cyber\n  Security (AICS)"},{"id":"http://arxiv.org/abs/2302.03655v1","updated":"2023-02-07T18:16:13Z","published":"2023-02-07T18:16:13Z","title":"Reducing SO(3) Convolutions to SO(2) for Efficient Equivariant GNNs","summary":"  Graph neural networks that model 3D data, such as point clouds or atoms, are\ntypically desired to be $SO(3)$ equivariant, i.e., equivariant to 3D rotations.\nUnfortunately equivariant convolutions, which are a fundamental operation for\nequivariant networks, increase significantly in computational complexity as\nhigher-order tensors are used. In this paper, we address this issue by reducing\nthe $SO(3)$ convolutions or tensor products to mathematically equivalent\nconvolutions in $SO(2)$ . This is accomplished by aligning the node embeddings'\nprimary axis with the edge vectors, which sparsifies the tensor product and\nreduces the computational complexity from $O(L^6)$ to $O(L^3)$, where $L$ is\nthe degree of the representation. We demonstrate the potential implications of\nthis improvement by proposing the Equivariant Spherical Channel Network (eSCN),\na graph neural network utilizing our novel approach to equivariant\nconvolutions, which achieves state-of-the-art results on the large-scale OC-20\ndataset.\n","authors":["Saro Passaro","C. Lawrence Zitnick"],"pdf_url":"https://arxiv.org/pdf/2302.03655v1.pdf","comment":"17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2302.03654v1","updated":"2023-02-07T18:12:48Z","published":"2023-02-07T18:12:48Z","title":"A Privacy-Preserving Hybrid Federated Learning Framework for Financial\n  Crime Detection","summary":"  The recent decade witnessed a surge of increase in financial crimes across\nthe public and private sectors, with an average cost of scams of \\$102m to\nfinancial institutions in 2022. Developing a mechanism for battling financial\ncrimes is an impending task that requires in-depth collaboration from multiple\ninstitutions, and yet such collaboration imposed significant technical\nchallenges due to the privacy and security requirements of distributed\nfinancial data. For example, consider the Society for Worldwide Interbank\nFinancial Telecommunications (SWIFT) system, which generates 42 million\ntransactions per day across its 11,000 global institutions. Training a\ndetection model of fraudulent transactions requires not only secured SWIFT\ntransactions but also the private account activities of those involved in each\ntransaction from corresponding bank systems. The distributed nature of both\nsamples and features prevents most existing learning systems from being\ndirectly adopted to handle the data mining task. In this paper, we collectively\naddress these challenges by proposing a hybrid federated learning system that\noffers secure and privacy-aware learning and inference for financial crime\ndetection. We conduct extensive empirical studies to evaluate the proposed\nframework's detection performance and privacy-protection capability, evaluating\nits robustness against common malicious attacks of collaborative learning. We\nrelease our source code at https://github.com/illidanlab/HyFL .\n","authors":["Haobo Zhang","Junyuan Hong","Fan Dong","Steve Drew","Liangjie Xue","Jiayu Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03648v1","updated":"2023-02-07T17:59:05Z","published":"2023-02-07T17:59:05Z","title":"Deep Class-Incremental Learning: A Survey","summary":"  Deep models, e.g., CNNs and Vision Transformers, have achieved impressive\nachievements in many vision tasks in the closed world. However, novel classes\nemerge from time to time in our ever-changing world, requiring a learning\nsystem to acquire new knowledge continually. For example, a robot needs to\nunderstand new instructions, and an opinion monitoring system should analyze\nemerging topics every day. Class-Incremental Learning (CIL) enables the learner\nto incorporate the knowledge of new classes incrementally and build a universal\nclassifier among all seen classes. Correspondingly, when directly training the\nmodel with new class instances, a fatal problem occurs -- the model tends to\ncatastrophically forget the characteristics of former ones, and its performance\ndrastically degrades. There have been numerous efforts to tackle catastrophic\nforgetting in the machine learning community. In this paper, we survey\ncomprehensively recent advances in deep class-incremental learning and\nsummarize these methods from three aspects, i.e., data-centric, model-centric,\nand algorithm-centric. We also provide a rigorous and unified evaluation of 16\nmethods in benchmark image classification tasks to find out the characteristics\nof different algorithms empirically. Furthermore, we notice that the current\ncomparison protocol ignores the influence of memory budget in model storage,\nwhich may result in unfair comparison and biased results. Hence, we advocate\nfair comparison by aligning the memory budget in evaluation, as well as several\nmemory-agnostic performance measures. The source code to reproduce these\nevaluations is available at https://github.com/zhoudw-zdw/CIL_Survey/\n","authors":["Da-Wei Zhou","Qi-Wei Wang","Zhi-Hong Qi","Han-Jia Ye","De-Chuan Zhan","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03648v1.pdf","comment":"Code is available at https://github.com/zhoudw-zdw/CIL_Survey/"},{"id":"http://arxiv.org/abs/2302.03629v1","updated":"2023-02-07T17:33:00Z","published":"2023-02-07T17:33:00Z","title":"Ethical Considerations for Collecting Human-Centric Image Datasets","summary":"  Human-centric image datasets are critical to the development of computer\nvision technologies. However, recent investigations have foregrounded\nsignificant ethical issues related to privacy and bias, which have resulted in\nthe complete retraction, or modification, of several prominent datasets. Recent\nworks have tried to reverse this trend, for example, by proposing analytical\nframeworks for ethically evaluating datasets, the standardization of dataset\ndocumentation and curation practices, privacy preservation methodologies, as\nwell as tools for surfacing and mitigating representational biases. Little\nattention, however, has been paid to the realities of operationalizing ethical\ndata collection. To fill this gap, we present a set of key ethical\nconsiderations and practical recommendations for collecting more\nethically-minded human-centric image data. Our research directly addresses\nissues of privacy and bias by contributing to the research community best\npractices for ethical data collection, covering purpose, privacy and consent,\nas well as diversity. We motivate each consideration by drawing on lessons from\ncurrent practices, dataset withdrawals and audits, and analytical ethical\nframeworks. Our research is intended to augment recent scholarship,\nrepresenting an important step toward more responsible data curation practices.\n","authors":["Jerone T. A. Andrews","Dora Zhao","William Thong","Apostolos Modas","Orestis Papakyriakopoulos","Shruti Nagpal","Alice Xiang"],"pdf_url":"https://arxiv.org/pdf/2302.03629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12293v4","updated":"2023-02-07T17:28:17Z","published":"2022-01-28T17:58:38Z","title":"Understanding Why Generalized Reweighting Does Not Improve Over ERM","summary":"  Empirical risk minimization (ERM) is known in practice to be non-robust to\ndistributional shift where the training and the test distributions are\ndifferent. A suite of approaches, such as importance weighting, and variants of\ndistributionally robust optimization (DRO), have been proposed to solve this\nproblem. But a line of recent work has empirically shown that these approaches\ndo not significantly improve over ERM in real applications with distribution\nshift. The goal of this work is to obtain a comprehensive theoretical\nunderstanding of this intriguing phenomenon. We first posit the class of\nGeneralized Reweighting (GRW) algorithms, as a broad category of approaches\nthat iteratively update model parameters based on iterative reweighting of the\ntraining samples. We show that when overparameterized models are trained under\nGRW, the resulting models are close to that obtained by ERM. We also show that\nadding small regularization which does not greatly affect the empirical\ntraining accuracy does not help. Together, our results show that a broad\ncategory of what we term GRW approaches are not able to achieve\ndistributionally robust generalization. Our work thus has the following\nsobering takeaway: to make progress towards distributionally robust\ngeneralization, we either have to develop non-GRW approaches, or perhaps devise\nnovel classification/regression loss functions that are adapted to the class of\nGRW approaches.\n","authors":["Runtian Zhai","Chen Dan","Zico Kolter","Pradeep Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2201.12293v4.pdf","comment":"ICLR 2023. 40 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.03620v1","updated":"2023-02-07T17:24:08Z","published":"2023-02-07T17:24:08Z","title":"Recent advances in the Self-Referencing Embedding Strings (SELFIES)\n  library","summary":"  String-based molecular representations play a crucial role in cheminformatics\napplications, and with the growing success of deep learning in chemistry, have\nbeen readily adopted into machine learning pipelines. However, traditional\nstring-based representations such as SMILES are often prone to syntactic and\nsemantic errors when produced by generative models. To address these problems,\na novel representation, SELF-referencIng Embedded Strings (SELFIES), was\nproposed that is inherently 100% robust, alongside an accompanying open-source\nimplementation. Since then, we have generalized SELFIES to support a wider\nrange of molecules and semantic constraints and streamlined its underlying\ngrammar. We have implemented this updated representation in subsequent versions\nof \\selfieslib, where we have also made major advances with respect to design,\nefficiency, and supported features. Hence, we present the current status of\n\\selfieslib (version 2.1.1) in this manuscript.\n","authors":["Alston Lo","Robert Pollice","AkshatKumar Nigam","Andrew D. White","Mario Krenn","Alán Aspuru-Guzik"],"pdf_url":"https://arxiv.org/pdf/2302.03620v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2111.05385v2","updated":"2023-02-07T17:22:43Z","published":"2021-11-09T19:52:22Z","title":"Subtyping patients with chronic disease using longitudinal BMI patterns","summary":"  Obesity is a major health problem, increasing the risk of various major\nchronic diseases, such as diabetes, cancer, and stroke. While the role of\nobesity identified by cross-sectional BMI recordings has been heavily studied,\nthe role of BMI trajectories is much less explored. In this study, we use a\nmachine-learning approach to subtype individuals' risk of developing 18 major\nchronic diseases by using their BMI trajectories extracted from a large and\ngeographically diverse EHR dataset capturing the health status of around two\nmillion individuals for a period of six years. We define nine new interpretable\nand evidence-based variables based on the BMI trajectories to cluster the\npatients into subgroups using the k-means clustering method. We thoroughly\nreview each cluster's characteristics in terms of demographic, socioeconomic,\nand physiological measurement variables to specify the distinct properties of\nthe patients in the clusters. In our experiments, the direct relationship of\nobesity with diabetes, hypertension, Alzheimer's, and dementia has been\nre-established and distinct clusters with specific characteristics for several\nof the chronic diseases have been found to be conforming or complementary to\nthe existing body of knowledge.\n","authors":["Md Mozaharul Mottalib","Jessica C Jones-Smith","Bethany Sheridan","Rahmatollah Beheshti"],"pdf_url":"https://arxiv.org/pdf/2111.05385v2.pdf","comment":"https://ieeexplore.ieee.org/document/10018864"},{"id":"http://arxiv.org/abs/2302.03616v1","updated":"2023-02-07T17:21:51Z","published":"2023-02-07T17:21:51Z","title":"Can gamification reduce the burden of self-reporting in mHealth\n  applications? Feasibility study using machine learning from smartwatch data\n  to estimate cognitive load","summary":"  The effectiveness of digital treatments can be measured by requiring patients\nto self-report their mental and physical state through mobile applications.\nHowever, self-reporting can be overwhelming and may cause patients to disengage\nfrom the intervention. In order to address this issue, we conduct a feasibility\nstudy to explore the impact of gamification on the cognitive burden of\nself-reporting. Our approach involves the creation of a system to assess\ncognitive burden through the analysis of photoplethysmography (PPG) signals\nobtained from a smartwatch. The system is built by collecting PPG data during\nboth cognitively demanding tasks and periods of rest. The obtained data is\nutilized to train a machine learning model to detect cognitive load (CL).\nSubsequently, we create two versions of health surveys: a gamified version and\na traditional version. Our aim is to estimate the cognitive load experienced by\nparticipants while completing these surveys using their mobile devices. We find\nthat CL detector performance can be enhanced via pre-training on stress\ndetection tasks and requires capturing of a minimum 30 seconds of PPG signal to\nwork adequately. For 10 out of 13 participants, a personalized cognitive load\ndetector can achieve an F1 score above 0.7. We find no difference between the\ngamified and non-gamified mobile surveys in terms of time spent in the state of\nhigh cognitive load but participants prefer the gamified version. The average\ntime spent on each question is 5.5 for gamified survey vs 6 seconds for the\nnon-gamified version.\n","authors":["Michal K. Grzeszczyk","Paulina Adamczyk","Sylwia Marek","Ryszard Pręcikowski","Maciej Kuś","M. Patrycja Lelujko","Rosmary Blanco","Tomasz Trzciński","Arkadiusz Sitek","Maciej Malawski","Aneta Lisowska"],"pdf_url":"https://arxiv.org/pdf/2302.03616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03608v1","updated":"2023-02-07T17:12:49Z","published":"2023-02-07T17:12:49Z","title":"Online Reinforcement Learning with Uncertain Episode Lengths","summary":"  Existing episodic reinforcement algorithms assume that the length of an\nepisode is fixed across time and known a priori. In this paper, we consider a\ngeneral framework of episodic reinforcement learning when the length of each\nepisode is drawn from a distribution. We first establish that this problem is\nequivalent to online reinforcement learning with general discounting where the\nlearner is trying to optimize the expected discounted sum of rewards over an\ninfinite horizon, but where the discounting function is not necessarily\ngeometric. We show that minimizing regret with this new general discounting is\nequivalent to minimizing regret with uncertain episode lengths. We then design\na reinforcement learning algorithm that minimizes regret with general\ndiscounting but acts for the setting with uncertain episode lengths. We\ninstantiate our general bound for different types of discounting, including\ngeometric and polynomial discounting. We also show that we can obtain similar\nregret bounds even when the uncertainty over the episode lengths is unknown, by\nestimating the unknown distribution over time. Finally, we compare our learning\nalgorithms with existing value-iteration based episodic RL algorithms in a\ngrid-world environment.\n","authors":["Debmalya Mandal","Goran Radanovic","Jiarui Gan","Adish Singla","Rupak Majumdar"],"pdf_url":"https://arxiv.org/pdf/2302.03608v1.pdf","comment":"To appear at AAAI-2023"},{"id":"http://arxiv.org/abs/2302.03596v1","updated":"2023-02-07T17:07:46Z","published":"2023-02-07T17:07:46Z","title":"Graph Generation with Destination-Driven Diffusion Mixture","summary":"  Generation of graphs is a major challenge for real-world tasks that require\nunderstanding the complex nature of their non-Euclidean structures. Although\ndiffusion models have achieved notable success in graph generation recently,\nthey are ill-suited for modeling the structural information of graphs since\nlearning to denoise the noisy samples does not explicitly capture the graph\ntopology. To tackle this limitation, we propose a novel generative process that\nmodels the topology of graphs by predicting the destination of the process.\nSpecifically, we design the generative process as a mixture of diffusion\nprocesses conditioned on the endpoint in the data distribution, which drives\nthe process toward the probable destination. Further, we introduce new training\nobjectives for learning to predict the destination, and discuss the advantages\nof our generative framework that can explicitly model the graph topology and\nexploit the inductive bias of the data. Through extensive experimental\nvalidation on general graph and 2D/3D molecular graph generation tasks, we show\nthat our method outperforms previous generative models, generating graphs with\ncorrect topology with both continuous and discrete features.\n","authors":["Jaehyeong Jo","Dongki Kim","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2302.03596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10018v2","updated":"2023-02-07T17:03:44Z","published":"2022-07-20T16:31:19Z","title":"Mitigating Algorithmic Bias with Limited Annotations","summary":"  Existing work on fairness modeling commonly assumes that sensitive attributes\nfor all instances are fully available, which may not be true in many real-world\napplications due to the high cost of acquiring sensitive information. When\nsensitive attributes are not disclosed or available, it is needed to manually\nannotate a small part of the training data to mitigate bias. However, the\nskewed distribution across different sensitive groups preserves the skewness of\nthe original dataset in the annotated subset, which leads to non-optimal bias\nmitigation. To tackle this challenge, we propose Active Penalization Of\nDiscrimination (APOD), an interactive framework to guide the limited\nannotations towards maximally eliminating the effect of algorithmic bias. The\nproposed APOD integrates discrimination penalization with active instance\nselection to efficiently utilize the limited annotation budget, and it is\ntheoretically proved to be capable of bounding the algorithmic bias. According\nto the evaluation on five benchmark datasets, APOD outperforms the\nstate-of-the-arts baseline methods under the limited annotation budget, and\nshows comparable performance to fully annotated bias mitigation, which\ndemonstrates that APOD could benefit real-world applications when sensitive\ninformation is limited.\n","authors":["Guanchu Wang","Mengnan Du","Ninghao Liu","Na Zou","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2207.10018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01404v2","updated":"2023-02-07T16:54:46Z","published":"2023-02-02T20:34:45Z","title":"Provably Bounding Neural Network Preimages","summary":"  Most work on the formal verification of neural networks has focused on\nbounding forward images of neural networks, i.e., the set of outputs of a\nneural network that correspond to a given set of inputs (for example, bounded\nperturbations of a nominal input). However, many use cases of neural network\nverification require solving the inverse problem, i.e, over-approximating the\nset of inputs that lead to certain outputs. In this work, we present the first\nefficient bound propagation algorithm, INVPROP, for verifying properties over\nthe preimage of a linearly constrained output set of a neural network, which\ncan be combined with branch-and-bound to achieve completeness. Our efficient\nalgorithm allows multiple passes of intermediate bound refinements, which are\ncrucial for tight inverse verification because the bounds of an intermediate\nlayer depend on relaxations both before and after this layer. We demonstrate\nour algorithm on applications related to quantifying safe control regions for a\ndynamical system and detecting out-of-distribution inputs to a neural network.\nOur results show that in certain settings, we can find over-approximations that\nare over 2500 times tighter than prior work while being 2.5 times faster on the\nsame hardware.\n","authors":["Suhas Kotha","Christopher Brix","Zico Kolter","Krishnamurthy Dvijotham","Huan Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01404v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03586v1","updated":"2023-02-07T16:53:33Z","published":"2023-02-07T16:53:33Z","title":"Adaptive Aggregation for Safety-Critical Control","summary":"  Safety has been recognized as the central obstacle to preventing the use of\nreinforcement learning (RL) for real-world applications. Different methods have\nbeen developed to deal with safety concerns in RL. However, learning reliable\nRL-based solutions usually require a large number of interactions with the\nenvironment. Likewise, how to improve the learning efficiency, specifically,\nhow to utilize transfer learning for safe reinforcement learning, has not been\nwell studied. In this work, we propose an adaptive aggregation framework for\nsafety-critical control. Our method comprises two key techniques: 1) we learn\nto transfer the safety knowledge by aggregating the multiple source tasks and a\ntarget task through the attention network; 2) we separate the goal of improving\ntask performance and reducing constraint violations by utilizing a safeguard.\nExperiment results demonstrate that our algorithm can achieve fewer safety\nviolations while showing better data efficiency compared with several\nbaselines.\n","authors":["Huiliang Zhang","Di Wu","Benoit Boulet"],"pdf_url":"https://arxiv.org/pdf/2302.03586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.01632v2","updated":"2023-02-07T16:46:13Z","published":"2021-11-02T14:44:50Z","title":"Elucidating Robust Learning with Uncertainty-Aware Corruption Pattern\n  Estimation","summary":"  Robust learning methods aim to learn a clean target distribution from noisy\nand corrupted training data where a specific corruption pattern is often\nassumed a priori. Our proposed method can not only successfully learn the clean\ntarget distribution from a dirty dataset but also can estimate the underlying\nnoise pattern. To this end, we leverage a mixture-of-experts model that can\ndistinguish two different types of predictive uncertainty, aleatoric and\nepistemic uncertainty. We show that the ability to estimate the uncertainty\nplays a significant role in elucidating the corruption patterns as these two\nobjectives are tightly intertwined. We also present a novel validation scheme\nfor evaluating the performance of the corruption pattern estimation. Our\nproposed method is extensively assessed in terms of both robustness and\ncorruption pattern estimation through a number of domains, including computer\nvision and natural language processing.\n","authors":["Jeongeun Park","Seungyoun Shin","Sangheum Hwang","Sungjoon Choi"],"pdf_url":"https://arxiv.org/pdf/2111.01632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03580v1","updated":"2023-02-07T16:45:52Z","published":"2023-02-07T16:45:52Z","title":"Multi-Scale Message Passing Neural PDE Solvers","summary":"  We propose a novel multi-scale message passing neural network algorithm for\nlearning the solutions of time-dependent PDEs. Our algorithm possesses both\ntemporal and spatial multi-scale resolution features by incorporating\nmulti-scale sequence models and graph gating modules in the encoder and\nprocessor, respectively. Benchmark numerical experiments are presented to\ndemonstrate that the proposed algorithm outperforms baselines, particularly on\na PDE with a range of spatial and temporal scales.\n","authors":["Léonard Equer","T. Konstantin Rusch","Siddhartha Mishra"],"pdf_url":"https://arxiv.org/pdf/2302.03580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03573v1","updated":"2023-02-07T16:37:19Z","published":"2023-02-07T16:37:19Z","title":"Local Neural Descriptor Fields: Locally Conditioned Object\n  Representations for Manipulation","summary":"  A robot operating in a household environment will see a wide range of unique\nand unfamiliar objects. While a system could train on many of these, it is\ninfeasible to predict all the objects a robot will see. In this paper, we\npresent a method to generalize object manipulation skills acquired from a\nlimited number of demonstrations, to novel objects from unseen shape\ncategories. Our approach, Local Neural Descriptor Fields (L-NDF), utilizes\nneural descriptors defined on the local geometry of the object to effectively\ntransfer manipulation demonstrations to novel objects at test time. In doing\nso, we leverage the local geometry shared between objects to produce a more\ngeneral manipulation framework. We illustrate the efficacy of our approach in\nmanipulating novel objects in novel poses -- both in simulation and in the real\nworld.\n","authors":["Ethan Chun","Yilun Du","Anthony Simeonov","Tomas Lozano-Perez","Leslie Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2302.03573v1.pdf","comment":"ICRA 2023, Project Page: https://elchun.github.io/lndf/"},{"id":"http://arxiv.org/abs/2207.06917v2","updated":"2023-02-07T16:35:41Z","published":"2022-07-07T20:21:54Z","title":"Online Bayesian Meta-Learning for Cognitive Tracking Radar","summary":"  A key component of cognitive radar is the ability to generalize, or achieve\nconsistent performance across a range of sensing environments, since aspects of\nthe physical scene may vary over time. This presents a challenge for\nlearning-based waveform selection approaches, since transmission policies which\nare effective in one scene may be highly suboptimal in another. We address this\nproblem by strategically biasing a learning algorithm by exploiting high-level\nstructure across tracking instances, referred to as meta-learning. In this\nwork, we develop an online meta-learning approach for waveform-agile tracking.\nThis approach uses information gained from previous target tracks to speed up\nand enhance learning in new tracking instances. This results in\nsample-efficient learning across a class of finite state target channels by\nexploiting inherent similarity across tracking scenes, attributed to common\nphysical elements such as target type or clutter statistics. We formulate the\nonline waveform selection problem within the framework of Bayesian learning,\nand provide prior-dependent performance bounds for the meta-learning problem\nusing Probability Approximately Correct (PAC)-Bayes theory. We present a\ncomputationally feasible meta-posterior sampling algorithm and study the\nperformance in a simulation study consisting of diverse scenes. Finally, we\nexamine the potential performance benefits and practical challenges associated\nwith online meta-learning for waveform-agile tracking.\n","authors":["Charles E. Thornton","R. Michael Buehrer","Anthony F. Martone"],"pdf_url":"https://arxiv.org/pdf/2207.06917v2.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.03567v1","updated":"2023-02-07T16:28:10Z","published":"2023-02-07T16:28:10Z","title":"From Utilitarian to Rawlsian Designs for Algorithmic Fairness","summary":"  There is a lack of consensus within the literature as to how `fairness' of\nalgorithmic systems can be measured, and different metrics can often be at\nodds. In this paper, we approach this task by drawing on the ethical frameworks\nof utilitarianism and John Rawls. Informally, these two theories of\ndistributive justice measure the `good' as either a population's sum of\nutility, or worst-off outcomes, respectively. We present a parameterized class\nof objective functions that interpolates between these two (possibly)\nconflicting notions of the `good'. This class is shown to represent a\nrelaxation of the Rawlsian `veil of ignorance', and its sequence of optimal\nsolutions converges to both a utilitarian and Rawlsian optimum. Several other\nproperties of this class are studied, including: 1) a relationship to\nregularized optimization, 2) feasibility of consistent estimation, and 3)\nalgorithmic cost. In several real-world datasets, we compute optimal solutions\nand construct the tradeoff between utilitarian and Rawlsian notions of the\n`good'. Empirically, we demonstrate that increasing model complexity can\nmanifest strict improvements to both measures of the `good'. This work suggests\nthat the proper degree of `fairness' can be informed by a designer's\npreferences over the space of induced utilitarian and Rawlsian `good'.\n","authors":["Daniel E. Rigobon"],"pdf_url":"https://arxiv.org/pdf/2302.03567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16414v5","updated":"2023-02-07T16:25:15Z","published":"2022-10-28T21:40:56Z","title":"Meta-Learning Biologically Plausible Plasticity Rules with Random\n  Feedback Pathways","summary":"  Backpropagation is widely used to train artificial neural networks, but its\nrelationship to synaptic plasticity in the brain is unknown. Some biological\nmodels of backpropagation rely on feedback projections that are symmetric with\nfeedforward connections, but experiments do not corroborate the existence of\nsuch symmetric backward connectivity. Random feedback alignment offers an\nalternative model in which errors are propagated backward through fixed, random\nbackward connections. This approach successfully trains shallow models, but\nlearns slowly and does not perform well with deeper models or online learning.\nIn this study, we develop a meta-learning approach to discover interpretable,\nbiologically plausible plasticity rules that improve online learning\nperformance with fixed random feedback connections. The resulting plasticity\nrules show improved online training of deep models in the low data regime. Our\nresults highlight the potential of meta-learning to discover effective,\ninterpretable learning rules satisfying biological constraints.\n","authors":["Navid Shervani-Tabar","Robert Rosenbaum"],"pdf_url":"https://arxiv.org/pdf/2210.16414v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12625v2","updated":"2023-02-07T16:19:43Z","published":"2022-08-26T12:34:55Z","title":"Take One Gram of Neural Features, Get Enhanced Group Robustness","summary":"  Predictive performance of machine learning models trained with empirical risk\nminimization (ERM) can degrade considerably under distribution shifts. The\npresence of spurious correlations in training datasets leads ERM-trained models\nto display high loss when evaluated on minority groups not presenting such\ncorrelations. Extensive attempts have been made to develop methods improving\nworst-group robustness. However, they require group information for each\ntraining input or at least, a validation set with group labels to tune their\nhyperparameters, which may be expensive to get or unknown a priori. In this\npaper, we address the challenge of improving group robustness without group\nannotation during training or validation. To this end, we propose to partition\nthe training dataset into groups based on Gram matrices of features extracted\nby an ``identification'' model and to apply robust optimization based on these\npseudo-groups. In the realistic context where no group labels are available,\nour experiments show that our approach not only improves group robustness over\nERM but also outperforms all recent baselines\n","authors":["Simon Roburin","Charles Corbière","Gilles Puy","Nicolas Thome","Matthieu Aubry","Renaud Marlet","Patrick Pérez"],"pdf_url":"https://arxiv.org/pdf/2208.12625v2.pdf","comment":"Long version (Previous version: OOD-CV Workshop @ ECCV 2022)"},{"id":"http://arxiv.org/abs/2302.03561v1","updated":"2023-02-07T16:17:25Z","published":"2023-02-07T16:17:25Z","title":"Optimizing Audio Recommendations for the Long-Term: A Reinforcement\n  Learning Perspective","summary":"  We study the problem of optimizing a recommender system for outcomes that\noccur over several weeks or months. We begin by drawing on reinforcement\nlearning to formulate a comprehensive model of users' recurring relationships\nwith a recommender system. Measurement, attribution, and coordination\nchallenges complicate algorithm design. We describe careful modeling --\nincluding a new representation of user state and key conditional independence\nassumptions -- which overcomes these challenges and leads to simple, testable\nrecommender system prototypes. We apply our approach to a podcast recommender\nsystem that makes personalized recommendations to hundreds of millions of\nlisteners. A/B tests demonstrate that purposefully optimizing for long-term\noutcomes leads to large performance gains over conventional approaches that\noptimize for short-term proxies.\n","authors":["Lucas Maystre","Daniel Russo","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03560v1","updated":"2023-02-07T16:14:39Z","published":"2023-02-07T16:14:39Z","title":"Learning to cooperatively estimate road surface friction","summary":"  We present a system for estimating the friction of the pavement surface at\nany curved road section, by arriving at a consensus estimate, based on data\nfrom vehicles that have recently passed through that section. This estimate can\nhelp following vehicles. To keep costs down, we depend only on standard\nautomotive sensors, such as the IMU, and sensors for the steering angle and\nwheel speeds. Our system's workflow consists of: (i) processing of measurements\nfrom existing vehicular sensors, to implement a virtual sensor that captures\nthe effect of low friction on the vehicle, (ii) transmitting short kinematic\nsummaries from vehicles to a road side unit (RSU), using V2X communication, and\n(iii) estimating the friction coefficients, by running a machine learning\nregressor at the RSU, on summaries from individual vehicles, and then combining\nseveral such estimates.\n  In designing and implementing our system over a road network, we face two key\nquestions: (i) should each individual road section have a local friction\ncoefficient regressor, or can we use a global regressor that covers all the\npossible road sections? and (ii) how accurate are the resulting regressor\nestimates? We test the performance of design variations of our solution, using\nsimulations on the commercial package Dyna4. We consider a single vehicle type\nwith varying levels of tyre wear, and a range of road friction coefficients. We\nfind that: (a) only a marginal loss of accuracy is incurred in using a global\nregressor as compared to local regressors, (b) the consensus estimate at the\nRSU has a worst case error of about ten percent, if the combination is based on\nat least fifty recently passed vehicles, and (c) our regressors have root mean\nsquare (RMS) errors that are less than five percent. The RMS error rate of our\nsystem is half as that of a commercial friction estimation service.\n","authors":["Jens-Patrick Langstand","Maben Rabi"],"pdf_url":"https://arxiv.org/pdf/2302.03560v1.pdf","comment":"Submited to the 2023 IEEE CCTA"},{"id":"http://arxiv.org/abs/2207.00046v2","updated":"2023-02-07T16:07:50Z","published":"2022-06-30T18:26:03Z","title":"Performative Reinforcement Learning","summary":"  We introduce the framework of performative reinforcement learning where the\npolicy chosen by the learner affects the underlying reward and transition\ndynamics of the environment. Following the recent literature on performative\nprediction~\\cite{Perdomo et. al., 2020}, we introduce the concept of\nperformatively stable policy. We then consider a regularized version of the\nreinforcement learning problem and show that repeatedly optimizing this\nobjective converges to a performatively stable policy under reasonable\nassumptions on the transition dynamics. Our proof utilizes the dual perspective\nof the reinforcement learning problem and may be of independent interest in\nanalyzing the convergence of other algorithms with decision-dependent\nenvironments. We then extend our results for the setting where the learner just\nperforms gradient ascent steps instead of fully optimizing the objective, and\nfor the setting where the learner has access to a finite number of trajectories\nfrom the changed environment. For both settings, we leverage the dual\nformulation of performative reinforcement learning and establish convergence to\na stable solution. Finally, through extensive experiments on a grid-world\nenvironment, we demonstrate the dependence of convergence on various parameters\ne.g. regularization, smoothness, and the number of samples.\n","authors":["Debmalya Mandal","Stelios Triantafyllou","Goran Radanovic"],"pdf_url":"https://arxiv.org/pdf/2207.00046v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03550v1","updated":"2023-02-07T15:59:08Z","published":"2023-02-07T15:59:08Z","title":"Convergence rates for momentum stochastic gradient descent with noise of\n  machine learning type","summary":"  We consider the momentum stochastic gradient descent scheme (MSGD) and its\ncontinuous-in-time counterpart in the context of non-convex optimization. We\nshow almost sure exponential convergence of the objective function value for\ntarget functions that are Lipschitz continuous and satisfy the\nPolyak-Lojasiewicz inequality on the relevant domain, and under assumptions on\nthe stochastic noise that are motivated by overparameterized supervised\nlearning applications. Moreover, we optimize the convergence rate over the set\nof friction parameters and show that the MSGD process almost surely converges.\n","authors":["Benjamin Gess","Sebastian Kassing"],"pdf_url":"https://arxiv.org/pdf/2302.03550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03542v1","updated":"2023-02-07T15:50:49Z","published":"2023-02-07T15:50:49Z","title":"Two Losses Are Better Than One: Faster Optimization Using a Cheaper\n  Proxy","summary":"  We present an algorithm for minimizing an objective with hard-to-compute\ngradients by using a related, easier-to-access function as a proxy. Our\nalgorithm is based on approximate proximal point iterations on the proxy\ncombined with relatively few stochastic gradients from the objective. When the\ndifference between the objective and the proxy is $\\delta$-smooth, our\nalgorithm guarantees convergence at a rate matching stochastic gradient descent\non a $\\delta$-smooth objective, which can lead to substantially better sample\nefficiency. Our algorithm has many potential applications in machine learning,\nand provides a principled means of leveraging synthetic data, physics\nsimulators, mixed public and private data, and more.\n","authors":["Blake Woodworth","Konstantin Mishchenko","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2302.03542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08244v2","updated":"2023-02-07T15:46:25Z","published":"2022-09-17T04:54:32Z","title":"MA2QL: A Minimalist Approach to Fully Decentralized Multi-Agent\n  Reinforcement Learning","summary":"  Decentralized learning has shown great promise for cooperative multi-agent\nreinforcement learning (MARL). However, non-stationarity remains a significant\nchallenge in fully decentralized learning. In the paper, we tackle the\nnon-stationarity problem in the simplest and fundamental way and propose\nmulti-agent alternate Q-learning (MA2QL), where agents take turns updating\ntheir Q-functions by Q-learning. MA2QL is a minimalist approach to fully\ndecentralized cooperative MARL but is theoretically grounded. We prove that\nwhen each agent guarantees $\\varepsilon$-convergence at each turn, their joint\npolicy converges to a Nash equilibrium. In practice, MA2QL only requires\nminimal changes to independent Q-learning (IQL). We empirically evaluate MA2QL\non a variety of cooperative multi-agent tasks. Results show MA2QL consistently\noutperforms IQL, which verifies the effectiveness of MA2QL, despite such\nminimal changes.\n","authors":["Kefan Su","Siyuan Zhou","Jiechuan Jiang","Chuang Gan","Xiangjun Wang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2209.08244v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2302.03534v1","updated":"2023-02-07T15:36:08Z","published":"2023-02-07T15:36:08Z","title":"Towards Robust Inductive Graph Incremental Learning via Experience\n  Replay","summary":"  Inductive node-wise graph incremental learning is a challenging task due to\nthe dynamic nature of evolving graphs and the dependencies between nodes. In\nthis paper, we propose a novel experience replay framework, called\nStructure-Evolution-Aware Experience Replay (SEA-ER), that addresses these\nchallenges by leveraging the topological awareness of GNNs and importance\nreweighting technique. Our framework effectively addresses the data dependency\nof node prediction problems in evolving graphs, with a theoretical guarantee\nthat supports its effectiveness. Through empirical evaluation, we demonstrate\nthat our proposed framework outperforms the current state-of-the-art GNN\nexperience replay methods on several benchmark datasets, as measured by metrics\nsuch as accuracy and forgetting.\n","authors":["Junwei Su","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2302.03534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06243v4","updated":"2023-02-07T15:33:59Z","published":"2022-06-13T15:23:31Z","title":"Contrastive Learning for Unsupervised Domain Adaptation of Time Series","summary":"  Unsupervised domain adaptation (UDA) aims at learning a machine learning\nmodel using a labeled source domain that performs well on a similar yet\ndifferent, unlabeled target domain. UDA is important in many applications such\nas medicine, where it is used to adapt risk scores across different patient\ncohorts. In this paper, we develop a novel framework for UDA of time series\ndata, called CLUDA. Specifically, we propose a contrastive learning framework\nto learn contextual representations in multivariate time series, so that these\npreserve label information for the prediction task. In our framework, we\nfurther capture the variation in the contextual representations between source\nand target domain via a custom nearest-neighbor contrastive learning. To the\nbest of our knowledge, ours is the first framework to learn domain-invariant,\ncontextual representation for UDA of time series data. We evaluate our\nframework using a wide range of time series datasets to demonstrate its\neffectiveness and show that it achieves state-of-the-art performance for time\nseries UDA.\n","authors":["Yilmazcan Ozyurt","Stefan Feuerriegel","Ce Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.06243v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2206.12510v2","updated":"2023-02-07T15:32:50Z","published":"2022-06-24T22:57:24Z","title":"Black Box Optimization Using QUBO and the Cross Entropy Method","summary":"  Black-box optimization (BBO) can be used to optimize functions whose analytic\nform is unknown. A common approach to realising BBO is to learn a surrogate\nmodel which approximates the target black-box function which can then be solved\nvia white-box optimization methods. In this paper, we present our approach\nBOX-QUBO, where the surrogate model is a QUBO matrix. However, unlike in\nprevious state-of-the-art approaches, this matrix is not trained entirely by\nregression, but mostly by classification between 'good' and 'bad' solutions.\nThis better accounts for the low capacity of the QUBO matrix, resulting in\nsignificantly better solutions overall. We tested our approach against the\nstate-of-the-art on four domains and in all of them BOX-QUBO showed better\nresults. A second contribution of this paper is the idea to also solve\nwhite-box problems, i.e. problems which could be directly formulated as QUBO,\nby means of black-box optimization in order to reduce the size of the QUBOs to\nthe information-theoretic minimum. Experiments show that this significantly\nimproves the results for MAX-k-SAT.\n","authors":["Jonas Nüßlein","Christoph Roch","Thomas Gabor","Jonas Stein","Claudia Linnhoff-Popien","Sebastian Feld"],"pdf_url":"https://arxiv.org/pdf/2206.12510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11719v3","updated":"2023-02-07T15:15:36Z","published":"2022-07-24T11:23:31Z","title":"Gradient-based Bi-level Optimization for Deep Learning: A Survey","summary":"  Bi-level optimization, especially the gradient-based category, has been\nwidely used in the deep learning community including hyperparameter\noptimization and meta knowledge extraction. Bi-level optimization embeds one\nproblem within another and the gradient-based category solves the outer level\ntask by computing the hypergradient, which is much more efficient than\nclassical methods such as the evolutionary algorithm. In this survey, we first\ngive a formal definition of the gradient-based bi-level optimization. Secondly,\nwe illustrate how to formulate a research problem as a bi-level optimization\nproblem, which is of great practical use for beginners. More specifically,\nthere are two formulations: the single-task formulation to optimize\nhyperparameters such as regularization parameters and the distilled data, and\nthe multi-task formulation to extract meta knowledge such as the model\ninitialization. With a bi-level formulation, we then discuss four bi-level\noptimization solvers to update the outer variable including explicit gradient\nupdate, proxy update, implicit function update, and closed-form update. Last\nbut not least, we conclude the survey by pointing out the great potential of\ngradient-based bi-level optimization on science problems (AI4Science).\n","authors":["Can Chen","Xi Chen","Chen Ma","Zixuan Liu","Xue Liu"],"pdf_url":"https://arxiv.org/pdf/2207.11719v3.pdf","comment":"AI4Science; Bi-level Optimization; Hyperparameter Optimization; Meta\n  Learning; Implicit Function"},{"id":"http://arxiv.org/abs/2302.03519v1","updated":"2023-02-07T15:09:23Z","published":"2023-02-07T15:09:23Z","title":"Efficient Parametric Approximations of Neural Network Function Space\n  Distance","summary":"  It is often useful to compactly summarize important properties of model\nparameters and training data so that they can be used later without storing\nand/or iterating over the entire dataset. As a specific case, we consider\nestimating the Function Space Distance (FSD) over a training set, i.e. the\naverage discrepancy between the outputs of two neural networks. We propose a\nLinearized Activation Function TRick (LAFTR) and derive an efficient\napproximation to FSD for ReLU neural networks. The key idea is to approximate\nthe architecture as a linear network with stochastic gating. Despite requiring\nonly one parameter per unit of the network, our approach outcompetes other\nparametric approximations with larger memory requirements. Applied to continual\nlearning, our parametric approximation is competitive with state-of-the-art\nnonparametric approximations, which require storing many training examples.\nFurthermore, we show its efficacy in estimating influence functions accurately\nand detecting mislabeled examples without expensive iterations over the entire\ndataset.\n","authors":["Nikita Dhawan","Sicong Huang","Juhan Bae","Roger Grosse"],"pdf_url":"https://arxiv.org/pdf/2302.03519v1.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2103.04992v2","updated":"2023-02-07T15:09:15Z","published":"2021-03-08T18:35:06Z","title":"Self-learning Machines based on Hamiltonian Echo Backpropagation","summary":"  A physical self-learning machine can be defined as a nonlinear dynamical\nsystem that can be trained on data (similar to artificial neural networks), but\nwhere the update of the internal degrees of freedom that serve as learnable\nparameters happens autonomously. In this way, neither external processing and\nfeedback nor knowledge of (and control of) these internal degrees of freedom is\nrequired. We introduce a general scheme for self-learning in any\ntime-reversible Hamiltonian system. We illustrate the training of such a\nself-learning machine numerically for the case of coupled nonlinear wave\nfields.\n","authors":["Victor Lopez-Pastor","Florian Marquardt"],"pdf_url":"https://arxiv.org/pdf/2103.04992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15675v2","updated":"2023-02-07T15:05:43Z","published":"2022-10-27T12:12:45Z","title":"Feature Necessity & Relevancy in ML Classifier Explanations","summary":"  Given a machine learning (ML) model and a prediction, explanations can be\ndefined as sets of features which are sufficient for the prediction. In some\napplications, and besides asking for an explanation, it is also critical to\nunderstand whether sensitive features can occur in some explanation, or whether\na non-interesting feature must occur in all explanations. This paper starts by\nrelating such queries respectively with the problems of relevancy and necessity\nin logic-based abduction. The paper then proves membership and hardness results\nfor several families of ML classifiers. Afterwards the paper proposes concrete\nalgorithms for two classes of classifiers. The experimental results confirm the\nscalability of the proposed algorithms.\n","authors":["Xuanxiang Huang","Martin C. Cooper","Antonio Morgado","Jordi Planes","Joao Marques-Silva"],"pdf_url":"https://arxiv.org/pdf/2210.15675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00660v3","updated":"2023-02-07T15:02:14Z","published":"2022-10-03T00:28:44Z","title":"A Non-monotonic Self-terminating Language Model","summary":"  Recent large-scale neural autoregressive sequence models have shown\nimpressive performances on a variety of natural language generation tasks.\nHowever, their generated sequences often exhibit degenerate properties such as\nnon-termination, undesirable repetition, and premature termination, when\ngenerated with decoding algorithms such as greedy search, beam search, top-$k$\nsampling, and nucleus sampling. In this paper, we focus on the problem of\nnon-terminating sequences resulting from an incomplete decoding algorithm. We\nfirst define an incomplete probable decoding algorithm which includes greedy\nsearch, top-$k$ sampling, and nucleus sampling, beyond the incomplete decoding\nalgorithm originally put forward by Welleck et al. (2020). We then propose a\nnon-monotonic self-terminating language model, which significantly relaxes the\nconstraint of monotonically increasing termination probability in the\noriginally proposed self-terminating language model by Welleck et al. (2020),\nto address the issue of non-terminating sequences when using incomplete\nprobable decoding algorithms. We prove that our proposed model prevents\nnon-terminating sequences when using not only incomplete probable decoding\nalgorithms but also beam search. We empirically validate our model on sequence\ncompletion tasks with various architectures.\n","authors":["Eugene Choi","Kyunghyun Cho","Cheolhyoung Lee"],"pdf_url":"https://arxiv.org/pdf/2210.00660v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03505v1","updated":"2023-02-07T14:45:34Z","published":"2023-02-07T14:45:34Z","title":"OPORP: One Permutation + One Random Projection","summary":"  Consider two $D$-dimensional data vectors (e.g., embeddings): $u, v$. In many\nembedding-based retrieval (EBR) applications where the vectors are generated\nfrom trained models, $D=256\\sim 1024$ are common. In this paper, OPORP (one\npermutation + one random projection) uses a variant of the ``count-sketch''\ntype of data structures for achieving data reduction/compression. With OPORP,\nwe first apply a permutation on the data vectors. A random vector $r$ is\ngenerated i.i.d. with moments: $E(r_i) = 0, E(r_i^2)=1, E(r_i^3) =0,\nE(r_i^4)=s$. We multiply (as dot product) $r$ with all permuted data vectors.\nThen we break the $D$ columns into $k$ equal-length bins and aggregate (i.e.,\nsum) the values in each bin to obtain $k$ samples from each data vector. One\ncrucial step is to normalize the $k$ samples to the unit $l_2$ norm. We show\nthat the estimation variance is essentially: $(s-1)A +\n\\frac{D-k}{D-1}\\frac{1}{k}\\left[ (1-\\rho^2)^2 -2A\\right]$, where $A\\geq 0$ is a\nfunction of the data ($u,v$). This formula reveals several key properties: (1)\nWe need $s=1$. (2) The factor $\\frac{D-k}{D-1}$ can be highly beneficial in\nreducing variances. (3) The term $\\frac{1}{k}(1-\\rho^2)^2$ is actually the\nasymptotic variance of the classical correlation estimator.\n  We illustrate that by letting the $k$ in OPORP to be $k=1$ and repeat the\nprocedure $m$ times, we exactly recover the work of ``very spars random\nprojections'' (VSRP). This immediately leads to a normalized estimator for VSRP\nwhich substantially improves the original estimator of VSRP.\n  In summary, with OPORP, the two key steps: (i) the normalization and (ii) the\nfixed-length binning scheme, have considerably improved the accuracy in\nestimating the cosine similarity, which is a routine (and crucial) task in\nmodern embedding-based retrieval (EBR) applications.\n","authors":["Ping Li","Xiaoyun Li"],"pdf_url":"https://arxiv.org/pdf/2302.03505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03493v1","updated":"2023-02-07T14:37:44Z","published":"2023-02-07T14:37:44Z","title":"Revised Conditional t-SNE: Looking Beyond the Nearest Neighbors","summary":"  Conditional t-SNE (ct-SNE) is a recent extension to t-SNE that allows removal\nof known cluster information from the embedding, to obtain a visualization\nrevealing structure beyond label information. This is useful, for example, when\none wants to factor out unwanted differences between a set of classes. We show\nthat ct-SNE fails in many realistic settings, namely if the data is well\nclustered over the labels in the original high-dimensional space. We introduce\na revised method by conditioning the high-dimensional similarities instead of\nthe low-dimensional similarities and storing within- and across-label nearest\nneighbors separately. This also enables the use of recently proposed speedups\nfor t-SNE, improving the scalability. From experiments on synthetic data, we\nfind that our proposed method resolves the considered problems and improves the\nembedding quality. On real data containing batch effects, the expected\nimprovement is not always there. We argue revised ct-SNE is preferable overall,\ngiven its improved scalability. The results also highlight new open questions,\nsuch as how to handle distance variations between clusters.\n","authors":["Edith Heiter","Bo Kang","Ruth Seurinck","Jefrey Lijffijt"],"pdf_url":"https://arxiv.org/pdf/2302.03493v1.pdf","comment":"13 pages, 8 pages supplement, to be published in the Proceedings of\n  the 21st International Symposium on Intelligent Data Analysis (IDA 2023),\n  Springer, 2023"},{"id":"http://arxiv.org/abs/2302.03491v1","updated":"2023-02-07T14:35:35Z","published":"2023-02-07T14:35:35Z","title":"Learning Translation Quality Evaluation on Low Resource Languages from\n  Large Language Models","summary":"  Learned metrics such as BLEURT have in recent years become widely employed to\nevaluate the quality of machine translation systems. Training such metrics\nrequires data which can be expensive and difficult to acquire, particularly for\nlower-resource languages. We show how knowledge can be distilled from Large\nLanguage Models (LLMs) to improve upon such learned metrics without requiring\nhuman annotators, by creating synthetic datasets which can be mixed into\nexisting datasets, requiring only a corpus of text in the target language. We\nshow that the performance of a BLEURT-like model on lower resource languages\ncan be improved in this way.\n","authors":["Amirkeivan Mohtashami","Mauro Verzetti","Paul K. Rubenstein"],"pdf_url":"https://arxiv.org/pdf/2302.03491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03490v1","updated":"2023-02-07T14:34:39Z","published":"2023-02-07T14:34:39Z","title":"Natural Language Processing for Policymaking","summary":"  Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2\n","authors":["Zhijing Jin","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2302.03490v1.pdf","comment":"Handbook of Computational Social Science for Policy (2023), Chapter 7\n  (pages 141-162). Open Access on Springer:\n  https://doi.org/10.1007/978-3-031-16624-2"},{"id":"http://arxiv.org/abs/2301.12866v2","updated":"2023-02-07T14:15:26Z","published":"2023-01-30T13:19:19Z","title":"N-Gram Nearest Neighbor Machine Translation","summary":"  Nearest neighbor machine translation augments the Autoregressive\nTranslation~(AT) with $k$-nearest-neighbor retrieval, by comparing the\nsimilarity between the token-level context representations of the target tokens\nin the query and the datastore. However, the token-level representation may\nintroduce noise when translating ambiguous words, or fail to provide accurate\nretrieval results when the representation generated by the model contains\nindistinguishable context information, e.g., Non-Autoregressive\nTranslation~(NAT) models. In this paper, we propose a novel $n$-gram nearest\nneighbor retrieval method that is model agnostic and applicable to both AT and\nNAT models. Specifically, we concatenate the adjacent $n$-gram hidden\nrepresentations as the key, while the tuple of corresponding target tokens is\nthe value. In inference, we propose tailored decoding algorithms for AT and NAT\nmodels respectively. We demonstrate that the proposed method consistently\noutperforms the token-level method on both AT and NAT models as well on general\nas on domain adaptation translation tasks. On domain adaptation, the proposed\nmethod brings $1.03$ and $2.76$ improvements regarding the average BLEU score\non AT and NAT models respectively.\n","authors":["Rui Lv","Junliang Guo","Rui Wang","Xu Tan","Qi Liu","Tao Qin"],"pdf_url":"https://arxiv.org/pdf/2301.12866v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03480v1","updated":"2023-02-07T14:09:41Z","published":"2023-02-07T14:09:41Z","title":"A Bayesian Optimization approach for calibrating large-scale\n  activity-based transport models","summary":"  The use of Agent-Based and Activity-Based modeling in transportation is\nrising due to the capability of addressing complex applications such as\ndisruptive trends (e.g., remote working and automation) or the design and\nassessment of disaggregated management strategies. Still, the broad adoption of\nlarge-scale disaggregate models is not materializing due to the inherently high\ncomplexity and computational needs. Activity-based models focused on behavioral\ntheory, for example, may involve hundreds of parameters that need to be\ncalibrated to match the detailed socio-economical characteristics of the\npopulation for any case study. This paper tackles this issue by proposing a\nnovel Bayesian Optimization approach incorporating a surrogate model in the\nform of an improved Random Forest, designed to automate the calibration process\nof the behavioral parameters. The proposed method is tested on a case study for\nthe city of Tallinn, Estonia, where the model to be calibrated consists of 477\nbehavioral parameters, using the SimMobility MT software. Satisfactory\nperformance is achieved in the major indicators defined for the calibration\nprocess: the error for the overall number of trips is equal to 4% and the\naverage error in the OD matrix is 15.92 vehicles per day.\n","authors":["Serio Agriesti","Vladimir Kuzmanovski","Jaakko Hollmén","Claudio Roncoli","Bat-hen Nahmias-Biran"],"pdf_url":"https://arxiv.org/pdf/2302.03480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03473v1","updated":"2023-02-07T13:58:08Z","published":"2023-02-07T13:58:08Z","title":"Med-NCA: Robust and Lightweight Segmentation with Neural Cellular\n  Automata","summary":"  Access to the proper infrastructure is critical when performing medical image\nsegmentation with Deep Learning. This requirement makes it difficult to run\nstate-of-the-art segmentation models in resource-constrained scenarios like\nprimary care facilities in rural areas and during crises. The recently emerging\nfield of Neural Cellular Automata (NCA) has shown that locally interacting\none-cell models can achieve competitive results in tasks such as image\ngeneration or segmentations in low-resolution inputs. However, they are\nconstrained by high VRAM requirements and the difficulty of reaching\nconvergence for high-resolution images. To counteract these limitations we\npropose Med-NCA, an end-to-end NCA training pipeline for high-resolution image\nsegmentation. Our method follows a two-step process. Global knowledge is first\ncommunicated between cells across the downscaled image. Following that,\npatch-based segmentation is performed. Our proposed Med-NCA outperforms the\nclassic UNet by 2% and 3% Dice for hippocampus and prostate segmentation,\nrespectively, while also being 500 times smaller. We also show that Med-NCA is\nby design invariant with respect to image scale, shape and translation,\nexperiencing only slight performance degradation even with strong shifts; and\nis robust against MRI acquisition artefacts. Med-NCA enables high-resolution\nmedical image segmentation even on a Raspberry Pi B+, arguably the smallest\ndevice able to run PyTorch and that can be powered by a standard power bank.\n","authors":["John Kalkhof","Camila González","Anirban Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2302.03473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03465v1","updated":"2023-02-07T13:40:56Z","published":"2023-02-07T13:40:56Z","title":"Robustness Implies Fairness in Casual Algorithmic Recourse","summary":"  Algorithmic recourse aims to disclose the inner workings of the black-box\ndecision process in situations where decisions have significant consequences,\nby providing recommendations to empower beneficiaries to achieve a more\nfavorable outcome. To ensure an effective remedy, suggested interventions must\nnot only be low-cost but also robust and fair. This goal is accomplished by\nproviding similar explanations to individuals who are alike. This study\nexplores the concept of individual fairness and adversarial robustness in\ncausal algorithmic recourse and addresses the challenge of achieving both. To\nresolve the challenges, we propose a new framework for defining adversarially\nrobust recourse. The new setting views the protected feature as a pseudometric\nand demonstrates that individual fairness is a special case of adversarial\nrobustness. Finally, we introduce the fair robust recourse problem to achieve\nboth desirable properties and show how it can be satisfied both theoretically\nand empirically.\n","authors":["Ahmad-Reza Ehyaei","Amir-Hossein Karimi","Bernhard Schölkopf","Setareh Maghsudi"],"pdf_url":"https://arxiv.org/pdf/2302.03465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03462v1","updated":"2023-02-07T13:36:27Z","published":"2023-02-07T13:36:27Z","title":"Diverse Probabilistic Trajectory Forecasting with Admissibility\n  Constraints","summary":"  Predicting multiple trajectories for road users is important for automated\ndriving systems: ego-vehicle motion planning indeed requires a clear view of\nthe possible motions of the surrounding agents. However, the generative models\nused for multiple-trajectory forecasting suffer from a lack of diversity in\ntheir proposals. To avoid this form of collapse, we propose a novel method for\nstructured prediction of diverse trajectories. To this end, we complement an\nunderlying pretrained generative model with a diversity component, based on a\ndeterminantal point process (DPP). We balance and structure this diversity with\nthe inclusion of knowledge-based quality constraints, independent from the\nunderlying generative model. We combine these two novel components with a\ngating operation, ensuring that the predictions are both diverse and within the\ndrivable area. We demonstrate on the nuScenes driving dataset the relevance of\nour compound approach, which yields significant improvements in the diversity\nand the quality of the generated trajectories.\n","authors":["Laura Calem","Hedi Ben-Younes","Patrick Pérez","Nicolas Thome"],"pdf_url":"https://arxiv.org/pdf/2302.03462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03460v1","updated":"2023-02-07T13:31:02Z","published":"2023-02-07T13:31:02Z","title":"Mind the Gap! Bridging Explainable Artificial Intelligence and Human\n  Understanding with Luhmann's Functional Theory of Communication","summary":"  Over the past decade explainable artificial intelligence has evolved from a\npredominantly technical discipline into a field that is deeply intertwined with\nsocial sciences. Insights such as human preference for contrastive -- more\nprecisely, counterfactual -- explanations have played a major role in this\ntransition, inspiring and guiding the research in computer science. Other\nobservations, while equally important, have received much less attention. The\ndesire of human explainees to communicate with artificial intelligence\nexplainers through a dialogue-like interaction has been mostly neglected by the\ncommunity. This poses many challenges for the effectiveness and widespread\nadoption of such technologies as delivering a single explanation optimised\naccording to some predefined objectives may fail to engender understanding in\nits recipients and satisfy their unique needs given the diversity of human\nknowledge and intention. Using insights elaborated by Niklas Luhmann and, more\nrecently, Elena Esposito we apply social systems theory to highlight challenges\nin explainable artificial intelligence and offer a path forward, striving to\nreinvigorate the technical research in this direction. This paper aims to\ndemonstrate the potential of systems theoretical approaches to communication in\nunderstanding problems and limitations of explainable artificial intelligence.\n","authors":["Bernard Keenan","Kacper Sokol"],"pdf_url":"https://arxiv.org/pdf/2302.03460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08771v3","updated":"2023-02-07T13:30:38Z","published":"2022-11-16T08:59:26Z","title":"On the symmetries in the dynamics of wide two-layer neural networks","summary":"  We consider the idealized setting of gradient flow on the population risk for\ninfinitely wide two-layer ReLU neural networks (without bias), and study the\neffect of symmetries on the learned parameters and predictors. We first\ndescribe a general class of symmetries which, when satisfied by the target\nfunction $f^*$ and the input distribution, are preserved by the dynamics. We\nthen study more specific cases. When $f^*$ is odd, we show that the dynamics of\nthe predictor reduces to that of a (non-linearly parameterized) linear\npredictor, and its exponential convergence can be guaranteed. When $f^*$ has a\nlow-dimensional structure, we prove that the gradient flow PDE reduces to a\nlower-dimensional PDE. Furthermore, we present informal and numerical arguments\nthat suggest that the input neurons align with the lower-dimensional structure\nof the problem.\n","authors":["Karl Hajjar","Lenaic Chizat"],"pdf_url":"https://arxiv.org/pdf/2211.08771v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03459v1","updated":"2023-02-07T13:29:06Z","published":"2023-02-07T13:29:06Z","title":"On the relationship between multivariate splines and infinitely-wide\n  neural networks","summary":"  We consider multivariate splines and show that they have a random feature\nexpansion as infinitely wide neural networks with one-hidden layer and a\nhomogeneous activation function which is the power of the rectified linear\nunit. We show that the associated function space is a Sobolev space on a\nEuclidean ball, with an explicit bound on the norms of derivatives. This link\nprovides a new random feature expansion for multivariate splines that allow\nefficient algorithms. This random feature expansion is numerically better\nbehaved than usual random Fourier features, both in theory and practice. In\nparticular, in dimension one, we compare the associated leverage scores to\ncompare the two random expansions and show a better scaling for the neural\nnetwork expansion.\n","authors":["Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2302.03459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.14057v2","updated":"2023-02-07T13:26:05Z","published":"2022-08-30T08:17:55Z","title":"Symmetric Pruning in Quantum Neural Networks","summary":"  Many fundamental properties of a quantum system are captured by its\nHamiltonian and ground state. Despite the significance of ground states\npreparation (GSP), this task is classically intractable for large-scale\nHamiltonians. Quantum neural networks (QNNs), which exert the power of modern\nquantum machines, have emerged as a leading protocol to conquer this issue. As\nsuch, how to enhance the performance of QNNs becomes a crucial topic in GSP.\nEmpirical evidence showed that QNNs with handcraft symmetric ansatzes generally\nexperience better trainability than those with asymmetric ansatzes, while\ntheoretical explanations have not been explored. To fill this knowledge gap,\nhere we propose the effective quantum neural tangent kernel (EQNTK) and connect\nthis concept with over-parameterization theory to quantify the convergence of\nQNNs towards the global optima. We uncover that the advance of symmetric\nansatzes attributes to their large EQNTK value with low effective dimension,\nwhich requests few parameters and quantum circuit depth to reach the\nover-parameterization regime permitting a benign loss landscape and fast\nconvergence. Guided by EQNTK, we further devise a symmetric pruning (SP) scheme\nto automatically tailor a symmetric ansatz from an over-parameterized and\nasymmetric one to greatly improve the performance of QNNs when the explicit\nsymmetry information of Hamiltonian is unavailable. Extensive numerical\nsimulations are conducted to validate the analytical results of EQNTK and the\neffectiveness of SP.\n","authors":["Xinbiao Wang","Junyu Liu","Tongliang Liu","Yong Luo","Yuxuan Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2208.14057v2.pdf","comment":"Accepted to International Conference on Learning Representations\n  (ICLR) 2023"},{"id":"http://arxiv.org/abs/2302.00747v2","updated":"2023-02-07T13:09:43Z","published":"2023-02-01T20:47:58Z","title":"Universal Soldier: Using Universal Adversarial Perturbations for\n  Detecting Backdoor Attacks","summary":"  Deep learning models achieve excellent performance in numerous machine\nlearning tasks. Yet, they suffer from security-related issues such as\nadversarial examples and poisoning (backdoor) attacks. A deep learning model\nmay be poisoned by training with backdoored data or by modifying inner network\nparameters. Then, a backdoored model performs as expected when receiving a\nclean input, but it misclassifies when receiving a backdoored input stamped\nwith a pre-designed pattern called \"trigger\". Unfortunately, it is difficult to\ndistinguish between clean and backdoored models without prior knowledge of the\ntrigger. This paper proposes a backdoor detection method by utilizing a special\ntype of adversarial attack, universal adversarial perturbation (UAP), and its\nsimilarities with a backdoor trigger. We observe an intuitive phenomenon: UAPs\ngenerated from backdoored models need fewer perturbations to mislead the model\nthan UAPs from clean models. UAPs of backdoored models tend to exploit the\nshortcut from all classes to the target class, built by the backdoor trigger.\nWe propose a novel method called Universal Soldier for Backdoor detection (USB)\nand reverse engineering potential backdoor triggers via UAPs. Experiments on\n345 models trained on several datasets show that USB effectively detects the\ninjected backdoor and provides comparable or better results than\nstate-of-the-art methods.\n","authors":["Xiaoyun Xu","Oguzhan Ersoy","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2302.00747v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03093v2","updated":"2023-02-07T12:56:33Z","published":"2022-07-07T05:22:44Z","title":"Backpropagation on Dynamical Networks","summary":"  Dynamical networks are versatile models that can describe a variety of\nbehaviours such as synchronisation and feedback. However, applying these models\nin real world contexts is difficult as prior information pertaining to the\nconnectivity structure or local dynamics is often unknown and must be inferred\nfrom time series observations of network states. Additionally, the influence of\ncoupling interactions between nodes further complicates the isolation of local\nnode dynamics. Given the architectural similarities between dynamical networks\nand recurrent neural networks (RNN), we propose a network inference method\nbased on the backpropagation through time (BPTT) algorithm commonly used to\ntrain recurrent neural networks. This method aims to simultaneously infer both\nthe connectivity structure and local node dynamics purely from observation of\nnode states. An approximation of local node dynamics is first constructed using\na neural network. This is alternated with an adapted BPTT algorithm to regress\ncorresponding network weights by minimising prediction errors of the dynamical\nnetwork based on the previously constructed local models until convergence is\nachieved. This method was found to be succesful in identifying the connectivity\nstructure for coupled networks of Lorenz, Chua and FitzHugh-Nagumo oscillators.\nFreerun prediction performance with the resulting local models and weights was\nfound to be comparable to the true system with noisy initial conditions. The\nmethod is also extended to non-conventional network couplings such as\nasymmetric negative coupling.\n","authors":["Eugene Tan","Débora Corrêa","Thomas Stemler","Michael Small"],"pdf_url":"https://arxiv.org/pdf/2207.03093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03439v1","updated":"2023-02-07T12:51:20Z","published":"2023-02-07T12:51:20Z","title":"Ensemble Value Functions for Efficient Exploration in Multi-Agent\n  Reinforcement Learning","summary":"  Cooperative multi-agent reinforcement learning (MARL) requires agents to\nexplore to learn to cooperate. Existing value-based MARL algorithms commonly\nrely on random exploration, such as $\\epsilon$-greedy, which is inefficient in\ndiscovering multi-agent cooperation. Additionally, the environment in MARL\nappears non-stationary to any individual agent due to the simultaneous training\nof other agents, leading to highly variant and thus unstable optimisation\nsignals. In this work, we propose ensemble value functions for multi-agent\nexploration (EMAX), a general framework to extend any value-based MARL\nalgorithm. EMAX trains ensembles of value functions for each agent to address\nthe key challenges of exploration and non-stationarity: (1) The uncertainty of\nvalue estimates across the ensemble is used in a UCB policy to guide the\nexploration of agents to parts of the environment which require cooperation.\n(2) Average value estimates across the ensemble serve as target values. These\ntargets exhibit lower variance compared to commonly applied target networks and\nwe show that they lead to more stable gradients during the optimisation. We\ninstantiate three value-based MARL algorithms with EMAX, independent DQN, VDN\nand QMIX, and evaluate them in 21 tasks across four environments. Using\nensembles of five value functions, EMAX improves sample efficiency and final\nevaluation returns of these algorithms by 54%, 55%, and 844%, respectively,\naveraged all 21 tasks.\n","authors":["Lukas Schäfer","Oliver Slumbers","Stephen McAleer","Yali Du","Stefano V. Albrecht","David Mguni"],"pdf_url":"https://arxiv.org/pdf/2302.03439v1.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2302.03438v1","updated":"2023-02-07T12:46:54Z","published":"2023-02-07T12:46:54Z","title":"Uncoupled Learning of Differential Stackelberg Equilibria with\n  Commitments","summary":"  A natural solution concept for many multiagent settings is the Stackelberg\nequilibrium, under which a ``leader'' agent selects a strategy that maximizes\nits own payoff assuming the ``follower'' chooses their best response to this\nstrategy. Recent work has presented asymmetric learning updates that can be\nshown to converge to the \\textit{differential} Stackelberg equilibria of\ntwo-player differentiable games. These updates are ``coupled'' in the sense\nthat the leader requires some information about the follower's payoff function.\nSuch coupled learning rules cannot be applied to \\textit{ad hoc} interactive\nlearning settings, and can be computationally impractical even in centralized\ntraining settings where the follower's payoffs are known. In this work, we\npresent an ``uncoupled'' learning process under which each player's learning\nupdate only depends on their observations of the other's behavior. We prove\nthat this process converges to a local Stackelberg equilibrium under similar\nconditions as previous coupled methods. We conclude with a discussion of the\npotential applications of our approach to human--AI cooperation and multi-agent\nreinforcement learning.\n","authors":["Robert Loftin","Mustafa Mert Çelikok","Herke van Hoof","Samuel Kaski","Frans A. Oliehoek"],"pdf_url":"https://arxiv.org/pdf/2302.03438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11482v3","updated":"2023-02-07T12:43:42Z","published":"2023-01-27T01:11:42Z","title":"Diffusion Denoising for Low-Dose-CT Model","summary":"  Low-dose Computed Tomography (LDCT) reconstruction is an important task in\nmedical image analysis. Recent years have seen many deep learning based\nmethods, proved to be effective in this area. However, these methods mostly\nfollow a supervised architecture, which needs paired CT image of full dose and\nquarter dose, and the solution is highly dependent on specific measurements. In\nthis work, we introduce Denoising Diffusion LDCT Model, dubbed as DDLM,\ngenerating noise-free CT image using conditioned sampling. DDLM uses pretrained\nmodel, and need no training nor tuning process, thus our proposal is in\nunsupervised manner. Experiments on LDCT images have shown comparable\nperformance of DDLM using less inference time, surpassing other\nstate-of-the-art methods, proving both accurate and efficient. Implementation\ncode will be set to public soon.\n","authors":["Runyi Li"],"pdf_url":"https://arxiv.org/pdf/2301.11482v3.pdf","comment":"The method and experiment of this paper has some error, and we need\n  to revise it"},{"id":"http://arxiv.org/abs/2207.03116v3","updated":"2023-02-07T12:40:18Z","published":"2022-07-07T06:55:52Z","title":"Equivariant Representation Learning via Class-Pose Decomposition","summary":"  We introduce a general method for learning representations that are\nequivariant to symmetries of data. Our central idea is to decompose the latent\nspace into an invariant factor and the symmetry group itself. The components\nsemantically correspond to intrinsic data classes and poses respectively. The\nlearner is trained on a loss encouraging equivariance based on supervision from\nrelative symmetry information. The approach is motivated by theoretical results\nfrom group theory and guarantees representations that are lossless,\ninterpretable and disentangled. We provide an empirical investigation via\nexperiments involving datasets with a variety of symmetries. Results show that\nour representations capture the geometry of data and outperform other\nequivariant representation learning frameworks.\n","authors":["Giovanni Luca Marchetti","Gustaf Tegnér","Anastasiia Varava","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2207.03116v3.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2302.03429v1","updated":"2023-02-07T12:30:52Z","published":"2023-02-07T12:30:52Z","title":"Towards Skilled Population Curriculum for Multi-Agent Reinforcement\n  Learning","summary":"  Recent advances in multi-agent reinforcement learning (MARL) allow agents to\ncoordinate their behaviors in complex environments. However, common MARL\nalgorithms still suffer from scalability and sparse reward issues. One\npromising approach to resolving them is automatic curriculum learning (ACL).\nACL involves a student (curriculum learner) training on tasks of increasing\ndifficulty controlled by a teacher (curriculum generator). Despite its success,\nACL's applicability is limited by (1) the lack of a general student framework\nfor dealing with the varying number of agents across tasks and the sparse\nreward problem, and (2) the non-stationarity of the teacher's task due to\never-changing student strategies. As a remedy for ACL, we introduce a novel\nautomatic curriculum learning framework, Skilled Population Curriculum (SPC),\nwhich adapts curriculum learning to multi-agent coordination. Specifically, we\nendow the student with population-invariant communication and a hierarchical\nskill set, allowing it to learn cooperation and behavior skills from distinct\ntasks with varying numbers of agents. In addition, we model the teacher as a\ncontextual bandit conditioned by student policies, enabling a team of agents to\nchange its size while still retaining previously acquired skills. We also\nanalyze the inherent non-stationarity of this multi-agent automatic curriculum\nteaching problem and provide a corresponding regret bound. Empirical results\nshow that our method improves the performance, scalability and sample\nefficiency in several MARL environments.\n","authors":["Rundong Wang","Longtao Zheng","Wei Qiu","Bowei He","Bo An","Zinovi Rabinovich","Yujing Hu","Yingfeng Chen","Tangjie Lv","Changjie Fan"],"pdf_url":"https://arxiv.org/pdf/2302.03429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02524v2","updated":"2023-02-07T12:25:20Z","published":"2023-02-06T01:44:45Z","title":"Novel Fundus Image Preprocessing for Retcam Images to Improve Deep\n  Learning Classification of Retinopathy of Prematurity","summary":"  Retinopathy of Prematurity (ROP) is a potentially blinding eye disorder\nbecause of damage to the eye's retina which can affect babies born prematurely.\nScreening of ROP is essential for early detection and treatment. This is a\nlaborious and manual process which requires trained physician performing\ndilated ophthalmological examination which can be subjective resulting in lower\ndiagnosis success for clinically significant disease. Automated diagnostic\nmethods can assist ophthalmologists increase diagnosis accuracy using deep\nlearning. Several research groups have highlighted various approaches. This\npaper proposes the use of new novel fundus preprocessing methods using\npretrained transfer learning frameworks to create hybrid models to give higher\ndiagnosis accuracy. The evaluations show that these novel methods in comparison\nto traditional imaging processing contribute to higher accuracy in classifying\nPlus disease, Stages of ROP and Zones. We achieve accuracy of 97.65% for Plus\ndisease, 89.44% for Stage, 90.24% for Zones with limited training dataset.\n","authors":["Sajid Rahim","Kourosh Sabri","Anna Ells","Alan Wassyng","Mark Lawford","Linyang Chu","Wenbo He"],"pdf_url":"https://arxiv.org/pdf/2302.02524v2.pdf","comment":"10 pages, 4 figures, 7 tables. arXiv admin note: text overlap with\n  arXiv:1904.08796 by other authors"},{"id":"http://arxiv.org/abs/2302.03421v1","updated":"2023-02-07T12:11:59Z","published":"2023-02-07T12:11:59Z","title":"A unified recipe for deriving (time-uniform) PAC-Bayes bounds","summary":"  We present a unified framework for deriving PAC-Bayesian generalization\nbounds. Unlike most previous literature on this topic, our bounds are\nanytime-valid (i.e., time-uniform), meaning that they hold at all stopping\ntimes, not only for a fixed sample size. Our approach combines four tools in\nthe following order: (a) nonnegative supermartingales or reverse\nsubmartingales, (b) the method of mixtures, (c) the Donsker-Varadhan formula\n(or other convex duality principles), and (d) Ville's inequality. We derive\ntime-uniform generalizations of well-known classical PAC-Bayes bounds, such as\nthose of Seeger, McAllester, Maurer, and Catoni, in addition to many recent\nbounds. We also present several novel bounds and, more importantly, general\ntechniques for constructing them. Despite being anytime-valid, our extensions\nremain as tight as their fixed-time counterparts. Moreover, they enable us to\nrelax traditional assumptions; in particular, we consider nonstationary loss\nfunctions and non-i.i.d. data. In sum, we unify the derivation of past bounds\nand ease the search for future bounds: one may simply check if our\nsupermartingale or submartingale conditions are met and, if so, be guaranteed a\n(time-uniform) PAC-Bayes bound.\n","authors":["Ben Chugg","Hongjian Wang","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2302.03421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03407v1","updated":"2023-02-07T11:29:05Z","published":"2023-02-07T11:29:05Z","title":"Averaged Method of Multipliers for Bi-Level Optimization without\n  Lower-Level Strong Convexity","summary":"  Gradient methods have become mainstream techniques for Bi-Level Optimization\n(BLO) in learning fields. The validity of existing works heavily rely on either\na restrictive Lower- Level Strong Convexity (LLSC) condition or on solving a\nseries of approximation subproblems with high accuracy or both. In this work,\nby averaging the upper and lower level objectives, we propose a single loop\nBi-level Averaged Method of Multipliers (sl-BAMM) for BLO that is simple yet\nefficient for large-scale BLO and gets rid of the limited LLSC restriction. We\nfurther provide non-asymptotic convergence analysis of sl-BAMM towards KKT\nstationary points, and the comparative advantage of our analysis lies in the\nabsence of strong gradient boundedness assumption, which is always required by\nothers. Thus our theory safely captures a wider variety of applications in deep\nlearning, especially where the upper-level objective is quadratic w.r.t. the\nlower-level variable. Experimental results demonstrate the superiority of our\nmethod.\n","authors":["Risheng Liu","Yaohua Liu","Wei Yao","Shangzhi Zeng","Jin Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03407v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2209.13803v2","updated":"2023-02-07T11:14:06Z","published":"2022-09-28T03:14:10Z","title":"FedVeca: Federated Vectorized Averaging on Non-IID Data with Adaptive\n  Bi-directional Global Objective","summary":"  Federated Learning (FL) is a distributed machine learning framework to\nalleviate the data silos, where decentralized clients collaboratively learn a\nglobal model without sharing their private data. However, the clients'\nNon-Independent and Identically Distributed (Non-IID) data negatively affect\nthe trained model, and clients with different numbers of local updates may\ncause significant gaps to the local gradients in each communication round. In\nthis paper, we propose a Federated Vectorized Averaging (FedVeca) method to\naddress the above problem on Non-IID data. Specifically, we set a novel\nobjective for the global model which is related to the local gradients. The\nlocal gradient is defined as a bi-directional vector with step size and\ndirection, where the step size is the number of local updates and the direction\nis divided into positive and negative according to our definition. In FedVeca,\nthe direction is influenced by the step size, thus we average the\nbi-directional vectors to reduce the effect of different step sizes. Then, we\ntheoretically analyze the relationship between the step sizes and the global\nobjective, and obtain upper bounds on the step sizes per communication round.\nBased on the upper bounds, we design an algorithm for the server and the client\nto adaptively adjusts the step sizes that make the objective close to the\noptimum. Finally, we conduct experiments on different datasets, models and\nscenarios by building a prototype system, and the experimental results\ndemonstrate the effectiveness and efficiency of the FedVeca method.\n","authors":["Ping Luo","Jieren Cheng","Zhenhao Liu","N. Xiong","Jie Wu"],"pdf_url":"https://arxiv.org/pdf/2209.13803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03391v1","updated":"2023-02-07T10:52:04Z","published":"2023-02-07T10:52:04Z","title":"Sparse GEMINI for Joint Discriminative Clustering and Feature Selection","summary":"  Feature selection in clustering is a hard task which involves simultaneously\nthe discovery of relevant clusters as well as relevant variables with respect\nto these clusters. While feature selection algorithms are often model-based\nthrough optimised model selection or strong assumptions on $p(\\pmb{x})$, we\nintroduce a discriminative clustering model trying to maximise a geometry-aware\ngeneralisation of the mutual information called GEMINI with a simple $\\ell_1$\npenalty: the Sparse GEMINI. This algorithm avoids the burden of combinatorial\nfeature subset exploration and is easily scalable to high-dimensional data and\nlarge amounts of samples while only designing a clustering model\n$p_\\theta(y|\\pmb{x})$. We demonstrate the performances of Sparse GEMINI on\nsynthetic datasets as well as large-scale datasets. Our results show that\nSparse GEMINI is a competitive algorithm and has the ability to select relevant\nsubsets of variables with respect to the clustering without using relevance\ncriteria or prior hypotheses.\n","authors":["Louis Ohl","Pierre-Alexandre Mattei","Charles Bouveyron","Mickaël Leclercq","Arnaud Droit","Frédéric Precioso"],"pdf_url":"https://arxiv.org/pdf/2302.03391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03390v1","updated":"2023-02-07T10:51:53Z","published":"2023-02-07T10:51:53Z","title":"Learning Discretized Neural Networks under Ricci Flow","summary":"  In this paper, we consider Discretized Neural Networks (DNNs) consisting of\nlow-precision weights and activations, which suffer from either infinite or\nzero gradients caused by the non-differentiable discrete function in the\ntraining process. In this case, most training-based DNNs use the standard\nStraight-Through Estimator (STE) to approximate the gradient w.r.t. discrete\nvalue. However, the standard STE will cause the gradient mismatch problem,\ni.e., the approximated gradient direction may deviate from the steepest descent\ndirection. In other words, the gradient mismatch implies the approximated\ngradient with perturbations. To address this problem, we introduce the duality\ntheory to regard the perturbation of the approximated gradient as the\nperturbation of the metric in Linearly Nearly Euclidean (LNE) manifolds.\nSimultaneously, under the Ricci-DeTurck flow, we prove the dynamical stability\nand convergence of the LNE metric with the $L^2$-norm perturbation, which can\nprovide a theoretical solution for the gradient mismatch problem. In practice,\nwe also present the steepest descent gradient flow for DNNs on LNE manifolds\nfrom the viewpoints of the information geometry and mirror descent. The\nexperimental results on various datasets demonstrate that our method achieves\nbetter and more stable performance for DNNs than other representative\ntraining-based methods.\n","authors":["Jun Chen","Hanwen Chen","Mengmeng Wang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03390v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2111.08410"},{"id":"http://arxiv.org/abs/2302.03380v1","updated":"2023-02-07T10:39:44Z","published":"2023-02-07T10:39:44Z","title":"Phase Transitions in the Detection of Correlated Databases","summary":"  We study the problem of detecting the correlation between two Gaussian\ndatabases $\\mathsf{X}\\in\\mathbb{R}^{n\\times d}$ and $\\mathsf{Y}^{n\\times d}$,\neach composed of $n$ users with $d$ features. This problem is relevant in the\nanalysis of social media, computational biology, etc. We formulate this as a\nhypothesis testing problem: under the null hypothesis, these two databases are\nstatistically independent. Under the alternative, however, there exists an\nunknown permutation $\\sigma$ over the set of $n$ users (or, row permutation),\nsuch that $\\mathsf{X}$ is $\\rho$-correlated with $\\mathsf{Y}^\\sigma$, a\npermuted version of $\\mathsf{Y}$. We determine sharp thresholds at which\noptimal testing exhibits a phase transition, depending on the asymptotic regime\nof $n$ and $d$. Specifically, we prove that if $\\rho^2d\\to0$, as $d\\to\\infty$,\nthen weak detection (performing slightly better than random guessing) is\nstatistically impossible, irrespectively of the value of $n$. This compliments\nthe performance of a simple test that thresholds the sum all entries of\n$\\mathsf{X}^T\\mathsf{Y}$. Furthermore, when $d$ is fixed, we prove that strong\ndetection (vanishing error probability) is impossible for any\n$\\rho<\\rho^\\star$, where $\\rho^\\star$ is an explicit function of $d$, while\nweak detection is again impossible as long as $\\rho^2d\\to0$. These results\nclose significant gaps in current recent related studies.\n","authors":["Dor Elimelech","Wasim Huleihel"],"pdf_url":"https://arxiv.org/pdf/2302.03380v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2302.03379v1","updated":"2023-02-07T10:35:24Z","published":"2023-02-07T10:35:24Z","title":"Data augmentation for machine learning of chemical process flowsheets","summary":"  Artificial intelligence has great potential for accelerating the design and\nengineering of chemical processes. Recently, we have shown that\ntransformer-based language models can learn to auto-complete chemical process\nflowsheets using the SFILES 2.0 string notation. Also, we showed that language\ntranslation models can be used to translate Process Flow Diagrams (PFDs) into\nProcess and Instrumentation Diagrams (P&IDs). However, artificial intelligence\nmethods require big data and flowsheet data is currently limited. To mitigate\nthis challenge of limited data, we propose a new data augmentation methodology\nfor flowsheet data that is represented in the SFILES 2.0 notation. We show that\nthe proposed data augmentation improves the performance of artificial\nintelligence-based process design models. In our case study flowsheet data\naugmentation improved the prediction uncertainty of the flowsheet\nautocompletion model by 14.7%. In the future, our flowsheet data augmentation\ncan be used for other machine learning algorithms on chemical process\nflowsheets that are based on SFILES notation.\n","authors":["Lukas Schulze Balhorn","Edwin Hirtreiter","Lynn Luderer","Artur M. Schweidtmann"],"pdf_url":"https://arxiv.org/pdf/2302.03379v1.pdf","comment":"Submitted to PROCEEDINGS OF THE 33rd European Symposium on Computer\n  Aided Process Engineering (ESCAPE33), June 18-21, 2023, Athens, Greece"},{"id":"http://arxiv.org/abs/2302.03375v1","updated":"2023-02-07T10:31:14Z","published":"2023-02-07T10:31:14Z","title":"Transfer learning for process design with reinforcement learning","summary":"  Process design is a creative task that is currently performed manually by\nengineers. Artificial intelligence provides new potential to facilitate process\ndesign. Specifically, reinforcement learning (RL) has shown some success in\nautomating process design by integrating data-driven models that learn to build\nprocess flowsheets with process simulation in an iterative design process.\nHowever, one major challenge in the learning process is that the RL agent\ndemands numerous process simulations in rigorous process simulators, thereby\nrequiring long simulation times and expensive computational power. Therefore,\ntypically short-cut simulation methods are employed to accelerate the learning\nprocess. Short-cut methods can, however, lead to inaccurate results. We thus\npropose to utilize transfer learning for process design with RL in combination\nwith rigorous simulation methods. Transfer learning is an established approach\nfrom machine learning that stores knowledge gained while solving one problem\nand reuses this information on a different target domain. We integrate transfer\nlearning in our RL framework for process design and apply it to an illustrative\ncase study comprising equilibrium reactions, azeotropic separation, and\nrecycles, our method can design economically feasible flowsheets with stable\ninteraction with DWSIM. Our results show that transfer learning enables RL to\neconomically design feasible flowsheets with DWSIM, resulting in a flowsheet\nwith an 8% higher revenue. And the learning time can be reduced by a factor of\n2.\n","authors":["Qinghe Gao","Haoyu Yang","Shachi M. Shanbhag","Artur M. Schweidtmann"],"pdf_url":"https://arxiv.org/pdf/2302.03375v1.pdf","comment":"Submitted to PROCEEDINGS OF THE 33rd European Symposium on Computer\n  Aided Process Engineering (ESCAPE33), June 18-21, 2023, Athens, Greece"},{"id":"http://arxiv.org/abs/2302.02343v2","updated":"2023-02-07T10:30:53Z","published":"2023-02-05T09:12:07Z","title":"LExecutor: Learning-Guided Execution","summary":"  Executing code is essential for various program analysis tasks, e.g., to\ndetect bugs that manifest through exceptions or to obtain execution traces for\nfurther dynamic analysis. However, executing an arbitrary piece of code is\noften difficult in practice, e.g., because of missing variable definitions,\nmissing user inputs, and missing third-party dependencies. This paper presents\nLExecutor, a learning-guided approach for executing arbitrary code snippets in\nan underconstrained way. The key idea is to let a neural model predict missing\nvalues that otherwise would cause the program to get stuck, and to inject these\nvalues into the execution. For example, LExecutor injects likely values for\notherwise undefined variables and likely return values of calls to otherwise\nmissing functions. We evaluate the approach on Python code from popular\nopen-source projects and on code snippets extracted from Stack Overflow. The\nneural model predicts realistic values with an accuracy between 80.1% and\n94.2%, allowing LExecutor to closely mimic real executions. As a result, the\napproach successfully executes significantly more code than any available\ntechnique, such as simply executing the code as-is. For example, executing the\nopen-source code snippets as-is covers only 4.1% of all lines, because the code\ncrashes early on, whereas LExecutor achieves a coverage of 50.1%.\n","authors":["Beatriz Souza","Michael Pradel"],"pdf_url":"https://arxiv.org/pdf/2302.02343v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02656v2","updated":"2023-02-07T10:23:53Z","published":"2022-11-03T13:09:08Z","title":"A Fuzzy-set-based Joint Distribution Adaptation Method for Regression\n  and its Application to Online Damage Quantification for Structural Digital\n  Twin","summary":"  Online damage quantification suffers from insufficient labeled data that\nweakens its accuracy. In this context, adopting the domain adaptation on\nhistorical labeled data from similar structures/damages or simulated digital\ntwin data to assist the current diagnosis task would be beneficial. However,\nmost domain adaptation methods are designed for classification and cannot\nefficiently address damage quantification, a regression problem with continuous\nreal-valued labels. This study first proposes a novel domain adaptation method,\nthe Online Fuzzy-set-based Joint Distribution Adaptation for Regression, to\naddress this challenge. By converting the continuous real-valued labels to\nfuzzy class labels via fuzzy sets, the marginal and conditional distribution\ndiscrepancy are simultaneously measured to achieve the domain adaptation for\nthe damage quantification task. Thanks to the superiority of the proposed\nmethod, a state-of-the-art online damage quantification framework based on\ndomain adaptation is presented. Finally, the framework has been comprehensively\ndemonstrated with a damaged helicopter panel, in which three types of damage\ndomain adaptations (across different damage locations, across different damage\ntypes, and from simulation to experiment) are all conducted, proving the\naccuracy of damage quantification can be significantly improved in a realistic\nenvironment. It is expected that the proposed approach to be applied to the\nfleet-level digital twin considering the individual differences.\n","authors":["Xuan Zhou","Claudio Sbarufatti","Marco Giglio","Leiting Dong"],"pdf_url":"https://arxiv.org/pdf/2211.02656v2.pdf","comment":"29 pages, 10 figures"},{"id":"http://arxiv.org/abs/2211.14577v2","updated":"2023-02-07T10:19:52Z","published":"2022-11-26T14:33:34Z","title":"Distribution estimation and change-point estimation for time series via\n  DNN-based GANs","summary":"  The generative adversarial networks (GANs) have recently been applied to\nestimating the distribution of independent and identically distributed data,\nand have attracted a lot of research attention. In this paper, we use the\nblocking technique to demonstrate the effectiveness of GANs for estimating the\ndistribution of stationary time series. Theoretically, we derive a\nnon-asymptotic error bound for the Deep Neural Network (DNN)-based GANs\nestimator for the stationary distribution of the time series. Based on our\ntheoretical analysis, we propose an algorithm for estimating the change point\nin time series distribution. The two main results are verified by two Monte\nCarlo experiments respectively, one is to estimate the joint stationary\ndistribution of $5$-tuple samples of a 20 dimensional AR(3) model, the other is\nabout estimating the change point at the combination of two different\nstationary time series. A real world empirical application to the human\nactivity recognition dataset highlights the potential of the proposed methods.\n","authors":["Jianya Lu","Yingjun Mo","Zhijie Xiao","Lihu Xu","Qiuran Yao"],"pdf_url":"https://arxiv.org/pdf/2211.14577v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03364v1","updated":"2023-02-07T10:16:00Z","published":"2023-02-07T10:16:00Z","title":"Population-size-Aware Policy Optimization for Mean-Field Games","summary":"  In this work, we attempt to bridge the two fields of finite-agent and\ninfinite-agent games, by studying how the optimal policies of agents evolve\nwith the number of agents (population size) in mean-field games, an\nagent-centric perspective in contrast to the existing works focusing typically\non the convergence of the empirical distribution of the population. To this\nend, the premise is to obtain the optimal policies of a set of finite-agent\ngames with different population sizes. However, either deriving the closed-form\nsolution for each game is theoretically intractable, training a distinct policy\nfor each game is computationally intensive, or directly applying the policy\ntrained in a game to other games is sub-optimal. We address these challenges\nthrough the Population-size-Aware Policy Optimization (PAPO). Our contributions\nare three-fold. First, to efficiently generate efficient policies for games\nwith different population sizes, we propose PAPO, which unifies two natural\noptions (augmentation and hypernetwork) and achieves significantly better\nperformance. PAPO consists of three components: i) the population-size encoding\nwhich transforms the original value of population size to an equivalent\nencoding to avoid training collapse, ii) a hypernetwork to generate a distinct\npolicy for each game conditioned on the population size, and iii) the\npopulation size as an additional input to the generated policy. Next, we\nconstruct a multi-task-based training procedure to efficiently train the neural\nnetworks of PAPO by sampling data from multiple games with different population\nsizes. Finally, extensive experiments on multiple environments show the\nsignificant superiority of PAPO over baselines, and the analysis of the\nevolution of the generated policies further deepens our understanding of the\ntwo fields of finite-agent and infinite-agent games.\n","authors":["Pengdeng Li","Xinrun Wang","Shuxin Li","Hau Chan","Bo An"],"pdf_url":"https://arxiv.org/pdf/2302.03364v1.pdf","comment":"Accepted to International Conference on Learning Representations\n  (ICLR 2023)"},{"id":"http://arxiv.org/abs/2302.03362v1","updated":"2023-02-07T10:08:35Z","published":"2023-02-07T10:08:35Z","title":"Machine learning benchmarks for the classification of equivalent circuit\n  models from solid-state electrochemical impedance spectra","summary":"  Analysis of Electrochemical Impedance Spectroscopy (EIS) data for\nelectrochemical systems often consists of defining an Equivalent Circuit Model\n(ECM) using expert knowledge and then optimizing the model parameters to\ndeconvolute various resistance, capacitive, inductive, or diffusion responses.\nFor small data sets, this procedure can be conducted manually; however, it is\nnot feasible to manually define a proper ECM for extensive data sets with a\nwide range of EIS responses. Automatic identification of an ECM would\nsubstantially accelerate the analysis of large sets of EIS data. Here, we\nshowcase machine learning methods developed during the BatteryDEV hackathon to\nclassify the ECMs of 9,300 EIS measurements provided by QuantumScape. The\nbest-performing approach is a gradient-boosted tree model utilizing a library\nto automatically generate features, followed by a random forest model using the\nraw spectral data. A convolutional neural network using boolean images of\nNyquist representations is presented as an alternative, although it achieves a\nlower accuracy. We publish the data and open source the associated code. The\napproaches described in this article can serve as benchmarks for further\nstudies. A key remaining challenge is that the labels contain uncertainty and\nhuman bias, underlined by the performance of the trained models.\n","authors":["Joachim Schaeffer","Paul Gasper","Esteban Garcia-Tamayo","Raymond Gasper","Masaki Adachi","Juan Pablo Gaviria-Cardona","Simon Montoya-Bedoya","Anoushka Bhutani","Andrew Schiek","Rhys Goodall","Rolf Findeisen","Richard D. Braatz","Simon Engelke"],"pdf_url":"https://arxiv.org/pdf/2302.03362v1.pdf","comment":"Manuscript: 16 pages, 8 figures; Supplementary Information: 7 pages,\n  3 figures"},{"id":"http://arxiv.org/abs/2302.03361v1","updated":"2023-02-07T10:06:48Z","published":"2023-02-07T10:06:48Z","title":"A conceptual model for leaving the data-centric approach in machine\n  learning","summary":"  For a long time, machine learning (ML) has been seen as the abstract problem\nof learning relationships from data independent of the surrounding settings.\nThis has recently been challenged, and methods have been proposed to include\nexternal constraints in the machine learning models. These methods usually come\nfrom application-specific fields, such as de-biasing algorithms in the field of\nfairness in ML or physical constraints in the fields of physics and\nengineering. In this paper, we present and discuss a conceptual high-level\nmodel that unifies these approaches in a common language. We hope that this\nwill enable and foster exchange between the different fields and their\ndifferent methods for including external constraints into ML models, and thus\nleaving purely data-centric approaches.\n","authors":["Sebastian Scher","Bernhard Geiger","Simone Kopeinik","Andreas Trügler","Dominik Kowald"],"pdf_url":"https://arxiv.org/pdf/2302.03361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03358v1","updated":"2023-02-07T10:04:52Z","published":"2023-02-07T10:04:52Z","title":"Deep-OSG: A deep learning approach for approximating a family of\n  operators in semigroup to model unknown autonomous systems","summary":"  This paper proposes a novel deep learning approach for approximating\nevolution operators and modeling unknown autonomous dynamical systems using\ntime series data collected at varied time lags. It is a sequel to the previous\nworks [T. Qin, K. Wu, and D. Xiu, J. Comput. Phys., 395:620--635, 2019], [K. Wu\nand D. Xiu, J. Comput. Phys., 408:109307, 2020], and [Z. Chen, V. Churchill, K.\nWu, and D. Xiu, J. Comput. Phys., 449:110782, 2022], which focused on learning\nsingle evolution operator with a fixed time step. This paper aims to learn a\nfamily of evolution operators with variable time steps, which constitute a\nsemigroup for an autonomous system. The semigroup property is very crucial and\nlinks the system's evolutionary behaviors across varying time scales, but it\nwas not considered in the previous works. We propose for the first time a\nframework of embedding the semigroup property into the data-driven learning\nprocess, through a novel neural network architecture and new loss functions.\nThe framework is very feasible, can be combined with any suitable neural\nnetworks, and is applicable to learning general autonomous ODEs and PDEs. We\npresent the rigorous error estimates and variance analysis to understand the\nprediction accuracy and robustness of our approach, showing the remarkable\nadvantages of semigroup awareness in our model. Moreover, our approach allows\none to arbitrarily choose the time steps for prediction and ensures that the\npredicted results are well self-matched and consistent. Extensive numerical\nexperiments demonstrate that embedding the semigroup property notably reduces\nthe data dependency of deep learning models and greatly improves the accuracy,\nrobustness, and stability for long-time prediction.\n","authors":["Junfeng Chen","Kailiang Wu"],"pdf_url":"https://arxiv.org/pdf/2302.03358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03357v1","updated":"2023-02-07T10:02:05Z","published":"2023-02-07T10:02:05Z","title":"Towards Better Time Series Contrastive Learning: A Dynamic Bad Pair\n  Mining Approach","summary":"  Not all positive pairs are beneficial to time series contrastive learning. In\nthis paper, we study two types of bad positive pairs that impair the quality of\ntime series representation learned through contrastive learning ($i.e.$, noisy\npositive pair and faulty positive pair). We show that, with the presence of\nnoisy positive pairs, the model tends to simply learn the pattern of noise\n(Noisy Alignment). Meanwhile, when faulty positive pairs arise, the model\nspends considerable efforts aligning non-representative patterns (Faulty\nAlignment). To address this problem, we propose a Dynamic Bad Pair Mining\n(DBPM) algorithm, which reliably identifies and suppresses bad positive pairs\nin time series contrastive learning. DBPM utilizes a memory module to track the\ntraining behavior of each positive pair along training process. This allows us\nto identify potential bad positive pairs at each epoch based on their\nhistorical training behaviors. The identified bad pairs are then down-weighted\nusing a transformation module. Our experimental results show that DBPM\neffectively mitigates the negative impacts of bad pairs, and can be easily used\nas a plug-in to boost performance of state-of-the-art methods. Codes will be\nmade publicly available.\n","authors":["Xiang Lan","Hanshu Yan","Shenda Hong","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2302.03357v1.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2302.03355v1","updated":"2023-02-07T09:57:54Z","published":"2023-02-07T09:57:54Z","title":"AMFPMC -- An improved method of detecting multiple types of drug-drug\n  interactions using only known drug-drug interactions","summary":"  Adverse drug interactions are largely preventable causes of medical\naccidents, which frequently result in physician and emergency room encounters.\nThe detection of drug interactions in a lab, prior to a drug's use in medical\npractice, is essential, however it is costly and time-consuming. Machine\nlearning techniques can provide an efficient and accurate means of predicting\npossible drug-drug interactions and combat the growing problem of adverse drug\ninteractions. Most existing models for predicting interactions rely on the\nchemical properties of drugs. While such models can be accurate, the required\nproperties are not always available.\n","authors":["Bar Vered","Guy Shtar","Lior Rokach","Bracha Shapira"],"pdf_url":"https://arxiv.org/pdf/2302.03355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03347v1","updated":"2023-02-07T09:41:21Z","published":"2023-02-07T09:41:21Z","title":"An Informative Path Planning Framework for Active Learning in UAV-based\n  Semantic Mapping","summary":"  Unmanned aerial vehicles (UAVs) are crucial for aerial mapping and general\nmonitoring tasks. Recent progress in deep learning enabled automated semantic\nsegmentation of imagery to facilitate the interpretation of large-scale complex\nenvironments. Commonly used supervised deep learning for segmentation relies on\nlarge amounts of pixel-wise labelled data, which is tedious and costly to\nannotate. The domain-specific visual appearance of aerial environments often\nprevents the usage of models pre-trained on a static dataset. To address this,\nwe propose a novel general planning framework for UAVs to autonomously acquire\ninformative training images for model re-training. We leverage multiple\nacquisition functions and fuse them into probabilistic terrain maps. Our\nframework combines the mapped acquisition function information into the UAV's\nplanning objectives. In this way, the UAV adaptively acquires informative\naerial images to be manually labelled for model re-training. Experimental\nresults on real-world data and in a photorealistic simulation show that our\nframework maximises model performance and drastically reduces labelling\nefforts. Our map-based planners outperform state-of-the-art local planning.\n","authors":["Julius Rückin","Federico Magistri","Cyrill Stachniss","Marija Popović"],"pdf_url":"https://arxiv.org/pdf/2302.03347v1.pdf","comment":"15 pages, 20 figures"},{"id":"http://arxiv.org/abs/2302.02667v2","updated":"2023-02-07T09:33:37Z","published":"2023-02-06T10:07:41Z","title":"A Scalable and Efficient Iterative Method for Copying Machine Learning\n  Classifiers","summary":"  Differential replication through copying refers to the process of replicating\nthe decision behavior of a machine learning model using another model that\npossesses enhanced features and attributes. This process is relevant when\nexternal constraints limit the performance of an industrial predictive system.\nUnder such circumstances, copying enables the retention of original prediction\ncapabilities while adapting to new demands. Previous research has focused on\nthe single-pass implementation for copying. This paper introduces a novel\nsequential approach that significantly reduces the amount of computational\nresources needed to train or maintain a copy, leading to reduced maintenance\ncosts for companies using machine learning models in production. The\neffectiveness of the sequential approach is demonstrated through experiments\nwith synthetic and real-world datasets, showing significant reductions in time\nand resources, while maintaining or improving accuracy.\n","authors":["Nahuel Statuto","Irene Unceta","Jordi Nin","Oriol Pujol"],"pdf_url":"https://arxiv.org/pdf/2302.02667v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00979v2","updated":"2023-02-07T09:24:07Z","published":"2022-06-02T10:50:46Z","title":"Graph Kernels Based on Multi-scale Graph Embeddings","summary":"  Graph kernels are conventional methods for computing graph similarities.\nHowever, most of the R-convolution graph kernels face two challenges: 1) They\ncannot compare graphs at multiple different scales, and 2) they do not consider\nthe distributions of substructures when computing the kernel matrix. These two\nchallenges limit their performances. To mitigate the two challenges, we propose\na novel graph kernel called the Multi-scale Path-pattern Graph kernel (MPG), at\nthe heart of which is the multi-scale path-pattern node feature map. Each\nelement of the path-pattern node feature map is the number of occurrences of a\npath-pattern around a node. A path-pattern is constructed by the concatenation\nof all the node labels in a path of a truncated BFS tree rooted at each node.\nSince the path-pattern node feature map can only compare graphs at local\nscales, we incorporate into it the multiple different scales of the graph\nstructure, which are captured by the truncated BFS trees of different depth. We\nuse the Wasserstein distance to compute the similarity between the multi-scale\npath-pattern node feature maps of two graphs, considering the distributions of\npath-patterns. We empirically validate MPG on various benchmark graph datasets\nand demonstrate that it achieves state-of-the-art performance.\n","authors":["Wei Ye","Hao Tian","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2206.00979v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2301.05603v2","updated":"2023-02-07T09:21:44Z","published":"2023-01-13T15:11:38Z","title":"A Comprehensive Survey of Dataset Distillation","summary":"  Deep learning technology has developed unprecedentedly in the last decade and\nhas become the primary choice in many application domains. This progress is\nmainly attributed to a systematic collaboration in which rapidly growing\ncomputing resources encourage advanced algorithms to deal with massive data.\nHowever, it has gradually become challenging to handle the unlimited growth of\ndata with limited computing power. To this end, diverse approaches are proposed\nto improve data processing efficiency. Dataset distillation, a dataset\nreduction method, addresses this problem by synthesizing a small typical\ndataset from substantial data and has attracted much attention from the deep\nlearning community. Existing dataset distillation methods can be taxonomized\ninto meta-learning and data matching frameworks according to whether they\nexplicitly mimic the performance of target data. Although dataset distillation\nhas shown surprising performance in compressing datasets, there are still\nseveral limitations such as distilling high-resolution data. This paper\nprovides a holistic understanding of dataset distillation from multiple\naspects, including distillation frameworks and algorithms, factorized dataset\ndistillation, performance comparison, and applications. Finally, we discuss\nchallenges and promising directions to further promote future studies on\ndataset distillation.\n","authors":["Shiye Lei","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2301.05603v2.pdf","comment":"27 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.03332v1","updated":"2023-02-07T09:14:59Z","published":"2023-02-07T09:14:59Z","title":"Towards a User Privacy-Aware Mobile Gaming App Installation Prediction\n  Model","summary":"  Over the past decade, programmatic advertising has received a great deal of\nattention in the online advertising industry. A real-time bidding (RTB) system\nis rapidly becoming the most popular method to buy and sell online advertising\nimpressions. Within the RTB system, demand-side platforms (DSP) aim to spend\nadvertisers' campaign budgets efficiently while maximizing profit, seeking\nimpressions that result in high user responses, such as clicks or installs. In\nthe current study, we investigate the process of predicting a mobile gaming app\ninstallation from the point of view of a particular DSP, while paying attention\nto user privacy, and exploring the trade-off between privacy preservation and\nmodel performance. There are multiple levels of potential threats to user\nprivacy, depending on the privacy leaks associated with the data-sharing\nprocess, such as data transformation or de-anonymization. To address these\nconcerns, privacy-preserving techniques were proposed, such as cryptographic\napproaches, for training privacy-aware machine-learning models. However, the\nability to train a mobile gaming app installation prediction model without\nusing user-level data, can prevent these threats and protect the users'\nprivacy, even though the model's ability to predict may be impaired.\nAdditionally, current laws might force companies to declare that they are\ncollecting data, and might even give the user the option to opt out of such\ndata collection, which might threaten companies' business models in digital\nadvertising, which are dependent on the collection and use of user-level data.\nWe conclude that privacy-aware models might still preserve significant\ncapabilities, enabling companies to make better decisions, dependent on the\nprivacy-efficacy trade-off utility function of each case.\n","authors":["Ido Zehori","Nevo Itzhak","Yuval Shahar","Mia Dor Schiller"],"pdf_url":"https://arxiv.org/pdf/2302.03332v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.03328v1","updated":"2023-02-07T09:11:17Z","published":"2023-02-07T09:11:17Z","title":"Multi-Task Recommendations with Reinforcement Learning","summary":"  In recent years, Multi-task Learning (MTL) has yielded immense success in\nRecommender System (RS) applications. However, current MTL-based recommendation\nmodels tend to disregard the session-wise patterns of user-item interactions\nbecause they are predominantly constructed based on item-wise datasets.\nMoreover, balancing multiple objectives has always been a challenge in this\nfield, which is typically avoided via linear estimations in existing works. To\naddress these issues, in this paper, we propose a Reinforcement Learning (RL)\nenhanced MTL framework, namely RMTL, to combine the losses of different\nrecommendation tasks using dynamic weights. To be specific, the RMTL structure\ncan address the two aforementioned issues by (i) constructing an MTL\nenvironment from session-wise interactions and (ii) training multi-task\nactor-critic network structure, which is compatible with most existing\nMTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL\nloss function using the weights generated by critic networks. Experiments on\ntwo real-world public datasets demonstrate the effectiveness of RMTL with a\nhigher AUC against state-of-the-art MTL-based recommendation models.\nAdditionally, we evaluate and validate RMTL's compatibility and transferability\nacross various MTL models.\n","authors":["Ziru Liu","Jiejie Tian","Qingpeng Cai","Xiangyu Zhao","Jingtong Gao","Shuchang Liu","Dayou Chen","Tonghao He","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.03328v1.pdf","comment":"TheWebConf2023"},{"id":"http://arxiv.org/abs/2302.02004v2","updated":"2023-02-07T09:05:57Z","published":"2023-02-03T21:19:56Z","title":"Koopman Operator Learning: Sharp Spectral Rates and Spurious Eigenvalues","summary":"  Non-linear dynamical systems can be handily described by the associated\nKoopman operator, whose action evolves every observable of the system forward\nin time. Learning the Koopman operator from data is enabled by a number of\nalgorithms. In this work we present nonasymptotic learning bounds for the\nKoopman eigenvalues and eigenfunctions estimated by two popular algorithms:\nExtended Dynamic Mode Decomposition (EDMD) and Reduced Rank Regression (RRR).\nWe focus on time-reversal-invariant Markov chains, implying that the Koopman\noperator is self-adjoint. This includes important examples of stochastic\ndynamical systems, notably Langevin dynamics. Our spectral learning bounds are\ndriven by the simultaneous control of the operator norm risk of the estimators\nand a metric distortion associated to the corresponding eigenfunctions. Our\nanalysis indicates that both algorithms have similar variance, but EDMD suffers\nfrom a larger bias which might be detrimental to its learning rate. We further\nargue that a large metric distortion may lead to spurious eigenvalues, a\nphenomenon which has been empirically observed, and note that metric distortion\ncan be estimated from data. Numerical experiments complement the theoretical\nfindings.\n","authors":["Vladimir Kostic","Karim Lounici","Pietro Novelli","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2302.02004v2.pdf","comment":"8 pages, 3 figures, 6 appendices"},{"id":"http://arxiv.org/abs/2302.03322v1","updated":"2023-02-07T08:54:37Z","published":"2023-02-07T08:54:37Z","title":"Attacking Cooperative Multi-Agent Reinforcement Learning by Adversarial\n  Minority Influence","summary":"  Cooperative multi-agent reinforcement learning (c-MARL) offers a general\nparadigm for a group of agents to achieve a shared goal by taking individual\ndecisions, yet is found to be vulnerable to adversarial attacks. Though\nharmful, adversarial attacks also play a critical role in evaluating the\nrobustness and finding blind spots of c-MARL algorithms. However, existing\nattacks are not sufficiently strong and practical, which is mainly due to the\nignorance of complex influence between agents and cooperative nature of victims\nin c-MARL.\n  In this paper, we propose adversarial minority influence (AMI), the first\npractical attack against c-MARL by introducing an adversarial agent. AMI\naddresses the aforementioned problems by unilaterally influencing other\ncooperative victims to a targeted worst-case cooperation. Technically, to\nmaximally deviate victim policy under complex agent-wise influence, our\nunilateral attack characterize and maximize the influence from adversary to\nvictims. This is done by adapting a unilateral agent-wise relation metric\nderived from mutual information, which filters out the detrimental influence\nfrom victims to adversary. To fool victims into a jointly worst-case failure,\nour targeted attack influence victims to a long-term, cooperatively worst case\nby distracting each victim to a specific target. Such target is learned by a\nreinforcement learning agent in a trial-and-error process. Extensive\nexperiments in simulation environments, including discrete control (SMAC),\ncontinuous control (MAMujoco) and real-world robot swarm control demonstrate\nthe superiority of our AMI approach. Our codes are available in\nhttps://anonymous.4open.science/r/AMI.\n","authors":["Simin Li","Jun Guo","Jingqiao Xiu","Pu Feng","Xin Yu","Jiakai Wang","Aishan Liu","Wenjun Wu","Xianglong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03319v1","updated":"2023-02-07T08:49:12Z","published":"2023-02-07T08:49:12Z","title":"Leveraging Demonstrations to Improve Online Learning: Quality Matters","summary":"  We investigate the extent to which offline demonstration data can improve\nonline learning. It is natural to expect some improvement, but the question is\nhow, and by how much? We show that the degree of improvement must depend on the\nquality of the demonstration data. To generate portable insights, we focus on\nThompson sampling (TS) applied to a multi-armed bandit as a prototypical online\nlearning algorithm and model. The demonstration data is generated by an expert\nwith a given competence level, a notion we introduce. We propose an informed TS\nalgorithm that utilizes the demonstration data in a coherent way through Bayes'\nrule and derive a prior-dependent Bayesian regret bound. This offers insight\ninto how pretraining can greatly improve online performance and how the degree\nof improvement increases with the expert's competence level. We also develop a\npractical, approximate informed TS algorithm through Bayesian bootstrapping and\nshow substantial empirical regret reduction through experiments.\n","authors":["Botao Hao","Rahul Jain","Tor Lattimore","Benjamin Van Roy","Zheng Wen"],"pdf_url":"https://arxiv.org/pdf/2302.03319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12458v3","updated":"2023-02-07T08:45:35Z","published":"2023-01-29T15:00:43Z","title":"SeeGera: Self-supervised Semi-implicit Graph Variational Auto-encoders\n  with Masking","summary":"  Generative graph self-supervised learning (SSL) aims to learn node\nrepresentations by reconstructing the input graph data. However, most existing\nmethods focus on unsupervised learning tasks only and very few work has shown\nits superiority over the state-of-the-art graph contrastive learning (GCL)\nmodels, especially on the classification task. While a very recent model has\nbeen proposed to bridge the gap, its performance on unsupervised learning tasks\nis still unknown. In this paper, to comprehensively enhance the performance of\ngenerative graph SSL against other GCL models on both unsupervised and\nsupervised learning tasks, we propose the SeeGera model, which is based on the\nfamily of self-supervised variational graph auto-encoder (VGAE). Specifically,\nSeeGera adopts the semi-implicit variational inference framework, a\nhierarchical variational framework, and mainly focuses on feature\nreconstruction and structure/feature masking. On the one hand, SeeGera\nco-embeds both nodes and features in the encoder and reconstructs both links\nand features in the decoder. Since feature embeddings contain rich semantic\ninformation on features, they can be combined with node embeddings to provide\nfine-grained knowledge for feature reconstruction. On the other hand, SeeGera\nadds an additional layer for structure/feature masking to the hierarchical\nvariational framework, which boosts the model generalizability. We conduct\nextensive experiments comparing SeeGera with 9 other state-of-the-art\ncompetitors. Our results show that SeeGera can compare favorably against other\nstate-of-the-art GCL methods in a variety of unsupervised and supervised\nlearning tasks.\n","authors":["Xiang Li","Tiandi Ye","Caihua Shan","Dongsheng Li","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2301.12458v3.pdf","comment":"Accepted by WebConf 2023"},{"id":"http://arxiv.org/abs/2210.03150v3","updated":"2023-02-07T08:37:18Z","published":"2022-10-06T18:23:10Z","title":"Towards Out-of-Distribution Adversarial Robustness","summary":"  Adversarial robustness continues to be a major challenge for deep learning. A\ncore issue is that robustness to one type of attack often fails to transfer to\nother attacks. While prior work establishes a theoretical trade-off in\nrobustness against different $L_p$ norms, we show that there is potential for\nimprovement against many commonly used attacks by adopting a domain\ngeneralisation approach. Concretely, we treat each type of attack as a domain,\nand apply the Risk Extrapolation method (REx), which promotes similar levels of\nrobustness against all training attacks. Compared to existing methods, we\nobtain similar or superior worst-case adversarial robustness on attacks seen\nduring training. Moreover, we achieve superior performance on families or\ntunings of attacks only encountered at test time. On ensembles of attacks, our\napproach improves the accuracy from 3.4% the best existing baseline to 25.9% on\nMNIST, and from 16.9% to 23.5% on CIFAR10.\n","authors":["Adam Ibrahim","Charles Guille-Escuret","Ioannis Mitliagkas","Irina Rish","David Krueger","Pouya Bashivan"],"pdf_url":"https://arxiv.org/pdf/2210.03150v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03314v1","updated":"2023-02-07T08:35:04Z","published":"2023-02-07T08:35:04Z","title":"Federated Variational Inference Methods for Structured Latent Variable\n  Models","summary":"  Federated learning methods, that is, methods that perform model training\nusing data situated across different sources, whilst simultaneously not having\nthe data leave their original source, are of increasing interest in a number of\nfields. However, despite this interest, the classes of models for which\neasily-applicable and sufficiently general approaches are available is limited,\nexcluding many structured probabilistic models. We present a general yet\nelegant resolution to the aforementioned issue. The approach is based on\nadopting structured variational inference, an approach widely used in Bayesian\nmachine learning, to the federated setting. Additionally, a\ncommunication-efficient variant analogous to the canonical FedAvg algorithm is\nexplored. The effectiveness of the proposed algorithms are demonstrated, and\ntheir performance is compared on Bayesian multinomial regression, topic\nmodelling, and mixed model examples.\n","authors":["Conor Hassan","Robert Salomone","Kerrie Mengersen"],"pdf_url":"https://arxiv.org/pdf/2302.03314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02568v2","updated":"2023-02-07T08:12:45Z","published":"2023-02-06T05:11:27Z","title":"Less is More: Understanding Word-level Textual Adversarial Attack via\n  n-gram Frequency Descend","summary":"  Word-level textual adversarial attacks have achieved striking performance in\nfooling natural language processing models. However, the fundamental questions\nof why these attacks are effective, and the intrinsic properties of the\nadversarial examples (AEs), are still not well understood. This work attempts\nto interpret textual attacks through the lens of $n$-gram frequency.\nSpecifically, it is revealed that existing word-level attacks exhibit a strong\ntendency toward generation of examples with $n$-gram frequency descend\n($n$-FD). Intuitively, this finding suggests a natural way to improve model\nrobustness by training the model on the $n$-FD examples. To verify this idea,\nwe devise a model-agnostic and gradient-free AE generation approach that relies\nsolely on the $n$-gram frequency information, and further integrate it into the\nrecently proposed convex hull framework for adversarial training. Surprisingly,\nthe resultant method performs quite similarly to the original gradient-based\nmethod in terms of model robustness. These findings provide a\nhuman-understandable perspective for interpreting word-level textual\nadversarial attacks, and a new direction to improve model robustness.\n","authors":["Ning Lu","Shengcai Liu","Zhirui Zhang","Qi Wang","Haifeng Liu","Ke Tang"],"pdf_url":"https://arxiv.org/pdf/2302.02568v2.pdf","comment":"8 pages, 4 figures. In progress"},{"id":"http://arxiv.org/abs/2205.12904v2","updated":"2023-02-07T08:08:05Z","published":"2022-05-25T16:49:29Z","title":"Analyzing Tree Architectures in Ensembles via Neural Tangent Kernel","summary":"  A soft tree is an actively studied variant of a decision tree that updates\nsplitting rules using the gradient method. Although soft trees can take various\narchitectures, their impact is not theoretically well known. In this paper, we\nformulate and analyze the Neural Tangent Kernel (NTK) induced by soft tree\nensembles for arbitrary tree architectures. This kernel leads to the remarkable\nfinding that only the number of leaves at each depth is relevant for the tree\narchitecture in ensemble learning with an infinite number of trees. In other\nwords, if the number of leaves at each depth is fixed, the training behavior in\nfunction space and the generalization performance are exactly the same across\ndifferent tree architectures, even if they are not isomorphic. We also show\nthat the NTK of asymmetric trees like decision lists does not degenerate when\nthey get infinitely deep. This is in contrast to the perfect binary trees,\nwhose NTK is known to degenerate and leads to worse generalization performance\nfor deeper trees.\n","authors":["Ryuichi Kanoh","Mahito Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2205.12904v2.pdf","comment":"Accepted to ICLR 2023. arXiv admin note: text overlap with\n  arXiv:2109.04983"},{"id":"http://arxiv.org/abs/2302.03306v1","updated":"2023-02-07T07:56:19Z","published":"2023-02-07T07:56:19Z","title":"Mismatched estimation of non-symmetric rank-one matrices corrupted by\n  structured noise","summary":"  We study the performance of a Bayesian statistician who estimates a rank-one\nsignal corrupted by non-symmetric rotationally invariant noise with a generic\ndistribution of singular values. As the signal-to-noise ratio and the noise\nstructure are unknown, a Gaussian setup is incorrectly assumed. We derive the\nexact analytic expression for the error of the mismatched Bayes estimator and\nalso provide the analysis of an approximate message passing (AMP) algorithm.\nThe first result exploits the asymptotic behavior of spherical integrals for\nrectangular matrices and of low-rank matrix perturbations; the second one\nrelies on the design and analysis of an auxiliary AMP. The numerical\nexperiments show that there is a performance gap between the AMP and Bayes\nestimators, which is due to the incorrect estimation of the signal norm.\n","authors":["Teng Fu","YuHao Liu","Jean Barbier","Marco Mondelli","ShanSuo Liang","TianQi Hou"],"pdf_url":"https://arxiv.org/pdf/2302.03306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03916v2","updated":"2023-02-07T07:33:25Z","published":"2022-04-08T08:29:52Z","title":"A Survey of Supernet Optimization and its Applications: Spatial and\n  Temporal Optimization for Neural Architecture Search","summary":"  This survey focuses on categorizing and evaluating the methods of supernet\noptimization in the field of Neural Architecture Search (NAS). Supernet\noptimization involves training a single, over-parameterized network that\nencompasses the search space of all possible network architectures. The survey\nanalyses supernet optimization methods based on their approaches to spatial and\ntemporal optimization. Spatial optimization relates to optimizing the\narchitecture and parameters of the supernet and its subnets, while temporal\noptimization deals with improving the efficiency of selecting architectures\nfrom the supernet. The benefits, limitations, and potential applications of\nthese methods in various tasks and settings, including transferability, domain\ngeneralization, and Transformer models, are also discussed.\n","authors":["Stephen Cha","Taehyeon Kim","Hayeon Lee","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2204.03916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10690v2","updated":"2023-02-07T07:33:25Z","published":"2022-06-21T19:12:06Z","title":"Learning Continuous Rotation Canonicalization with Radial Beam Sampling","summary":"  Nearly all state of the art vision models are sensitive to image rotations.\nExisting methods often compensate for missing inductive biases by using\naugmented training data to learn pseudo-invariances. Alongside the resource\ndemanding data inflation process, predictions often poorly generalize. The\ninductive biases inherent to convolutional neural networks allow for\ntranslation equivariance through kernels acting parallely to the horizontal and\nvertical axes of the pixel grid. This inductive bias, however, does not allow\nfor rotation equivariance. We propose a radial beam sampling strategy along\nwith radial kernels operating on these beams to inherently incorporate\ncenter-rotation covariance. Together with an angle distance loss, we present a\nradial beam-based image canonicalization model, short BIC. Our model allows for\nmaximal continuous angle regression and canonicalizes arbitrary center-rotated\ninput images. As a pre-processing model, this enables rotation-invariant vision\npipelines with model-agnostic rotation-sensitive downstream predictions. We\nshow that our end-to-end trained angle regressor is able to predict continuous\nrotation angles on several vision datasets, i.e. FashionMNIST, CIFAR10,\nCOIL100, and LFW.\n","authors":["Johann Schmidt","Sebastian Stober"],"pdf_url":"https://arxiv.org/pdf/2206.10690v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03302v1","updated":"2023-02-07T07:27:26Z","published":"2023-02-07T07:27:26Z","title":"Towards Meaningful Anomaly Detection: The Effect of Counterfactual\n  Explanations on the Investigation of Anomalies in Multivariate Time Series","summary":"  Detecting rare events is essential in various fields, e.g., in cyber security\nor maintenance. Often, human experts are supported by anomaly detection systems\nas continuously monitoring the data is an error-prone and tedious task.\nHowever, among the anomalies detected may be events that are rare, e.g., a\nplanned shutdown of a machine, but are not the actual event of interest, e.g.,\nbreakdowns of a machine. Therefore, human experts are needed to validate\nwhether the detected anomalies are relevant. We propose to support this anomaly\ninvestigation by providing explanations of anomaly detection. Related work only\nfocuses on the technical implementation of explainable anomaly detection and\nneglects the subsequent human anomaly investigation. To address this research\ngap, we conduct a behavioral experiment using records of taxi rides in New York\nCity as a testbed. Participants are asked to differentiate extreme weather\nevents from other anomalous events such as holidays or sporting events. Our\nresults show that providing counterfactual explanations do improve the\ninvestigation of anomalies, indicating potential for explainable anomaly\ndetection in general.\n","authors":["Max Schemmer","Joshua Holstein","Niklas Bauer","Niklas Kühl","Gerhard Satzger"],"pdf_url":"https://arxiv.org/pdf/2302.03302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02596v2","updated":"2023-02-07T07:14:50Z","published":"2023-02-06T07:07:15Z","title":"Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook\n  for Sparse Neural Network Researchers","summary":"  This article does not propose any novel algorithm or new hardware for\nsparsity. Instead, it aims to serve the \"common good\" for the increasingly\nprosperous Sparse Neural Network (SNN) research community. We attempt to\nsummarize some most common confusions in SNNs, that one may come across in\nvarious scenarios such as paper review/rebuttal and talks - many drawn from the\nauthors' own bittersweet experiences! We feel that doing so is meaningful and\ntimely, since the focus of SNN research is notably shifting from traditional\npruning to more diverse and profound forms of sparsity before, during, and\nafter training. The intricate relationships between their scopes, assumptions,\nand approaches lead to misunderstandings, for non-experts or even experts in\nSNNs. In response, we summarize ten Q\\&As of SNNs from many key aspects,\nincluding dense vs. sparse, unstructured sparse vs. structured sparse, pruning\nvs. sparse training, dense-to-sparse training vs. sparse-to-sparse training,\nstatic sparsity vs. dynamic sparsity, before-training/during-training vs.\npost-training sparsity, and many more. We strive to provide proper and\ngenerically applicable answers to clarify those confusions to the best extent\npossible. We hope our summary provides useful general knowledge for people who\nwant to enter and engage with this exciting community; and also provides some\n\"mind of ease\" convenience for SNN researchers to explain their work in the\nright contexts. At the very least (and perhaps as this article's most\ninsignificant target functionality), if you are writing/planning to write a\npaper or rebuttal in the field of SNNs, we hope some of our answers could help\nyou!\n","authors":["Shiwei Liu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.02596v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.12993v3","updated":"2023-02-07T07:09:04Z","published":"2022-02-25T21:52:09Z","title":"Projective Ranking-based GNN Evasion Attacks","summary":"  Graph neural networks (GNNs) offer promising learning methods for\ngraph-related tasks. However, GNNs are at risk of adversarial attacks. Two\nprimary limitations of the current evasion attack methods are highlighted: (1)\nThe current GradArgmax ignores the \"long-term\" benefit of the perturbation. It\nis faced with zero-gradient and invalid benefit estimates in certain\nsituations. (2) In the reinforcement learning-based attack methods, the learned\nattack strategies might not be transferable when the attack budget changes. To\nthis end, we first formulate the perturbation space and propose an evaluation\nframework and the projective ranking method. We aim to learn a powerful attack\nstrategy then adapt it as little as possible to generate adversarial samples\nunder dynamic budget settings. In our method, based on mutual information, we\nrank and assess the attack benefits of each perturbation for an effective\nattack strategy. By projecting the strategy, our method dramatically minimizes\nthe cost of learning a new attack strategy when the attack budget changes. In\nthe comparative assessment with GradArgmax and RL-S2V, the results show our\nmethod owns high attack performance and effective transferability. The\nvisualization of our method also reveals various attack patterns in the\ngeneration of adversarial samples.\n","authors":["He Zhang","Xingliang Yuan","Chuan Zhou","Shirui Pan"],"pdf_url":"https://arxiv.org/pdf/2202.12993v3.pdf","comment":"Accepted by IEEE Transactions on Knowledge and Data Engineering"},{"id":"http://arxiv.org/abs/2302.03294v1","updated":"2023-02-07T07:06:02Z","published":"2023-02-07T07:06:02Z","title":"Scalable Gaussian process regression enables accurate prediction of\n  protein and small molecule properties with uncertainty quantitation","summary":"  Gaussian process (GP) is a Bayesian model which provides several advantages\nfor regression tasks in machine learning such as reliable quantitation of\nuncertainty and improved interpretability. Their adoption has been precluded by\ntheir excessive computational cost and by the difficulty in adapting them for\nanalyzing sequences (e.g. amino acid and nucleotide sequences) and graphs (e.g.\nones representing small molecules). In this study, we develop efficient and\nscalable approaches for fitting GP models as well as fast convolution kernels\nwhich scale linearly with graph or sequence size. We implement these\nimprovements by building an open-source Python library called xGPR. We compare\nthe performance of xGPR with the reported performance of various deep learning\nmodels on 20 benchmarks, including small molecule, protein sequence and tabular\ndata. We show that xGRP achieves highly competitive performance with much\nshorter training time. Furthermore, we also develop new kernels for sequence\nand graph data and show that xGPR generally outperforms convolutional neural\nnetworks on predicting key properties of proteins and small molecules.\nImportantly, xGPR provides uncertainty information not available from typical\ndeep learning models. Additionally, xGPR provides a representation of the input\ndata that can be used for clustering and data visualization. These results\ndemonstrate that xGPR provides a powerful and generic tool that can be broadly\nuseful in protein engineering and drug discovery.\n","authors":["Jonathan Parkinson","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03284v1","updated":"2023-02-07T06:33:07Z","published":"2023-02-07T06:33:07Z","title":"Unsupervised Deep Learning for IoT Time Series","summary":"  IoT time series analysis has found numerous applications in a wide variety of\nareas, ranging from health informatics to network security. Nevertheless, the\ncomplex spatial temporal dynamics and high dimensionality of IoT time series\nmake the analysis increasingly challenging. In recent years, the powerful\nfeature extraction and representation learning capabilities of deep learning\n(DL) have provided an effective means for IoT time series analysis. However,\nfew existing surveys on time series have systematically discussed unsupervised\nDL-based methods. To fill this void, we investigate unsupervised deep learning\nfor IoT time series, i.e., unsupervised anomaly detection and clustering, under\na unified framework. We also discuss the application scenarios, public\ndatasets, existing challenges, and future research directions in this area.\n","authors":["Ya Liu","Yingjie Zhou","Kai Yang","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03284v1.pdf","comment":"22 pages, 8 figures, has been accepted by IEEE Internet of Things\n  Journal"},{"id":"http://arxiv.org/abs/2212.03597v2","updated":"2023-02-07T06:28:47Z","published":"2022-12-07T12:27:28Z","title":"DeepSpeed Data Efficiency: Improving Deep Learning Model Quality and\n  Training Efficiency via Efficient Data Sampling and Routing","summary":"  Recent advances on deep learning models come at the price of formidable\ntraining cost. The increasing model size is one of the root causes, but another\nless-emphasized fact is that data scale is actually increasing at a similar\nspeed as model scale, and the training cost is proportional to both of them.\nCompared to the rapidly evolving model architecture, how to efficiently use the\ntraining data (especially for the expensive foundation model pretraining) is\nboth less explored and difficult to realize due to the lack of a convenient\nframework that focus on data efficiency capabilities. To this end, we present\nDeepSpeed Data Efficiency, a framework that makes better use of data, increases\ntraining efficiency, and improves model quality. Specifically, we propose and\ncombine two novel data efficiency techniques: efficient data sampling via a\ngeneral curriculum learning library, and efficient data routing via a novel\nrandom layerwise token dropping technique. DeepSpeed Data Efficiency also takes\nextensibility, flexibility and composability into consideration, so that users\ncan easily utilize the framework to compose multiple techniques and apply\ncustomized strategies. By applying our solution to GPT-3 1.3B and BERT-large\nlanguage model pretraining, we can achieve similar model quality with up to 2x\nless data and 2x less time, or achieve better model quality under similar\namount of data and time.\n","authors":["Conglong Li","Zhewei Yao","Xiaoxia Wu","Minjia Zhang","Connor Holmes","Cheng Li","Yuxiong He"],"pdf_url":"https://arxiv.org/pdf/2212.03597v2.pdf","comment":"Equal contribution by the first 3 authors. Code has been released as\n  a part of https://github.com/microsoft/DeepSpeed. Part of this paper is from\n  our previous arxiv report (arXiv:2211.11586)"},{"id":"http://arxiv.org/abs/2302.03282v1","updated":"2023-02-07T06:22:14Z","published":"2023-02-07T06:22:14Z","title":"An End-to-End Two-Phase Deep Learning-Based workflow to Segment Man-made\n  Objects Around Reservoirs","summary":"  Reservoirs are fundamental infrastructures for the management of water\nresources. Constructions around them can negatively impact their quality. Such\nunauthorized constructions can be monitored by land cover mapping (LCM) remote\nsensing (RS) images. In this paper, we develop a new approach based on DL and\nimage processing techniques for man-made object segmentation around the\nreservoirs. In order to segment man-made objects around the reservoirs in an\nend-to-end procedure, segmenting reservoirs and identifying the region of\ninterest (RoI) around them are essential. In the proposed two-phase workflow,\nthe reservoir is initially segmented using a DL model. A post-processing stage\nis proposed to remove errors such as floating vegetation. Next, the RoI around\nthe reservoir (RoIaR) is identified using the proposed image processing\ntechniques. Finally, the man-made objects in the RoIaR are segmented using a DL\narchitecture. We trained the proposed workflow using collected Google Earth\n(GE) images of eight reservoirs in Brazil over two different years. The\nU-Net-based and SegNet-based architectures are trained to segment the\nreservoirs. To segment man-made objects in the RoIaR, we trained and evaluated\nfour possible architectures, U-Net, FPN, LinkNet, and PSPNet. Although the\ncollected data has a high diversity (for example, they belong to different\nstates, seasons, resolutions, etc.), we achieved good performances in both\nphases. Furthermore, applying the proposed post-processing to the output of\nreservoir segmentation improves the precision in all studied reservoirs except\ntwo cases. We validated the prepared workflow with a reservoir dataset outside\nthe training reservoirs. The results show high generalization ability of the\nprepared workflow.\n","authors":["Nayereh Hamidishad","Roberto Marcondes Cesar Junior"],"pdf_url":"https://arxiv.org/pdf/2302.03282v1.pdf","comment":"21 pages, 13 figures"},{"id":"http://arxiv.org/abs/2302.03281v1","updated":"2023-02-07T06:14:48Z","published":"2023-02-07T06:14:48Z","title":"Utility-based Perturbed Gradient Descent: An Optimizer for Continual\n  Learning","summary":"  Modern representation learning methods may fail to adapt quickly under\nnon-stationarity since they suffer from the problem of catastrophic forgetting\nand decaying plasticity. Such problems prevent learners from fast adaptation to\nchanges since they result in increasing numbers of saturated features and\nforgetting useful features when presented with new experiences. Hence, these\nmethods are rendered ineffective for continual learning. This paper proposes\nUtility-based Perturbed Gradient Descent (UPGD), an online\nrepresentation-learning algorithm well-suited for continual learning agents\nwith no knowledge about task boundaries. UPGD protects useful weights or\nfeatures from forgetting and perturbs less useful ones based on their\nutilities. Our empirical results show that UPGD alleviates catastrophic\nforgetting and decaying plasticity, enabling modern representation learning\nmethods to work in the continual learning setting.\n","authors":["Mohamed Elsayed","A. Rupam Mahmood"],"pdf_url":"https://arxiv.org/pdf/2302.03281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01735v2","updated":"2023-02-07T06:05:05Z","published":"2023-02-03T13:50:25Z","title":"Rethinking Semi-Supervised Medical Image Segmentation: A\n  Variance-Reduction Perspective","summary":"  For medical image segmentation, contrastive learning is the dominant practice\nto improve the quality of visual representations by contrasting semantically\nsimilar and dissimilar pairs of samples. This is enabled by the observation\nthat without accessing ground truth label, negative examples with truly\ndissimilar anatomical features, if sampled, can significantly improve the\nperformance. In reality, however, these samples may come from similar\nanatomical features and the models may struggle to distinguish the minority\ntail-class samples, making the tail classes more prone to misclassification,\nboth of which typically lead to model collapse. In this paper, we propose ARCO,\na semi-supervised contrastive learning (CL) framework with stratified group\nsampling theory in medical image segmentation. In particular, we first propose\nbuilding ARCO through the concept of variance-reduced estimation, and show that\ncertain variance-reduction techniques are particularly beneficial in medical\nimage segmentation tasks with extremely limited labels. Furthermore, we\ntheoretically prove these sampling techniques are universal in variance\nreduction. Finally, we experimentally validate our approaches on three\nbenchmark datasets with different label settings, and our methods consistently\noutperform state-of-the-art semi- and fully-supervised methods. Additionally,\nwe augment the CL frameworks with these sampling techniques and demonstrate\nsignificant gains over previous methods. We believe our work is an important\nstep towards semi-supervised medical image segmentation by quantifying the\nlimitation of current self-supervision objectives for accomplishing medical\nimage analysis tasks.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Fenglin Liu","Xiaoran Zhang","Chen Feng","David A. Clifton","S Kevin Zhou","Lawrence Hamilton Staib","James S Duncan"],"pdf_url":"https://arxiv.org/pdf/2302.01735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03271v1","updated":"2023-02-07T05:56:42Z","published":"2023-02-07T05:56:42Z","title":"IB-UQ: Information bottleneck based uncertainty quantification for\n  neural function regression and neural operator learning","summary":"  In this paper, a novel framework is established for uncertainty\nquantification via information bottleneck (IB-UQ) for scientific machine\nlearning tasks, including deep neural network (DNN) regression and neural\noperator learning (DeepONet). Specifically, we first employ the General\nIncompressible-Flow Networks (GIN) model to learn a \"wide\" distribution\nfromnoisy observation data. Then, following the information bottleneck\nobjective, we learn a stochastic map from input to some latent representation\nthat can be used to predict the output. A tractable variational bound on the IB\nobjective is constructed with a normalizing flow reparameterization. Hence, we\ncan optimize the objective using the stochastic gradient descent method. IB-UQ\ncan provide both mean and variance in the label prediction by explicitly\nmodeling the representation variables. Compared to most DNN regression methods\nand the deterministic DeepONet, the proposed model can be trained on noisy data\nand provide accurate predictions with reliable uncertainty estimates on unseen\nnoisy data. We demonstrate the capability of the proposed IB-UQ framework via\nseveral representative examples, including discontinuous function regression,\nreal-world dataset regression and learning nonlinear operators for\ndiffusion-reaction partial differential equation.\n","authors":["Ling Guo","Hao Wu","Wenwen Zhou","Tao Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.03271v1.pdf","comment":"22 pages, 36figures"},{"id":"http://arxiv.org/abs/2302.03266v1","updated":"2023-02-07T05:32:11Z","published":"2023-02-07T05:32:11Z","title":"Learning to Count Isomorphisms with Graph Neural Networks","summary":"  Subgraph isomorphism counting is an important problem on graphs, as many\ngraph-based tasks exploit recurring subgraph patterns. Classical methods\nusually boil down to a backtracking framework that needs to navigate a huge\nsearch space with prohibitive computational costs. Some recent studies resort\nto graph neural networks (GNNs) to learn a low-dimensional representation for\nboth the query and input graphs, in order to predict the number of subgraph\nisomorphisms on the input graph. However, typical GNNs employ a node-centric\nmessage passing scheme that receives and aggregates messages on nodes, which is\ninadequate in complex structure matching for isomorphism counting. Moreover, on\nan input graph, the space of possible query graphs is enormous, and different\nparts of the input graph will be triggered to match different queries. Thus,\nexpecting a fixed representation of the input graph to match diversely\nstructured query graphs is unrealistic. In this paper, we propose a novel GNN\ncalled Count-GNN for subgraph isomorphism counting, to deal with the above\nchallenges. At the edge level, given that an edge is an atomic unit of encoding\ngraph structures, we propose an edge-centric message passing scheme, where\nmessages on edges are propagated and aggregated based on the edge adjacency to\npreserve fine-grained structural information. At the graph level, we modulate\nthe input graph representation conditioned on the query, so that the input\ngraph can be adapted to each query individually to improve their matching.\nFinally, we conduct extensive experiments on a number of benchmark datasets to\ndemonstrate the superior performance of Count-GNN.\n","authors":["Xingtong Yu","Zemin Liu","Yuan Fang","Xinming Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03264v1","updated":"2023-02-07T05:29:38Z","published":"2023-02-07T05:29:38Z","title":"Delving Deep into Simplicity Bias for Long-Tailed Image Recognition","summary":"  Simplicity Bias (SB) is a phenomenon that deep neural networks tend to rely\nfavorably on simpler predictive patterns but ignore some complex features when\napplied to supervised discriminative tasks. In this work, we investigate SB in\nlong-tailed image recognition and find the tail classes suffer more severely\nfrom SB, which harms the generalization performance of such underrepresented\nclasses. We empirically report that self-supervised learning (SSL) can mitigate\nSB and perform in complementary to the supervised counterpart by enriching the\nfeatures extracted from tail samples and consequently taking better advantage\nof such rare samples. However, standard SSL methods are designed without\nexplicitly considering the inherent data distribution in terms of classes and\nmay not be optimal for long-tailed distributed data. To address this\nlimitation, we propose a novel SSL method tailored to imbalanced data. It\nleverages SSL by triple diverse levels, i.e., holistic-, partial-, and\naugmented-level, to enhance the learning of predictive complex patterns, which\nprovides the potential to overcome the severe SB on tail data. Both\nquantitative and qualitative experimental results on five long-tailed benchmark\ndatasets show our method can effectively mitigate SB and significantly\noutperform the competing state-of-the-arts.\n","authors":["Xiu-Shen Wei","Xuhao Sun","Yang Shen","Anqi Xu","Peng Wang","Faen Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.15239v2","updated":"2023-02-07T05:28:36Z","published":"2020-10-28T21:22:34Z","title":"A Cloud-Based Energy Management Strategy for Hybrid Electric City Bus\n  Considering Real-Time Passenger Load Prediction","summary":"  Electric city bus gains popularity in recent years for its low greenhouse gas\nemission, low noise level, etc. Different from a passenger car, the weight of a\ncity bus varies significantly with different amounts of onboard passengers.\nAfter analyzing the importance of battery aging and passenger load effects on\nan optimal energy management strategy, this study introduces the passenger load\nprediction into the hybrid-electric city buses energy management problem, which\nis not well studied in the existing literature. The average model, Decision\nTree, Gradient Boost Decision Tree, and Neural Networks models are compared in\nthe passenger load prediction. The Gradient Boost Decision Tree model is\nselected due to its best accuracy and high stability. Given the predicted\npassenger load, a dynamic programming algorithm determines the optimal power\ndemand for supercapacitor and battery by optimizing the battery aging and\nenergy usage leveraging cloud techniques. Then, rule extraction is conducted on\ndynamic programming results, and the rule is real-time loaded to the vehicle\nonboard controller to handle prediction errors and uncertainties. The proposed\ncloud-based Dynamic Programming and rule extraction framework with the\npassenger load prediction show 4% and 11% lower bus operating costs in off-peak\nand peak hours, respectively. The operating cost by the proposed framework is\nless than 1% of the dynamic programming with the true passenger load\ninformation.\n","authors":["Junzhe Shi","Bin Xu","Xingyu Zhou","Jun Hou"],"pdf_url":"https://arxiv.org/pdf/2010.15239v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12673v3","updated":"2023-02-07T05:27:31Z","published":"2022-07-26T06:26:00Z","title":"A Data Driven Method for Multi-step Prediction of Ship Roll Motion in\n  High Sea States","summary":"  Ship roll motion in high sea states has large amplitudes and nonlinear\ndynamics, and its prediction is significant for operability, safety, and\nsurvivability. This paper presents a novel data-driven methodology to provide a\nmulti-step prediction of ship roll motions in high sea states. A hybrid neural\nnetwork is proposed that combines long short-term memory (LSTM) and\nconvolutional neural network (CNN) in parallel. The motivation is to extract\nthe nonlinear dynamic characteristics and the hydrodynamic memory information\nthrough the advantage of CNN and LSTM, respectively. For the feature selection,\nthe time histories of motion states and wave heights are selected to involve\nsufficient information. Taken a scaled KCS as the study object, the ship\nmotions in sea state 7 irregular long-crested waves are simulated and used for\nthe validation. The results show that at least one period of roll motion can be\naccurately predicted. Compared with the single LSTM and CNN methods, the\nproposed method has better performance in predicting the amplitude of roll\nangles. Besides, the comparison results also demonstrate that selecting motion\nstates and wave heights as feature space improves the prediction accuracy,\nverifying the effectiveness of the proposed method.\n","authors":["Dan Zhang","Xi Zhou","Zi-Hao Wang","Yan Peng","Shao-Rong Xie"],"pdf_url":"https://arxiv.org/pdf/2207.12673v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01169v2","updated":"2023-02-07T05:21:30Z","published":"2022-09-29T07:27:59Z","title":"Neural-network solutions to stochastic reaction networks","summary":"  The stochastic reaction network in which chemical species evolve through a\nset of reactions is widely used to model stochastic processes in physics,\nchemistry and biology. To characterize the evolving joint probability\ndistribution in the state space of species counts requires solving a system of\nordinary differential equations, the chemical master equation, where the size\nof the counting state space increases exponentially with the type of species,\nmaking it challenging to investigate the stochastic reaction network. Here, we\npropose a machine-learning approach using the variational autoregressive\nnetwork to solve the chemical master equation. Training the autoregressive\nnetwork employs the policy gradient algorithm in the reinforcement learning\nframework, which does not require any data simulated in prior by another\nmethod. Different from simulating single trajectories, the approach tracks the\ntime evolution of the joint probability distribution, and supports direct\nsampling of configurations and computing their normalized joint probabilities.\nWe apply the approach to representative examples in physics and biology, and\ndemonstrate that it accurately generates the probability distribution over\ntime. The variational autoregressive network exhibits a plasticity in\nrepresenting the multimodal distribution, cooperates with the conservation law,\nenables time-dependent reaction rates, and is efficient for high-dimensional\nreaction networks with allowing a flexible upper count limit. The results\nsuggest a general approach to investigate stochastic reaction networks based on\nmodern machine learning.\n","authors":["Ying Tang","Jiayu Weng","Pan Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.01169v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03262v1","updated":"2023-02-07T05:20:20Z","published":"2023-02-07T05:20:20Z","title":"Membership Inference Attacks against Diffusion Models","summary":"  Diffusion models have attracted attention in recent years as innovative\ngenerative models. In this paper, we investigate whether a diffusion model is\nresistant to a membership inference attack, which evaluates the privacy leakage\nof a machine learning model. We primarily discuss the diffusion model from the\nstandpoints of comparison with a generative adversarial network (GAN) as\nconventional models and hyperparameters unique to the diffusion model, i.e.,\ntime steps, sampling steps, and sampling variances. We conduct extensive\nexperiments with DDIM as a diffusion model and DCGAN as a GAN on the CelebA and\nCIFAR-10 datasets in both white-box and black-box settings and then confirm if\nthe diffusion model is comparably resistant to a membership inference attack as\nGAN. Next, we demonstrate that the impact of time steps is significant and\nintermediate steps in a noise schedule are the most vulnerable to the attack.\nWe also found two key insights through further analysis. First, we identify\nthat DDIM is vulnerable to the attack for small sample sizes instead of\nachieving a lower FID. Second, sampling steps in hyperparameters are important\nfor resistance to the attack, whereas the impact of sampling variances is quite\nlimited.\n","authors":["Tomoya Matsumoto","Takayuki Miura","Naoto Yanai"],"pdf_url":"https://arxiv.org/pdf/2302.03262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03258v1","updated":"2023-02-07T05:09:10Z","published":"2023-02-07T05:09:10Z","title":"Climate Intervention Analysis using AI Model Guided by Statistical\n  Physics Principles","summary":"  The availability of training data remains a significant obstacle for the\nimplementation of machine learning in scientific applications. In particular,\nestimating how a system might respond to external forcings or perturbations\nrequires specialized labeled data or targeted simulations, which may be\ncomputationally intensive to generate at scale. In this study, we propose a\nnovel solution to this challenge by utilizing a principle from statistical\nphysics known as the Fluctuation-Dissipation Theorem (FDT) to discover\nknowledge using an AI model that can rapidly produce scenarios for different\nexternal forcings. By leveraging FDT, we are able to extract information\nencoded in a large dataset produced by Earth System Models, which includes 8250\nyears of internal climate fluctuations, to estimate the climate system's\nresponse to forcings. Our model, AiBEDO, is capable of capturing the complex,\nmulti-timescale effects of radiation perturbations on global and regional\nsurface climate, allowing for a substantial acceleration of the exploration of\nthe impacts of spatially-heterogenous climate forcers. To demonstrate the\nutility of AiBEDO, we use the example of a climate intervention technique\ncalled Marine Cloud Brightening, with the ultimate goal of optimizing the\nspatial pattern of cloud brightening to achieve regional climate targets and\nprevent known climate tipping points. While we showcase the effectiveness of\nour approach in the context of climate science, it is generally applicable to\nother scientific disciplines that are limited by the extensive computational\ndemands of domain simulation models. Source code of AiBEDO framework is made\navailable at https://github.com/kramea/kdd_aibedo. A sample dataset is made\navailable at https://doi.org/10.5281/zenodo.7597027. Additional data available\nupon request.\n","authors":["Soo Kyung Kim","Kalai Ramea","Salva Rühling Cachay","Haruki Hirasawa","Subhashis Hazarika","Dipti Hingmire","Peetak Mitra","Philip J. Rasch","Hansi A. Singh"],"pdf_url":"https://arxiv.org/pdf/2302.03258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03255v1","updated":"2023-02-07T04:53:21Z","published":"2023-02-07T04:53:21Z","title":"DivBO: Diversity-aware CASH for Ensemble Learning","summary":"  The Combined Algorithm Selection and Hyperparameters optimization (CASH)\nproblem is one of the fundamental problems in Automated Machine Learning\n(AutoML). Motivated by the success of ensemble learning, recent AutoML systems\nbuild post-hoc ensembles to output the final predictions instead of using the\nbest single learner. However, while most CASH methods focus on searching for a\nsingle learner with the best performance, they neglect the diversity among base\nlearners (i.e., they may suggest similar configurations to previously evaluated\nones), which is also a crucial consideration when building an ensemble. To\ntackle this issue and further enhance the ensemble performance, we propose\nDivBO, a diversity-aware framework to inject explicit search of diversity into\nthe CASH problems. In the framework, we propose to use a diversity surrogate to\npredict the pair-wise diversity of two unseen configurations. Furthermore, we\nintroduce a temporary pool and a weighted acquisition function to guide the\nsearch of both performance and diversity based on Bayesian optimization.\nEmpirical results on 15 public datasets show that DivBO achieves the best\naverage ranks (1.82 and 1.73) on both validation and test errors among 10\ncompared methods, including post-hoc designs in recent AutoML systems and\nstate-of-the-art baselines for ensemble learning on CASH problems.\n","authors":["Yu Shen","Yupeng Lu","Yang Li","Yaofeng Tu","Wentao Zhang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2302.03255v1.pdf","comment":"with appendix, accepted by NeurIPS 2022"},{"id":"http://arxiv.org/abs/2301.02389v2","updated":"2023-02-07T04:52:01Z","published":"2023-01-06T05:51:53Z","title":"Provable Reset-free Reinforcement Learning by No-Regret Reduction","summary":"  Real-world reinforcement learning (RL) is often severely limited since\ntypical RL algorithms heavily rely on the reset mechanism to sample proper\ninitial states. In practice, the reset mechanism is expensive to implement due\nto the need for human intervention or heavily engineered environments. To make\nlearning more practical, we propose a generic no-regret reduction to\nsystematically design reset-free RL algorithms. Our reduction turns reset-free\nRL into a two-player game. We show that achieving sublinear regret in this\ntwo-player game would imply learning a policy that has both sublinear\nperformance regret and sublinear total number of resets in the original RL\nproblem. This means that the agent eventually learns to perform optimally and\navoid resets. By this reduction, we design an instantiation for linear Markov\ndecision processes, which is the first provably correct reset-free RL algorithm\nto our knowledge.\n","authors":["Hoai-An Nguyen","Ching-An Cheng"],"pdf_url":"https://arxiv.org/pdf/2301.02389v2.pdf","comment":"Full version of the paper accepted to AAAI 2023 RL4PROD Workshop.\n  Full version of the paper also submitted to a conference and under review to\n  be published"},{"id":"http://arxiv.org/abs/2302.02551v2","updated":"2023-02-07T04:39:13Z","published":"2023-02-06T03:59:15Z","title":"CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets","summary":"  Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot\nclassification through their ability generate embeddings for each class based\non their (natural language) names. Prior work has focused on improving the\naccuracy of these models through prompt engineering or by incorporating a small\namount of labeled downstream data (via finetuning). However, there has been\nlittle focus on improving the richness of the class names themselves, which can\npose issues when class labels are coarsely-defined and uninformative. We\npropose Classification with Hierarchical Label Sets (or CHiLS), an alternative\nstrategy for zero-shot classification specifically designed for datasets with\nimplicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each\nclass, produce a set of subclasses, using either existing label hierarchies or\nby querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though\nthese subclasses were the labels of interest; (iii) map the predicted subclass\nback to its parent to produce the final prediction. Across numerous datasets\nwith underlying hierarchical structure, CHiLS leads to improved accuracy in\nsituations both with and without ground-truth hierarchical information. CHiLS\nis simple to implement within existing CLIP pipelines and requires no\nadditional training cost. Code is available at:\nhttps://github.com/acmi-lab/CHILS.\n","authors":["Zachary Novack","Saurabh Garg","Julian McAuley","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2302.02551v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.07341v4","updated":"2023-02-07T04:33:49Z","published":"2020-12-14T08:50:23Z","title":"A One-Size-Fits-All Solution to Conservative Bandit Problems","summary":"  In this paper, we study a family of conservative bandit problems (CBPs) with\nsample-path reward constraints, i.e., the learner's reward performance must be\nat least as well as a given baseline at any time. We propose a\nOne-Size-Fits-All solution to CBPs and present its applications to three\nencompassed problems, i.e. conservative multi-armed bandits (CMAB),\nconservative linear bandits (CLB) and conservative contextual combinatorial\nbandits (CCCB). Different from previous works which consider high probability\nconstraints on the expected reward, we focus on a sample-path constraint on the\nactually received reward, and achieve better theoretical guarantees\n($T$-independent additive regrets instead of $T$-dependent) and empirical\nperformance. Furthermore, we extend the results and consider a novel\nconservative mean-variance bandit problem (MV-CBP), which measures the learning\nperformance with both the expected reward and variability. For this extended\nproblem, we provide a novel algorithm with $O(1/T)$ normalized additive regrets\n($T$-independent in the cumulative form) and validate this result through\nempirical evaluation.\n","authors":["Yihan Du","Siwei Wang","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2012.07341v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.13425v4","updated":"2023-02-07T04:19:54Z","published":"2022-12-27T09:33:50Z","title":"GEDI: GEnerative and DIscriminative Training for Self-Supervised\n  Learning","summary":"  Self-supervised learning is a popular and powerful method for utilizing large\namounts of unlabeled data, for which a wide variety of training objectives have\nbeen proposed in the literature. In this study, we perform a Bayesian analysis\nof state-of-the-art self-supervised learning objectives and propose a unified\nformulation based on likelihood learning. Our analysis suggests a simple method\nfor integrating self-supervised learning with generative models, allowing for\nthe joint training of these two seemingly distinct approaches. We refer to this\ncombined framework as GEDI, which stands for GEnerative and DIscriminative\ntraining. Additionally, we demonstrate an instantiation of the GEDI framework\nby integrating an energy-based model with a cluster-based self-supervised\nlearning model. Through experiments on synthetic and real-world data, including\nSVHN, CIFAR10, and CIFAR100, we show that GEDI outperforms existing\nself-supervised learning strategies in terms of clustering performance by a\nwide margin. We also demonstrate that GEDI can be integrated into a\nneural-symbolic framework to address tasks in the small data regime, where it\ncan use logical constraints to further improve clustering and classification\nperformance.\n","authors":["Emanuele Sansone","Robin Manhaeve"],"pdf_url":"https://arxiv.org/pdf/2212.13425v4.pdf","comment":"Fixed typos/cleaned the experimental section"},{"id":"http://arxiv.org/abs/2302.03246v1","updated":"2023-02-07T04:13:48Z","published":"2023-02-07T04:13:48Z","title":"CDANs: Temporal Causal Discovery from Autocorrelated and Non-Stationary\n  Time Series Data","summary":"  This study presents a novel constraint-based causal discovery approach for\nautocorrelated and non-stationary time series data (CDANs). Our proposed method\naddresses several limitations of existing causal discovery methods for\nautocorrelated and non-stationary time series data, such as high\ndimensionality, the inability to identify lagged causal relationships, and the\noverlook of changing modules. Our approach identifies both lagged and\ninstantaneous/contemporaneous causal relationships along with changing modules\nthat vary over time. The method optimizes the conditioning sets in a\nconstraint-based search by considering lagged parents instead of conditioning\non the entire past that addresses high dimensionality. The changing modules are\ndetected by considering both contemporaneous and lagged parents. The approach\nfirst detects the lagged adjacencies, then identifies the changing modules and\ncontemporaneous adjacencies, and finally determines the causal direction. We\nextensively evaluated the proposed method using synthetic datasets and a\nreal-world clinical dataset and compared its performance with several baseline\napproaches. The results demonstrate the effectiveness of the proposed method in\ndetecting causal relationships and changing modules in autocorrelated and\nnon-stationary time series data.\n","authors":["Muhammad Hasan Ferdous","Uzma Hasan","Md Osman Gani"],"pdf_url":"https://arxiv.org/pdf/2302.03246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07983v3","updated":"2023-02-07T04:13:39Z","published":"2022-10-14T17:27:56Z","title":"Improving Transfer Learning with a Dual Image and Video Transformer for\n  Multi-label Movie Trailer Genre Classification","summary":"  In this paper, we study the transferability of ImageNet spatial and Kinetics\nspatio-temporal representations to multi-label Movie Trailer Genre\nClassification (MTGC). In particular, we present an extensive evaluation of the\ntransferability of ConvNet and Transformer models pretrained on ImageNet and\nKinetics to Trailers12k, a new manually-curated movie trailer dataset composed\nof 12,000 videos labeled with 10 different genres and associated metadata. We\nanalyze different aspects that can influence transferability, such as frame\nrate, input video extension, and spatio-temporal modeling. In order to reduce\nthe spatio-temporal structure gap between ImageNet/Kinetics and Trailers12k, we\npropose Dual Image and Video Transformer Architecture (DIViTA), which performs\nshot detection so as to segment the trailer into highly correlated clips,\nproviding a more cohesive input for pretrained backbones and improving\ntransferability (a 1.83% increase for ImageNet and 3.75% for Kinetics). Our\nresults demonstrate that representations learned on either ImageNet or Kinetics\nare comparatively transferable to Trailers12k. Moreover, both datasets provide\ncomplementary information that can be combined to improve classification\nperformance (a 2.91% gain compared to the top single pretraining).\nInterestingly, using lightweight ConvNets as pretrained backbones resulted in\nonly a 3.46% drop in classification performance compared with the top\nTransformer while requiring only 11.82% of its parameters and 0.81% of its\nFLOPS.\n","authors":["Ricardo Montalvo-Lezama","Berenice Montalvo-Lezama","Gibran Fuentes-Pineda"],"pdf_url":"https://arxiv.org/pdf/2210.07983v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01724v2","updated":"2023-02-07T04:12:02Z","published":"2023-02-03T13:25:43Z","title":"Reinforcing User Retention in a Billion Scale Short Video Recommender\n  System","summary":"  Recently, short video platforms have achieved rapid user growth by\nrecommending interesting content to users. The objective of the recommendation\nis to optimize user retention, thereby driving the growth of DAU (Daily Active\nUsers). Retention is a long-term feedback after multiple interactions of users\nand the system, and it is hard to decompose retention reward to each item or a\nlist of items. Thus traditional point-wise and list-wise models are not able to\noptimize retention. In this paper, we choose reinforcement learning methods to\noptimize the retention as they are designed to maximize the long-term\nperformance. We formulate the problem as an infinite-horizon request-based\nMarkov Decision Process, and our objective is to minimize the accumulated time\ninterval of multiple sessions, which is equal to improving the app open\nfrequency and user retention. However, current reinforcement learning\nalgorithms can not be directly applied in this setting due to uncertainty,\nbias, and long delay time incurred by the properties of user retention. We\npropose a novel method, dubbed RLUR, to address the aforementioned challenges.\nBoth offline and live experiments show that RLUR can significantly improve user\nretention. RLUR has been fully launched in Kuaishou app for a long time, and\nachieves consistent performance improvement on user retention and DAU.\n","authors":["Qingpeng Cai","Shuchang Liu","Xueliang Wang","Tianyou Zuo","Wentao Xie","Bin Yang","Dong Zheng","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03244v1","updated":"2023-02-07T04:04:39Z","published":"2023-02-07T04:04:39Z","title":"Quantum Recurrent Neural Networks for Sequential Learning","summary":"  Quantum neural network (QNN) is one of the promising directions where the\nnear-term noisy intermediate-scale quantum (NISQ) devices could find\nadvantageous applications against classical resources. Recurrent neural\nnetworks are the most fundamental networks for sequential learning, but up to\nnow there is still a lack of canonical model of quantum recurrent neural\nnetwork (QRNN), which certainly restricts the research in the field of quantum\ndeep learning. In the present work, we propose a new kind of QRNN which would\nbe a good candidate as the canonical QRNN model, where, the quantum recurrent\nblocks (QRBs) are constructed in the hardware-efficient way, and the QRNN is\nbuilt by stacking the QRBs in a staggered way that can greatly reduce the\nalgorithm's requirement with regard to the coherent time of quantum devices.\nThat is, our QRNN is much more accessible on NISQ devices. Furthermore, the\nperformance of the present QRNN model is verified concretely using three\ndifferent kinds of classical sequential data, i.e., meteorological indicators,\nstock price, and text categorization. The numerical experiments show that our\nQRNN achieves much better performance in prediction (classification) accuracy\nagainst the classical RNN and state-of-the-art QNN models for sequential\nlearning, and can predict the changing details of temporal sequence data. The\npractical circuit structure and superior performance indicate that the present\nQRNN is a promising learning model to find quantum advantageous applications in\nthe near term.\n","authors":["Yanan Li","Zhimin Wang","Rongbing Han","Shangshang Shi","Jiaxin Li","Ruimin Shang","Haiyong Zheng","Guoqiang Zhong","Yongjian Gu"],"pdf_url":"https://arxiv.org/pdf/2302.03244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.00415v2","updated":"2023-02-07T03:58:25Z","published":"2022-05-01T07:51:22Z","title":"Don't Blame the Annotator: Bias Already Starts in the Annotation\n  Instructions","summary":"  In recent years, progress in NLU has been driven by benchmarks. These\nbenchmarks are typically collected by crowdsourcing, where annotators write\nexamples based on annotation instructions crafted by dataset creators. In this\nwork, we hypothesize that annotators pick up on patterns in the crowdsourcing\ninstructions, which bias them to write many similar examples that are then\nover-represented in the collected data. We study this form of bias, termed\ninstruction bias, in 14 recent NLU benchmarks, showing that instruction\nexamples often exhibit concrete patterns, which are propagated by crowdworkers\nto the collected data. This extends previous work (Geva et al., 2019) and\nraises a new concern of whether we are modeling the dataset creator's\ninstructions, rather than the task. Through a series of experiments, we show\nthat, indeed, instruction bias can lead to overestimation of model performance,\nand that models struggle to generalize beyond biases originating in the\ncrowdsourcing instructions. We further analyze the influence of instruction\nbias in terms of pattern frequency and model size, and derive concrete\nrecommendations for creating future NLU benchmarks.\n","authors":["Mihir Parmar","Swaroop Mishra","Mor Geva","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2205.00415v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2209.01207v2","updated":"2023-02-07T03:58:21Z","published":"2022-09-02T17:57:32Z","title":"Co-Imitation: Learning Design and Behaviour by Imitation","summary":"  The co-adaptation of robots has been a long-standing research endeavour with\nthe goal of adapting both body and behaviour of a system for a given task,\ninspired by the natural evolution of animals. Co-adaptation has the potential\nto eliminate costly manual hardware engineering as well as improve the\nperformance of systems. The standard approach to co-adaptation is to use a\nreward function for optimizing behaviour and morphology. However, defining and\nconstructing such reward functions is notoriously difficult and often a\nsignificant engineering effort. This paper introduces a new viewpoint on the\nco-adaptation problem, which we call co-imitation: finding a morphology and a\npolicy that allow an imitator to closely match the behaviour of a demonstrator.\nTo this end we propose a co-imitation methodology for adapting behaviour and\nmorphology by matching state distributions of the demonstrator. Specifically,\nwe focus on the challenging scenario with mismatched state- and action-spaces\nbetween both agents. We find that co-imitation increases behaviour similarity\nacross a variety of tasks and settings, and demonstrate co-imitation by\ntransferring human walking, jogging and kicking skills onto a simulated\nhumanoid.\n","authors":["Chang Rajani","Karol Arndt","David Blanco-Mulero","Kevin Sebastian Luck","Ville Kyrki"],"pdf_url":"https://arxiv.org/pdf/2209.01207v2.pdf","comment":"14 pages, 11 figures, accepted for AAAI-23"},{"id":"http://arxiv.org/abs/2302.03241v1","updated":"2023-02-07T03:57:55Z","published":"2023-02-07T03:57:55Z","title":"Continual Learning of Language Models","summary":"  Language models (LMs) have been instrumental for the rapid advance of natural\nlanguage processing. This paper studies continual learning of LMs, in\nparticular, continual domain-adaptive pre-training (or continual DAP-training).\nExisting research has shown that further pre-training an LM using a domain\ncorpus to adapt the LM to the domain can improve the end-task performance in\nthe domain. This paper proposes a novel method to continually DAP-train an LM\nwith a sequence of unlabeled domain corpora to adapt the LM to these domains to\nimprove their end-task performances. The key novelty of our method is a\nsoft-masking mechanism that directly controls the update to the LM. A novel\nproxy is also proposed to preserve the general knowledge in the original LM.\nAdditionally, it contrasts the representations of the previously learned domain\nknowledge (including the general knowledge in the pre-trained LM) and the\nknowledge from the current full network to achieve knowledge integration. The\nmethod not only overcomes catastrophic forgetting, but also achieves knowledge\ntransfer to improve end-task performances. Empirical evaluation demonstrates\nthe effectiveness of the proposed method.\n","authors":["Zixuan Ke","Yijia Shao","Haowei Lin","Tatsuya Konishi","Gyuhak Kim","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03241v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03238v1","updated":"2023-02-07T03:50:38Z","published":"2023-02-07T03:50:38Z","title":"Decentralized Inexact Proximal Gradient Method With Network-Independent\n  Stepsizes for Convex Composite Optimization","summary":"  This paper considers decentralized convex composite optimization over\nundirected and connected networks, where the local loss function contains both\nsmooth and nonsmooth terms. For this problem, a novel CTA\n(Combine-Then-Adapt)-based decentralized algorithm is proposed under\nuncoordinated network-independent constant stepsizes. Particularly, the\nproposed algorithm only needs to approximately solve a sequence of proximal\nmappings, which benefits the decentralized composite optimization where the\nproximal mappings of the nonsmooth loss functions may not have analytic\nsolutions. For the general convex case, we prove the O(1/k) convergence rate of\nthe proposed algorithm, which can be improved to o(1/k) if the proximal\nmappings are solved exactly. Moreover, with metric subregularity, we establish\nthe linear convergence rate. Finally, the numerical experiments demonstrate the\nefficiency of the algorithm.\n","authors":["Luyao Guo","Xinli Shi","Jinde Cao","Zihao Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02150v2","updated":"2023-02-07T03:50:25Z","published":"2023-02-04T11:49:38Z","title":"This Intestine Does Not Exist: Multiscale Residual Variational\n  Autoencoder for Realistic Wireless Capsule Endoscopy Image Generation","summary":"  Medical image synthesis has emerged as a promising solution to address the\nlimited availability of annotated medical data needed for training machine\nlearning algorithms in the context of image-based Clinical Decision Support\n(CDS) systems. To this end, Generative Adversarial Networks (GANs) have been\nmainly applied to support the algorithm training process by generating\nsynthetic images for data augmentation. However, in the field of Wireless\nCapsule Endoscopy (WCE), the limited content diversity and size of existing\npublicly available annotated datasets, adversely affect both the training\nstability and synthesis performance of GANs. Aiming to a viable solution for\nWCE image synthesis, a novel Variational Autoencoder architecture is proposed,\nnamely \"This Intestine Does not Exist\" (TIDE). The proposed architecture\ncomprises multiscale feature extraction convolutional blocks and residual\nconnections, which enable the generation of high-quality and diverse datasets\neven with a limited number of training images. Contrary to the current\napproaches, which are oriented towards the augmentation of the available\ndatasets, this study demonstrates that using TIDE, real WCE datasets can be\nfully substituted by artificially generated ones, without compromising\nclassification performance. Furthermore, qualitative and user evaluation\nstudies by experienced WCE specialists, validate from a medical viewpoint that\nboth the normal and abnormal WCE images synthesized by TIDE are sufficiently\nrealistic.\n","authors":["Dimitrios E. Diamantis","Panagiota Gatoula","Anastasios Koulaouzidis","Dimitris K. Iakovidis"],"pdf_url":"https://arxiv.org/pdf/2302.02150v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2302.03236v1","updated":"2023-02-07T03:42:57Z","published":"2023-02-07T03:42:57Z","title":"Exact Inference in High-order Structured Prediction","summary":"  In this paper, we study the problem of inference in high-order structured\nprediction tasks. In the context of Markov random fields, the goal of a\nhigh-order inference task is to maximize a score function on the space of\nlabels, and the score function can be decomposed into sum of unary and\nhigh-order potentials. We apply a generative model approach to study the\nproblem of high-order inference, and provide a two-stage convex optimization\nalgorithm for exact label recovery. We also provide a new class of hypergraph\nstructural properties related to hyperedge expansion that drives the success in\ngeneral high-order inference problems. Finally, we connect the performance of\nour algorithm and the hyperedge expansion property using a novel hypergraph\nCheeger-type inequality.\n","authors":["Chuyang Ke","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2302.03236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03232v1","updated":"2023-02-07T03:28:56Z","published":"2023-02-07T03:28:56Z","title":"Linear optimal partial transport embedding","summary":"  Optimal transport (OT) has gained popularity due to its various applications\nin fields such as machine learning, statistics, and signal processing. However,\nthe balanced mass requirement limits its performance in practical problems. To\naddress these limitations, variants of the OT problem, including unbalanced OT,\nOptimal partial transport (OPT), and Hellinger Kantorovich (HK), have been\nproposed. In this paper, we propose the Linear optimal partial transport (LOPT)\nembedding, which extends the (local) linearization technique on OT and HK to\nthe OPT problem. The proposed embedding allows for faster computation of OPT\ndistance between pairs of positive measures. Besides our theoretical\ncontributions, we demonstrate the LOPT embedding technique in point-cloud\ninterpolation and PCA analysis.\n","authors":["Yikun Bai","Ivan Medri","Rocio Diaz Martin","Rana Muhammad Shahroz Khan","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2302.03232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.12868v2","updated":"2023-02-07T03:24:44Z","published":"2021-04-22T05:12:49Z","title":"Fuzzy Expert Systems for Prediction of ICU Admission in Patients with\n  COVID-19","summary":"  The pandemic COVID-19 disease has had a dramatic impact on almost all\ncountries around the world so that many hospitals have been overwhelmed with\nCovid-19 cases. As medical resources are limited, deciding on the proper\nallocation of these resources is a very crucial issue. Besides, uncertainty is\na major factor that can affect decisions, especially in medical fields. To cope\nwith this issue, we use fuzzy logic (FL) as one of the most suitable methods in\nmodeling systems with high uncertainty and complexity. We intend to make use of\nthe advantages of FL in decisions on cases that need to treat in ICU. In this\nstudy, an interval type-2 fuzzy expert system is proposed for prediction of ICU\nadmission in COVID-19 patients. For this prediction task, we also developed an\nadaptive neuro-fuzzy inference system (ANFIS). Finally, the results of these\nfuzzy systems are compared to some well-known classification methods such as\nNaive Bayes (NB), Case-Based Reasoning (CBR), Decision Tree (DT), and K Nearest\nNeighbor (KNN). The results show that the type-2 fuzzy expert system and ANFIS\nmodels perform competitively in terms of accuracy and F-measure compared to the\nother system modeling techniques.\n","authors":["Ali Akbar Sadat Asl","Mohammad Mahdi Ershadi","Shahabeddin Sotudian","Xingyu Li","Scott Dick"],"pdf_url":"https://arxiv.org/pdf/2104.12868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03228v1","updated":"2023-02-07T03:21:55Z","published":"2023-02-07T03:21:55Z","title":"Heterophily-Aware Graph Attention Network","summary":"  Graph Neural Networks (GNNs) have shown remarkable success in graph\nrepresentation learning. Unfortunately, current weight assignment schemes in\nstandard GNNs, such as the calculation based on node degrees or pair-wise\nrepresentations, can hardly be effective in processing the networks with\nheterophily, in which the connected nodes usually possess different labels or\nfeatures. Existing heterophilic GNNs tend to ignore the modeling of heterophily\nof each edge, which is also a vital part in tackling the heterophily problem.\nIn this paper, we firstly propose a heterophily-aware attention scheme and\nreveal the benefits of modeling the edge heterophily, i.e., if a GNN assigns\ndifferent weights to edges according to different heterophilic types, it can\nlearn effective local attention patterns, which enable nodes to acquire\nappropriate information from distinct neighbors. Then, we propose a novel\nHeterophily-Aware Graph Attention Network (HA-GAT) by fully exploring and\nutilizing the local distribution as the underlying heterophily, to handle the\nnetworks with different homophily ratios. To demonstrate the effectiveness of\nthe proposed HA-GAT, we analyze the proposed heterophily-aware attention scheme\nand local distribution exploration, by seeking for an interpretation from their\nmechanism. Extensive results demonstrate that our HA-GAT achieves\nstate-of-the-art performances on eight datasets with different homophily ratios\nin both the supervised and semi-supervised node classification tasks.\n","authors":["Junfu Wang","Yuanfang Guo","Liang Yang","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03227v1","updated":"2023-02-07T03:21:33Z","published":"2023-02-07T03:21:33Z","title":"Automatic Sleep Stage Classification with Cross-modal Self-supervised\n  Features from Deep Brain Signals","summary":"  The detection of human sleep stages is widely used in the diagnosis and\nintervention of neurological and psychiatric diseases. Some patients with deep\nbrain stimulator implanted could have their neural activities recorded from the\ndeep brain. Sleep stage classification based on deep brain recording has great\npotential to provide more precise treatment for patients. The accuracy and\ngeneralizability of existing sleep stage classifiers based on local field\npotentials are still limited. We proposed an applicable cross-modal transfer\nlearning method for sleep stage classification with implanted devices. This\nend-to-end deep learning model contained cross-modal self-supervised feature\nrepresentation, self-attention, and classification framework. We tested the\nmodel with deep brain recording data from 12 patients with Parkinson's disease.\nThe best total accuracy reached 83.2% for sleep stage classification. Results\nshowed speech self-supervised features catch the conversion pattern of sleep\nstages effectively. We provide a new method on transfer learning from acoustic\nsignals to local field potentials. This method supports an effective solution\nfor the insufficient scale of clinical data. This sleep stage classification\nmodel could be adapted to chronic and continuous monitor sleep for Parkinson's\npatients in daily life, and potentially utilized for more precise treatment in\ndeep brain-machine interfaces, such as closed-loop deep brain stimulation.\n","authors":["Chen Gong","Yue Chen","Yanan Sui","Luming Li"],"pdf_url":"https://arxiv.org/pdf/2302.03227v1.pdf","comment":"4 pages, 5 figures, 11th International IEEE EMBS Conference on Neural\n  Engineering (NER)"},{"id":"http://arxiv.org/abs/2302.03225v1","updated":"2023-02-07T03:15:38Z","published":"2023-02-07T03:15:38Z","title":"Efficient XAI Techniques: A Taxonomic Survey","summary":"  Recently, there has been a growing demand for the deployment of Explainable\nArtificial Intelligence (XAI) algorithms in real-world applications. However,\ntraditional XAI methods typically suffer from a high computational complexity\nproblem, which discourages the deployment of real-time systems to meet the\ntime-demanding requirements of real-world scenarios. Although many approaches\nhave been proposed to improve the efficiency of XAI methods, a comprehensive\nunderstanding of the achievements and challenges is still needed. To this end,\nin this paper we provide a review of efficient XAI. Specifically, we categorize\nexisting techniques of XAI acceleration into efficient non-amortized and\nefficient amortized methods. The efficient non-amortized methods focus on\ndata-centric or model-centric acceleration upon each individual instance. In\ncontrast, amortized methods focus on learning a unified distribution of model\nexplanations, following the predictive, generative, or reinforcement\nframeworks, to rapidly derive multiple model explanations. We also analyze the\nlimitations of an efficient XAI pipeline from the perspectives of the training\nphase, the deployment phase, and the use scenarios. Finally, we summarize the\nchallenges of deploying XAI acceleration methods to real-world scenarios,\novercoming the trade-off between faithfulness and efficiency, and the selection\nof different acceleration methods.\n","authors":["Yu-Neng Chuang","Guanchu Wang","Fan Yang","Zirui Liu","Xuanting Cai","Mengnan Du","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2302.03225v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2112.01922v4","updated":"2023-02-07T03:15:32Z","published":"2021-12-03T14:05:52Z","title":"MetaQA: Combining Expert Agents for Multi-Skill Question Answering","summary":"  The recent explosion of question answering (QA) datasets and models has\nincreased the interest in the generalization of models across multiple domains\nand formats by either training on multiple datasets or by combining multiple\nmodels. Despite the promising results of multi-dataset models, some domains or\nQA formats may require specific architectures, and thus the adaptability of\nthese models might be limited. In addition, current approaches for combining\nmodels disregard cues such as question-answer compatibility. In this work, we\npropose to combine expert agents with a novel, flexible, and training-efficient\narchitecture that considers questions, answer predictions, and\nanswer-prediction confidence scores to select the best answer among a list of\nanswer candidates. Through quantitative and qualitative experiments we show\nthat our model i) creates a collaboration between agents that outperforms\nprevious multi-agent and multi-dataset approaches in both in-domain and\nout-of-domain scenarios, ii) is highly data-efficient to train, and iii) can be\nadapted to any QA format. We release our code and a dataset of answer\npredictions from expert agents for 16 QA datasets to foster future developments\nof multi-agent systems on https://github.com/UKPLab/MetaQA.\n","authors":["Haritz Puerto","Gözde Gül Şahin","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2112.01922v4.pdf","comment":"Accepted at EACL 2023"},{"id":"http://arxiv.org/abs/2302.03224v1","updated":"2023-02-07T03:14:00Z","published":"2023-02-07T03:14:00Z","title":"Undersampling and Cumulative Class Re-decision Methods to Improve\n  Detection of Agitation in People with Dementia","summary":"  Agitation is one of the most prevalent symptoms in people with dementia (PwD)\nthat can place themselves and the caregiver's safety at risk. Developing\nobjective agitation detection approaches is important to support health and\nsafety of PwD living in a residential setting. In a previous study, we\ncollected multimodal wearable sensor data from 17 participants for 600 days and\ndeveloped machine learning models for predicting agitation in one-minute\nwindows. However, there are significant limitations in the dataset, such as\nimbalance problem and potential imprecise labels as the occurrence of agitation\nis much rarer in comparison to the normal behaviours. In this paper, we first\nimplement different undersampling methods to eliminate the imbalance problem,\nand come to the conclusion that only 20% of normal behaviour data are adequate\nto train a competitive agitation detection model. Then, we design a weighted\nundersampling method to evaluate the manual labeling mechanism given the\nambiguous time interval (ATI) assumption. After that, the postprocessing method\nof cumulative class re-decision (CCR) is proposed based on the historical\nsequential information and continuity characteristic of agitation, improving\nthe decision-making performance for the potential application of agitation\ndetection system. The results show that a combination of undersampling and CCR\nimproves best F1-score by 26.6% and other metrics to varying degrees with less\ntraining time and data used, and inspires a way to find the potential range of\noptimal threshold reference for clinical purpose.\n","authors":["Zhidong Meng","Andrea Iaboni","Bing Ye","Kristine Newman","Alex Mihailidis","Zhihong Deng","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2302.03224v1.pdf","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.03221v1","updated":"2023-02-07T03:06:29Z","published":"2023-02-07T03:06:29Z","title":"Towards Lightweight Cross-domain Sequential Recommendation via External\n  Attention-enhanced Graph Convolution Network","summary":"  Cross-domain Sequential Recommendation (CSR) is an emerging yet challenging\ntask that depicts the evolution of behavior patterns for overlapped users by\nmodeling their interactions from multiple domains. Existing studies on CSR\nmainly focus on using composite or in-depth structures that achieve significant\nimprovement in accuracy but bring a huge burden to the model training.\nMoreover, to learn the user-specific sequence representations, existing works\nusually adopt the global relevance weighting strategy (e.g., self-attention\nmechanism), which has quadratic computational complexity. In this work, we\nintroduce a lightweight external attention-enhanced GCN-based framework to\nsolve the above challenges, namely LEA-GCN. Specifically, by only keeping the\nneighborhood aggregation component and using the Single-Layer Aggregating\nProtocol (SLAP), our lightweight GCN encoder performs more efficiently to\ncapture the collaborative filtering signals of the items from both domains. To\nfurther alleviate the framework structure and aggregate the user-specific\nsequential pattern, we devise a novel dual-channel External Attention (EA)\ncomponent, which calculates the correlation among all items via a lightweight\nlinear structure. Extensive experiments are conducted on two real-world\ndatasets, demonstrating that LEA-GCN requires a smaller volume and less\ntraining time without affecting the accuracy compared with several\nstate-of-the-art methods.\n","authors":["Jinyu Zhang","Huichuan Duan","Lei Guo","Liancheng Xu","Xinhua Wang"],"pdf_url":"https://arxiv.org/pdf/2302.03221v1.pdf","comment":"16 pages, 4 figures, conference paper, accepted by DASFAA 2023"},{"id":"http://arxiv.org/abs/2301.09732v2","updated":"2023-02-07T02:58:12Z","published":"2023-01-23T21:49:28Z","title":"Backdoor Attacks in Peer-to-Peer Federated Learning","summary":"  We study backdoor attacks in peer-to-peer federated learning systems on\ndifferent graph topologies and datasets. We show that only 5% attacker nodes\nare sufficient to perform a backdoor attack with 42% attack success without\ndecreasing the accuracy on clean data by more than 2%. We also demonstrate that\nthe attack can be amplified by the attacker crashing a small number of nodes.\nWe evaluate defenses proposed in the context of centralized federated learning\nand show they are ineffective in peer-to-peer settings. Finally, we propose a\ndefense that mitigates the attacks by applying different clipping norms to the\nmodel updates received from peers and local model trained by a node.\n","authors":["Gokberk Yar","Cristina Nita-Rotaru","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2301.09732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03213v1","updated":"2023-02-07T02:51:10Z","published":"2023-02-07T02:51:10Z","title":"LUT-NN: Towards Unified Neural Network Inference by Table Lookup","summary":"  DNN inference requires huge effort of system development and resource cost.\nThis drives us to propose LUT-NN, the first trial towards empowering deep\nneural network (DNN) inference by table lookup, to eliminate the diverse\ncomputation kernels as well as save running cost. Based on the feature\nsimilarity of each layer, LUT-NN can learn the typical features, named\ncentroids, of each layer from the training data, precompute them with model\nweights, and save the results in tables. For future input, the results of the\nclosest centroids with the input features can be directly read from the table,\nas the approximation of layer output.\n  We propose the novel centroid learning technique for DNN, which enables\ncentroid learning through backpropagation, and adapts three levels of\napproximation to minimize the model loss. By this technique, LUT-NN achieves\ncomparable accuracy (<5% difference) with original models on real complex\ndataset, including CIFAR, ImageNet, and GLUE. LUT-NN simplifies the computing\noperators to only two: closest centroid search and table lookup. We implement\nthem for Intel and ARM CPUs. The model size is reduced by up to 3.5x for CNN\nmodels and 7x for BERT. Latency-wise, the real speedup of LUT-NN is up to 7x\nfor BERT and 2x for ResNet, much lower than theoretical results because of the\ncurrent unfriendly hardware design for table lookup. We expect firstclass table\nlookup support in the future to unleash the potential of LUT-NN.\n","authors":["Xiaohu Tang","Yang Wang","Ting Cao","Li Lyna Zhang","Qi Chen","Deng Cai","Yunxin Liu","Mao Yang"],"pdf_url":"https://arxiv.org/pdf/2302.03213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02092v2","updated":"2023-02-07T02:41:11Z","published":"2023-02-04T04:52:22Z","title":"Interpolation for Robust Learning: Data Augmentation on Geodesics","summary":"  We propose to study and promote the robustness of a model as per its\nperformance through the interpolation of training data distributions.\nSpecifically, (1) we augment the data by finding the worst-case Wasserstein\nbarycenter on the geodesic connecting subpopulation distributions of different\ncategories. (2) We regularize the model for smoother performance on the\ncontinuous geodesic path connecting subpopulation distributions. (3)\nAdditionally, we provide a theoretical guarantee of robustness improvement and\ninvestigate how the geodesic location and the sample size contribute,\nrespectively. Experimental validations of the proposed strategy on four\ndatasets, including CIFAR-100 and ImageNet, establish the efficacy of our\nmethod, e.g., our method improves the baselines' certifiable robustness on\nCIFAR10 up to $7.7\\%$, with $16.8\\%$ on empirical robustness on CIFAR-100. Our\nwork provides a new perspective of model robustness through the lens of\nWasserstein geodesic-based interpolation with a practical off-the-shelf\nstrategy that can be combined with existing robust training methods.\n","authors":["Jiacheng Zhu","Jielin Qiu","Aritra Guha","Zhuolin Yang","Xuanlong Nguyen","Bo Li","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.02092v2.pdf","comment":"33 pages, 3 figures, 18 tables"},{"id":"http://arxiv.org/abs/2302.03201v1","updated":"2023-02-07T02:22:31Z","published":"2023-02-07T02:22:31Z","title":"Near-Minimax-Optimal Risk-Sensitive Reinforcement Learning with CVaR","summary":"  In this paper, we study risk-sensitive Reinforcement Learning (RL), focusing\non the objective of Conditional Value at Risk (CVaR) with risk tolerance\n$\\tau$. Starting with multi-arm bandits (MABs), we show the minimax CVaR regret\nrate is $\\Omega(\\sqrt{\\tau^{-1}AK})$, where $A$ is the number of actions and\n$K$ is the number of episodes, and that it is achieved by an Upper Confidence\nBound algorithm with a novel Bernstein bonus. For online RL in tabular Markov\nDecision Processes (MDPs), we show a minimax regret lower bound of\n$\\Omega(\\sqrt{\\tau^{-1}SAK})$ (with normalized cumulative rewards), where $S$\nis the number of states, and we propose a novel bonus-driven Value Iteration\nprocedure. We show that our algorithm achieves the optimal regret of\n$\\widetilde O(\\sqrt{\\tau^{-1}SAK})$ under a continuity assumption and in\ngeneral attains a near-optimal regret of $\\widetilde O(\\tau^{-1}\\sqrt{SAK})$,\nwhich is minimax-optimal for constant $\\tau$. This improves on the best\navailable bounds. By discretizing rewards appropriately, our algorithms are\ncomputationally efficient.\n","authors":["Kaiwen Wang","Nathan Kallus","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2302.03201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03193v1","updated":"2023-02-07T01:56:09Z","published":"2023-02-07T01:56:09Z","title":"On the Ideal Number of Groups for Isometric Gradient Propagation","summary":"  Recently, various normalization layers have been proposed to stabilize the\ntraining of deep neural networks. Among them, group normalization is a\ngeneralization of layer normalization and instance normalization by allowing a\ndegree of freedom in the number of groups it uses. However, to determine the\noptimal number of groups, trial-and-error-based hyperparameter tuning is\nrequired, and such experiments are time-consuming. In this study, we discuss a\nreasonable method for setting the number of groups. First, we find that the\nnumber of groups influences the gradient behavior of the group normalization\nlayer. Based on this observation, we derive the ideal number of groups, which\ncalibrates the gradient scale to facilitate gradient descent optimization. Our\nproposed number of groups is theoretically grounded, architecture-aware, and\ncan provide a proper value in a layer-wise manner for all layers. The proposed\nmethod exhibited improved performance over existing methods in numerous neural\nnetwork architectures, tasks, and datasets.\n","authors":["Bum Jun Kim","Hyeyeon Choi","Hyeonah Jang","Sang Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2302.03193v1.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2301.12061v2","updated":"2023-02-07T01:31:57Z","published":"2023-01-28T02:30:15Z","title":"(Private) Kernelized Bandits with Distributed Biased Feedback","summary":"  In this paper, we study kernelized bandits with distributed biased feedback.\nThis problem is motivated by several real-world applications (such as dynamic\npricing, cellular network configuration, and policy making), where users from a\nlarge population contribute to the reward of the action chosen by a central\nentity, but it is difficult to collect feedback from all users. Instead, only\nbiased feedback (due to user heterogeneity) from a subset of users may be\navailable. In addition to such partial biased feedback, we are also faced with\ntwo practical challenges due to communication cost and computation complexity.\nTo tackle these challenges, we carefully design a new \\emph{distributed\nphase-then-batch-based elimination (\\texttt{DPBE})} algorithm, which samples\nusers in phases for collecting feedback to reduce the bias and employs\n\\emph{maximum variance reduction} to select actions in batches within each\nphase. By properly choosing the phase length, the batch size, and the\nconfidence width used for eliminating suboptimal actions, we show that\n\\texttt{DPBE} achieves a sublinear regret of\n$\\tilde{O}(T^{1-\\alpha/2}+\\sqrt{\\gamma_T T})$, where $\\alpha\\in (0,1)$ is the\nuser-sampling parameter one can tune. Moreover, \\texttt{DPBE} can significantly\nreduce both communication cost and computation complexity in distributed\nkernelized bandits, compared to some variants of the state-of-the-art\nalgorithms (originally developed for standard kernelized bandits). Furthermore,\nby incorporating various \\emph{differential privacy} models (including the\ncentral, local, and shuffle models), we generalize \\texttt{DPBE} to provide\nprivacy guarantees for users participating in the distributed learning process.\nFinally, we conduct extensive simulations to validate our theoretical results\nand evaluate the empirical performance.\n","authors":["Fengjiao Li","Xingyu Zhou","Bo Ji"],"pdf_url":"https://arxiv.org/pdf/2301.12061v2.pdf","comment":"This work has been accepted by ACM SIGMETRICS 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.03533v1","updated":"2023-02-07T15:34:14Z","published":"2023-02-07T15:34:14Z","title":"Revisiting Pre-training in Audio-Visual Learning","summary":"  Pre-training technique has gained tremendous success in enhancing model\nperformance on various tasks, but found to perform worse than training from\nscratch in some uni-modal situations. This inspires us to think: are the\npre-trained models always effective in the more complex multi-modal scenario,\nespecially for the heterogeneous modalities such as audio and visual ones? We\nfind that the answer is No. Specifically, we explore the effects of pre-trained\nmodels on two audio-visual learning scenarios: cross-modal initialization and\nmulti-modal joint learning. When cross-modal initialization is applied, the\nphenomena of \"dead channel\" caused by abnormal Batchnorm parameters hinders the\nutilization of model capacity. Thus, we propose Adaptive Batchnorm\nRe-initialization (ABRi) to better exploit the capacity of pre-trained models\nfor target tasks. In multi-modal joint learning, we find a strong pre-trained\nuni-modal encoder would bring negative effects on the encoder of another\nmodality. To alleviate such problem, we introduce a two-stage Fusion Tuning\nstrategy, taking better advantage of the pre-trained knowledge while making the\nuni-modal encoders cooperate with an adaptive masking method. The experiment\nresults show that our methods could further exploit pre-trained models'\npotential and boost performance in audio-visual learning.\n","authors":["Ruoxuan Feng","Wenke Xia","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2302.03533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12109v2","updated":"2023-02-07T09:28:48Z","published":"2022-11-22T09:22:28Z","title":"Video compression dataset and benchmark of learning-based video-quality\n  metrics","summary":"  Video-quality measurement is a critical task in video processing. Nowadays,\nmany implementations of new encoding standards - such as AV1, VVC, and LCEVC -\nuse deep-learning-based decoding algorithms with perceptual metrics that serve\nas optimization objectives. But investigations of the performance of modern\nvideo- and image-quality metrics commonly employ videos compressed using older\nstandards, such as AVC. In this paper, we present a new benchmark for\nvideo-quality metrics that evaluates video compression. It is based on a new\ndataset consisting of about 2,500 streams encoded using different standards,\nincluding AVC, HEVC, AV1, VP9, and VVC. Subjective scores were collected using\ncrowdsourced pairwise comparisons. The list of evaluated metrics includes\nrecent ones based on machine learning and neural networks. The results\ndemonstrate that new no-reference metrics exhibit a high correlation with\nsubjective quality and approach the capability of top full-reference metrics.\n","authors":["Anastasia Antsiferova","Sergey Lavrushkin","Maksim Smirnov","Alexander Gushchin","Dmitriy Vatolin","Dmitriy Kulikov"],"pdf_url":"https://arxiv.org/pdf/2211.12109v2.pdf","comment":"10 pages, 4 figures, 6 tables, 1 supplementary material"},{"id":"http://arxiv.org/abs/2302.03242v1","updated":"2023-02-07T04:03:55Z","published":"2023-02-07T04:03:55Z","title":"Online Misinformation Video Detection: A Survey","summary":"  With information consumption via online video streaming becoming increasingly\npopular, misinformation video poses a new threat to the health of the online\ninformation ecosystem. Though previous studies have made much progress in\ndetecting misinformation in text and image formats, video-based misinformation\nbrings new and unique challenges to automatic detection systems: 1) high\ninformation heterogeneity brought by various modalities, 2) blurred distinction\nbetween misleading video manipulation and ubiquitous artistic video editing,\nand 3) new patterns of misinformation propagation due to the dominant role of\nrecommendation systems on online video platforms. To facilitate research on\nthis challenging task, we conduct this survey to present advances in\nmisinformation video detection research. We first analyze and characterize the\nmisinformation video from three levels including signals, semantics, and\nintents. Based on the characterization, we systematically review existing works\nfor detection from features of various modalities to techniques for clue\nintegration. We also introduce existing resources including representative\ndatasets and widely used tools. Besides summarizing existing studies, we\ndiscuss related areas and outline open issues and future directions to\nencourage and guide more research on misinformation video detection. Our\ncorresponding public repository is available at\nhttps://github.com/ICTMCG/Awesome-Misinfo-Video-Detection.\n","authors":["Yuyan Bu","Qiang Sheng","Juan Cao","Peng Qi","Danding Wang","Jintao Li"],"pdf_url":"https://arxiv.org/pdf/2302.03242v1.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2209.07126v2","updated":"2023-02-07T02:34:50Z","published":"2022-09-15T08:19:12Z","title":"Forgetting to Remember: A Scalable Incremental Learning Framework for\n  Cross-Task Blind Image Quality Assessment","summary":"  Recent years have witnessed the great success of blind image quality\nassessment (BIQA) in various task-specific scenarios, which present invariable\ndistortion types and evaluation criteria. However, due to the rigid structure\nand learning framework, they cannot apply to the cross-task BIQA scenario,\nwhere the distortion types and evaluation criteria keep changing in practical\napplications. This paper proposes a scalable incremental learning framework\n(SILF) that could sequentially conduct BIQA across multiple evaluation tasks\nwith limited memory capacity. More specifically, we develop a dynamic parameter\nisolation strategy to sequentially update the task-specific parameter subsets,\nwhich are non-overlapped with each other. Each parameter subset is temporarily\nsettled to Remember one evaluation preference toward its corresponding task,\nand the previously settled parameter subsets can be adaptively reused in the\nfollowing BIQA to achieve better performance based on the task relevance. To\nsuppress the unrestrained expansion of memory capacity in sequential tasks\nlearning, we develop a scalable memory unit by gradually and selectively\npruning unimportant neurons from previously settled parameter subsets, which\nenable us to Forget part of previous experiences and free the limited memory\ncapacity for adapting to the emerging new tasks. Extensive experiments on\neleven IQA datasets demonstrate that our proposed method significantly\noutperforms the other state-of-the-art methods in cross-task BIQA. The source\ncode of the proposed method is available at\nhttps://github.com/maruiperfect/SILF.\n","authors":["Rui Ma","Qingbo Wu","King Ngi Ngan","Hongliang Li","Fanman Meng","Linfeng Xu"],"pdf_url":"https://arxiv.org/pdf/2209.07126v2.pdf","comment":null}]}}